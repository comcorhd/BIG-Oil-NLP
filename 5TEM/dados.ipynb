{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/elvis/ACDC-UD')\n",
    "import estrutura_ud\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pre = estrutura_ud.Corpus()\n",
    "corpus_pos = estrutura_ud.Corpus()\n",
    "corpus_pre.load(\"ju_intro/5TEM_ju.conllu\")\n",
    "corpus_pos.load(\"5TEM_golden.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/elvis/Petrolês/processado-utf8’: File exists\n",
      "mkdir: cannot create directory ‘/home/elvis/Petrolês/gambiarra-utf8’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/elvis/Petrolês/processado-utf8\n",
    "!mkdir /home/elvis/Petrolês/gambiarra-utf8\n",
    "for file in os.listdir(\"/home/elvis/Petrolês/TXT_Teses e Monografias\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(f\"/home/elvis/Petrolês/TXT_Teses e Monografias/{file}\", encoding=\"utf-16\") as f:\n",
    "            with open(f\"/home/elvis/Petrolês/processado-utf8/{file}\", 'w', encoding=\"utf-8\") as r:\n",
    "                r.write(f.read())\n",
    "                \n",
    "for file in os.listdir(\"/home/elvis/Petrolês/Corpus Gambiarra\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(f\"/home/elvis/Petrolês/Corpus Gambiarra/{file}\", encoding=\"utf-16\") as f:\n",
    "            with open(f\"/home/elvis/Petrolês/gambiarra-utf8/{file}\", 'w', encoding=\"utf-8\") as r:\n",
    "                r.write(f.read())\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UDPipe model: done.\n",
      "Loading UDPipe model: done.\n"
     ]
    }
   ],
   "source": [
    "!/home/elvis/BIG-Oil-NLP/udpipe/udpipe-1.2.0 --tokenize --tag --parse /home/elvis/BIG-Oil-NLP/udpipe/bosqueud_2.5_workbench.udpipe /home/elvis/Petrolês/processado-utf8/*.txt > /home/elvis/Petrolês/bem_processado.conllu\n",
    "!/home/elvis/BIG-Oil-NLP/udpipe/udpipe-1.2.0 --tokenize --tag --parse /home/elvis/BIG-Oil-NLP/udpipe/bosqueud_2.5_workbench.udpipe /home/elvis/Petrolês/gambiarra-utf8/*.txt > /home/elvis/Petrolês/gambiarra.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar sentenças que não foram modificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "19 frases para 3 pessoas\n",
      "0-20150121-TESEMSC_0-13\n",
      "0-20150121-TESEMSC_0-16\n",
      "10-20150122-MONOGRAFIA_0-1\n",
      "10-20150122-MONOGRAFIA_0-2\n",
      "10-20150122-MONOGRAFIA_0-17\n",
      "10-20150122-MONOGRAFIA_0-23\n",
      "10-20150122-MONOGRAFIA_0-27\n",
      "10-20150122-MONOGRAFIA_0-28\n",
      "10-20150122-MONOGRAFIA_0-29\n",
      "10-20150122-MONOGRAFIA_0-31\n",
      "10-20150122-MONOGRAFIA_0-33\n",
      "10-20150122-MONOGRAFIA_0-39\n",
      "10-20150122-MONOGRAFIA_0-40\n",
      "10-20150122-MONOGRAFIA_0-41\n",
      "10-20150122-MONOGRAFIA_0-48\n",
      "10-20150122-MONOGRAFIA_0-49\n",
      "10-20150122-MONOGRAFIA_0-54\n",
      "10-20150122-MONOGRAFIA_0-55\n",
      "10-20150122-MONOGRAFIA_0-58\n",
      "10-20150122-MONOGRAFIA_0-62\n",
      "10-20150122-MONOGRAFIA_0-63\n",
      "10-20150122-MONOGRAFIA_0-66\n",
      "10-20150122-MONOGRAFIA_0-67\n",
      "10-20150122-MONOGRAFIA_0-69\n",
      "10-20150122-MONOGRAFIA_0-73\n",
      "10-20150122-MONOGRAFIA_0-77\n",
      "10-20150122-MONOGRAFIA_0-79\n",
      "10-20150122-MONOGRAFIA_0-83\n",
      "10-20150122-MONOGRAFIA_0-86\n",
      "10-20150122-MONOGRAFIA_0-88\n",
      "10-20150122-MONOGRAFIA_0-89\n",
      "10-20150122-MONOGRAFIA_0-92\n",
      "10-20150122-MONOGRAFIA_0-93\n",
      "10-20150122-MONOGRAFIA_0-96\n",
      "10-20150122-MONOGRAFIA_0-104\n",
      "10-20150122-MONOGRAFIA_0-109\n",
      "10-20150122-MONOGRAFIA_0-115\n",
      "10-20150122-MONOGRAFIA_0-125\n",
      "10-20150122-MONOGRAFIA_0-130\n",
      "2-20150126-TESEDSC_0-1\n",
      "2-20150126-TESEDSC_0-16\n",
      "2-20150126-TESEDSC_0-17\n",
      "2-20150126-TESEDSC_0-18\n",
      "6-20140908-MONOGRAFIA_0-9\n",
      "6-20140908-MONOGRAFIA_0-15\n",
      "6-20140908-MONOGRAFIA_0-19\n",
      "6-20140908-MONOGRAFIA_0-26\n",
      "6-20140908-MONOGRAFIA_0-30\n",
      "6-20140908-MONOGRAFIA_0-49\n",
      "6-20140908-MONOGRAFIA_0-51\n",
      "6-20140908-MONOGRAFIA_0-52\n",
      "6-20140908-MONOGRAFIA_0-53\n",
      "6-20140908-MONOGRAFIA_0-54\n",
      "6-20140908-MONOGRAFIA_0-56\n",
      "6-20140908-MONOGRAFIA_0-57\n",
      "6-20140908-MONOGRAFIA_0-67\n"
     ]
    }
   ],
   "source": [
    "lista_iguais = []\n",
    "for sentid, sentence in corpus_pre.sentences.items():\n",
    "    if corpus_pre.sentences[sentid].to_str() == corpus_pos.sentences[sentid].to_str():\n",
    "        lista_iguais.append(sentid)\n",
    "        \n",
    "print(len(lista_iguais))\n",
    "print(str(round(len(lista_iguais)/3)) + \" frases para 3 pessoas\")\n",
    "for item in lista_iguais:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuição de DP e POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'acl', 'acl:relcl', 'advcl', 'advmod', 'amod', 'appos', 'appos:parataxis', 'aux', 'aux:pass', 'case', 'cc', 'ccomp', 'conj', 'cop', 'csubj', 'det', 'expl', 'fixed', 'flat:foreign', 'flat:name', 'iobj', 'mark', 'nmod', 'nsubj', 'nsubj:pass', 'nummod', 'obj', 'obl', 'obl:agent', 'parataxis', 'punct', 'root', 'xcomp']\n",
      "['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'acl', 'acl:relcl', 'advcl', 'advmod', 'amod', 'appos', 'appos:parataxis', 'appos:transl', 'aux', 'aux:pass', 'case', 'cc', 'ccomp', 'compound', 'conj', 'cop', 'csubj', 'det', 'expl', 'fixed', 'flat', 'flat:name', 'iobj', 'mark', 'nmod', 'nsubj', 'nsubj:pass', 'nummod', 'obj', 'obl', 'obl:agent', 'parataxis', 'punct', 'root', 'xcomp']\n"
     ]
    }
   ],
   "source": [
    "dic_pos_dp_pre = {}\n",
    "dic_pos_dp_pos = {}\n",
    "for sent, sentence in corpus_pre.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if not '-' in token.id:\n",
    "            dic_pos_dp_pre[token.upos] = 1 if not token.upos in dic_pos_dp_pre else dic_pos_dp_pre[token.upos] + 1\n",
    "            dic_pos_dp_pre[token.deprel] = 1 if not token.deprel in dic_pos_dp_pre else dic_pos_dp_pre[token.deprel] + 1\n",
    "for sent, sentence in corpus_pos.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if not '-' in token.id:\n",
    "            dic_pos_dp_pos[token.upos] = 1 if not token.upos in dic_pos_dp_pos else dic_pos_dp_pos[token.upos] + 1\n",
    "            dic_pos_dp_pos[token.deprel] = 1 if not token.deprel in dic_pos_dp_pos else dic_pos_dp_pos[token.deprel] + 1\n",
    "        \n",
    "print(sorted(dic_pos_dp_pre))\n",
    "print(sorted(dic_pos_dp_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0-20150121-TESEMSC_0\n",
      "* 10-20150122-MONOGRAFIA_0\n",
      "* 2-20150126-TESEDSC_0\n",
      "* 6-20140908-MONOGRAFIA_0\n",
      "\n",
      "|Versão|Sentenças|Tokens|\n",
      "|---|---|---|\n",
      "|jUD|257|7185|\n",
      "|GOLDEN|257|7185|\n",
      "\n",
      "|Anotação|jUD|GOLDEN|\n",
      "|---|---|---|\n",
      "|ADJ|557|571|\n",
      "|ADP|1167|1175|\n",
      "|ADV|205|197|\n",
      "|AUX|134|135|\n",
      "|CCONJ|237|243|\n",
      "|DET|913|905|\n",
      "|NOUN|1742|1754|\n",
      "|NUM|171|172|\n",
      "|PRON|123|131|\n",
      "|PROPN|343|347|\n",
      "|PUNCT|980|983|\n",
      "|SCONJ|68|64|\n",
      "|SYM|18|20|\n",
      "|VERB|526|482|\n",
      "|X|1|6|\n",
      "|acl|103|97|\n",
      "|acl:relcl|56|59|\n",
      "|advcl|96|89|\n",
      "|advmod|188|168|\n",
      "|amod|491|505|\n",
      "|appos|140|117|\n",
      "|appos:parataxis|47|77|\n",
      "|appos:transl|0|4|\n",
      "|aux|18|16|\n",
      "|aux:pass|54|61|\n",
      "|case|1146|1123|\n",
      "|cc|236|262|\n",
      "|ccomp|10|7|\n",
      "|compound|0|23|\n",
      "|conj|384|371|\n",
      "|cop|64|56|\n",
      "|csubj|6|4|\n",
      "|det|906|897|\n",
      "|expl|22|23|\n",
      "|fixed|64|84|\n",
      "|flat|0|3|\n",
      "|flat:foreign|1|0|\n",
      "|flat:name|125|255|\n",
      "|iobj|2|5|\n",
      "|mark|70|68|\n",
      "|nmod|724|709|\n",
      "|nsubj|245|227|\n",
      "|nsubj:pass|50|44|\n",
      "|nummod|54|45|\n",
      "|obj|244|223|\n",
      "|obl|281|270|\n",
      "|obl:agent|35|32|\n",
      "|parataxis|9|15|\n",
      "|punct|981|925|\n",
      "|root|257|257|\n",
      "|xcomp|76|64|\n"
     ]
    }
   ],
   "source": [
    "documentos = []\n",
    "[documentos.append(x.rsplit(\"-\", 1)[0]) for x in corpus_pre.sentences if x.rsplit(\"-\", 1)[0] not in documentos]\n",
    "print(\"\\n\".join([\"* \" + x for x in documentos]))\n",
    "\n",
    "# a contagem de tokens não leva em consideração aqueles que têm \"-\" no seu id (indicação de contração (a contração em si conta, é claro))\n",
    "print(\"\\n|Versão|Sentenças|Tokens|\")\n",
    "print(\"|---|---|---|\")\n",
    "print(\"|jUD|{}|{}|\".format(len(corpus_pre.sentences), len([x for sentence in corpus_pre.sentences.values() for x in sentence.tokens if not '-' in x.id])))\n",
    "print(\"|GOLDEN|{}|{}|\".format(len(corpus_pos.sentences), len([x for sentence in corpus_pos.sentences.values() for x in sentence.tokens if not '-' in x.id])))\n",
    "\n",
    "print(\"\\n|Anotação|jUD|GOLDEN|\")\n",
    "print(\"|---|---|---|\")\n",
    "lista_pos_dp = [x for x in dic_pos_dp_pre]\n",
    "[lista_pos_dp.append(x) for x in dic_pos_dp_pos if not x in lista_pos_dp]\n",
    "for pos_dp in sorted(lista_pos_dp):\n",
    "    print(\"|{}|{}|{}|\".format(pos_dp, dic_pos_dp_pre[pos_dp] if pos_dp in dic_pos_dp_pre else 0, dic_pos_dp_pos[pos_dp] if pos_dp in dic_pos_dp_pos else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
