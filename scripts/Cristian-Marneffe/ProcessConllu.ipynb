{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python lexicais_gramaticais.py --file_path bosque25_wb.conllu --type_filter gramaticais --ncpus 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "#from nltk.util import ngrams\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, freeze_support\n",
    "import argparse\n",
    "import pickle\n",
    "from Restrictions import Restrictions , process_result, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='5Resumos/Wograine/jptdp.conllu'\n",
    "type_filter='lexicais'\n",
    "ncpus=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_X: {'PUNCT', 'SYM', '_', 'CCONJ', 'SCONJ', 'PROPN', 'ADP', 'NOUN', 'NUM', 'ADJ', 'AUX', 'PRON', 'DET', 'ADV', 'VERB'}\n",
      "\n",
      "all_PronType:{'_', 'Art', 'Dem', 'Prs', 'Card', 'Ind', 'Tot', 'Rel'}\n",
      "setA: {'SCONJ', 'CCONJ', 'ADP', 'DET', 'PRON'}\n",
      "setB: {'VERB', '_', 'PROPN', 'NOUN', 'NUM', 'ADJ', 'AUX', 'ADV', 'SYM'}\n",
      "SetPronTypeA: {'Int', 'Rel'}\n",
      "SetPronTypeB: {'_', 'Art', 'Dem', 'Prs', 'Card', 'Ind', 'Tot'}\n"
     ]
    }
   ],
   "source": [
    "restrictions = Restrictions(type_filter)\n",
    "df = preprocessing(file_path)\n",
    "restrictions.calculate_restrictions(df)\n",
    "sent_total = df.index[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['l_ant_1']=df['l'].shift(periods=1)\n",
    "df['l_ant_2']=df['l'].shift(periods=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.l == '_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>x</th>\n",
       "      <th>g</th>\n",
       "      <th>f</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>Voice</th>\n",
       "      <th>Definite</th>\n",
       "      <th>Tense</th>\n",
       "      <th>Number</th>\n",
       "      <th>type</th>\n",
       "      <th>Person</th>\n",
       "      <th>Mood</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Case</th>\n",
       "      <th>Type</th>\n",
       "      <th>l-x</th>\n",
       "      <th>l_ant_1</th>\n",
       "      <th>l_ant_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>o</td>\n",
       "      <td>DET</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "      <td>_</td>\n",
       "      <td>Def</td>\n",
       "      <td>_</td>\n",
       "      <td>Sing</td>\n",
       "      <td>Art</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Fem</td>\n",
       "      <td>_</td>\n",
       "      <td>Art</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tendência</td>\n",
       "      <td>tendência</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>15</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Sing</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Fem</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>tendência</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atual</td>\n",
       "      <td>atual</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>2</td>\n",
       "      <td>amod</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Sing</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Fem</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>atual</td>\n",
       "      <td>tendência</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>6</td>\n",
       "      <td>case</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>de</td>\n",
       "      <td>atual</td>\n",
       "      <td>tendência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grandes</td>\n",
       "      <td>grande</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Plur</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Fem</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>grande</td>\n",
       "      <td>de</td>\n",
       "      <td>atual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             w          l     x   g      f                            sent_id  \\\n",
       "s i                                                                             \n",
       "1 1          A          o   DET   2    det  10-20150122-MONOGRAFIA_0_resumo-1   \n",
       "  2  tendência  tendência  NOUN  15  nsubj  10-20150122-MONOGRAFIA_0_resumo-1   \n",
       "  3      atual      atual   ADJ   2   amod  10-20150122-MONOGRAFIA_0_resumo-1   \n",
       "  4         de         de   ADP   6   case  10-20150122-MONOGRAFIA_0_resumo-1   \n",
       "  5    grandes     grande   ADJ   6   amod  10-20150122-MONOGRAFIA_0_resumo-1   \n",
       "\n",
       "    Voice Definite Tense Number type Person Mood Polarity Gender Case Type  \\\n",
       "s i                                                                          \n",
       "1 1     _      Def     _   Sing  Art      _    _        _    Fem    _  Art   \n",
       "  2     _        _     _   Sing    _      _    _        _    Fem    _    _   \n",
       "  3     _        _     _   Sing    _      _    _        _    Fem    _    _   \n",
       "  4     _        _     _      _    _      _    _        _      _    _    _   \n",
       "  5     _        _     _   Plur    _      _    _        _    Fem    _    _   \n",
       "\n",
       "           l-x    l_ant_1    l_ant_2  \n",
       "s i                                   \n",
       "1 1          o        NaN        NaN  \n",
       "  2  tendência          o        NaN  \n",
       "  3      atual  tendência          o  \n",
       "  4         de      atual  tendência  \n",
       "  5     grande         de      atual  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~(df.l=='_')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  pd.DataFrame([{'l-x': '<end>'}], index=['-1'])])\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  pd.DataFrame([{'l-x': '<end>'}], index=['-1'])])\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  pd.DataFrame([{'l-x': '<end>'}], index=['-1'])])\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  pd.DataFrame([{'l-x': '<end>'}], index=['-1'])])\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  pd.DataFrame([{'l-x': '<end>'}], index=['-1'])])\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  pd.DataFrame([{'l-x': '<end>'}], index=['-1'])])\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  pd.DataFrame([{'l-x': '<end>'}], index=['-1'])])\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:134: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  sent_df = sent_df.ix[1:-1]\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:134: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  sent_df = sent_df.ix[1:-1]\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:134: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  sent_df = sent_df.ix[1:-1]\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:134: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  sent_df = sent_df.ix[1:-1]\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:134: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  sent_df = sent_df.ix[1:-1]\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:134: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  sent_df = sent_df.ix[1:-1]\n",
      "/mnt/c/Users/elvis/BIG-Oil-NLP/scripts/Cristian-Marneffe/Restrictions.py:134: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  sent_df = sent_df.ix[1:-1]\n",
      "100%|██████████| 20/20 [00:00<00:00, 43351.98it/s]\n"
     ]
    }
   ],
   "source": [
    "with Pool(ncpus) as p:\n",
    "    args = [(df, type_filter, restrictions, i) for i in range(1,sent_total+1)]\n",
    "    results = list(tqdm.tqdm(p.map(process_result, args), total=len(args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ii</th>\n",
       "      <th>g</th>\n",
       "      <th>pair_ngram_a</th>\n",
       "      <th>pair_ngram_b</th>\n",
       "      <th>f</th>\n",
       "      <th>sent_id_int</th>\n",
       "      <th>reverse</th>\n",
       "      <th>type_a</th>\n",
       "      <th>type_b</th>\n",
       "      <th>x_a</th>\n",
       "      <th>x_b</th>\n",
       "      <th>x</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>det</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DET</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>tendência</td>\n",
       "      <td>diversificar</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>tendência</td>\n",
       "      <td>atual</td>\n",
       "      <td>amod</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>case</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ADP</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>grande</td>\n",
       "      <td>empresa</td>\n",
       "      <td>amod</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>10-20150122-MONOGRAFIA_0_resumo-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ii   g pair_ngram_a  pair_ngram_b      f  sent_id_int  reverse type_a  \\\n",
       "1  1   2                               det            1    False          \n",
       "2  2  15    tendência  diversificar  nsubj            1    False      _   \n",
       "3  3   2    tendência         atual   amod            1     True      _   \n",
       "4  4   6                              case            1    False          \n",
       "5  5   6       grande       empresa   amod            1    False      _   \n",
       "\n",
       "  type_b   x_a   x_b     x                            sent_id  \n",
       "1                      DET  10-20150122-MONOGRAFIA_0_resumo-1  \n",
       "2      _  NOUN  VERB  NOUN  10-20150122-MONOGRAFIA_0_resumo-1  \n",
       "3      _  NOUN   ADJ   ADJ  10-20150122-MONOGRAFIA_0_resumo-1  \n",
       "4                      ADP  10-20150122-MONOGRAFIA_0_resumo-1  \n",
       "5      _   ADJ  NOUN   ADJ  10-20150122-MONOGRAFIA_0_resumo-1  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair_ngram_freq = df_results.groupby(['ii','g','pair_ngram_a','pair_ngram_b','f','sent_id_int','reverse','type_a','type_b',\n",
    "#                   'x_a','x_b','x','sent_id'])\n",
    "df_results = df_results[~((df_results.pair_ngram_a=='') & (df_results.pair_ngram_b==''))]\n",
    "df_results['condition'] = df_results.apply(lambda row:(row.pair_ngram_a,row.pair_ngram_b,row.reverse),axis=1)\n",
    "pair_ngram_freq = df_results.groupby('condition')\n",
    "#pair_ngram_freq={}\n",
    "#for group_name, df_group in groups:\n",
    "#    pair_ngram_freq[group_name] = df_group[['reverse','sent_id_int','ii','g', 'type_a','type_b', 'sent_id', 'x_a', 'x_b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_pair_ngram_freq ={group_name:df_group for group_name , df_group in  pair_ngram_freq if len(df_group)>1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_pair_ngram_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pair_ngram_freq=defaultdict(list)\n",
    "total_results_lines = len(df_results.index)\n",
    "for ind in df_results.index:\n",
    "    group_ngram_distance = df_results.ix[ind]\n",
    "    i, j, ngram_a, ngram_b, relation , sent_id, reverse, type_a, type_b, x_a, x_b, x, sent_id_str = group_ngram_distance\n",
    "    if ngram_a=='' and ngram_b=='':\n",
    "        continue\n",
    "    pair_ngram_freq[(ngram_a, ngram_b, reverse)].append((relation,sent_id,i,j, type_a, type_b, sent_id_str, x_a, x_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colored_word(row, word1, word2):\n",
    "    #if '-' in row.name :\n",
    "    #    continue\n",
    "    if row.name == word1:\n",
    "        bold = '<font color=\"red\"><b>{}</b></font>'.format(row.w)\n",
    "        return bold #sentence.append(bold)\n",
    "    elif row.name == word2:\n",
    "        bold = '<font color=\"blue\"><b>{}</b></font>'.format(row.w)\n",
    "        return bold #sentence.append(bold)\n",
    "    else:\n",
    "        return row.w #sentence.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "examples = []\n",
    "for ind, (group_name, df_group) in enumerate(relevant_pair_ngram_freq.items()):\n",
    "    if ind%100==0:\n",
    "        print(ind, end=' ')\n",
    "    count_relations = Counter(list(df_group.f.values))\n",
    "    # Caso exista várias relações\n",
    "    if len(count_relations)>1:\n",
    "        sentences=[]\n",
    "        for ind,case_row in df_group.iterrows():\n",
    "            sent_id = case_row.sent_id_int\n",
    "            word1 = case_row.ii\n",
    "            word2 = case_row.g\n",
    "\n",
    "            sentence = list(df.loc[sent_id].apply(lambda row: get_colored_word(row, word1, word2), axis=1).values)       \n",
    "            #sentences.append((sentence , rel, sent_id, type_a, type_b, sent_id_str, x_a, x_b))\n",
    "            sentences.append((sentence , case_row))#rel, sent_id, type_a, type_b, sent_id_str, x_a, x_b))\n",
    "        examples.append((sentences, group_name, count_relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse if nn[2] else \n",
    "if type_filter=='gramaticais':\n",
    "    html_file = 'results/results_gramaticais.html'\n",
    "    reverse = \"<span style='font-size:25px;'>&#8678;</span>\"\n",
    "    no_reverse = \"<span style='font-size:25px;'>&#8680;</span>\"\n",
    "    with open(html_file,'w+',encoding=\"utf-8\") as file:\n",
    "\n",
    "        for i,more_than_sentences in enumerate(examples):\n",
    "            sentences,nn,a = more_than_sentences\n",
    "            blue_text = '<font color=\"blue\"><b>{}</b></font>'\n",
    "            red_text = '<font color=\"red\"><b>{}</b></font>'\n",
    "            file.write('<p><b>Exemplo {}:</b> ( {} , {} ) <b>{}</b> ( {} , {} )</p>'.format(i+1, \n",
    "                                                                    nn[0][0], \n",
    "                                                                    blue_text.format(nn[0][1]) if nn[2] else  red_text.format(nn[0][1]), \n",
    "                                                                    no_reverse,\\\n",
    "                                                                    red_text.format(nn[1][0]) if nn[2] else  blue_text.format(nn[1][0]), \n",
    "                                                                    nn[1][1]))\n",
    "            counter  = \" , \".join(['<b>{}</b> : {}'.format(k,v) for k,v in a.items()])\n",
    "            file.write('<p>[ {} ]</p>'.format(counter))\n",
    "            for more_than_sent in sentences:\n",
    "                #    'ii','g','pair_ngram_a','pair_ngram_b','f','sent_id_int','reverse','type_a','type_b',\n",
    "                #    'x_a','x_b','x','sent_id'\n",
    "                sent, case_row = more_than_sent\n",
    "                #sent , rel, sent_id, type_a, type_b, sent_id_str, x_a, x_b = more_than_sent\n",
    "                sent_id_str  = case_row.sent_id\n",
    "                rel = case_row.f\n",
    "                type_a = case_row.type_a\n",
    "                type_b = case_row.type_b\n",
    "                x_a = case_row.x_a\n",
    "                x_b = case_row.x_b\n",
    "                sentence = \"<p><b>Frase {}</b> \\t: {} - rel: <b>({})</b> ,  type: <b>({} - {})</b> , pos: <b>({} - {})</b> </p>\".format(\n",
    "                    sent_id_str, \" \".join(sent), rel,\n",
    "                    blue_text.format(type_a) if nn[2] else  red_text.format(type_a),\n",
    "                    red_text.format(type_b) if nn[2] else  blue_text.format(type_b),\n",
    "                    blue_text.format(x_a) if nn[2] else  red_text.format(x_a),\n",
    "                    red_text.format(x_b) if nn[2] else  blue_text.format(x_b))\n",
    "        \n",
    "                file.write('{}\\n'.format(sentence))\n",
    "            file.write('<br>')\n",
    "        \n",
    "elif type_filter=='lexicais':\n",
    "    html_file = 'results/results_lexicais.html'\n",
    "    reverse = \"<span style='font-size:25px;'>&#8678;</span>\"\n",
    "    no_reverse = \"<span style='font-size:25px;'>&#8680;</span>\"\n",
    "    with open(html_file,'w+',encoding=\"utf-8\") as file:\n",
    "        i=0\n",
    "        for more_than_sentences in examples:\n",
    "\n",
    "            pair = more_than_sentences[1][:2]\n",
    "            #if pair in all_pairs:\n",
    "            #    continue \n",
    "            i+=1    \n",
    "            sentences,nn,a = more_than_sentences\n",
    "            blue_text = '<font color=\"blue\"><b>{}</b></font>'\n",
    "            red_text = '<font color=\"red\"><b>{}</b></font>'\n",
    "            file.write('<p><b>Exemplo {}:</b> {} <b>{}</b>  {}  </p>'.format(i, \n",
    "                                                                    blue_text.format(nn[0]) if nn[2] else  red_text.format(nn[0]), \n",
    "                                                                    no_reverse,\\\n",
    "                                                                    red_text.format(nn[1]) if nn[2] else  blue_text.format(nn[1])))\n",
    "            counter  = \" , \".join(['<b>{}</b> : {}'.format(k,v) for k,v in a.items()])\n",
    "            file.write('<p>[ {} ]</p>'.format(counter))\n",
    "            for more_than_sent in sentences:\n",
    "                #    'ii','g','pair_ngram_a','pair_ngram_b','f','sent_id_int','reverse','type_a','type_b',\n",
    "                #    'x_a','x_b','x','sent_id'\n",
    "                sent, case_row = more_than_sent\n",
    "                #sent , rel, sent_id, type_a, type_b, sent_id_str, x_a, x_b = more_than_sent\n",
    "                sent_id_str  = case_row.sent_id\n",
    "                rel = case_row.f\n",
    "                type_a = case_row.type_a\n",
    "                type_b = case_row.type_b\n",
    "                x_a = case_row.x_a\n",
    "                x_b = case_row.x_b\n",
    "                sentence = \"<p><b>Frase {}</b> \\t: {} - rel: <b>({})</b> ,  type: <b>({} - {})</b> , pos: <b>({} - {})</b> </p>\".format(\n",
    "                    sent_id_str, \" \".join(sent), rel,\n",
    "                    blue_text.format(type_a) if nn[2] else  red_text.format(type_a),\n",
    "                    red_text.format(type_b) if nn[2] else  blue_text.format(type_b),\n",
    "                    blue_text.format(x_a) if nn[2] else  red_text.format(x_a),\n",
    "                    red_text.format(x_b) if nn[2] else  blue_text.format(x_b))\n",
    "                file.write('{}\\n'.format(sentence))\n",
    "            file.write('<br>')\n",
    "else:\n",
    "    raise Exception('unknown filter type (gramaticais, lexicais): {}'.format(type_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
