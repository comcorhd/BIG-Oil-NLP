
4 GEOQUÍMICA DE SUPERFÍCIE 4.1 INTRODUÇÃO O uso da geoquímica de superfície na exploração de petróleo tem sido amplamente baseado na detecção direta de hidrocarbonetos leves correspondente a observações diretas de exsudações de óleo e gás, denominadas de macroexsudações ou por medidas da reação de produtos de hidrocarbonetos próximos à superfície resultando em microexsudações (KLUSMAN, 2002).
As pequenas quantidades detectadas por análises diretas de hidrocarbonetos leves ocorrem nos espaços dos poros no solo e são adsorvidas nas porções dos grãos finos do solo, ou incorporadas nos grãos deste. As observações de microexsudações próximas da superfície se utilizam de métodos indiretos baseadas em expressões de moderada a longas faixas (SCHUMACHER, 2000). Tais métodos indiretos ocorrem por mudanças induzidas das microexsudações para solo, sedimento e vegetação (SCHUMACHER, 2000).
Desde 1930 os métodos de geoquímica de superfície têm sido usados, mas nas últimas décadas o interesse pela geoquímica de exploração se renovou. Esta renovação aliada ao desenvolvimento de métodos analíticos e de interpretação tem produzido um novo corpo de dados e insight sobre a geoquímica de exploração.
Levantamentos geoquímicos e estudos de pesquisa documentam que microexsudações de hidrocarbonetos originados a partir de acumulações de óleo e gás seguem alguns princípios básicos; como são comuns e muito espalhados, movem-se verticalmente, as acumulações são dinâmicas e os selos imperfeitos.
Indicações em superfície de exsudações de óleo e gás têm sido observadas por milhares de anos e têm liderado a descoberta de importantes áreas produtoras de petróleo. Embora a descoberta de uma anomalia de geoquímica de superfície não assegure a descoberta comercialmente significativa de petróleo, esta anomalia estabelece a presença de hidrocarbonetos na área de interesse. A falta ou ausência de microexsudações não indica necessariamente que a bacia é estéril. As exsudações de hidrocarbonetos em superfície podem representar o final do caminho de migração (SCHUMACHER, 2000). Estas anomalias podem representar concentrações de hidrocarbonetos presentes nos sedimentos e águas, anomalias microbiológicas e 
botânicas, mudanças mineralógicas e alterações elétricas, magnéticas e propriedades sísmicas próximas à superfície, bem como sedimentos deposicionais (MELLO, 1984).
4.2 OBJETIVOS DA GEOQUÍMICA DE SUPERFÍCIE Os principais objetivos de um levantamento de geoquímica de superfície encontrados para a exploração de óleo e gás são (SCHUMACHER, 2000): (1) Reconhecer a presença e a tipologia da distribuição de hidrocarbonetos na área de interesse de desenvolvimento e de exploração; (2) Determinar a provável carga de hidrocarboneto, somente inferido por modelagem, para especificar a exploração e a avaliação dos prospectos na atividade de exploração.
O objetivo de um levantamento geoquímico de superfície é encontrar exsudações e microexsudações que indiquem a evidência direta de hidrocarbonetos termogênicos, que documentam a presença de um sistema petrolífero ativo e identificam as porções da bacia que podem ser mais prospectivas.
4.3 PROSPECÇÃO NA GEOQUÍMICA DE SUPERFÍCIE A prospecção na geoquímica de superfície de uma determinada área a ser identificada, pode ocorrer em bacias terrestres (bacias onshore) ou em bacias marítimas (bacias offshore). Nas bacias onshore, as amostras de gases leves são comumente detectadas em headspace de solos em áreas ambientais. Já nas offshore, as amostras são coletadas por meio de piston core no assoalho marinho (PETERS et al., 2002).
4.3.1 Etapas do levantamento geoquímico de superfície Na seleção de uma área prospectável há certas questões importantes a serem consideradas. Entre elas, se existe uma área fonte rica em matéria orgânica, se a rocha fonte teria atingido uma temperatura suficiente para gerar grandes volumes de hidrocarbonetos (MELLO, 2003), e, por último, conhecer os caminhos de migração dos 
hidrocarbonetos que levem a uma trapa. São as seguintes as etapas básicas de um levantamento geoquímico: 1. Seleção da área a ser estudada Esta etapa corresponde a uma avaliação regional inicial, que compreende estudos geológicos, geofísicos e sensoriamento remotos.
2. Estudos preliminares Neste momento realizam-se avaliações de tendências e prospectos regionais.
3. Seleção do melhor programa geoquímico Nesta etapa devem ser aplicadas técnicas de amostragem de campo, e programas laboratoriais.
4. Programação de amostragem Corresponde à avaliação do programa de amostragem onshore e/ou offshore.
4.3.2 Amostragem geoquímica A amostragem geoquímica compreende algumas fases consideradas importantes para a realização de boas inspeções, tais como o planejamento, a logística e as ferramentas de coleta (MELLO, 2003). Segue-se o detalhamento destas fases.
4.3.2.1 Planejamento A fase de planejamento inclui a discussão da área a ser analisada, a malha de amostragem e a escolha de pontos, bem como os tipos de levantamentos. A discussão da área corresponde a levantar dados, discutir com o cliente sobre a geologia, a geofísica, as estruturas em subsuperfície, a quantidade de amostras, a logística (custos) e definir parâmetros cartográficos da área a ser levantada, tais como: datum, projeção e mc (meridiano central). A determinação da malha de amostragem e a escolha dos pontos é geralmente recomendada para estudos exploratórios, malhas de 500 m, e a distribuição 
de pontos deve ocorrer de forma mais regular possível, com estes pontos direcionados em cima de falhamentos e estruturas mapeadas. Os tipos de levantamentos devem ser em carta topográfica ou sísmica (MELLO, 2003).
4.3.2.2 Logística Durante a fase de logística são realizados os levantamentos das necessidades, como materiais de escritório, de campo e os equipamentos de segurança. Deve ser escolhida uma cidade para servir como área base do levantamento. O controle de custos também é importante por levantar e controlar as despesas com mão de obra, hospedagem, aluguel de carro, combustíveis, alimentação e outras. E, por último, a formação de uma equipe de campo (geólogo, técnico ou operador) e a localização dos pontos do levantamento são também consideradas necessárias para a realização de um bom levantamento geoquímico (MELLO, 2003).
4.3.2.3 Ferramentas de coleta As ferramentas de coleta compreendem tipos de amostragens que podem ser por gases livres (headspace e probe), hidrocarbonetos oclusos (blender) e/ou hidrocarbonetos adsorvidos (adsorvidos). Os gases livres são altamente móveis e encontrados em espaços intersticiais ou poros, enquanto os gases sorvidos (adsorvidos ou absorvidos) apresentam mobilidade restrita (MELLO, 2003).
Alguns tipos de ocorrências e maneiras de amostragem de gás no solo e exsudações na água são descritos a seguir.
• Gases Livres: Headspace (solo): comumente empregado para análises de amostras que são repassadas para recipientes em latas. As amostras são oriundas de perfurações e/ou sedimentos rasos. Nesta técnica um volume controlado de sedimento é inserido na lata com um volume de salmoura. A lata é então selada e um volume de salmoura medido é substituído pelo nitrogênio para criar um volume de headspace conhecido. Após o equilíbrio ser atingido, a concentração de gases livres pode então ser medida com injeção de uma seringa de uma amostra headspace dentro de um cromatógrafo de gás 
equipado com um detector de ionização de chama. A figura seguinte (MELLO, 2003) mostra a técnica do Headspace e sua metodologia.
Probe: corresponde a uma leitura direta de gases livres e comumente empregada em análises que devem ser conduzidas sobre fluidos de perfuração ou amostras de rocha recuperada a partir de uma escavação ou furo no solo. Estas escavações profundas quase sempre se encontram com água, o que pode influenciar a coleção de gases livres, forçando a análise do conteúdo de algum tipo de gás na água reciclada ou no sistema lama no qual é usado para perfurar o buraco.
Para tal, um pequeno tubo concêntrico selado é assentado no solo a algumas profundidades. Com um auxílio de uma seringa usada para evacuar os gases residuais a partir do probe antes da amostra de gás no solo ser coletada, a amostra de gás no solo é coletada em vidros de 125 ml e evacuada.
Blender (intersticiais): empregada em análises em que se utiliza um agregador de partículas. Os hidrocarbonetos são moídos e desagregados em um liquidificador, em seguida, realiza-se por meio de uma seringa, a amostragem que corresponde à injeção dos hidrocarbonetos no cromatógrafo e em seguida no interior do blender.
• Gases Adsorvidos: A análise deste gás ou extração ácida captura gases adsorvidos em sedimentos finos, seja em inclusões no interior de carbonatos autigênicos ou por águas estruturadas.
O gás permanece protegido no interior da estrutura da água e por isso: 1não realiza trocas com gases livres nos espaços intersticiais; 2é protegido de ataques microbianos; 
e 3-migra verticalmente segundo handshake migration. A adsorção aumenta quando o grânulo adsorvente diminui (aumento da área superficial); pode ser física ou química: 1. Física ou de Wan der Waal: ocorre por energia de adsorção baixa e ligação frouxa da substância adsorvida ao adsorvente.
2. Química: ocorre por energia de adsorção elevada e ligação firme da substância adsorvida. Pode envolver um cátion ou ânion estranho.
4.3.3 Análise geoquímica A análise geoquímica pode ser dividida em duas fases importantes: (1) A Quantificação dos hidrocarbonetos presentes (Screening Analysis), que pode ser realizada em todas as amostras por meio da análise de Cromatografia gasosa, Fluorescência Quantitativa e Cromatograma a Gás (Whole Extract-GC).
(2) A caracterização dos hidrocarbonetos encontrados (Detailed Analysis), que é realizada pelas análises de Biomarcadores (GM-MS), Diamantoides e Isótopos de Carbono. Esta última será realizada em amostras com alta concentração de gases (acima de 500ppm), pela espectrometria de massa com a finalidade de determinar a origem dos hidrocarbonetos (MELLO, 2003).
Nesta tese será descrito apenas o método de quantificação de cromatografia a gás por ter sido este o único método de análise geoquímica utilizado.
4.3.3.1Cromatografia gasosa Corresponde à análise geoquímica para quantificação dos hidrocarbonetos leves (C1 a C5), em que a mistura gasosa deverá ser retirada dos recipientes oriundos do campo e injetada em cromatógrafos de alta resolução capazes de determinar e quantificar as concentrações em ppm de metano, etano, propano, i-butano, n-butano e n-pentano.

O cromatógrafo deve ser equipado por uma coluna capilar e um detector de ionização de chama (FID ou DIC).
O princípio básico do cromatógrafo ocorre por separação das misturas e por interação diferencial dos seus componentes entre uma fase estacionária - FE (líquido ou sólido) e uma fase móvel - FM (líquido ou gás).
Para que se dê a separação destes constituintes das misturas, estes devem ser voláteis ou evaporáveis, termicamente estáveis e com ponto de ebulição até 300oC.
Assim, as amostras coletadas devem ser injetadas em um vaporizador em uma coluna cromatográfica gerando um sinal quando da passagem de substâncias que não o gás de arraste.
A calibração do cromatógrafo deve ser diária, utilizando-se uma mistura gasosa contendo concentrações conhecidas; o cálculo destas concentrações e a transferência dos valores para o formato digital deverão ser automatizados evitando assim erros de transcrição. Os erros analíticos devem ser inferiores a 15%.
4.3.4 Interpretação dos dados de Geoquímica de Superfície Os dados de geoquímica de superfície muitas vezes podem apresentar ruídos (noisy) (KLUSMAN, 2002). Isto tem constituído um grande problema para o uso das técnicas de geoquímica de superfície, além de ter gerado uma grande responsabilidade para os analistas no que se refere à interpretação dos resultados de muitas inspeções geoquímicas.
A característica da vida de uma população natural determinada em um solo ou sedimento irá incluir todos os possíveis membros de uma área de interesse. A população amostrada ou amostra estatística engloba amostras individuais ou medidas realizadas no campo. A população amostrada será então muito menor que a população total, requerendo que essa população amostrada deva ser representativa da população total.
Essa representatividade pode ser obtida por uma faixa amostrada, mas o grid (malha) amostrado é mais comumente usado em avaliações de lugares específicos que devem enfatizar uma área de interesse.
1 Definido como um tipo de detector onde os íons são gerados durante a queima dos eluentes em uma chama de H2 + ar (MELLO, 2003).

O número de amostras ou medidas requeridas depende também dos objetivos de um levantamento de geoquímica de superfície, importantes ao longo de um processo de planejamento. Durante o reconhecimento de um objetivo de uma avaliação da geoquímica de superfície, em que se deseja determinar se uma bacia é prospectiva ou não, poucas amostras são requeridas na identificação dos prospectos.
A separação de amostras com anomalias de amostras background é uma das partes mais críticas dos levantamentos de geoquímica de superfície (KLUSMAN, 2002; SCHUMACHER, 2000; SCHUMACHER, 2011 ; SCHUMACHER & CLAVAREAU, 2011; SCHUMACHER & CLAVAREAU, 2012). Não existe uma proporção de amostras com anomalias a ser distinguida a partir de amostras background. A prática comum de considerar amostras maiores que uma média ou dois desvios padrão como anomalias existenciais não tem base científica. Este limiar ou fronteira entre anomalias e background deve ser determinado objetivamente usando os dados disponíveis. Em um reconhecimento de um levantamento ou na determinação da prospectividade de uma fronteira de uma bacia, muito poucas amostras ou medidas devem ser anomalias.
4.4 BENEFÍCIOS DA GEOQUÍMICA DE SUPERFÍCIE Indicações em superfície de exsudações de óleo e gás são conhecidas há muitos anos como exsudações que têm liderado a descoberta de várias importantes áreas produtoras de petróleo (SCHUMACHER, 2000). Apesar de a descoberta de uma superfície com anomalias geoquímicas não garantir uma descoberta significativa de petróleo, isto estabelece a presença de hidrocarbonetos na área de interesse. As exsudações de hidrocarbonetos leves em superfície representam o caminho final da migração. Trapas e estruturas ao longo deste caminho devem ser considerados significativamente mais prospectivos do que aqueles associados às anomalias; assim, podem ser apontados como importantes benefícios potenciais para o completo êxito na busca desta detecção de hidrocarbonetos leves em superfície e, também, para a minimização do risco exploratório.
2 A amostra background não é um único valor; isto é uma faixa de valores, particularmente para cobrir uma ampla área de inspeções ou ter contraste no solo, condições geológicas e ambientais.

4.5 ANÁLISE GEOESTATÍSTICA Na geoestatística, a análise do semivariograma é uma etapa importante, pois o modelo de semivariograma escolhido é a interpretação da estrutura de correlação espacial a ser utilizada nos procedimentos inferenciais da krigagem. A análise completa do semivariograma compreende os seguintes passos: • Levantamento do semivariograma experimental: o cálculo do valor do semivariograma em cada distância é realizado utilizando os dados amostrais da variável regionalizada na equação abaixo, que é o estimador do semivariograma. O semivariograma experimental, quando apresenta dependência espacial, é uma curva irregular com flutuações que crescem com os valores de h. Os últimos pontos deste gráfico têm menor significância estatística, pois envolvem poucos pares de pontos. A curva experimental obtida é na realidade um estimador do verdadeiro semivariograma desconhecido; este possui propriedades matemáticas precisas, fazendo-se necessário, portanto, o ajuste de um modelo teórico que sirva de base para os cálculos posteriores.
• Ajuste a uma família de modelos de semivariogramas: o modelo ajustado ao semivariograma experimental está relacionado com o comportamento do semivariograma na origem e a existência ou não de um patamar. Ao modelo une-se o efeito pepita por extrapolação da curva. A adequação de um modelo teórico é fundamental, pois a partir dele serão feitas inferências com relação ao semivariograma verdadeiro.
• Validação do modelo a ser utilizado nos procedimentos da krigagem: a adequada modelagem da estrutura de dependência espacial valida qualquer outro procedimento de inferência e interpolação, além de ser um forte subsídio para decisões práticas sobre o fenômeno em estudo. Conhecido o semivariograma da variável em estudo e havendo dependência espacial entre as amostras, o próximo passo consiste na obtenção de informações de pontos não amostrados no campo por meio do método de interpolação denominado krigagem.
Os métodos de krigagem são métodos de interpolação que procuram minimizar o erro da estimação; na realidade, o erro médio de estimação é nulo. O problema que se coloca normalmente é o de estimar o valor de uma variável em locais não amostrados, , a partir dos valores de locais amostrados, . O estimador de krigagem é também um estimador linear que considera a organização espacial da variável: 
em que é o ponderador da distância e .
A krigagem é um método exato e não viesado, isto é, os valores nos locais amostrados são reproduzidos e o erro médio de estimação é nulo.
Para avaliar de forma adequada a análise geoestatística, alguns autores têm utilizado o método da validação cruzada. Nesta, assume-se que uma determinada amostra não tenha sido coletada, ou seja, elimina-se o seu valor e se estima a partir dos dados circundantes. Após essa estimação, o valor real dessa amostra é reintroduzido no sistema e o processo é repetido para todas as outras amostras, de forma que para cada ponto é possível obter o erro de estimação. Uma estimação terá sido sem bias se o erro médio for zero, isto é, se os valores estimados tiverem uma diferença média em relação aos valores experimentais igual a zero, e a variância estiver em torno de um.
É importante ressaltar que a análise geoestatística não se trata de um método contínuo em uma direção. A análise geoestatística consiste em ir e voltar, refazer e comparar antes de qualquer decisão definitiva. Várias decisões são tomadas ao longo do processo, ou seja, os resultados intermediários e finais não são obtidos de forma única, e as técnicas descritivas e exploratórias devem estar presentes em todas as fases do processo de análise e não só na fase inicial.
4.6 COMPARAÇÃO ENTRE OS MÉTODOS DE INTERPOLAÇÃO A krigagem permite que se faça uma validação cruzada para checagem dos dados, ou pelo menos uma comparação entre os erros. Por este método, o ideal seria ter um erro médio padronizado dos valores preditos próximo de zero, um quadrado médio do erro o mais baixo possível e um quadrado médio do erro padronizado próximo de um.
No caso dos interpoladores determinísticos (i,e., curvatura mínima e o inverso quadrado da distância), estes somente fornecem o quadrado médio do erro, e este tem que ser o mais baixo possível. O quadrado médio do erro (QME) é dado por: 
Os resultados obtidos para o quadrado médio do erro serão comparados, e o método que apresentar o menor quadrado médio residual será o método considerado como o mais eficiente, isto para que os valores dos pontos no mapa interpolado sejam o mais possível parecidos com os valores recolhidos nesses pontos.

5 RESULTADOS E DISCUSSÕES 5.1 ANÁLISE EXPLORATÓRIA DESCRITIVA Esta seção apresenta os resultados da aplicação da metodologia proposta como estudo de caso em um conjunto de dados piston core da Bacia de Santos, composto por n = 500 registros e p = 12 atributos.
Uma das dificuldades encontradas para o melhor desenvolvimento deste estudo, por ser inovador para geoquímica de superfície brasileira, foi a busca de referências bibliográficas relacionadas.
5.1.1 Dados originais Os dados piston core da Bacia de Santos foram obtidos a partir da ANP/BDEP (Agência Nacional do Petróleo, Gás Natural e Biocombustíveis / Banco de Dados de Exploração e Produção). Devido à diversidade de informações, foi necessário realizar um pré-processamento em diversas etapas (dados outliers, dados ausentes, entre outros) para se obter a base para a avaliação. Os atributos elencados abaixo estão na mesma ordem da figura 7: 1 - Intensidade da Fluorescência (nm); 2 - Emissão Máx. (nm); 3 - Excitação Máx. (nm); 4 - TSF R1 (nm); 5 - UCM Total (ppm); 6 - Alcanos Totais (ppm); 7 - Metano (ppm); 8 - Etano (ppm); 9 - Propano (ppm); 10 - i-Butano (ppm); 11 - n-Butano (ppm); 12 - n-Pentano (ppm).

A figura 7 é uma matriz de correlação dos dados Piston core. Observa-se que as linhas 1 e 5 (Intensidade da Fluorescência e UCM Total), assim como as linhas 2 e 3 (Emissão e Excitação), possuem forte correlação (aprox. 0,9). A correlação entre a Intensidade da Fluorescência e UCM Total pode se dever à predominância de hidrocarbonetos (amorfos) indicativos de matéria orgânica recente ou de óleo exsudado que foi biodegradado. O grau da maturação da matéria orgânica pode ser determinado por meio da intensidade e da cor da fluorescência do material analisado (TISSOT; WELTE, 1984). A matéria orgânica imatura geralmente apresenta fluorescência amarela. Quando no início da janela de geração, a coloração se torna laranja e, quando matura, marrom (MENDONÇA; MENESES, 2001). Os dados de gasometria apresentaram também boa correlação (aprox. 0,9) corroborando desta maneira com os dados das variáveis: Intensidade da Fluorescência, Emissão Máx. e UCM Total. As variáveis Excitação Máx, TSF R1 e Alcanos Totais apresentaram menor correlação com as demais variáveis em estudo (aprox. 0,3).
Figura 7: Matriz de correlação dos dados piston core da Bacia de Santos 
Baseado no gráfico da variância explicada (Fig. 8), temos que o primeiro componente principal explica cerca de 69% (CP1) da variação nos dados, o segundo principal componente explica 19% (CP2) e a terceira. 11% (CP3).
Figura 8 - Variância Explicada - Componentes Principais (n +1) versus X - Variância Percentual Pode-se assim dizer que quase toda a informação relevante para o modelo em estudo (cerca de 99%) pode estar contida nas três primeiras componentes principais. Em referência aos resultados da ACP (análise de componentes principais) (Fig. 8), Zuo (2011) obteve os mesmos resultados por meio da aplicação de análise estatística multivariada. ACP é uma ferramenta útil para combinar diversas variáveis correlacionadas em uma única variável e, assim, para reduzir a dimensionalidade de conjuntos de dados correlacionados em componentes principais com base na covariância ou correlações de variáveis, que representam as inter-relações entre as variáveis multidimensionais.
Na figura 9 ilustra-se a existência de diferentes comportamentos entre os parâmetros em estudo. Entre os parâmetros de gasometria (metano, etano e propano), intensidade da fluorescência máx, TSF R1, UCM total, emissão máx e excitação máx, 
apresentam-se com comportamentos distintos entre os mesmos. Já os parâmetros n-pentano, n-butano, alcanos totais e i-butano não se correlacionam com os demais.
Figura 9 - Gráfico de distribuição dos pesos aos parâmetros de piston core para a Componente Principal 1 versus Componente Principal 2 As estatísticas descritivas para os dados originais de Intensidade da Fluorescência (nm), Emissão Máx. (nm), Excitação Máx. (nm), TSF R1 (nm), UCM Total (ppm), Alcanos Totais (ppm), Metano (ppm), Etano (ppm), Propano (ppm), i-Butano (ppm), n-Butano (ppm) e n-Pentano (ppm) estão apresentadas na Tabela 1.
Para os dados do i-butano (ppm), o excesso de curtose foi bem superior a um.
Levando-se em conta que a curtose de uma curva normal é de 3, a curtose dessa série de dados indica uma curva além do valor, tendo a função de distribuição um pico mais elevado e denominado leptocúrtica.
Existe uma estreita relação entre o valor das medidas de tendência central e o comportamento da assimetria, tendo a média se apresentado maior que a mediana, demonstrando a assimetria positiva dos dados. Um expressivo desvio padrão implica uma menor representatividade estatística da média dos dados observados.

O coeficiente de variação de n-Pentano (207,39) mostra essa menor representatividade estatística da média dos dados e não permite nenhuma conclusão da distribuição dos dados; de acordo com Frizzo e Licht (2007), não indica conveniência da transformação dos dados brutos (originais) para seu logaritmo.
Segundo Warrick e Nielsen (1980), pode-se classificar a variabilidade da variável como média (0,12<CV<0,62).

Propano (ppm) i-butano (ppm) n-Butano n-Pentano (ppm) (ppm) 500,00 500,00 500,00 500,00 0,26 0,26 0,00 0,96 0,96 0,19 0,33 0,01 0,00 0,09 0,12 0,35 0,02 0,00 1,21 1,21 0,00 0,04 0,00 0,00 0,03 0,09 0,20 0,09 0,00 2,21 2,21 0,07 0,12 0,02 0,10 0,20 0,36 0,16 0,06 0,00 3,23 3,23 0,04 0,09 0,01 0,10 0,17 0,32 6,68 92,09 12,94 34,85 0,19 0,00 0,07 0,04 456,00 1031,00 875,00 7,82 23,00 4,07 280,07 4,09 1,77 1,86 3,44 4,94 52,39 9,88 9,03 58,16 89,25 74,32 120,03 49,77 45,19 254,30 185,75 207,39 
De acordo com a Tabela 1, para as demais variáveis, a média e a mediana também apresentaram entre si valores próximos, revelando uma variação mínima. Os valores de excesso de curtose apresentaram valores positivos indicando uma distribuição assimétrica positiva e um comportamento leptocúrtico da curva de distribuição, tendo a variável i-Butano apresentado o maior valor, e para as variáveis Intensidade da Fluorescência e UCM Total, os menores valores para o excesso de curtose respectivamente, indicando uma possível distribuição gaussiana.
Observando os valores do coeficiente de variação (CV), os menores valores também são das variáveis: Emissão Máx. e Excitação Máx. e as máximas para i-butano e n-Pentano.
Segundo Koch e Link (1971), para valores de coeficiente de variação menores que 0,3 ou 30%, a distribuição é normal ou muito aproximadamente normal, tendo as variáveis: Emissão Máx. e Excitação Máx. apresentado valores de CV dentro dessa faixa. Quando é observado para a variável com desvios padrão maior do que a média, o uso da distribuição normal fica inviabilizado (MACKAY; PATERSON, 1984).
Desta maneira, segundo Koch e Link (1971), já que ficaram com valores de CV entre 40% e 70%, não permitem qualquer conclusão para as variáveis estudadas. Segundo Warrick e Nielsen (1980), pode-se classificar a variabilidade das variáveis como alta (CV>0,62).
As estatísticas para as variáveis apontam claramente um distanciamento da hipótese de normalidade. Analisando estas hipóteses pelos testes formais de normalidade (Tabela 2), pode-se observar para as variáveis Emissão Máx.; Excitação Máx.; Metano; i-Butano; n-Butano e n-Pentano que não se rejeita a hipótese nula de que a distribuição é normal de acordo com K-S (valor em negrito). Para as demais variáveis também não se rejeita hipótese nula de ser a distribuição normal, contudo com menores valores.
Tabela 2 - Testes formais de normalidade Kolmogorov-Smirnov (K-S) para os dados originais 
Figura 10 - Histograma de frequência para as variáveis originais * Obs.: as curvas em linha vermelha representam a distribuição da curva gaussiana esperada para as variáveis estudadas.

Figura 10 - Histograma de frequência para as variáveis originais (continuação) * Obs.: as curvas em linha vermelha representam a distribuição da curva gaussiana esperada para as variáveis estudadas.

Figura 11 - Boxplot para as variáveis originais 
Figura 11 - Boxplot para as variáveis originais (continuação) 
Figura 12 - Gráfico de probabilidade para as variáveis originais * Obs.: as linhas em vermelho representam a reta probabilidade esperada para as variáveis estudadas.

Figura 12 - Gráfico de probabilidade para as variáveis originais (continuação) * Obs.: as linhas em vermelho representam a reta probabilidade esperada para as variáveis estudadas.

Como podemos verificar por meio dos histogramas, boxplots e gráficos de probabilidade, a maioria das variáveis não apresentam um ajuste à distribuição normal. Estas observações sugerem a existência significativa de outliers para estas variáveis e talvez um melhor ajuste à distribuição lognormal, como descrito por Ahrens (1953, 1954a, 1954b, 1957).
De acordo com a estatística, valores outliers deveriam ser removidos; no entanto, do ponto de vista geoquímico, estes valores extremos podem ter significado, constituindo anomalias geoquímicas. Segundo Reimann et al. (2005), a detecção de dados outliers é uma das principais tarefas da análise estatística de dados geoquímicos. Para minorar eventuais efeitos nocivos provocados por esses fenômenos (existência de “outliers” e comportamento lognormal), foi usada a transformação (ln, log e raiz quadrada (Sqrt)) dos dados, evitando assim a remoção de outliers e verificando se os dados geoquímicos melhor se ajustam ao comportamento lognormal.
5.1.2 Dados transformados (ln) As estatísticas descritivas para os dados transformados (ln) das variáveis estão apresentados na Tabela 3. A Tabela mostra que a variação entre a média e mediana de forma geral ficou menor após a transformação, mas a transformação dos dados não aproximou de fato numa distribuição lognormal.
Os valores de excesso de curtose apresentaram também valores mais próximos da normalidade, obtendo menores valores excesso de curtose para as variáveis: ln UCM Total; ln Alcanos Totais; ln i-butano; ln n-Butano e ln n-Pentano, e maiores valores para as variáveis: ln Intensidade da Fluorescência; ln Emissão Máx.; ln Excitação Máx.; ln Metano; ln Etano e ln Propano, que no item anterior ficaram próximas da normalidade. As variáveis: ln Emissão Máx.; ln Excitação Máx.; ln UCM Total; ln i-butano; ln n-Butano e ln n-Pentano tiveram seus valores de média menores que a mediana, apresentando assimetria negativa, ou seja, tiveram seus dados levemente concentrados à direita; para as demais variáveis, a assimetria é positiva, com maior acúmulo de dados à esquerda.

ln iln ln ln Propano butano (ppm) n-Butano n-Pentano (ppm) (ppm) (ppm) 500,00 -1,34 -1,35 -3,32 2,67 6,00 -1,66 -1,11 0,02 0,22 0,33 0,47 13,06 500,00 -2,49 -3,22 -4,61 2,24 6,85 -3,91 0,00 0,07 2,79 1,48 1,67 -1,17 500,00 -1,95 -2,30 -4,83 1,59 6,41 -2,53 -1,97 0,05 1,03 0,77 1,01 0,75 500,00 -2,29 -2,81 -3,91 3,71 7,63 -3,00 -1,66 0,05 1,39 0,95 1,18 1,04 3,33 3,00 4,72 2,87 20,11 0,17 15,54 0,02 14,53 0,02 2,34 -3,00 8,74 0,94 0,02 0,17 18,54 0,44 4,87 -0,70 2,90 -0,35 3,37 -0,67 0,41 -0,52 3,91 -0,51 
O valor máximo para a variável ln n-Butano está fora do intervalo dado pelo limite superior e as variáveis: ln TSF R1; ln UCM Total; ln Etano; ln Propano; ln i-butano; ln n-Butano e ln n-Pentano estão fora do intervalo dado pelo limite inferior, sugerindo possíveis candidatos a valores discrepantes.
Segundo Warrick e Nielsen (1980), pode-se classificar a variabilidade como média (0,12<CV<0,62) para as variáveis: ln Intensidade da Fluorescência; ln Alcanos Totais; ln Metano, e como alta (CV>0,62) para ln UCM Total, tendo apresentado o valor mais baixo para ln TSF R1 (-3,00) e valor mais alto para ln UCM Total (0,94).
Analisando os dados pelos testes formais de normalidade (Tabela 4), pode-se confirmar que não se rejeita a hipótese nula de que a distribuição é normal para as variáveis: ln emissão máx., ln excitação máx., ln UCM Total, ln alcanos totais, ln metano, ln i-butano, ln n-butano e ln n-pentano, as que mais se assemelham com uma distribuição normal pelo teste K-S (valores em negrito); já para as demais variáveis, rejeita-se a hipótese nula de que a distribuição é lognormal.
Podemos visualizar melhor a dispersão dos dados através das figuras boxplots, histogramas de frequência e de probabilidade para as variáveis transformadas: ln Intensidade da Fluorescência, ln TSF R1, ln Etano e ln Propano (Figura 5.4a,5.4b e 5.4c, respectivamente), as quais tiveram rejeitada a hipótese nula de que a distribuição é lognormal.

Figura 13a - Histograma de frequência para as variáveis transformadas (ln): Intensidade da Fluorescência (nm), TSF R1 (nm), Etano (ppm) e Propano (ppm) * Obs.: as curvas em linha vermelha representam a distribuição da curva gaussiana esperada para as variáveis estudadas.

Figura 13b - Boxplot para as variáveis transformadas (ln): Intensidade da Fluorescência (nm), TSF R1 (nm), Etano (ppm) e Propano (ppm) 
Figura 13c - Gráfico de probabilidade para as variáveis transformadas (ln): Intensidade da Fluorescência (nm), TSF R1 (nm), Etano (ppm) e Propano (ppm).
* Obs.: as linhas em vermelho representam a reta probabilidade esperada para as variáveis estudadas.

Fazendo a transformação dos dados por outros métodos (Tabela 5), pode-se verificar que os dados transformados (log) tiveram os mesmos resultados dos testes de normalidade para as variáveis transformadas (Ln). Já para os dados transformados pela raiz quadrada (Sqrt), o teste de normalidade mostra que se rejeita a hipótese nula de que a distribuição é normal somente para a variável Alcanos Totais (valor em negrito).
Tabela 5 - Testes formais de normalidade Kolmogorov-Smirnov (K-S) para dados originais 5.1.3 Interpolação pelos modelos: krigagem ordinária, curvatura mínima e inverso do quadrado da distância Os métodos da krigagem, curvatura mínima e inverso do quadrado da distância para cada variável foram ajustados conforme o padrão do software Surfer 8.01 em estudo.
Com o objetivo de comparar graficamente os interpoladores, os blocos diagrama e superfície destas interpolações são mostrados. Foram utilizados os métodos: [média + 1 desvio padrão], [média + 2 desvio padrão] e [média + 3 desvio padrão] para a determinação de limiares, onde a cor verde corresponde aos valores médios (background) e as cores de laranja a vermelha, aos valores anômalos.
Os blocos diagrama e superfície dos valores das variáreis nas figuras a seguir, estimados pelo método de krigagem, apresentam as mesmas sub-regiões descritas nas análises 
da superfície de valores. Entretanto, foi apresentado um efeito suavizador das diferenças, visto que o interpolador de krigagem superestima para baixas medidas e subestima para elevados valores, ou seja, tende à média dos dados.
Esse resultado é obtido principalmente pelo fato deste interpolador ser não viciado, com variância mínima, pois é um interpolador ótimo. A região dita anômala aparece bem delineada.
A interpolação pelo método de curvatura mínima para as variáveis apresentaram outras sub-regiões não descritas na analise da superfície de valores como se pode observar, apresentando uma distribuição espacial menos homogênea que a apresentada pelo método de krigagem. Pode-se verificar também uma extrapolação de valores, principalmente nas bordas do bloco.
Já a interpolação pelo método do inverso do quadrado da distância (IQD), os blocos diagrama e superfície para os valores das variáveis apresentaram uma distribuição espacial mais homogênea do que pelo método de curvatura mínima.

quadrado da distância 
Figura 14b - Mapas para a intensidade da fluorescência (nm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 
Figura 15a - Bloco diagrama interpolado para a emissão máx (nm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância.

Figura 15b - Mapas para emissão máx (nm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 
Figura 16a - Bloco diagrama interpolado para a excitação máx (nm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 
Figura 16b - Mapas para excitação máx (nm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 


Figura 18a - Bloco diagrama interpolado para UCM total (ppm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância.

curvatura mínima e (c) inverso do quadrado da distância.

Figura 19a - Bloco diagrama interpolado para alcanos totais (ppm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância.

ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 
Figura 20a - Bloco diagrama interpolado para metano (ppm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

Figura 21a - Bloco diagrama interpolado para etano (ppm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância.

Figura 22b - Mapas para propano (ppm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 
a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância.

Figura 23b - Mapas para i-butano (ppm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 
Figura 24a-Bloco diagrama interpolado para n-butano (ppm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância.


Figura 25a-Bloco diagrama interpolado para n-pentano (ppm) pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

5.1.4 Comparação entre métodos de interpolação Pela comparação dos blocos diagramas obtidos, verifica-se que o método de krigagem ordinária apresenta distribuição espacial muito mais homogênea do que os demais. Esse resultado é obtido principalmente pelo fato deste interpolador ser não tendencioso, com variância mínima.
O desempenho desses interpoladores foi obtido e comparado usando o critério do quadrado médio do erro (QME). Para os valores estimados pelos métodos do inverso do quadrado da distância e curvatura mínima, esse critério pode ser aplicado diretamente, pois não são interpoladores ótimos, e a diferença dos valores estimados e os observados não são nulos. Entretanto, para o interpolador de krigagem ordinária, por ser ótimo, essa diferença é nula; logo, para ter os valores estimados no ponto observado, o método de validação cruzada (VIEIRA, 2000; ISAAKS; SRIVASTAVA, 1989) foi usado. Esse método envolve a estimativa de cada ponto medido, simulando que ele não existe durante a sua estimativa. A razão é que krigagem ordinária é um interpolador exato, passando exatamente pelo ponto observado, quando esse é usado no cálculo.
Na Tabela 6, apresentam-se os resultados obtidos para o critério de comparação (QME) para as variáveis. O valor do critério deve ser próximo de zero se o algoritmo for preciso. Altos erros estimados são obtidos para os três interpoladores.
Para os dados das variáveis, o interpolador que apresentou resultado mais acurado conforme a tabela a seguir, foi o de krigagem ordinária, seguido pelo inverso do quadrado da distância e, por último, pela curvatura mínima.

Tabela 6 - Resultados obtidos para o quadrado médio do erro (QME) 5.2 AVALIAÇÃO DA CLUSTERIZAÇÃO FUZZY C-MEANS (FCMC) O algoritmo da clusterização Fuzzy c-Means (FCMC) particiona o conjunto de dados em um pré-determinado “c”-número de clusters. É uma técnica de agrupamento de dados, onde cada ponto de dados de alguma forma pertence a um cluster que é especificado por um grau de pertinência. Este método fornece a informação de como os pontos de dados de grupo demonstram como preencher um espaço multidimensional em um número específico em diferentes clusters. Clustering é uma ferramenta matemática que tenta descobrir estruturas ou certos padrões em um conjunto de dados, onde os objetos dentro de cada cluster mostram certo grau de semelhança. Neste estudo, a avaliação de agrupamento FCM é considerada como a estrutura mais adequada em conjuntos de dados geoquímicos (ZIAII et al., 2009; GATH et al., 1997).
A avaliação do agrupamento FCM foi realizada a partir do índice de validação PBM para determinar qual o número de clusters no conjunto de dados (EVSUKOFF et al., 2004;.
PAKHIRA et al., 2004). Para esclarecimentos sobre outros indicadores, vide o capítulo 3 
sobre inteligência computacional, para determinar o melhor número possível de agrupamentos nos dados. Posteriormente, como pode ser visto na Tabela 7, para muitos dos valores “m” do parâmetro fuzzy, o índice de validação indica três agrupamentos no conjunto de dados. Assim, a classificação foi realizada considerando basicamente três agrupamentos (classes), conforme apresentado nas figuras 5.20, 5.21 e 5.22.
O valor do índice diminui na medida quando o valor de “m” aumenta. Isso se deve ao fato de que quanto maior for o valor do parâmetro de fuzzificação, mais imprecisas serão as partições geradas, conforme as figuras 26, 27 e 28, adiante.



Os resultados na Tabela 7 apresentam que, para valores maiores do parâmetro “m”, o índice PBM é menor, uma vez que a partição é mais fuzzy. As partições permitem um registro fuzzy a ser atribuído a mais de uma classe, possibilitando transições graduais entre os clusters.
Desta maneira, o classificador geo-fuzzy foi assim atribuído para classificar os clusters gerados com “m = 1,6” (parâmetro de fuzzificação).
5.3 CLASSIFICAÇÕES DOS RESULTADOS O classificador geo-fuzzy foi determinado a partir dos resultados de análise de cluster para avaliar cada cluster no domínio geográfico. Para esta aplicação, a base da regra foi gerada usando n = 10 conjuntos fuzzy para cada coordenada, resultando em 100 regras (10) e uma grade de 62.500 (250 x 250) pontos regularmente espaçados dentro do domínio (EVSUKOFF et al., 2004).
Os resultados são mostrados nas figuras 29 e 30 (a e b), nas quais os membros da classe são representados por um grau de cores: o verde representa a participação (0,0) nula e o vermelho representa a adesão (1,0) completa.

anômalas para o cluster 1 
anômalas para o cluster 2 
Figura 30b - Mapa do Cluster 3, longitude versus latitude, ilustrando áreas anômalas para o cluster 3.

As interpretações de cada cluster podem ser feitas a partir de seu centro de coordenadas, mostrado na Tabela 8. As colunas indicam os atributos do piston core utilizados para a avaliação dos clusters.
Obs.: ppm = partes por milhão; TSF R1 = Fluorescência total Razão (Este parâmetro possibilita uma estimativa qualitativa da razão de hidrocarbonetos de três anéis para dois anéis aromáticos); UCM = mistura complexa não resolvida (A quantificação deste parâmetro obtido a partir da cromatografia gasosa provém uma medida de concentração de hidrocarbonetos extraíveis em amostras biodegradadas).
O cluster 1, ilustrado na figura 29, refere-se à concentração mais comum das amostras com menores concentrações de hidrocarbonetos, nas quais poderiam ser indicativos da possível ausência de fontes significativas em subsuperfície ou a existência de barreiras de permeabilidade entre as fontes e da superfície.
O cluster 2, apresentado na figura 30a, representa concentrações intermediárias entre os cluster 1 e 3. Finalmente, o cluster 3 (Figura 30b) é semelhante ao cluster 2, apresentando valores outliers apenas para o metano, que poderiam indicar uma possível contribuição de 
gases biogênicos gerados pela degradação da matéria orgânica. Se no banco de dados deste estudo houvesse, por exemplo, a indicação aos dados de isótopos de carbono, poder-se-ia comprovar esta indicação.
Nas áreas dos clusters onde há anomalias com sobreposição dos pontos de piston core e de poços, pode haver indícios de acumulações na área. Para confirmar a existência deste foram utilizadas as informações contidas no banco de dados disponíveis da ANP/BDEP a fim de corroborar os campos identificados nas figuras 31; 32 e 33, a seguir. No caso em que não existem anomalias pode ser devido ao fato de as rochas selantes serem muito efetivas e poderem existir acumulações de petróleo, ou mesmo, ser grande a probabilidade de não existirem acumulações na área em estudo.
Nas áreas onde somente existem os pontos de piston core e nenhum poço perfurado isto pode ser devido ao fato de haver anomalias com possíveis acumulações. De outra maneira, por não existirem anomalias, pode ter acumulações (mas os hidrocarbonetos não se difundem) ou não é grande a probabilidade de que não existam acumulações significativas de petróleo.

campos identificados em produção para o cluster 1 
campos identificados em produção para o cluster 2 
Figura 33 - Mapa do Cluster 3, longitude versus latitude, ilustrando campos identificados em produção para o cluster 3 
As amostras puderam ser agrupadas de acordo com seus valores mais elevados de adesão. O número absoluto e relativo de amostras agrupadas em cada cluster é apresentado na tabela 9.
Os resultados na tabela 9 são semelhantes aos da área de regiões na figura 30b. O cluster 3 é o cluster mais comum, agrupando 38% dos dados, enquanto os clusters 1 e 2 são os que reagrupam o menor número de amostras.
Estes resultados podem ser uma indicação da existência de uma região de anomalia no agrupamento 3, mas deve ser confirmada por estudos geológicos para maiores detalhes.
Em exploração geoquímica, a clusterização fuzzy c-means fornece uma forma objetiva e eficaz para especificar litologicamente as concentrações background na composição geoquímica de sedimentos. Deve ser evitado utilizar somente esta técnica, pois poderá ocasionar uma má interpretação de áreas anômalas, que estão apenas relacionadas com a composição litológica dentro da área de drenagem das amostras (RANTITSCH, 2000).

6 CONCLUSÕES Neste estudo buscou-se a avaliação de dados geoquímicos de superfície com ênfase nos hidrocarbonetos leves de 500 amostras piston core da Bacia de Santos. As amostras foram analisadas por Fluorescência, Head Space e Cromatografia Gasosa. Foram construídos diversos blocos diagramas, mapas de contorno e mapas de clusterização fuzzy dos parâmetros em estudo.
Os dados geoquímicos de superfície não apresentam uma distribuição lognormal ou normal. Mesmo quando usados outros diferentes métodos de tratamento, não se aproximaram de uma distribuição normal.
Foram obtidos melhores resultados com o interpolador geoestatístico de krigagem ordinária do que com os demais interpoladores curvatura mínimo e inverso do quadrado da distância, que não ponderam a dependência espacial entre as observações.
Desta forma a krigagem ordinária indica maior precisão para os locais da previsão da distribuição das variáveis estudadas, inferindo subsídios para delimitar áreas com possíveis potenciais petrolíferos, assim como para reduzir o custo de novas pesquisas.
Foi apresentada uma metodologia do geoprocessamento fuzzy para mapas de geoquímica de superfície e estudo de data mining para a Bacia de Santos.
Os resultados permitiram uma definição mais precisa das áreas anômalas visualizadas nos mapas de clusterização fuzzy, tendo em conta todos os parâmetros geoquímicos de forma integrada (em vez de avaliação das concentrações de cada gás de forma independente), proporcionando uma alternativa a geoestatística padrão.

7 RECOMENDAÇÕES As técnicas de inteligência computacional contribuem como ferramenta de apoio na tomada de decisão para auxiliar no aumento da confiabilidade na exploração e da minimização do risco exploratório na indústria petrolífera.
Empregar outros métodos para adquirir outros conhecimentos como, por exemplo, Regras de Associação, ou ainda para preencher os valores de algumas variáveis que se encontram ausentes, por meio de Regressão Linear.
Aumentar a densidade de amostragem piston core para ter uma maior abrangência da área com a finalidade de obter uma maior confiabilidade.
Não foram evidenciados claramente trabalhos aplicados à geoquímica de superfície de hidrocarbonetos gasosos implementados com ferramentas geoestatísticas, o aprendizado estatístico e geoestatístico. Também se constatou a ausência de maiores informações interdisciplinares sobre a região estudada, as quais contribuiriam para uma melhor avaliação dos dados.
