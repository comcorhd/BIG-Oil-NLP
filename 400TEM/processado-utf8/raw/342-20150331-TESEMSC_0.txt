
IntroduÃ§Ã£o do estado da arte em adiÃ§Ã£o de contexto.
Por fim, no CapÃ­tulo 7 as conclusÃµes deste trabalho sÃ£o apresentadas.

1 FundamentaÃ§Ã£o TeÃ³rica 1: Detectores de Pontos de Interesse Este capÃ­tulo apresenta a fundamentaÃ§Ã£o teÃ³rica sobre detectores de pontos de interesse. Formalmente pontos de interesse sÃ£o definidos como um padrÃ£o de uma imagem que difere de sua vizinhanÃ§a imediata (TUYTELAARS; MIKOLAJCZYK, 2008).
Normalmente sÃ£o pontos com particularidades de uma imagem as quais possuem alguma caracterÃ­stica visual relevante. Vale notar que, apesar do termo utilizado ser "pontos de interesse", nÃ£o Ã© utilizada a definiÃ§Ã£o matemÃ¡tica de um ponto infinitesimal sendo definidos como pequenas regiÃµes. Pontos de interesse servem como Ã¢ncoras de regiÃµes da imagem, determinando quais posiÃ§Ãµes podem ser descritas para se ter uma representaÃ§Ã£o confiÃ¡vel da mesma. Distintas aplicaÃ§Ãµes fazem uso dos pontos de interesse como: a classificaÃ§Ã£o de imagens (PADMAVATHI; MUTHUKUMAR; THAKUR, 2010), reconstruÃ§Ã£o 3D (BEALL et al., 2010) (NICOSEVICI et al., 2009), mapeamento e localizaÃ§Ã£o (GIL et al., 2010) , rastreio (CORKE et al., 2007), etc.
Um exemplo de pontos de interesse seriam as quinas, as quais sÃ£o responsÃ¡veis por boa parte do processo de interpretaÃ§Ã£o visual de um objeto (TUYTELAARS; MIKOLAJCZYK, 2008). Muitas vezes, os pontos de interesse apresentam uma relaÃ§Ã£o semÃ¢ntica mais estreita com a aplicaÃ§Ã£o. Por exemplo, ao classificar faces, as regiÃµes do olho ou da boca sÃ£o de grande interesse para a classificaÃ§Ã£o.
A utilizaÃ§Ã£o de pontos de interesse locais traz as seguintes vantagens, em contraste com o uso do contexto geral da imagem: âˆ™ ReduÃ§Ã£o significativa do custo computacional; âˆ™ Descarte de parte do ruÃ­do presente na imagem pois somente os pontos relevantes sÃ£o utilizados; âˆ™ ObtenÃ§Ã£o e uso de apenas caracterÃ­sticas mais distintas da imagem; âˆ™ Possibilidade de reconhecimento de cenas sem a necessidade de segmentaÃ§Ã£o.
PorÃ©m, para um ponto de interesse ser eficaz, a presenÃ§a de algumas propriedades sÃ£o de fundamental importÃ¢ncia (TUYTELAARS; MIKOLAJCZYK, 2008). Entre as mais importantes tem-se: âˆ™ Repetibilidade: Um ponto de interesse deve representar caracterÃ­sticas que possam ser encontradas em determinados objetos, independente da configuraÃ§Ã£o em que tal 
CapÃ­tulo 1. FundamentaÃ§Ã£o TeÃ³rica 1: Detectores de Pontos de Interesse objecto foi fotografado. Dado duas imagens de um mesmo objeto ou cena, o que foi visto em ambas as cenas deve ser detectado como ponto de interesse em ambas as cenas.
âˆ™ Distintividade: Um ponto de interesse deve representar caracterÃ­sticas que sejam distintas, com destaque sobre as demais caracterÃ­sticas e que sejam especificas de um determinado objeto. SÃ³ assim este objeto pode ser descriminado com relaÃ§Ã£o aos demais.
A repetibilidade, de fato a propriedade mais importante (TUYTELAARS; MIKOLAJCZYK, 2008), pode ser atingida tendo os pontos de interesse sendo invariantes a determinadas transformaÃ§Ãµes que uma imagem pode sofrer, tais como: âˆ™ RotaÃ§Ã£o: Um ponto que pertence a uma cena, deve ser encontrado independente da orientaÃ§Ã£o que a cena foi capturada.
âˆ™ TranslaÃ§Ã£o: Se o ponto representa o mesma objeto, o mesmo deve ser encontrado independente da posiÃ§Ã£o na imagem onde ele foi capturado.
âˆ™ Escala: Independente da distÃ¢ncia em que a cena foi capturada, o mesmo ponto deverÃ¡ ser encontrado.
Para outras transformaÃ§Ãµes que a imagem possa sofrer, muitas vezes Ã© interessante que um ponto seja somente robusto. Ou seja, capaz de ser encontrado somente atÃ© um determinado nÃ­vel da transformaÃ§Ã£o. Alguns efeitos, ou transformaÃ§Ãµes, a se ter robustez sÃ£o: efeitos de discretizaÃ§Ã£o, artefatos causados por compressÃ£o, borramento devido a movimento, ruÃ­do branco, distorÃ§Ã£o de perspectiva, etc.
Diversos algoritmos sÃ£o desenvolvidos para encontrar pontos os quais apresentam as propriedades acima descritas. SÃ£o eles chamados os Detectores de Pontos de Interesse.
Os Detectores sÃ£o desenvolvidos de forma a terem um valor de retorno alto em relaÃ§Ã£o a certas estruturas presentes na imagens. Define-se estrutura como um determinado padrÃ£o com respeito a variaÃ§Ã£o de intensidade luminosa em uma regiÃ£o da imagem.
Divide-se os Detectores de Pontos de Interesse com respeito as determinadas propriedades as quais os mesmos possuem invariÃ¢ncia.
Neste trabalho, selecionou-se nove detectores principais encontrados na bibliografia a serem fundamentados. Primeiramente, na seÃ§Ã£o 1.1, sÃ£o expostos os detectores capazes de responder a estruturas possuindo invariÃ¢ncia a rotaÃ§Ã£o e translaÃ§Ã£o. Tais detectores sÃ£o chamados tambÃ©m de detectores de Ãºnica escala pois, nÃ£o possuindo invariÃ¢ncia a escala, somente analisam a imagem em uma Ãºnica escala.

1.1. Detectores de Ãšnica Escala Por fim, na seÃ§Ã£o 1.2, sÃ£o apresentados detectores que convivem tambÃ©m com a invariÃ¢ncia a escala. Estes simulam mÃºltiplas escalas de forma a encontrar pontos invariantes a escala. Tais detectores sÃ£o chamados de detectores de mÃºltipla escala.
1.1 Detectores de Ãšnica Escala Os detectores apresentados nessa seÃ§Ã£o possuem invariÃ¢ncia a translaÃ§Ã£o ou rotaÃ§Ã£o, podendo possuir em algum nÃ­vel, tambÃ©m invariÃ¢ncia a escala. Os detectores apresentados podem tambÃ©m ter robustez a diversos tipos de ruÃ­do.
Normalmente um detector Ã© implementado como uma funÃ§Ã£o, ou kernel, o qual Ã© convoluida com a imagem e produz uma imagem de saÃ­da a qual apresenta o resultado da aplicaÃ§Ã£o deste kernel.
Como jÃ¡ explicado, existem diversas caracterÃ­sticas em uma imagem a serem buscadas como pontos de interesse. Neste trabalho, tanto para o caso de Ãºnica, como de mÃºltipla escala, seleciona-se caracterÃ­sticas baseadas na alta curvatura de uma regiÃ£o, calculada atravÃ©s do gradiente da imagem. Duas estruturas sÃ£o escolhidas, quinas e blobs.
Ambas sÃ£o bastante utilizadas como pontos de interesse pelos detectores mais populares.
As quinas, sÃ£o estruturas que nÃ£o necessariamente representam uma quina de fato. SÃ£o estruturas as quais possuem gradientes de alta intensidade em pelo menos duas direÃ§Ãµes distintas.
Blobs sÃ£o definidos como regiÃµes que sÃ£o diferentes em intensidade da regiÃ£o ao redor. Normalmente sÃ£o associados com algum ponto de extremo na intensidade da imagem (LINDEBERG; EKLUNDH, 1991).
1.1.1 Harris O detector Harris (HARRIS; STEPHENS, 1988) Ã© um dos mais populares detectores de quinas encontrados na literatura. Uma quina Ã© detectada quando existir variaÃ§Ã£o em duas direÃ§Ãµes principais de uma funÃ§Ã£o analÃ­tica de auto-correlaÃ§Ã£o na imagem. Tal funÃ§Ã£o indica a variaÃ§Ã£o de intensidade em todas as direÃ§Ãµes para uma imagem ğ¼(ğ‘¥, ğ‘¦) e pode ser definida pela equaÃ§Ã£o 1.1.
â¤â¦ (1.1) onde: (1.2) 
CapÃ­tulo 1. FundamentaÃ§Ã£o TeÃ³rica 1: Detectores de Pontos de Interesse e ğ‘” Ã© uma funÃ§Ã£o gaussiana definida por: (1.3) A quina pode ser computada por uma anÃ¡lise dos autovalores da matriz ğ‘€ .
Quando os dois autovalores tiverem valores altos, isso indica a existÃªncia de uma quina.
Uma maneira de medir a intensidade dos autovalores sem a necessidade de computar os autovalores de ğ‘€ diretamente, Ã© atravÃ©s da medida de Harris dada por: (1.4) onde ğ‘˜ Ã© uma constante normalmente setada entre 0.04 e 0.06. Quando a medida ğ‘ğ‘–ğ‘› da Eq. 1.4 for alta, a presenÃ§a de quinas tambÃ©m o serÃ¡ (HARRIS; STEPHENS, 1988). Um ponto da imagem Ã© considerado uma quina, se a saÃ­da da aplicaÃ§Ã£o da Eq. 1.4 for maior que um limiar ğ‘¡.
Harris jÃ¡ foi avaliado como sendo o detector com melhor repetibilidade quando comparado com outros detectores de Ãºnica escala (SCHMID; MOHR; BAUCKHAGE, 2000).
1.1.2 Hessian e Laplacian O detector Hessian, proposto inicialmente por (BEAUDET, 1978), Ã© um mÃ©todo bastante usado para detecÃ§Ã£o de blobs em imagens. Para uma imagem ğ¼(ğ‘¥, ğ‘¦), os blobs podem ser calculado pelo determinante da matriz Hessiana: (1.5) O determinante responde aos gradientes em mÃºltiplas direÃ§Ãµes da imagem e tende a revelar blobs de alta curvatura, o que representa uma regiÃ£o distinta. O detector, determinante de Hessian, ou simplesmente detector Hessian Ã© dado selecionando os pontos os quais tem uma saÃ­da com respeito a matriz H maior que um valor de limiar ğ‘¡.
Uma variaÃ§Ã£o do Hessian Ã© a aplicaÃ§Ã£o de um kernel Laplacian o qual Ã© computado pelo traÃ§o da matriz ğ» ( ğ¼ğ‘¥ğ‘¥+ğ¼ğ‘¦ğ‘¦). PorÃ©m o Laplacian tende tambÃ©m a responder a bordas (TUYTELAARS; MIKOLAJCZYK, 2008). Bordas nÃ£o sÃ£o bons pontos de interesse pois, nÃ£o possuem uma aceitÃ¡vel invariÃ¢ncia a rotaÃ§Ã£o (TUYTELAARS; MIKOLAJCZYK, 2008).

1.2. Detectores Invariantes a Escala 1.1.3 ComparaÃ§Ã£o A Figura 1 mostra um exemplo de aplicaÃ§Ã£o do Hessian e Harris em uma imagem.
As blobs podem ser vistos como a Ã¡rea mais elevada em morros de intensidade. As quinas podem ser juntas "T"ou "L", tambÃ©m podendo ter formato mais arredondado.
(b) Harris (c) Hessian Figura 1 â€“ Comportamento da aplicaÃ§Ã£o dos kernels Hessian e Harris para uma imagem teste (1a). (1b) mostra a saÃ­da da medida de Harris (Eq. 1.4). (1c) mostra a saÃ­da do determinante da matriz Hessian ( Eq. 1.5 ) para a imagem teste. Tanto o Hessian como o Harris tem como saÃ­da as regiÃµes de alta curvatura ( Figura por Sojka (2003)).
Percebe-se que hÃ¡ semelhanÃ§a entre ambos, dado que ambos sÃ£o associados a regiÃµes de alto gradiente.
1.2 Detectores Invariantes a Escala A noÃ§Ã£o de escala Ã© crucial na interpretaÃ§Ã£o de uma imagem (LINDEBERG, 1994).
Alguns objetos sÃ³ sÃ£o entidades visuais significativas em uma determinada escala. Sendo assim, uma modelagem explicita de cada nÃ­vel de escala se torna necessÃ¡rio para o pro- 
CapÃ­tulo 1. FundamentaÃ§Ã£o TeÃ³rica 1: Detectores de Pontos de Interesse cessamento (LINDEBERG, 1998). Ou seja, uma imagem nÃ£o mais pode ser representada como uma matriz ğ¼(ğ‘¥, ğ‘¦) e passa a ter um terceiro componente de escala ğ‘ , sendo assim determinada como a funÃ§Ã£o ğ¿(ğ‘¥, ğ‘¦, ğ‘ ).
Para gerar o conjunto espaÃ§os de escala ğ¿(ğ‘¥, ğ‘¦, ğ‘ ), pode-se utilizar o princÃ­pio da difusÃ£o (LINDEBERG, 1994). O qual determina que uma famÃ­lia de escalas ğ¿ pode ser determinada atravÃ©s da equaÃ§Ã£o da difusÃ£o: (1.6) O que representa o fato de que, Ã  medida que a escala se torna menos detalhada, a informaÃ§Ã£o visual tende a se dispersar.
Portanto, para a geraÃ§Ã£o do espaÃ§o de escala de uma imagem ğ¿(ğ‘¥, ğ‘¦, ğ‘ ) deve ser proposta uma equaÃ§Ã£o que atenda a EquaÃ§Ã£o 1.6. Inicialmente, foi adotado que a funÃ§Ã£o gaussiana seria a Ãºnica a ser uma soluÃ§Ã£o da equaÃ§Ã£o 1.6. Posteriormente, outras funÃ§Ãµes foram colocadas como possÃ­veis para geraÃ§Ã£o do espaÃ§o de escala (LINDEBERG, 1997).
Considerando determinada uma escala ğ‘ , definida igual a um parÃ¢metro de difusÃ£o ğœ, a geraÃ§Ã£o de um espaÃ§o de escala ğœ Ã© dada por: (1.7) sendo a funÃ§Ã£o gaussiana ğ‘”(ğ‘¥, ğ‘¦, ğœ) calculada como na Eq.1.3.
De forma a atingir a invariÃ¢ncia a escala, os detectores passam a considerar essa funÃ§Ã£o ğ¿(ğ‘¥, ğ‘¦, ğœ) para se detectar os pontos de interesse. PorÃ©m, (LINDEBERG, 1994) determinou que Ã© possÃ­vel realizar a escolha de uma escala, e tal escala serÃ¡ sempre escolhida independente do ambiente e sem a necessidade de escolha de parÃ¢metros. Caracterizando uma escala onde existe invariÃ¢ncia.
Foi sugerido que os pontos de extremo de funÃ§Ãµes gradientes das estruturas entre as escalas tem propriedades invariantes. Isso representa a escala com o mÃ¡ximo de sensibilidade a funÃ§Ã£o. Tal escala Ã© chamada de escala caracterÃ­stica.
Nesta seÃ§Ã£o apresentam-se alguns detectores invariantes a escala. A ideia de mÃ¡ximo de uma determinada funÃ§Ã£o gradiente entre escalas Ã© usada por todos os mÃ©todos apresentados.
1.2.1 Hessian-Laplace e Hessian-Laplace Umas primeiras extensÃµes para detectores de mÃºltipla escala foram feitas para as as funÃ§Ãµes Harris e Hessian (MIKOLAJCZYK; SCHMID, 2004) Nestes mÃ©todos, o espaÃ§o 
1.2. Detectores Invariantes a Escala de escala Ã© gerado por uma equaÃ§Ã£o gaussiana tal como na Eq. 1.7. Os pontos de extremo entre um conjunto de escalas ğœğ‘› sÃ£o computados conforme a Eq. 1.8.
(1.8) sendo a Eq. 1.8 uma representaÃ§Ã£o da funÃ§Ã£o Laplacian em mÃºltiplas escalas. Desta forma , sÃ£o selecionados os pontos extremos que tem alta reposta a funÃ§Ã£o Harris, para o caso do Harris-Laplace ou da funÃ§Ã£o Hessian para o caso do Hessian-Laplace.
1.2.2 Diference-of-Gaussians(DoG) O detector DoG Ã© uma otimizaÃ§Ã£o a aplicaÃ§Ã£o do Hessian-Laplace. Ã‰ o detector proposto pelo mÃ©todo SIFT (LOWE, 2004).
Ao invÃ©s de computar o Laplacian para cada escala, neste aplica-se o Laplacian pela diferenÃ§a, ğ·(ğ‘¥, ğ‘¦, ğœ), entre mÃºltiplos nÃ­veis do espaÃ§o gaussiano ğ¿(ğ‘¥, ğ‘¦, ğœ). Sendo assim: (1.9) Diversos nÃ­veis de escala sÃ£o gerados. A cada determinado nÃºmero de imagens, chamado oitava, Ã© feito um redimensionamento na imagem. Dentro de uma oitava, as imagens diferentes sÃ£o criadas pela aplicaÃ§Ã£o do filtro gaussiano. A funÃ§Ã£o ğ· Ã© gerada a partir da diferenÃ§a entre nÃ­veis vizinhos. O processo utilizado pelo algoritmo Ã© mostrado na Figura 2.
Para se encontrar a escala caracterÃ­stica, basta encontrar o mÃ¡ximo na funÃ§Ã£o ğ·(ğ‘¥, ğ‘¦, ğœ) variando ğœ. Ao final, os extremos do espaÃ§o, os quais tem baixa resposta Ã  funÃ§Ã£o Hessian sÃ£o eliminados.
1.2.3 Fast Hessian Trata-se de um mÃ©todo que busca fazer uma otimizaÃ§Ã£o ainda maior em relaÃ§Ã£o ao DoG para geraÃ§Ã£o do espaÃ§o de escala (BAY et al., 2008). Trata-se de um filtro que nÃ£o usa o filtro gaussiano para geraÃ§Ã£o do espaÃ§o de escala . Os filtros gaussianos sÃ£o aproximados por filtros caixas. Um filtro caixa basicamente computa a mÃ©dia de uma imagem dado uma janela de convoluÃ§Ã£o, podendo ser computado rapidamente pela utilizaÃ§Ã£o de Imagens Integrais (DERPANIS; LEUNG; SIZINTSEV, 2007).
Ã‰ possÃ­vel neste caso fazer a abordagem de diferenÃ§a de caixas, o que permite juntar a aplicaÃ§Ã£o do filtro Hessian com a geraÃ§Ã£o do espaÃ§o de escala. Uma aproximaÃ§Ã£o do Hessian jÃ¡ Ã© computada diretamente ao se aplicar as diferenÃ§as de caixas.

CapÃ­tulo 1. FundamentaÃ§Ã£o TeÃ³rica 1: Detectores de Pontos de Interesse Figura 2 â€“ O processo para geraÃ§Ã£o do espaÃ§o de escala pelo DoG. Ao invÃ©s de computar o Laplacian para cada escala, o mesmo Ã© estimado pela diferenÃ§a entre escalas consecutivas.
Figura adaptada de (LOWE, 2004).
Para um determinado tamanho de caixa de aresta ğ‘, a resposta do Hessian Ã© dada por: (1.10) A Figura 22 mostra um exemplo de filtros ğ·ğ‘¥ğ‘¥ e ğ·ğ‘¥ğ‘¦ que sÃ£o aplicados. Enquanto aplicar a diferenÃ§a entre caixas, produz o Hessian, a computaÃ§Ã£o em blocos aplica a difusÃ£o na imagem.
Para relacionar com o espaÃ§o gaussiano, basta saber que uma imagem de filtro gaussiano ğœ = 1.2 Ã© equivalente a utilizaÃ§Ã£o de um filtro caixa 9x9. EntÃ£o, para geraÃ§Ã£o 
1.2. Detectores Invariantes a Escala do espaÃ§o de escala basta gerar a resposta de vÃ¡rios tamanhos de caixa ğ‘ = 9, 11, 13..
etc.
Para encontrar os pontos caracterÃ­sticos basta encontrar o mÃ¡ximo para todos os nÃ­veis de escala.
1.2.4 Center Surround Extrema Filters(CenSurE) O Filtro de centro e arredores (AGRAWAL; KONOLIGE; BLAS, 2008) tem uma abordagem similar a utilizada pelo detector Fast Hessian, porÃ©m realizando a diferenÃ§a entre mÃºltiplos nÃ­veis como no caso do DoG. Este processo visa tambÃ©m uma aproximaÃ§Ã£o do Laplacian. Os espaÃ§os de escala sÃ£o criados pela geraÃ§Ã£o de polÃ­gonos de mÃºltiplos tamanhos. Tal como o filtro caixa, um filtro poligonal representa a media atravÃ©s de uma janela de convoluÃ§Ã£o.
De maneira similar ao FastHessian, um filtro de polÃ­gono lado ğ‘ = 2 Ã© equivalente a um espaÃ§o gaussiano de ğœ = 1.88 A Figura 4 mostra alguns tipos de polÃ­gonos usados para gerar o espaÃ§o de escala. Os polÃ­gonos podem ter estruturas estreladas, poligonais, entre outras.
Para gerar o Laplacian uma imagem a qual teve aplicada um filtro maior Ã© subtraÃ­da de uma imagem com um polÃ­gono menor aplicado.
O mÃ¡ximo deste espaÃ§o gerado Ã© encontrado como pontos de interesse.
Por fim uma funÃ§Ã£o Harris Ã© aplicada, eliminando os pontos que obtiveram baixa resposta. Isso segue, pelo fato do Harris ter sido determinado como uma funÃ§Ã£o com melhor repetibilidade.
1.2.5 KAZE A ideia do KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) Ã© gerar um espaÃ§o de escala suavizando de maneira diferente em locais com alta intensidade de bordas.
Tal abordagem trata-se de uma difusÃ£o nÃ£o linear.

CapÃ­tulo 1. FundamentaÃ§Ã£o TeÃ³rica 1: Detectores de Pontos de Interesse A geraÃ§Ã£o do espaÃ§o de escala Ã© dada pela soluÃ§Ã£o para equaÃ§Ã£o da difusÃ£o nÃ£o linear: (1.11) Abordagens que aplicam uma difusÃ£o nÃ£o linear podem obter resultados melhores para o caso da segmentaÃ§Ã£o de imagens e remoÃ§Ã£o de ruÃ­do (WEICKERT; ROMENY; VIERGEVER, 1998).
(1.12) sendo k um parÃ¢metro que controla o nÃ­vel de difusÃ£o. Alcantarilla, Bartoli e Davison (2012) propÃ´s uma terceira formulaÃ§Ã£o de kernel: (1.13) Levando em conta os kernels definidos, cada nÃ­vel do espaÃ§o de escala ğ¿ğ‘˜(ğ‘¥, ğ‘¦, ğ‘¡) Ã© gerado pela aplicaÃ§Ã£o da seguinte funÃ§Ã£o recursiva: (1.14) onde ğ‘¡ Ã© um parÃ¢metro de escala temporal facilmente relacionado a ğœ. Ao final, tambÃ©m sÃ£o desconsideradas as regiÃµes que tem baixa resposta a aplicaÃ§Ã£o de uma matriz Hessian.
1.2.6 ComparaÃ§Ã£o A Figura 5 apresenta exemplos de geraÃ§Ã£o do espaÃ§o de escala baseado em 4 funÃ§Ãµes diferentes. O gaussiano, utilizado pelo DoG, Harris-Laplace e Hessian-Laplace, a funÃ§Ã£o de caixas utilizada pelo FastHessian, uma funÃ§Ã£o poligonal estrelar de seis lados, utilizadas pelo CenSurE e a funÃ§Ã£o de difusÃ£o anisotrÃ³pica utilizado pelo KAZE.
Pode-se perceber que determinadas estruturas se mantem mais que outras para espaÃ§os diferentes. Claramente algumas aplicaÃ§Ãµes se beneficiariam do uso de um espaÃ§o de escala diferente. No CapÃ­tulo 5 se estudam os melhores detectores para o campo de estudo de imagens subaquÃ¡ticas com presenÃ§a de turbidez.

1.2. Detectores Invariantes a Escala 
2 FundamentaÃ§Ã£o TeÃ³rica 2: ClassificaÃ§Ã£o de Imagens Utilizando Contexto Este capÃ­tulo apresenta a fundamentaÃ§Ã£o teÃ³rica utilizada neste trabalho associada a utilizaÃ§Ã£o de contexto para a classificaÃ§Ã£o de imagens. Inicialmente sÃ£o postuladas as definiÃ§Ãµes de como representar as relaÃ§Ãµes de contexto em uma imagem. TambÃ©m Ã© feita a definiÃ§Ã£o de classificaÃ§Ã£o de imagens incorporando o conceito de contexto, bem como uma revisÃ£o dos mÃ©todos de visÃ£o computacional que os tratam sÃ£o apresentados. Um destaque Ã© dado aos mÃ©todos que utilizam os Conditional Random Field (CRF).
2.1 UtilizaÃ§Ã£o do Contexto em VisÃ£o Computacional Existem diversos descritores capazes de discriminar os objetos com base em suas caracterÃ­sticas visuais, como textura, cor e forma. Tais caracterÃ­sticas buscam capturar a variabilidade dos objetos para sua classificaÃ§Ã£o (GALLEGUILLOS; BELONGIE, 2010).
PorÃ©m, estudos envolvendo o sistema perceptivo visual humano trazem novas perspectivas no que tange a como as tÃ­picas configuraÃ§Ãµes dos objetos em uma cena podem contribuir para a percepÃ§Ã£o, de tal forma que o reconhecimento de objetos no sistema visual humano considera nÃ£o somente os aspectos locais referentes a interpretaÃ§Ã£o da cena, mas tambÃ©m a situaÃ§Ã£o geral onde um objeto foi encontrado.
Biederman (BIEDERMAN; MEZZANOTTE; RABINOWITZ, 1982) estabelece alguns tipos de relaÃ§Ãµes contextuais importantes que sÃ£o fundamentais para o reconhecimento de objetos no sistema visual humano. Estas relaÃ§Ãµes estabelecem nÃ­veis semÃ¢nticos tais como: i suporte (onde os objetos tendem a sustentar ou ser sustentados por outros), interposiÃ§Ã£o (relativo a relaÃ§Ãµes de oclusÃ£o), ii probabilidade (objetos tendem a aparecer na mesma situaÃ§Ã£o), iii posiÃ§Ã£o (objetos tendem a ficar em determinada posiÃ§Ã£o relativa com outros) e iv tamanho (objetos tendem a ter certo tamanho se comparado com outros em uma dada escala).
VÃ¡rios modelos computacionais jÃ¡ fizeram uso destas relaÃ§Ãµes semÃ¢nticas as quais podem ser usadas para classificar objetos. Essas relaÃ§Ãµes normalmente sÃ£o resumidas em trÃªs tipos de contexto principais: semÃ¢ntico, posiÃ§Ã£o e escala.
O contexto semÃ¢ntico, tende a incluir as relaÃ§Ãµes de ocorrÃªncia entre objetos. Ao encontrar um determinado objeto em uma cena, o qual se possui certeza de sua presenÃ§a, considera-se uma maior probabilidade de presenÃ§a de outros objetos. Por exemplo, a existÃªncia de um bule de chÃ¡ implica em uma maior probabilidade de existÃªncia de 
CapÃ­tulo 2. FundamentaÃ§Ã£o TeÃ³rica 2: ClassificaÃ§Ã£o de Imagens Utilizando Contexto outros utensÃ­lios de cozinha como talheres ou um fogÃ£o (FISCHLER; ELSCHLAGER, 1973) (HANSON; RISEMAN, 1978). Como exemplo, Rabinovich et al. (2007), incorporou a informaÃ§Ã£o anotada pelos Google Sets indicando objetos que tendem a aparecer em situaÃ§Ãµes semelhantes de forma a melhorar a classificaÃ§Ã£o.
O contexto de posiÃ§Ã£o indica que os objetos tendem a ter uma relaÃ§Ã£o espacial na imagem. Como por exemplo, o cÃ©u em uma imagem tende a estar acima do chÃ£o.
JÃ¡ o contexto de escala esta associado as relaÃ§Ãµes de tamanho entre objetos na cena (TORRALBA, 2003) (KUMAR; HEBERT, 2005) (TORRALBA; MURPHY; FREEMAN, 2004). Pois, existe jÃ¡, uma relaÃ§Ã£o de tamanho tÃ­pica que os objetos possuem entre eles (GALLEGUILLOS; BELONGIE, 2010).
Para incluir tais tipos de contexto na classificaÃ§Ã£o de imagens, alguns aspectos fundamentais devem ser considerados. Primeiramente, qual nÃ­vel de contexto serÃ¡ classificado. Se as relaÃ§Ãµes a serem consideradas serÃ£o apenas entre objetos prÃ³ximos, ou no domÃ­nio geral de uma imagem. Ou ainda, por meio de que tipo de estrutura visual encontrada na imagem, a interaÃ§Ã£o de contexto ocorre.
2.1.1 NÃ­veis de Contexto Os sistemas que adicionam contexto na classificaÃ§Ã£o normalmente dividem o contexto em dois nÃ­veis (GALLEGUILLOS; BELONGIE, 2010): local e global.
O contexto local Ã© onde somente as interaÃ§Ãµes de vizinhanÃ§a sÃ£o utilizadas para adicionar o contexto a um determinado objeto. O contexto local estÃ¡ relacionado aos objetos que cercam outros objetos. Vale notar que a aplicaÃ§Ã£o de contexto Ã© recursiva, ou seja, a prÃ³pria vizinhanÃ§a possuÃ­ tambÃ©m suas prÃ³prias relaÃ§Ãµes de contexto. Isso faz que nÃ£o somente as relaÃ§Ãµes estritamente prÃ³ximas faÃ§am parte do contexto local.
O contexto global estÃ¡ relacionado as interaÃ§Ãµes de contexto presentes ao longo de toda a imagem utilizada. O contexto global normalmente estÃ¡ associado ao ambiente onde os objetos estÃ£o posicionados. Por exemplo, se as relaÃ§Ãµes contextuais indicam que os objetos estÃ£o em uma cozinha, isso implica em uma alta probabilidade de um dos objetos ser uma panela.
2.1.2 InteraÃ§Ãµes de Contexto NÃ£o necessariamente cada componente da imagem deve ser um objeto com um conceito semÃ¢ntico relacionado. Na literatura se estabelecem trÃªs nÃ­veis bÃ¡sicos de interaÃ§Ã£o nos quais o contexto pode ser integrado (GALLEGUILLOS; BELONGIE, 2010).
AlÃ©m de objetos, as interaÃ§Ãµes tambÃ©m se dÃ£o entre pixeis ou regiÃµes.
A interaÃ§Ã£o em nÃ­vel de pixel estabelece que pixeis vizinhos tendem a ter a mesma classe. Tais interaÃ§Ãµes ajudam a inferir as bordas existentes na imagem. Vale notar a 
2.2.
IntegraÃ§Ã£o de Contexto Na ClassificaÃ§Ã£o utilizaÃ§Ã£o de tais interaÃ§Ãµes sÃ£o mais computacionalmente intensas, dado que existem diversas combinaÃ§Ãµes entre pixeis da imagem. Ressalta-se que o uso de nÃ­veis mais baixos de contexto nÃ£o necessariamente implica na perda da informaÃ§Ã£o semÃ¢ntica. Ou seja, encontrar que pixeis de determinado objeto sÃ£o prÃ³ximos, Ã© tambÃ©m identificar a alta probabilidade de proximidade de tais objetos.
O conceito de pixel pode ser estendido para o nÃ­vel de representaÃ§Ã£o de regiÃµes. Ao utilizar regiÃµes, tende-se a reduzir a complexidade levantada pelo grande nÃºmero de pixeis existentes na imagem. Uma estrutura de regiÃ£o bastante utilizada Ã© a consideraÃ§Ã£o de pequenas regiÃµes adaptadas a estrutura local da imagem. Tais regiÃµes chamadas, superpixeis, capturam a redundÃ¢ncia dos dados, facilitando a utilizaÃ§Ã£o do contexto (FULKERSON; VEDALDI; SOATTO, 2009).
JÃ¡ a interaÃ§Ã£o em nÃ­vel de objetos Ã© a representaÃ§Ã£o mais natural para reconhecimento de contexto humano (BAR, 2004). Sabendo-se jÃ¡ a classe do objeto Ã© possÃ­vel treinar as relaÃ§Ãµes de contexto. No trabalho de (TORRALBA; MURPHY; FREEMAN, 2004), os objetos mais fÃ¡ceis de classificar ajudam, atravÃ©s do contexto, a obter a classe de objetos mais difÃ­ceis. Se por um lado usar objetos tende a capturar melhor as interaÃ§Ãµes existentes na cena, o uso do contexto em nÃ­vel de objetos implica jÃ¡ o conhecimento prÃ©vio ( classificaÃ§Ã£o) dos objetos existentes na imagem. A interaÃ§Ã£o entre regiÃµes, por outro lado, ajuda a reduzir a quantidade de combinaÃ§Ãµes existentes na interaÃ§Ã£o de pixeis, sem a necessidade de um conhecimento maior sobre a imagem (GALLEGUILLOS; BELONGIE, 2010).
2.2 IntegraÃ§Ã£o de Contexto Na ClassificaÃ§Ã£o Nesta seÃ§Ã£o sÃ£o apresentadas algumas abordagens para integraÃ§Ã£o do contexto na classificaÃ§Ã£o de imagens. SÃ£o escolhidos mÃ©todos com integraÃ§Ã£o baseada em superpixeis, com foco para integraÃ§Ã£o local de contexto. Quanto aos tipos de contexto, por considerar o nÃ­vel de interaÃ§Ã£o como superpixeis, os principais tipos integrados sÃ£o os de posiÃ§Ã£o e escala.
Nesta seÃ§Ã£o sÃ£o especificadas duas formas de incorporar o contexto. Utilizando a vizinhanÃ§a de um superpixel ğ‘ ğ‘ diretamente no classificador ou atravÃ©s de modelos probabilÃ­sticos grÃ¡ficos (MPGs).

CapÃ­tulo 2. FundamentaÃ§Ã£o TeÃ³rica 2: ClassificaÃ§Ã£o de Imagens Utilizando Contexto 2.2.1 Integrando contexto com base em Classificadores As informaÃ§Ãµes locais advindas de uma anÃ¡lise de contexto podem ser incorporadas diretamente aos sistemas de classificaÃ§Ã£o, considerando uma janela de contexto em torno da regiÃ£o a ser classificada (Figura 6) Fink e Perona (2003) incorporou o contexto local usando a janela da regiÃ£o para treinamento de classificador fracos em um esquema de boosting.
Kruppa e Schiele (2003), visando melhorar a classificaÃ§Ã£o de rostos, incorporou a descriÃ§Ã£o dos descritores da vizinhanÃ§a local da face em um sistema Naive Bayes O principal problema Ã© que tais aplicaÃ§Ãµes nÃ£o levam em conta as possÃ­veis correlaÃ§Ãµes entre os vizinhos. Este problema Ã© demonstrado na Figura 6, a vizinhanÃ§a sÃ³ afeta o que foi considerado no centro da imagem, sem afetar a si prÃ³pria. Tais problemas sÃ£o parcialmente resolvidos criando-se interaÃ§Ãµes mais conectadas, como no caso dos modelos probabilÃ­sticos grÃ¡ficos a serem explicados na prÃ³xima seÃ§Ã£o.
Figura 6 â€“ Janela considerada para a classificaÃ§Ã£o usando contexto. No caso da integraÃ§Ã£o de contexto diretamente nos classificadores (Fig. 6a), nÃ£o sÃ£o considerada as relaÃ§Ãµes entre a vizinhanÃ§a com si prÃ³pria (Fig. 6b). Ou seja, se existem propriedades correlacionadas na vizinhanÃ§a.
2.2.2 Integrando contexto com base em Modelos ProbabilÃ­sticos GrÃ¡ficos Nesta seÃ§Ã£o, serÃ£o apresentados os principais conceitos associados aos Modelos ProbabilÃ­sticos GrÃ¡ficos (MPGs) e seu uso na integraÃ§Ã£o contextual em classificaÃ§Ã£o de imagens.
Uma forma natural de representar a dependÃªncia entre variÃ¡veis Ã© utilizando os Modelos Probabilisticos GrÃ¡ficos (MPGs)(SUTTON; MCCALLUM, 2006). Estes modelos representam algumas fatorizaÃ§Ãµes de uma funÃ§Ã£o de probabilidades como o Markov Random Fields MRF ou Conditional Random Fields CRF.

2.2.
IntegraÃ§Ã£o de Contexto Na ClassificaÃ§Ã£o Um MPG Ã© usado para capturar a correlaÃ§Ãµes existentes dentro de um conjunto de dados. Baseado neste modelo, Ã© possÃ­vel calcular uma funÃ§Ã£o potencial. Esta abordagem, quando baseada em modelos probabilÃ­sticos nÃ£o direcionadas, Ã© usada no MRF e no CRF (SUTTON; MCCALLUM, 2006).
O MRF modela a funÃ§Ã£o de probabilidade ğ‘(ğ‘¦, ğ‘¥) de um dado conjunto de rÃ³tulos ğ‘¦ e os conjunto de descritores de entrada ğ‘¥. Esse modelo necessita um alto custo computacional para classificaÃ§Ã£o de imagens (CARBONETTO; FREITAS; BARNARD, 2004).
Ainda, dado que deve seguir a premissa de Markov, nenhuma caracterÃ­stica global deve ser adicionada. Paro caso de Markov, a computaÃ§Ã£o de ğ‘(ğ‘¦, ğ‘¥) necessita a computaÃ§Ã£o de ğ‘(ğ‘¦) e tambÃ©m ğ‘(ğ‘¥), o qual nÃ£o se tem conhecimento sobre, pois estÃ¡ relacionado a probabilidade das descriÃ§Ãµes de entrada aparecerem.
Uma abordagem mais comumente utilizada para classificaÃ§Ã£o de imagens Ã© o modelo CRF. Neste modelo, somente a distribuiÃ§Ã£o condicional, ğ‘(ğ‘¦|ğ‘¥) , Ã© computada. Normalmente o CRF tem uma melhor associaÃ§Ã£o aos dados, dado que nÃ£o Ã© necessÃ¡rio computar a probabilidade a priori para os dados de entrada (ğ‘(ğ‘¥)) (SUTTON; MCCALLUM, 2006).
(2.1) Os pesos ğ‘¤ğ‘¢ e ğ‘¤ğ‘™ facilitam a calibraÃ§Ã£o empÃ­rica do modelo, determinando a importÃ¢ncia de cada termo na Eq. 2.1. A Figura 7, mostra uma representaÃ§Ã£o visual de parte da modelagem usando CRF para a aplicaÃ§Ã£o de interesse que Ã© a classificaÃ§Ã£o e segmentaÃ§Ã£o de imagens.
No modelo CRF tambÃ©m Ã© possÃ­vel incluir diferentes aspectos baseado em proprie- 
CapÃ­tulo 2. FundamentaÃ§Ã£o TeÃ³rica 2: ClassificaÃ§Ã£o de Imagens Utilizando Contexto Figura 7 â€“ A representaÃ§Ã£o grÃ¡fica de um modelo CRF. Os quadrados em vermelho (ğœ™ğ‘¢ ğ‘– (ğ‘¥ğ‘–, ğœƒğ‘¢)) sÃ£o os fatores unitÃ¡rios calculados com o resultado dado pelo classificador.
Os quadrados em azul sÃ£o os fatores locais computados em cada aresta e utilizados para introduzir informaÃ§Ã£o contextual. Os circulos verdes representam os superpixeis sendo classificados.
dades da imagem. A funÃ§Ã£o de bordas de Potts (SHOTTON et al., 2009) (FULKERSON; VEDALDI; SOATTO, 2009) reforÃ§a nodos que nÃ£o sÃ£o separados por bordas a pertencerem a mesma classe. Isto Ã© implementado incluindo o atributo ğ‘”ğ‘–ğ‘— em ğœ™ğ¿ ğ‘– . Onde ğ‘”ğ‘–ğ‘— Ã© definido pela Eq. 2.2.
(2.2) 2.2.2.1 O Problema da InferÃªncia EstatÃ­stica Dado um modelo probabilÃ­stico grÃ¡fico e uma funÃ§Ã£o de probabilidades, uma das principais dificuldades Ã© encontrar um conjunto de rÃ³tulos ğ¿â€² que maximize uma funÃ§Ã£o de probabilidades como a funÃ§Ã£o da Eq. 2.1. Em outras palavras, seria encontrar a configuraÃ§Ã£o de classificaÃ§Ã£o na imagem mais provÃ¡vel, dado um modelo probabilÃ­stico. Este problema Ã© considerado NP-Hard, dado que existe uma combinaÃ§Ã£o de rÃ³tulos exponencialmente grande. O problema de inferÃªncia Ã© especialmente difÃ­cil quando se utiliza a abordagem MRF, dado que existem muito mais casos para computar a distribuiÃ§Ã£o de probabilidades conjunta.
Algumas aproximaÃ§Ãµes sÃ£o introduzidas de forma reduzir o custo computacional.

2.3. Trabalhos utilizando Modelos ProbabilÃ­sticos GrÃ¡ficos Por exemplo, a abordagem loopy belief propagation (LBP) propaga as informaÃ§Ãµes de dis-tribuiÃ§Ã£o de probabilidades dos vÃ©rtices ao longo do grafo atravÃ©s de mensagens e obtem boa performance (WEISS, 2000), entretanto, a convergÃªncia nÃ£o pode ser garantida. Outra estratÃ©gia Ã© o corte de grafos baseado no alpha-cut (BOYKOV; JOLLY, 2001). Este algoritmo produz melhores resultados apesar de possuir maior complexidade.
2.2.2.2 Aprendizado de parÃ¢metros Ã‰ necessÃ¡rio estimar os parÃ¢metros ğœƒğ‘¢ and ğœƒğ‘™. Estes parÃ¢metros sÃ£o a matriz de covariÃ¢ncia que representa as tendÃªncias das classes serem vizinhas (ğœƒğ‘™), a matriz ğœƒğ‘™ esta associada Ã s relaÃ§Ãµes espaciais entre as classes.
Os parÃ¢metros podem ser estimados utilizando a tÃ©cnica de mÃ¡ximo a-posteriori (MAP). Esta tÃ©cnica seleciona os parÃ¢metros que maximizam os resultados para a Eq.
2.1. Isto Ã© custoso, dado que existe a necessidade de computar a inferÃªncia diversas vezes.
PorÃ©m, Ã© possÃ­vel realizar a estimativa, parte a parte, dividindo os parÃ¢metros os quais maximizar (SHOTTON et al., 2009), entÃ£o reduzindo o custo computacional.
A Figura 10 mostra um exemplo de uma matriz de covariÃ¢ncia estimada, sendo quanto mais claro for o quadrado mais relacionadas espacialmente as classes estÃ£o. Ã‰ possÃ­vel perceber que a classe B tem uma probabilidade muito maior de ficar prÃ³xima ao C mas nÃ£o necessariamente a classe E.
2.3 Trabalhos utilizando Modelos ProbabilÃ­sticos GrÃ¡ficos Diversos trabalhos jÃ¡ utilizaram os modelos probablÃ­stico grÃ¡ficos (MPGs) para adiÃ§Ã£o de contexto. Apresenta-se aqui alguns relevantes para elaboraÃ§Ã£o deste trabalho.
Carbonetto, Freitas e Barnard (2004) foi um dos primeiros trabalhos a usar MPGs para classificaÃ§Ã£o de imagens . O autor utilizou uma versÃ£o usando um modelo MRF com o contexto local e propÃ´s uma forma de reduzir o tempo de inferÃªncia usando uma tÃ©cnica de expectation maximization (EM) (DEMPSTER; LAIRD; RUBIN, 1977).
Shotton et al. (2009) utilizou uma combinaÃ§Ã£o de descritores diretamente dos descritores de textura, cor e localizaÃ§Ã£o como fatores unÃ¡rios e adicionou a informaÃ§Ã£o de contexto local usando a medida de potts. O nÃ­vel de interaÃ§Ã£o foi baseado em regiÃµes utilizando um novo esquema de representaÃ§Ã£o de imagens atravÃ©s "canais de textura". A inferÃªncia foi feita utilizando o algoritmo de alpha-cut (BOYKOV; JOLLY, 2001).
Fulkerson, Vedaldi e Soatto (2009), utiliza uma representaÃ§Ã£o usando SIFT (LOWE, 2004) para bag-of-words (SIVIC; ZISSERMAN, 2006) para o fator unÃ¡rio. Como nÃ­vel de interaÃ§Ã£o, foram utilizadas regiÃµes baseadas em superpixeis. Em seguida, aplica-se um sistema CRF similar ao proposto por (SHOTTON et al., 2009).

CapÃ­tulo 2. FundamentaÃ§Ã£o TeÃ³rica 2: ClassificaÃ§Ã£o de Imagens Utilizando Contexto Koltun e Vladlen (2011), utiliza um CRF com uma maior conectividade entre os vÃ©rtices e utiliza um nÃ­vel de interaÃ§Ã£o por pixel. Neste caso, dado o conjunto de pixeis, cada par possÃ­vel de pixeis Ã© conectado. O aumento da complexidade de inferÃªncia Ã© resolvido com um sistema aproximado baseado em mÃ©dias.
Boix et al. (2012) propÃµem adicionar o contexto global ao CRF. Para isso, a EquaÃ§Ã£o 2.1 pode ser extendida para a Eq. 2.3.
onde a porÃ§Ã£o ğœ™ğº 
2.4. SumÃ¡rio mado seu conjunto de parÃ¢metros ğœƒğ‘”, indica as configuraÃ§Ãµes mais provÃ¡veis entre todas as porÃ§Ãµes da imagem. Com tal modelo, as relaÃ§Ãµes de contexto global, como o conjunto tÃ­pico de objetos possÃ­veis em cena, podem ser incorporadas.
Por fim, Lucchi et al. (2011) critica o funcionamento do CRF, comparando a utilizaÃ§Ã£o do CRF com pontos de interesse globais (BOIX et al., 2012), concluindo que nÃ£o hÃ¡ ganho significativo. AlÃ©m disso, o contexto local adicionado pelo CRF a tende apenas melhorar a suavizaÃ§Ã£o da classificaÃ§Ã£o local. Ou seja, dado uma pequena regiÃ£o da imagem, as variabilidade de classes Ã© reduzida.
2.4 SumÃ¡rio Este capÃ­tulo apresentou os conceitos de utilizaÃ§Ã£o de contexto para visÃ£o computacional. Apresentou-se em quais nÃ­veis o contexto pode ser utilizado, sendo eles globais ou locais. TambÃ©m foi apresentado quais nÃ­veis de interaÃ§Ã£o o contexto podem se dar, sendo eles no nÃ­vel de pixeis, regiÃµes ou objetos.
Nesse Ã¢mbito, formalizou-se a classificaÃ§Ã£o utilizando contexto, considerando o nÃ­vel de interaÃ§Ã£o baseado em regiÃµes, no caso, superpixeis. Em seguida, foram apresentadas formas de utilizar o contexto. Primeiramente foram apresentadas formas de aplicar o contexto diretamente no classificador. Em seguida, foi apresentado o uso de modelos probabilÃ­sticos grÃ¡ficos para a aplicaÃ§Ã£o de contexto.
Por fim, alguns dos principais trabalhos em modelos probabilÃ­sticos grÃ¡ficos foram apresentados.

3 ClassificaÃ§Ã£o Baseada em Contexto utilizando GeoestatÃ­stica Tendo em vista as limitaÃ§Ãµes existentes no CRF (LUCCHI et al., 2011) e o conhecimento obtido atravÃ©s de estudos em GeoestatÃ­stica, neste capÃ­tulo, busca-se propor um novo mÃ©todo para adiÃ§Ã£o de contexto baseado em GeoestatÃ­stica.
Tal abordagem agrega duas Ã¡reas com aplicaÃ§Ãµes distintas mas conceitos semelhantes. No campo da modelagem geolÃ³gica, uma abordagem baseada em geostatÃ­stica primeiramente busca modelar a variabilidade espacial de uma determinada medida com o objetivo de interpolar este comportamento para Ã¡reas desconhecidas (CARLE; FOGG, 1996). Esta estratÃ©gia Ã© bastante utilizada para aplicaÃ§Ãµes como modelagem de reservatÃ³rios em campos de de extraÃ§Ã£o Ã³leo (BEATTIE; MILLS; MAYO, 1998) ou mapeamento geolÃ³gico (PURKIS; VLASWINKEL; GRACIAS, 2012).
PorÃ©m, neste trabalho busca-se tambÃ©m mostrar que este conceito se aplica para o caso de adiÃ§Ã£o de contexto classificaÃ§Ã£o de imagens. A abordagem apresentada Ã© capaz de assegurar a suavizaÃ§Ã£o de estruturas espaciais de maneira similar que o CRF, porÃ©m, o mÃ©todo proposto, tambÃ©m considera correlaÃ§Ãµes em longa distÃ¢ncia entre rÃ³tulos.
3.1 VisÃ£o Geral da Proposta A EquaÃ§Ã£o 3.1 apresenta a adiÃ§Ã£o do contexto espacial utilizando GeoestatÃ­stica: (3.1) sabe-se que a probabilidade, ğ‘ƒ de um dado conjunto de rÃ³tulos ğ¿, Ã© dada pela soma ponderada, pelos pesos ğ‘¤ğ‘¢ e ğ‘¤ğ‘™, das probabilidades unÃ¡ria ğ‘ƒğ‘¢(ğ¿|ğœƒğ‘¢), da parte segmentada, e a probabilidade do contexto local ğ‘ƒğ‘™(ğ¿|ğ‘Š). A matriz W estÃ¡ associada ao peso atribuÃ­do aos superpixeis da vizinhanÃ§a. ğœƒğ‘¢ estÃ¡ associado aos parÃ¢metros de usados para obtenÃ§Ã£o da distribuiÃ§Ã£o unÃ¡ria.
Como nÃ­vel de interaÃ§Ã£o, parte-se de uma segmentaÃ§Ã£o baseada em superpixeis em um grid retangular e uniforme onde cada superpixel tem aproximadamente o mesmo tamanho. O sistema de classificaÃ§Ã£o proposto neste capÃ­tulo, Ã© mostrado na Figura 10.
Nesta proposta, o nÃ­vel de interaÃ§Ã£o, em uma imagem segmentada ocorre atravÃ©s de Turbopixels (LEVINSHTEIN et al., 2009).
No nÃ­vel unÃ¡rio ğ‘ƒğ‘¢(ğ¿|ğœƒğ‘¢), somente as informaÃ§Ãµes visuais descritas de um Ãºnico 
CapÃ­tulo 3. ClassificaÃ§Ã£o Baseada em Contexto utilizando GeoestatÃ­stica superpixel sÃ£o relevantes para a classificaÃ§Ã£o do mesmo. Na seÃ§Ã£o 3.2, mostra-se a computaÃ§Ã£o do nÃ­vel unÃ¡rio e a necessidade do mesmo de produzir uma distribuiÃ§Ã£o confiÃ¡vel.
No nÃ­vel local ğ‘ƒğ‘™(ğ¿|ğ‘Š), se considera as conexÃµes de uma determinada Ã¡rea onde medidas estatÃ­sticas sÃ£o utilizadas (Circulo Azul Fig. 10). O nÃ­vel ğ‘ƒğ‘™(ğ¿|ğ‘Š) Ã© apresentado na seÃ§Ã£o 3.4.
3.2 NÃ­vel UnÃ¡rio ğ‘ƒğ‘¢(ğ¿|ğœƒğ‘¢) Para o sistema proposto, o foco da classificaÃ§Ã£o unÃ¡ria Ã© obter uma distribuiÃ§Ã£o de probabilidades previa para cada superpixel. Essa probabilidade a priori vai ser usada para inferir a vizinhanÃ§a.
Em um dado superpixel o qual pode ser classificado como um dentre um conjunto onde âˆ‘ï¸€ ğ‘ƒğ‘¢(ğ¿|ğœƒğ‘¢) = 1. Onde ğœƒğ‘¢ Ã© conjunto de parÃ¢metros usados para se ter essa saÃ­da.
de rÃ³tulos ğ¿ = ğ‘™1, ğ‘™2..ğ‘™ğ‘› busca-se obter uma saÃ­da ğ‘ƒğ‘¢(ğ¿|ğœƒğ‘¢) = ğ‘ƒğ‘¢(ğ‘™1|ğœƒğ‘¢), ğ‘ƒğ‘¢(ğ‘™2|ğœƒğ‘¢)...ğ‘ƒğ‘¢(ğ‘™ğ‘›|ğœƒğ‘¢) Para se chegar em tal resultado, a geraÃ§Ã£o do nÃ­vel unÃ¡rio Ã© dividida em duas etapas. A primeira corresponde ao treinamento da funÃ§Ã£o de discriminaÃ§Ã£o ğ‘“(ğ‘¥), do classificador. No caso, Ã© feito o treinamento de um kernel linear para uma Support Vector Machine (SVM). A segunda etapa Ã© a determinaÃ§Ã£o das curvas de confianÃ§a, que corresponde ao grau de certeza da classificaÃ§Ã£o. Ou seja, o grau de certeza ğ¶ğ‘™ğ‘– Ã© dado como uma 3.2. NÃ­vel UnÃ¡rio ğ‘ƒğ‘¢(ğ¿|ğœƒğ‘¢) 
funÃ§Ã£o treinada, e Ã© usado para gerar ğ‘ƒğ‘¢(ğ¿|ğœƒğ‘¢) (ABFALG et al., 2007).
3.2.1 Classificador Como classificador, foi utilizado uma Support Vector Machine(SVM) com um kernel linear. A ideia do algoritmo Ã© encontrar uma funÃ§Ã£o de hiperplano ğ‘“ğ‘™ğ‘–(ğ‘¥), para cada classe ğ‘™ğ‘– que separa linearmente um conjunto de dados previamente rotulados, porÃ©m maximizando uma determinada margem. Trata-se de uma abordagem de classificaÃ§Ã£o supervisionada.
Para dada aplicaÃ§Ã£o Ã© necessÃ¡rio que o classificador produza uma distÃ¢ncia de um objeto Ã  borda de classe mais prÃ³xima a borda entre classes (ABFALG et al., 2007). Tal resultado Ã© obtido diretamente pelo SVM dado que sua funÃ§Ã£o de hiperplano jÃ¡ maximiza a margem entre classes. A saÃ­do numÃ©rica do SVM jÃ¡ Ã© prÃ³pria para se ter um certo grau de confianÃ§a do classificador.
Figura 10 â€“ Figura do separador linear obtido pelo treinamento do SVM. Dado os conjuntos de dados jÃ¡ rotulados ( Azuis e Vermelhos), o SVM determina o separador de mÃ¡xima margem. A saÃ­do numÃ©rica do SVM jÃ¡ Ã© prÃ³pria para se ter um certo grau de confianÃ§a do classificador.
3.2.2 Treinando Curvas de ConfianÃ§a Somente as distÃ¢ncias de saÃ­da do SVM (CRISTIANINI; SHAWE-TAYLOR, 2000), nÃ£o estabelecem diretamente o grau de confianÃ§a de uma classificaÃ§Ã£o (ABFALG et al., 2007) . Ou seja, uma distÃ¢ncia de valor nÃºmero 5 para o SVM pode ser para alguns casos uma saÃ­da confiÃ¡vel, para outros nÃ£o. Ã‰ necessÃ¡rio treinar para quais distÃ¢ncias existe uma 
CapÃ­tulo 3. ClassificaÃ§Ã£o Baseada em Contexto utilizando GeoestatÃ­stica grande probabilidade da prediÃ§Ã£o ser correta. Isso depende do dataset que foi utilizado, da classe (rÃ³tulo) e tambÃ©m do classificador.
O estudo apresentado por Platt (PLATT, 1999) demonstra que comportamento sigmoidal pode modelar a distribuiÃ§Ã£o de probabilidade do SVM.
Sendo assim, para cada classe ğ‘™ğ‘– Ã© feito um ajuste de uma funÃ§Ã£o sigmoidal ğ¶ğ‘™ğ‘–. Esta funÃ§Ã£o ğ¶ğ‘™ğ‘– nÃ£o mais retorna uma distÃ¢ncia e sim uma probabilidade de uma determinada entrada na funÃ§Ã£o ğ‘“ğ‘™ğ‘–(ğ‘¥) ser correta.
A Figura 11 apresenta a saÃ­da esperada para a curva de confianÃ§a treinada ğ¶ğ‘™ğ‘–, para um dado rÃ³tulo ğ‘™ğ‘–. Dado um conjunto de validaÃ§Ã£o em que jÃ¡ se possui os retornos ğ‘“ğ‘™ğ‘–(ğ‘¥), o treinamento Ã© feito da seguinte forma: ObtÃ©m-se os pontos em azul os quais indicam a porcentagem de acertos que se tem utilizando apenas as parcelas de dados as quais seu retorno vindo do classificador (ğ‘“ğ‘™ğ‘–(ğ‘¥)) Ã© de no mÃ¡ximo o que Ã© mostrado no eixo ğ‘¥. Por exemplo, na Figura 11, para um conjunto de dados com uma distÃ¢ncia do classificador(ğ‘“ğ‘™ğ‘–(ğ‘¥)) de atÃ© dois, tem-se uma porcentagem de acerto de 70%. Dado esse conjunto de pontos, o algoritmo de Levenberg-Marquardt (MARQUARDT, 1963) de otimizaÃ§Ã£o Ã© utilizado para encontrar os coeficientes, ğ›¼ğ‘˜ e ğ›½ğ‘˜ da funÃ§Ã£o sigmoidal: (3.2) onde ğ‘ğ‘™ğ‘– Ã© uma constante de normalizaÃ§Ã£o para a classe ğ‘™ğ‘–. A funÃ§Ã£o inicia de 0.5 pois Ã© a probabilidade inicial de uma classe ser acertada aleatoriamente. A abordagem proposta contrasta com a proposta apresentada por ABfalg et al. (2007) por propor uma curva de confianÃ§a para cada classe. Isso tambÃ©m leva em conta as diferenÃ§as existentes em cada classe. ğœƒğ‘¢ estÃ¡ relacionado aos parÃ¢metros ğ›¼ğ‘˜ e ğ›½ğ‘˜ de ğ‘ƒğ‘¢(ğ¿|ğœƒğ‘¢).
Figura 11 â€“ GrÃ¡fico mostrando a probabilidade de acerto em funÃ§Ã£o da mÃ¡xima confianÃ§a retornada pelo classificador para um conjunto de dados. Em vermelho tem-se a funÃ§Ã£o ğ¶ğ‘™ğ‘– treinada a partir do conjunto de dados em azul.

3.3. DistribuiÃ§Ã£o de Probabilidades 3.3 DistribuiÃ§Ã£o de Probabilidades Normalizando o grau de confianÃ§a para a distÃ¢ncia com relaÃ§Ã£o a todas as classes, se obtÃ©m a distribuiÃ§Ã£o de probabilidades para um determinado objeto. Sendo assim, um classificador nÃ£o mais produz somente uma saÃ­da, mas tambÃ©m uma chance de cada item de um conjunto de dados a pertencer a cada uma das classes. A Figura 12 mostra a saÃ­da da classificaÃ§Ã£o de um exemplo calculado. Sendo que cada barra representa a chance do objeto pertencer a tal classe.
Figura 12 â€“ Histograma mostrando a distribuiÃ§Ã£o de probabilidades de saÃ­da de um classificador. Para o caso, a segunda classe, Ã© a que obteve maior probabilidade, porÃ©m existe uma certa incerteza com relaÃ§Ã£o a primeira classe.
Observa-se na Figura 12 que a saÃ­da do classificador mostra a classe mais provÃ¡vel mas existe uma incerteza significativa para uma segunda classe ser a correta.
3.4 NÃ­vel Local ğ‘ƒğ‘™(ğ¿|ğ‘Š) A Figura 13 mostra o conjunto de passos para calcular os parcelas locais utilizando o contexto baseado em GeoestatÃ­stica.
A primeira parte do mÃ©todo (lado direito da Figura 13) Ã© estimar e modelar a incerteza existente nos conjunto de dados os quais se quer adicionar o contexto. Essa modelagem se da atravÃ©s da estimativa da matriz de probabilidade de transiÃ§Ã£o (ğ‘‡) entre os possÃ­veis rÃ³tulos presentes no conjunto de dados. Isso Ã© feito em uma etapa de treinamento offline do mÃ©todo A estimativa Ã© feita em duas partes que sÃ£o combinadas: analisando as frequÃªncias de transiÃ§Ãµes entre as classes de um conjunto de imagens (CARLE et al., 1998) e medindo propriedades estatÃ­sticas nos dados como proporÃ§Ãµes e espessuras.

CapÃ­tulo 3. ClassificaÃ§Ã£o Baseada em Contexto utilizando GeoestatÃ­stica Figura 13 â€“ Diagrama geral da adiÃ§Ã£o de contexto local utilizando GeoestatÃ­stica. Primeiramente Ã© medida a variabilidade entre as classes no contexto espacial. Tanto diretamente atravÃ©s das frequÃªncias de transiÃ§Ã£o na imagem (taxa de transiÃ§Ã£o medida), quanto atravÃ©s da inferÃªncia de propriedades estatÃ­sticas vindas da imagem (taxa de transiÃ§Ã£o modelada).
Em seguida sÃ£o calculados os vetores de transiÃ§Ã£o. Na segunda parte os vetores sÃ£o utilizados para gerar pesos para imagem. Com isso, utilizando os pesos, o sistema SIS computa a adiÃ§Ã£o de contexto local para cada superpixel.
A segunda parte do mÃ©todo Ã© a geraÃ§Ã£o do contexto local ğ‘ƒğ‘™(ğ¿|ğ‘Š). Deste modo, para cada superpixel que se deseja computar, a matriz de probabilidades de transiÃ§Ã£o Ã© usada para computar os pesos ğ‘Š, para servir como entrada em um sistema de SIS, Sequential Indicator Simulation (Indicador de simulaÃ§Ã£o sequencial) (EMERY, 2004) o qual computa ğ‘ƒğ‘™(ğ¿|ğ‘Š). Cada um dos processos apontados na Figura 13 sÃ£o detalhados no restante desta seÃ§Ã£o.
3.4.1 Medindo TransiÃ§Ãµes de Probabilidades Primeiramente, um sistema de transiÃ§Ã£o de probabilidades baseado em cadeias de Markov Ã© medido. Este modelo representa a variabilidade espacial existente juntamente com os dados da imagem.
A estrategia proposta Ã© calcular uma matriz ğ‘‡, onde cada componente Ã© a funÃ§Ã£o ğ‘¡ğ‘–ğ‘—(â„ğœ‘) a qual modela a probabilidade de uma classe ğ‘– de transitar para a classe ğ‘— em uma distÃ¢ncia â„ considerando a direÃ§Ã£o ğœ‘. Ã‰ necessÃ¡rio obter tal medida para cada par de classes ğ‘– e ğ‘— presente no conjunto de dados.
Neste mÃ©todo, assume-se que os dados sÃ£o isomÃ³rficos. Portanto, para uma dada transiÃ§Ã£o, todas as direÃ§Ãµes sÃ£o consideradas como idÃªnticas. NÃ£o obstante, a abordagem pode ser utilizada em casos nÃ£o isomÃ³rficos, considerando duas ou mais direÃ§Ãµes, cada uma com sua prÃ³pria matriz de probabilidade de transiÃ§Ãµes.
Foi assumido que a transiÃ§Ã£o de probabilidades tem um comportamento exponen-3.4. NÃ­vel Local ğ‘ƒğ‘™(ğ¿|ğ‘Š) 
cial, como proposto por (CARLE et al., 1998). As equaÃ§Ã£o 3.3 mostra como calcular a transiÃ§Ã£o de probabilidades entre classes diferentes e tambÃ©m para a mesma classe ( auto transiÃ§Ã£o).
(3.3) A funÃ§Ã£o de transiÃ§Ã£o na EquaÃ§Ã£o 3.3 tambÃ©m depende da distÃ¢ncia â„ e da probabilidade a priori da classe ğ‘ğ‘—. Cada fator ğ‘Ÿğ‘–ğ‘— Ã© um componente da matriz ğ‘… Essa matriz Ã© a taxa de transiÃ§Ã£o entre as classes, para ğ‘˜ classes, ğ‘… pode ser calculada como: (3.4) Cada elemento da matriz representa a taxa na qual ocorre a transiÃ§Ã£o, sendo assim: (3.5) A matriz ğ‘‡ nÃ£o pode ser diretamente calculada a partir dos dados (AGTERBERG, 1988). Para tal, primeiramente, Ã© necessario estimar a matriz ğ‘…. Carle et al. (1998), propÃµem obter o calculo de ğ‘… atravÃ©s da multiplicaÃ§Ã£o elemento a elemento das medidas da correlaÃ§Ã£o entre as configuraÃ§Ãµes espaciais diretas (ğ‘…ğ‘šğ‘’ğ‘ ) e da medida de conceitos estatÃ­sticos (ğ‘…ğ‘šğ‘œğ‘‘) extraÃ­dos das imagens: (3.6) 3.4.1.1 Taxa de TransiÃ§Ã£o Medida ğ‘…ğ‘šğ‘’ğ‘  ğ‘…ğ‘šğ‘’ğ‘  Ã© calculado medindo a frequÃªncia de transiÃ§Ã£o cumulativa da matriz ğ¹. Para computar ğ¹, foi somado o nÃºmero de vezes que cada classe transita para cada outra classe.
Foi considerado um conjunto de direÃ§Ãµes e um conjunto de distÃ¢ncias â„. Tal treinamento Ã© feito em um conjunto de imagens jÃ¡ previamente classificadas. Este processo Ã© apresentado na Figura 14. Foi utilizado um kernel de janela deslizante que iterativamente se desloca ao longo de toda a imagem.

CapÃ­tulo 3. ClassificaÃ§Ã£o Baseada em Contexto utilizando GeoestatÃ­stica Para cada posiÃ§Ã£o do kernel, foram contadas todas as transiÃ§Ãµes que o rÃ³tulo do ponto central do kernel faz. Isto Ã© feito para diversas distÃ¢ncias, o qual Ã© representado pelos quadrados coloridos da Fig. 14. Ao final, cada linha de ğ¹ Ã© normalizada.
Figura 14 â€“ Medida feita do nÃºmero de transiÃ§Ãµes que uma classe faz para cada outra para mÃºltiplas distÃ¢ncias. Foi utilizada um kernel mÃ³vel e foram contadas as transiÃ§Ãµes desde o centro (ponto vermelho) para todas as direÃ§Ãµes (representado pelos quadrados) A equaÃ§Ã£o 3.7 mostra um exemplo da matriz ğ¹ feitas para um "datasetâ€ exemplo.
(3.7) A matriz estimada ğ¹ Ã© afetada pelas incertezas nas premissas de probabilidade assumidas. Por exemplo, a premissa do isomorfismo assumida nÃ£o Ã© perfeitamente verdadeira. Para reduzir o efeito das incertezas e encontrar um padrÃ£o na representaÃ§Ã£o, uma anÃ¡lise de autovetores e autovalores Ã© aplicada na Eq. 3.7 (CARLE; FOGG, 1996).
A partir disso, Ã© possÃ­vel computar ğ‘…ğ‘šğ‘’ğ‘  aplicando a equaÃ§Ã£o 3.8.
(3.8) (3.9) Esta computaÃ§Ã£o consiste em uma medida inicial que congrega as tendÃªncias de verossimilhanÃ§a espacial entre as classes. Contudo, esta medida ainda contÃ©m muita im-3.4. NÃ­vel Local ğ‘ƒğ‘™(ğ¿|ğ‘Š) 
precisÃ£o para ser usada como entrada para a simulaÃ§Ã£o. A medida pode ser ainda mais estabilizada adicionando a computaÃ§Ã£o de ğ‘…ğ‘šğ‘œğ‘‘ assim como mostrado na Eq. 3.6.
3.4.1.2 Calculo da Matriz ğ‘…ğ‘šğ‘œğ‘‘ Computa-se ğ‘…ğ‘šğ‘œğ‘‘ utilizando estatÃ­sticas extraÃ­da dos dados, como: proporÃ§Ãµes das classes, comprimentos mÃ©dios das classes e as tendÃªncias de justaposiÃ§Ã£o.
A proporÃ§Ã£o de uma classe ğ‘™ğ‘– Ã© a probabilidade a priori desta classe aparecer. Em outras palavras, a proporÃ§Ã£o Ã© a chance de selecionar uma parcela da classe ğ‘™ğ‘– aleatoriamente da imagem classificada (CARLE; FOGG, 1996).
O comprimento mÃ©dio Ã© calculado pela quantidade mÃ©dia de pixeis contÃ­nuos de uma certa classe ao longo de uma determinada direÃ§Ã£o. Como assume-se isomorfismo nos dados, esta direÃ§Ã£o Ã© arbitraria. Considerando em termos de transiÃ§Ã£o de probabilidades, o comprimento mÃ©dio ğ¿â„ğœ‘ Ã© a taxa de decaimento da curva de transiÃ§Ã£o da funÃ§Ã£o ğ‘¡ğ‘–ğ‘–(â„ğœ‘) na direÃ§Ã£o ğœ‘ . O comprimento mÃ©dio Ã© mostrado na equaÃ§Ã£o 3.10.
(3.10) Isso Ã© anÃ¡logo a taxa de uma classe transitar para si mesma, como mostrado na Eq. 3.11 (CARLE; FOGG, 1996).
(3.11) O conceito de tendÃªncia de justaposiÃ§Ã£o modela as probabilidades de uma classe transitar fora de si mesmo e depois em outra dado uma distÃ¢ncia. Considerando ğ‘Ÿğ‘–ğ‘– como a taxa que a uma certa classe transita para si mesma, ğ‘Ÿğ‘–ğ‘— depende das proporÃ§Ãµes de ğ‘— como mostrado na Eq. 3.12.
(3.12) (3.13) 
CapÃ­tulo 3. ClassificaÃ§Ã£o Baseada em Contexto utilizando GeoestatÃ­stica da Figura 15 foram computados aplicando a Eq. 3.3 variando a distÃ¢ncia â„. Como um exemplo, pode-se perceber que o comprimento mÃ©dio da classe background Ã© bem alto.
Isso acontece por que o seu decaimento exponencial Ã© muito baixo.
Figura 15 â€“ A transiÃ§Ã£o de probabilidade modelada para um determinado dataset. O eixo y apresenta a distÃ¢ncia em pixeis. As linhas verdes mostram as proporÃ§Ãµes para cada classe. Pode-se observar uma certa tendÃªncia na classe Urchin em transitar para categoria de background. Ainda, percebe-se que a classe de background tem um grande comprimento mÃ©dio, dado que sua taxa de decaimento Ã© bastante alta.
3.4.2 Sequential Indicator Simulation Dado que a matriz de transiÃ§Ã£o ğ‘‡ jÃ¡ foi calculada para um dataset, o algoritmo Sequential Indicator Simulation (SIS) tenta simular o ğ‘ƒğ‘™(ğ¿|ğ‘Š) de um superpixel com base em sua vizinhanÃ§a espacial. Para simular os fatores locais de um certo superpixel ğ‘¥0, um certo nÃºmero ğ‘ de posiÃ§Ãµes aleatÃ³rias amostradas ğ‘¥ğ›¼ sÃ£o computados em torno da regiÃ£o em um raio ğ‘Ÿ. Cada uma das posiÃ§Ãµes amostradas vai contribuir para o computar o fator local, sendo que a contribuiÃ§Ã£o Ã© feita de forma a minimizar a varianÃ§a desta vizinhanÃ§a com respeito ao modelo.
Com isso, a probabilidade relacionada com o contexto espacial para cada classe ğ‘˜ 3.4. NÃ­vel Local ğ‘ƒğ‘™(ğ¿|ğ‘Š) 
em uma certa parcela ğ‘¥0 Ã© computada como: (3.14) âˆ‘ï¸€ğ¿ ğ‘—=1 ğ‘ƒğ‘¢(ğ‘‹ğ›¼ = ğ‘—)). O fator Ã© controlado pelo peso ğ‘¤ğ‘—ğ‘˜,ğ›¼.
este superpixel (âˆ‘ï¸€ğ‘ ğ›¼=1 Os pesos para cada posiÃ§Ã£o amostrada formam o conjunto de matrizes ğ‘Šğ‘ e sÃ£o calculados resolvendo o sistema linear da Eq. 3.15 : = onde: (3.16) A Figura 16 mostra o exemplo de um superpixel arbitrÃ¡rio e sua respectiva regiÃ£o amostrada, para a computaÃ§Ã£o do potencial local. Para tal regiÃ£o a Eq. 3.15 serÃ¡ aplicada de forma a encontrar o peso para cada uma das posiÃ§Ãµes. O peso encontrado Ã© o que tornaria a regiÃ£o o mais homogÃªnea possÃ­vel.
3.4.3 Computando o Potencial Final ğ‘ƒ(ğ¿) Depois de obter uma saÃ­da da curva de confianÃ§a para cada superpixel, primeiramente se busca os superpixeis com uma saÃ­da bem alta de confianÃ§a. Foi decido computar o potencial local apenas para superpixeis onde a confianÃ§a estÃ¡ abaixo de um limiar ğ‘¡. O limiar Ã© selecionado como a confianÃ§a mÃ¡xima, dado pelo conjunto de validaÃ§Ã£o.
O processo do SIS Ã© repetido para cada superpixel presente na imagem em ordem aleatÃ³ria e os pesos jÃ¡ sÃ£o atualizados. Isso garante que a correlaÃ§Ã£o entre a prÃ³pria vizinhanÃ§a seja considerada.
Os pesos sÃ£o obtidos diretamente pela Eq. 3.15. Dois parÃ¢metros devem ser escolhidos para este mÃ©todo, o nÃºmero de amostras ğ‘ e o raio ğ‘Ÿ onde vai ser feita a amostragem.
Experimentos preliminares mostraram que nÃ£o existe vantagem pratica em usar mais de 
CapÃ­tulo 3. ClassificaÃ§Ã£o Baseada em Contexto utilizando GeoestatÃ­stica Figura 16 â€“ Exemplo de uma vizinhanÃ§a sendo considerada para um superpixel ( apontado em vermelho). Um raio ğ‘Ÿ Ã© considerado e ğ‘ pontos sÃ£o amostrados nessa vizinhanÃ§a ( em azul). Cada um dos pontos amostrados irÃ¡ influenciar no potencial do superpixel apontado em vermelho.
25 amostras. TambÃ©m, o raio ğ‘Ÿ passa e se tornar irrelevante a partir de uma certa distÃ¢ncia, dado que Ã s transiÃ§Ãµes de probabilidade tendem a ser iguais as proporÃ§Ãµes no limite.
3.5 GeoestatÃ­stica e CRF Tanto as abordagem de CRF, quanto de GeoestatÃ­stica (GS) tentam minimizar uma funÃ§Ã£o que tenta impor uma certa homogeneidade espacial. Ou seja, superpixeis prÃ³ximos tendem a ser da mesma classe. A diferenÃ§a Ã© que o modelo de GeoestatÃ­stica Ã© baseado em uma amostragem o que torna o problema da inferÃªncia mais simples. O modelo de GS Ã© tambÃ©m anÃ¡logo a um CRF densamente conectado (KOLTUN; VLADLEN, 2011), mas com amostragens mais esparsas.
A abordagem de GS pode ser vista como uma representaÃ§Ã£o mais esparsa do CRF porÃ©m, com medidas estatÃ­sticas mais ricas. NÃ£o obstante, a computaÃ§Ã£o da matriz de pesos ğ‘Š para a Eq. 3.14 pode ser considerado como a minimizaÃ§Ã£o de uma funÃ§Ã£o de energia, usando uma soma ponderada.
Como uma forma de comparar ambos os mÃ©todos, a Figura 17 mostra o modelo GS como um modelo grÃ¡fico probabilÃ­stico. O vÃ©rtice central, em verde claro, Ã© o caso atual sendo calculado. Os vÃ©rtices em verde escuro sÃ£o aqueles amostrados. Cada vertice em verde escuro contribui para a distribuiÃ§Ã£o do vertice central dependendo das probabilidades de transiÃ§Ã£o estimadas da Fig. 15. Em vermelho sÃ£o representados os fatores 
3.6. SumÃ¡rio unÃ¡rios de cada quadrado em azul Ã© a contribuiÃ§Ã£o desses mesmos ( fatores locais).
Figura 17 â€“ RepresentaÃ§Ã£o grÃ¡fica do modelo de GeoestatÃ­stica (GS). Os fatores locais sÃ£o representados em azul e usam a estatÃ­stica de probabilidade de transiÃ§Ã£o computada pela Eq. 3.3. Diferentemente do que no modelo da Fig. 7, vizinhos de diferentes distÃ¢ncias tambÃ©m contribuem para calcular a distribuiÃ§Ã£o de cada posiÃ§Ã£o.
3.6 SumÃ¡rio Neste CapÃ­tulo apresentou-se um novo mÃ©todo para adiÃ§Ã£o de contexto na classificaÃ§Ã£o. O mÃ©todo foi inspirado nas tÃ©cnicas de modelagem da variabilidade espacial usada em GeoestatÃ­stica.
Foi feita, por fim, uma comparaÃ§Ã£o do mÃ©todo proposto com o CRF. Acredita-se que o mÃ©todo apresentado neste capÃ­tulo tende a se comportar melhor que o CRF quando existem menos dados de treinamento, e os mesmos dados nÃ£o possuem padrÃµes bem definidos, como no caso do ambiente subaquÃ¡tico. Isso pode ser atingido visto que o mÃ©todo proposto estima padrÃµes de forma para as classes. Sendo assim as relaÃ§Ãµes de correlaÃ§Ã£o espacial, sÃ£o tambÃ©m estimadas com base em um modelo para as classes. O mÃ©todo proposto serÃ¡ testado e avaliado no CapÃ­tulo 6.

4 ClassificaÃ§Ã£o de Imagens do Assoalho OceÃ¢nico Neste CapÃ­tulo Ã© apresentado o domÃ­nio de aplicaÃ§Ã£o no qual serÃ¡ aplicado o mÃ©todo de adiÃ§Ã£o de contexto proposto no CapÃ­tulo 3.
Como apresentado na introduÃ§Ã£o, o conhecimento sobre as espÃ©cies presentes no fundo do mar, especialmente os recifes de corais, Ã© de fundamental importÃ¢ncia para os especialistas na Ã¡rea.
Ao se fazer monitoramento do assoalho oceÃ¢nico, assim como para o caso do sensoriamento remoto, Ã© interessante ser capaz de rotular automÃ¡ticamente cada pixel das imagens e assim ser capaz de medir propriedades relevantes. O objetivo desta classificaÃ§Ã£o Ã© fazer os chamados mapas temÃ¡ticos. Tais mapas sÃ£o a representaÃ§Ã£o final de um mapa classificado de uma imagem, feito de forma visualmente interpretÃ¡vel. Mapas temÃ¡ticos agregam grandes conjuntos de imagens em mosaicos representando Ã¡reas de grande extensÃ£o.
Considerando o ambiente subaquÃ¡tico, suas propriedades fotomÃ©tricas demandam um tratamento especial para contornar a degradaÃ§Ã£o da imagem. Esses desafios prÃ³prios do meio nÃ£o sÃ£o comumente endereÃ§ados na literatura. Tais propriedades causam problemas como bordas confusas entre objetos, variaÃ§Ã£o na qualidade da imagem, etc.
Neste capÃ­tulo primeiramente Ã© formalizada as propriedades do meio subaquÃ¡tico, o que sera Ãºtil tambÃ©m para capÃ­tulos posteriores. Depois, Ã© apresentada uma visÃ£o geral dos principais sistemas utilizados para classificaÃ§Ã£o de mosaicos do assoalho oceÃ¢nico.
Entre os sistemas apresentados, um em especial serÃ¡ detalhado, o qual serÃ¡ utilizado como um estudo de caso para adiÃ§Ã£o de contexto.
4.1 Propriedades de Imagens SubaquÃ¡ticas De forma a obter imagens capturadas em ambiente subaquÃ¡tico com uma melhor qualidade visual, Ã© fundamental o entendimento de sua formaÃ§Ã£o, levando em conta os aspectos especÃ­ficos que ocorrem no meio subaquÃ¡tico.
Um modelo de formaÃ§Ã£o de imagens busca descrever os caminhos pelos quais a luz passa, desde a fonte atÃ© a sua captura, onde Ã© formada a imagem. A Figura 18 ilustra este processo de propagaÃ§Ã£o. Em meios participativos, a irradiaÃ§Ã£o, ou seja, a quantidade de energia luminosa em um pixel, pode ser obtida pelo somatÃ³rio de trÃªs componentes as quais chegam por caminhos distintos. A componente direta, a qual contÃ©m a luz sem es- 
CapÃ­tulo 4. ClassificaÃ§Ã£o de Imagens do Assoalho OceÃ¢nico palhamento que veio diretamente do objeto. Muitas vezes, informaÃ§Ãµes que vinham de um Ãºnico ponto sÃ£o espalhadas entre seus pontos vizinhos causando um efeito de borramento na imagem. Este fenÃ´meno Ã© chamado espalhamento dianteiro (forward scattering), representado pela componente forward scattering. O forward-scattering faz com que as informaÃ§Ãµes visuais da cena fiquem espalhadas, causando um efeito de borramento.
Figura 18 â€“ TrÃªs trajetÃ³rias da luz atÃ© o plano da imagem. O componente direto, contendo a informaÃ§Ã£o direta da cena. O forward-scattering, contendo informaÃ§Ã£o da cena espalhada. Por fim, o backscattering contendo informaÃ§Ãµes de fora da cena.
Por Ãºltimo, tem-se a componente de backscattering, a qual luz chega no plano da imagem a partir de um ponto que nÃ£o faz parte da cena observada. Isso acontece devido Ã  alguma partÃ­cula flutuante que desvia a trajetÃ³ria da luz para o plano da imagem. O backscattering se comporta tal como um ruÃ­do aditivo.
Para calcular cada uma das componentes, algumas simplificaÃ§Ãµes devem ser consideradas. Tais simplificaÃ§Ãµes visam tornar o modelo mais simples e tratÃ¡vel computacionalmente, ressaltando somente alguns aspectos principais na formaÃ§Ã£o da imagem.
Primeiramente, se assume o objeto como tendo sua reflectividade uniforme. Assume-se uma iluminaÃ§Ã£o completa e uniforme da cena. Por fim, pode-se descartar os parÃ¢metros da cÃ¢mera e considerar a captura da luz como sendo tambÃ©m uniforme.
Normalmente o efeito causado pelo forward-scattering tende ser desprezado, por contribuir com uma participaÃ§Ã£o menor que o backscattering na formaÃ§Ã£o da imagem (TREIBITZ; SCHECHNER, 2006).
A descriÃ§Ã£o final do modelo Ã© dada pela equaÃ§Ã£o de Koschmieder (KOSCHMIEDER, 1924), bastante utilizada para a propagaÃ§Ã£o da luz na nÃ©voa. Sendo assim, a 
4.1. Propriedades de Imagens SubaquÃ¡ticas formaÃ§Ã£o de um ponto (ğ‘¥, ğ‘¦) na imagem Ã© dado por: (4.1) Sendo ğ½(ğ‘¥, ğ‘¦) a imagem sem degradaÃ§Ã£o e ğ‘§(ğ‘¥, ğ‘¦) uma funÃ§Ã£o da distÃ¢ncia para cada ponto na imagem. Essa equaÃ§Ã£o pode ser interpretada da seguinte forma: quanto mais distante estiver o objeto maior serÃ¡ o componente backscattering, menos da cena real irÃ¡ existir na imagem.
Sabe-se que, devido as propriedades do meio subaquÃ¡tico, existe uma diferenÃ§a significativa entre a absorÃ§Ã£o e espalhamento dos comprimentos de onda (DUNTLEY, 1963) Desta forma, o modelo pode ser estendido de forma incorporar diferentes comprimentos de onda. A equaÃ§Ã£o 4.1 modela a quantidade de luminosidade capturada relativa a um determinado pixel. PorÃ©m Ã© possÃ­vel adequÃ¡-la para diferentes comprimentos de onda, ou no caso do padrÃ£o RGB de representaÃ§Ã£o, dividi-la em trÃªs canais conforme a equaÃ§Ã£o 4.2, (4.2) A Figura 19 apresenta uma tÃ­pica imagem com alto nÃ­vel de turbidez. Turbidez Ã© uma propriedade comum no meio aquÃ¡tico que esta relacionada com a quantidade de luz que Ã© absorvida ou espalhada ao invÃ©s de ser transmitida em uma linha reta (OMAR; MATJAFRI, 2009).
Figura 19 â€“ Imagem de exemplo para as degradaÃ§Ãµes do ambiente subaquÃ¡tico. Ã‰ possÃ­vel ver que existe uma variaÃ§Ã£o conforme a distÃ¢ncia e uma perda significativa da informaÃ§Ã£o de cor.

CapÃ­tulo 4. ClassificaÃ§Ã£o de Imagens do Assoalho OceÃ¢nico Ã‰ interessante observar que a degradaÃ§Ã£o nÃ£o afeta uniformemente a imagem.
Existem nÃ­veis de degradaÃ§Ã£o mais altos de acordo com a distÃ¢ncia. AlÃ©m disso, o comprimento de onda vermelho tende a se perder rapidamente, tendo a cor verde nesse caso como predominante.
Por fim, vale notar que, fenÃ´menos adicionais tambÃ©m acontecem. Um exemplo Ã© o efeito da "neve submarina", a qual causa aparecimento de pequenos pontos brancos na imagem. Por estes e outros fatos Ã© relevante constatar que o meio subaquÃ¡tico jÃ¡ tem uma alta presenÃ§a de ruÃ­do (BAZEILLE et al., 2006).
4.2 ClassificaÃ§Ã£o AutÃ´noma de Imagens do fundo OceÃ¢nico A Figura 20 mostra uma adaptaÃ§Ã£o do que Ã© usado pela maioria dos frameworks em visÃ£o computacional para criaÃ§Ã£o de mapas temÃ¡ticos de mosaicos em ambientes subaquÃ¡ticos (SHIHAVUDDIN et al., 2013).
Figura 20 â€“ A sequÃªncia utilizada para classificaÃ§Ã£o de imagens em meio subaquÃ¡tico.
Para classificar os objetos de uma imagem Ã© necessÃ¡rio passar por diversas etapas.
A seguir sÃ£o listadas as etapas apresentando algumas das tÃ©cnicas usadas na literatura: âˆ™ PrÃ©-processamento: etapa fundamental em ambientes subaquÃ¡ticos. Normalmente Ã© onde correÃ§Ãµes de cor (PIZARRO et al., 2008) e contraste (JOHNSON-ROBERSON; KUMAR; WILLAMS, 2007) sÃ£o aplicadas para atenuar a degradaÃ§Ã£o e ressaltar aspectos importantes das imagens subaquÃ¡ticas.
âˆ™ SegmentaÃ§Ã£o: Nesta etapa a imagem Ã© super-segmentada em regiÃµes com propriedades similares. Tal etapa pode ser evitada, para o caso onde ocorre uma seleÃ§Ã£o manual do que ser classificado.
âˆ™ ExtraÃ§Ã£o de Descritores: Ã© onde as caracterÃ­sticas relevantes para cada segmento sÃ£o extraÃ­das e representadas. Diversas abordagens sÃ£o utilizadas, um exemplo seria o uso de descritores locais e bag-of-words por Pizarro, Eustice e Singh (2004). Os 
4.2. ClassificaÃ§Ã£o AutÃ´noma de Imagens do fundo OceÃ¢nico descritores de textura e cor sÃ£o bastante utilizados no meio subaquÃ¡tico (BEIJBOM et al., 2012) (STOKES; DEANE, 2009), (MARCOS; SORIANO; SALOMA, 2005).
âˆ™ ClassificaÃ§Ã£o: Ã© onde se realiza o treinamento do classificador e classificaÃ§Ã£o para os testes. Diversos classificadores sÃ£o utilizados como o SVM (PIZARRO; EUSTICE; SINGH, 2004) ou o LDA (MARCOS; SORIANO; SALOMA, 2005).
âˆ™ PÃ³s-processamento: Ã© onde informaÃ§Ãµes adicionais sÃ£o utilizadas para refinar o resultado da classificaÃ§Ã£o. Em (SHIHAVUDDIN et al., 2013) Ã© feito um simples sistema de votaÃ§Ã£o para verificar a consistÃªncia da vizinhanÃ§a No caso, atÃ© onde se sabe, nÃ£o ocorreram outras aplicaÃ§Ãµes de tÃ©cnicas mais elaboradas para adiÃ§Ã£o de contexto.
Nesta seÃ§Ã£o Ã© especificado em detalhe cada etapa apresentada elucidando o que foi utilizado por Shihavuddin et al. (2013) para geraÃ§Ã£o de mapas temÃ¡ticos. Tal mÃ©todo foi escolhido como base para aplicaÃ§Ã£o de tÃ©cnicas para adiÃ§Ã£o de contexto. O mesmo foi escolhido devido a alta taxa de acerto na classificaÃ§Ã£o quando comparados com diversos mÃ©todos do estado da arte (SHIHAVUDDIN et al., 2013). Os algoritmos usados em cada uma das etapas da Figura 20 sÃ£o elucidados a seguir.
4.2.1 PrÃ©-Processamento O processo de prÃ©-processamento almeja deixar a imagem o mais prÃ³xima possÃ­vel da cena em qual a mesma foi capturada. Isso Ã© feito tanto no escopo radiomÃ©trico quanto geomÃ©trico. Ou seja, o objectivo Ã© tornar, as estruturas geomÃ©tricas , seu brilho e cor o mais prÃ³ximos possÃ­vel da cena (GONZALEZ; WOODS, 2006).
Para lidar com o processamento embaixo dâ€™Ã¡gua, primeiramente, precisa-se considerar todos os princÃ­pios bÃ¡sicos de propagaÃ§Ã£o da luz nesse meio os quais foram colocados na SeÃ§Ã£o 4.1. (SCHETTINI; CORCHS, 2010) Seguindo a ideia de que a qualidade visual subjetiva Ã© importante, pode-se melhor a qualidade de imagens subaquÃ¡ticas utilizando tÃ©cnicas que abordam diretamente os efeitos degradantes apontados. Esta seÃ§Ã£o apresenta as alternativas existentes para corrigir cada um dos tipos de degradaÃ§Ã£o.
4.2.1.1 Contraste Observa-se pela EquaÃ§Ã£o 4.1 que o processo de degradaÃ§Ã£o da imagem em ambiente subaquÃ¡tico nÃ£o Ã© uniforme ao longo da imagem. O mesmo depende da distÃ¢ncia de cada ponto a cÃ¢mera.
Nesse contexto, o Shihavuddin et al. (2013) faz o uso do CLAHE (Contrast Limited Adaptative Histogram Equalization) (ZUIDERVELD, 1994) para correÃ§Ã£o de contraste.

CapÃ­tulo 4. ClassificaÃ§Ã£o de Imagens do Assoalho OceÃ¢nico Tal mÃ©todo faz uma construÃ§Ã£o de histograma diferente para cada segmento da imagem e aplica uma equalizaÃ§Ã£o de histograma somente nesse segmento. AlÃ©m disso, o mÃ©todo coloca um limite de intensidade maxima, redistribuindo todos as intensidades que ficam acima deste limite.
4.2.1.2 CorreÃ§Ã£o de Cor Como mostrado na seÃ§Ã£o 4.1, existe uma nÃ£o uniformidade na absorÃ§Ã£o de cada comprimento de onda no ambiente subaquÃ¡tico. Isso causa que boa parte da informaÃ§Ã£o cromÃ¡tica da cena seja perdida.
De forma a obter cores mais prÃ³ximas de realidade existe a necessidade de estimar tais diferenÃ§as de absorÃ§Ã£o. Uma das formas de resolver isso Ã© considerar que Ã© possÃ­vel obter as diferenÃ§as de absorÃ§Ã£o considerando essas diferenÃ§as como uma questÃ£o de estimativa da fonte de luz. Colocado de tal forma, o problema, se torna basicamente a aplicaÃ§Ã£o de algoritmos de balanceamento de branco, os quais podem ser uma simples normalizaÃ§Ã£o.
O mÃ©todo de (SHIHAVUDDIN et al., 2013) aplicou a premissa de que que o ponto de maior intensidade da imagem foi causado por reflexÃ£o perfeita. Desta forma a iluminaÃ§Ã£o pode ser estimada achando o ponto de maior intensidade da imagem. Sendo assim, para tornar a cor da imagem balanceada, o ganho para cada pixel pode ser dado como: (4.3) 4.2.2 SegmentaÃ§Ã£o Diversos desafios em classificaÃ§Ã£o de imagens colocam o desafio atual como classificar os objetos pixel a pixel (FULKERSON; VEDALDI; SOATTO, 2009).
O caso da aplicaÃ§Ã£o em sensoriamento remoto, claramente se beneficia deste fato, onde cada pixel da imagem Ã© relevante. A questÃ£o Ã© que, devido ao custo computacional, e ao fato que somente um pixel nÃ£o possuir grande significado semÃ¢ntico para efetuar a classificaÃ§Ã£o e extrair os descritores, muitas vezes a abordagem de usar segmentos da imagem, ajuda a melhorar a consistÃªncia.
Existe e a tendÃªncia de muitos autores fazer uma prÃ©-segmentaÃ§Ã£o, a qual aparentemente nÃ£o esta relacionada com a classificaÃ§Ã£o final. PorÃ©m, tal segmentaÃ§Ã£o ajuda a a garantir que cada parte da imagem sendo classificada tenha uma homogeneidade local.
Tal segmentaÃ§Ã£o Ã© chamada de segmentaÃ§Ã£o em superpixeis.

4.2. ClassificaÃ§Ã£o AutÃ´noma de Imagens do fundo OceÃ¢nico Para o caso da abordagem de Shihavuddin et al. (2013), os superpixeis sÃ£o utilizados como estrutura de interaÃ§Ã£o. A imagem Ã© definida como um conjunto de superpixeis a serem classificados.
Diversos algoritmos existem para a criaÃ§Ã£o de superpixeis. PorÃ©m, Shihavuddin et al. (2013) selecionou aquele que tende a manter uma estrutura o mais regular possÃ­vel.
No caso foi utilizado os Turbopixels (LEVINSHTEIN et al., 2009) .
4.2.3 Descritores Para descrever a imagem foi utilizado majoritariamente descritores de textura.
Textura pode ser definida como a variaÃ§Ã£o dos dados visuais em escalas menores que a escala observada (PETROU; GARCÃA-SEVILLA, 2006).
O assoalho submarino Ã© tipicamente texturizado. Observou-se diversos bancos de dados de corais, e outras estruturas encontradas no meio, e percebe-se que existem sempre oscilaÃ§Ãµes na estrutura dos objetos em diferentes escalas. Tal fenÃ´meno caracteriza a existÃªncia da textura. AlÃ©m da tendÃªncia existente na literatura em usar textura (SHIHAVUDDIN et al., 2013).
Com isso em vista, (SHIHAVUDDIN et al., 2013) utiliza trÃªs descritores como descritores de texturas: Gabor Filter, Grey Level Co-occurence Matrix (GLCM) e Completed Local Binary Pattern (CLBP).
Os Gabor Filters sÃ£o um grupo de Wavelets 2D que tomam forma de uma gaussiana 2D modulada no espaÃ§o 2D (PORTER; CANAGARAJAH, 1997). Basicamente sÃ£o uma representaÃ§Ã£o da variaÃ§Ã£o de frequÃªncia em um segmento da imagem.
O GLCM (HARALICK; SHANMUGAM; DINSTEIN, 1973), utiliza a representaÃ§Ã£o de padrÃµes de variaÃ§Ãµes espaciais dos segmentos da imagem em uma matriz, que representa a variaÃ§Ã£o de intensidade dos pixeis em diferentes Ã¢ngulos e distÃ¢ncias. Diversos indicadores sÃ£o computados a partir dessas matrizes como a mÃ©dia de variaÃ§Ãµes ou a entropia.
O CLBP (GUO; ZHANG, 2010), Ã© um descritor de textura invariante a rotaÃ§Ã£o o qual retrata, principalmente, a variaÃ§Ã£o de sinais de um pixel central para com pixeis ao redor em uma determinada posiÃ§Ã£o.
A utilizaÃ§Ã£o de cor Ã© complexa dado a perda de cor nÃ£o uniforme entre os comprimentos de onda como mostrado na SeÃ§Ã£o 4.1. PorÃ©m ainda Ã© possÃ­vel utilizar um descritor de cor que possui propriedades importantes como robustez a variaÃ§Ãµes fotomÃ©tricas causadas por sombras, sombreamento e tambÃ©m mudanÃ§as geomÃ©tricas como escala e alteraÃ§Ã£o de ponto de vista. (SHIHAVUDDIN et al., 2013) utiliza o trabalho de (WEIJER; SCHMID, 2006) que aproximou tais propriedades.

CapÃ­tulo 4. ClassificaÃ§Ã£o de Imagens do Assoalho OceÃ¢nico Ao final, ao utilizar mÃºltiplos descritores, se tem uma representaÃ§Ã£o da imagem com uma grande quantidade de dimensÃµes e muitas vezes com um padrÃ£o pouco evidente.
Para resolver isso Ã© aplicado normalizaÃ§Ãµes e modificaÃ§Ãµes nos descritores. Por exemplo, os descritores podem ser manipulados de forma que os mesmos sejam o mais prÃ³ximos a se tornaram linearmente separÃ¡veis. Essa modificaÃ§Ã£o Ã© fundamental para se melhorar a qualidade da classificaÃ§Ã£o. Por fim, os descritores sÃ£o normalizados de forma a que todos os descritores estejam numa escala compatÃ­vel.
4.2.4 Treinamento e ClassificaÃ§Ã£o O treinamento foi feito utilizando trÃªs classificadores distintos de forma mutualmente exclusiva. Foram utilizados o Support Vector Machine (SVM), o K-nearest-neighbors e o PDWMD proposto por (STOKES; DEANE, 2009). Cada um destes classificadores foi utilizado dependendo das caracterÃ­sticas dos dados.
Dado que o aprendizado foi feito, novos dados podem ser classificados. Ã‰ feito um mapa temÃ¡tico baseado na segmentaÃ§Ã£o em superpixeis. Sendo que cada superpixel Ã© classificado individualmente.
4.3 ConclusÃµes Neste capÃ­tulo apresentou-se o cenÃ¡rio onde vai ser feito o estudo desta dissertaÃ§Ã£o.
TambÃ©m se apresentou alguns mÃ©todos os quais jÃ¡ fizeram classificaÃ§Ã£o de imagens do bentos.
No capÃ­tulo 6 serÃ£o apresentados os resultados de aplicaÃ§Ã£o do mÃ©todo de (SHIHAVUDDIN et al., 2013) e serÃ¡ feito o estudo sobre a incorporaÃ§Ã£o de contexto para esse mÃ©todo.

5 Testes e Resultados 1: DetecÃ§Ã£o de Pontos de Interesse em Ambiente SubaquÃ¡tico Uma das principais contribuiÃ§Ãµes desta dissertaÃ§Ã£o foi a criaÃ§Ã£o de um experimento para analizar e compreender o comportamento dos detectores de pontos de interesse quando utilizados em ambiente subaquÃ¡tico.
Como apresentado no CapÃ­tulo 1, diversos detectores foram desenvolvidos para serem invariantes a uma serie de fenÃ´menos. A ideia Ã© que o mesmo ponto de interesse possa ser encontrado independentemente de diversas circunstÃ¢ncias da cena.
PorÃ©m, existem fenÃ´menos adicionais que atuam sobre a cena no ambiente su-baquatico os quais devem ser considerados. Quando a luz se propaga neste meio, ela Ã© absorvida e espalhada pelos diferentes coeficientes de refraÃ§Ã£o encontrados nas particulas presentes no meio. Isso espalha a informaÃ§Ã£o capturada e cria o efeito de "enevoado"na imagem. Tais fenÃ´menos foram descritos mais detalhadamente no CapÃ­tulo 4, SeÃ§Ã£o 4.1.
Um estudo feito por Garcia e Gracias (GARCIA; GRACIAS, 2011), comparou os detectores de pontos de interesse mais populares na literatura. Eles encontraram que estruturas do tipo blob, obtidos por mÃ©todos baseados em Hessian (BEAUDET, 1978), por exemplo, sÃ£o melhores detectadas tanto para o caso de mÃ©todos invariantes a escala como os de Ãºnica escala. A justificativa Ã© que a turbidez da Ã¡gua tende a suavizar quinas e borrar regiÃµes definidas, fazendo com que mÃ©todos como Harris (HARRIS; STEPHENS, 1988) ou Harris-Laplace (MIKOLAJCZYK; SCHMID, 2004) sejam menos propÃ­cios para o ambiente. Entretanto, eles avaliaram somente algumas estruturas em uma Ãºnica cena.
Ã‰ do interesse desta dissertaÃ§Ã£o melhorar este estudo. Neste contexto, alguns principais objetivos sÃ£o buscados.
Foi proposto um novo dataset no qual Ã© possÃ­vel utilizar diferentes estruturas submarinas obtidas atravÃ©s da impressÃ£o de fotos subaquÃ¡ticas. Estas estruturas foram refotografadas dentro de um tanque de Ã¡gua onde imagens com a degradaÃ§Ã£o controlada foram produzidas. Isso Ã© uma melhoria a tentativas anteriores em termos de diversidade de elementos visuais. Considerando que a degradaÃ§Ã£o causada por imagens com baixa e alta turbidez nÃ£o Ã© linear, uma contribuiÃ§Ã£o Ã© dividir a anÃ¡lise em diferentes intervalos de turbidez.
Foram testados detectores de pontos de interesse, considerando diferentes abordagens, com respeito a sua robustez a degradaÃ§Ã£o causada pela turbidez. Foi focado investigar o problema de que detectores invariantes a escala tendem a ter baixa performance (GARCIA; GRACIAS, 2011). Isto Ã© feito atravÃ©s da anÃ¡lise de diferentes espaÃ§os de es- 
CapÃ­tulo 5. Testes e Resultados 1: DetecÃ§Ã£o de Pontos de Interesse em Ambiente SubaquÃ¡tico cala. Finalmente, foi indicado o melhor detector invariante para imagens subaquÃ¡ticas como sendo o DoG (LOWE, 2004).
Este CapÃ­tulo estÃ¡ organizado da seguinte maneira. A seÃ§Ã£o 5.1 apresenta a descriÃ§Ã£o completa do experimento a ser realizado. Tal seÃ§Ã£o mostra todos os detalhes da experimentaÃ§Ã£o necessÃ¡rios para que o mesmo seja bem sucedido. TambÃ©m explica todas as consideraÃ§Ãµes feitas para se ter dados aceitaveis. Por fim, a SeÃ§Ã£o 5.3 mostra os resultados obtidos para tal experimento, e apresenta uma discussÃ£o sobre os resultados encontrados.
5.1 DescriÃ§Ã£o do experimento Na literatura, poucos sÃ£o os trabalhos que analisam o comportamento dos detectores de pontos de interesse em ambiente subaquÃ¡tico. Nesta seÃ§Ã£o, descreve-se todo o processo de realizaÃ§Ã£o do experimento para que ele seja completamente reproduzÃ­vel.
Neste experimento foram capturadas diversas imagens em uma cena onde a Ãºnica modificaÃ§Ã£o entra as cenas Ã© a degradaÃ§Ã£o causada pela turbidez. O objetivo fundamental do experimento Ã© tentar obter o mÃ¡ximo de isolamento desta degradaÃ§Ã£o possÃ­vel. Para tal, a cÃ¢mera utilizada deve estar estÃ¡tica e a iluminaÃ§Ã£o deve ser controlada.
5.1.1 Cena Montada ConstruÃ­-se uma cena onde as imagens foram colocadas. A Figura 21 mostra a especificaÃ§Ã£o da cena.
Figura 21 â€“ A cena criada para avaliar os algoritmos de avaliaÃ§Ã£o de features. Ela Ã© composta por lampadas fluorescentes e uma camera fotografando fotos impressas do assoalho do oceano.
Na cena montada existe uma fotografia a ser capturada por uma cÃ¢mera posicionada a uma distÃ¢ncia perpendicular de 0.58ğ‘ğ‘š . A fotografia esta posicionada em uma 
5.1. DescriÃ§Ã£o do experimento caixa de Ã¡gua de mil litros. Duas luminÃ¡rias usando lÃ¢mpadas fluorescentes brancas foram posicionadas perto do tanque.
TrÃªs fotografias diferentes foram utilizadas, representando o fundo do mar capturado nas Bahamas em condiÃ§Ãµes prÃ³ximas ao ideal de turbidez (ZVULONI et al., 2009). As diferentes cenas contÃ©m os mais variados tipos de textura que podem ser encontradas no ambiente subaquÃ¡tico e tambÃ©m objetos feitos pelo homem. As fotografias foram impressas usando um "ploter"a laser usando uma mÃ­dia de vinil adesivo fosco e a prova dâ€™Ã¡gua.
Cada fotografia foi impressa num tamanho de 91cm X 60 cm e possuem 4928x3264 pixeis de resoluÃ§Ã£o. O diferencial desta deste dataset Ã© que ele contÃ©m verdadeiras estruturas do assoalho oceano, e ainda algumas estruturas feitas pelo homem, sendo o seu principal problema, a perda de resoluÃ§Ã£o devido a impressÃ£o e a refotografia. Isso cria uma perda de resoluÃ§Ã£o de 20 ğ‘ğ‘–ğ‘¥ğ‘’ğ‘™ğ‘ /ğ‘šğ‘š2 para 4 ğ‘ğ‘–ğ‘¥ğ‘’ğ‘™ğ‘ /ğ‘šğ‘š2 e adiÃ§Ã£o de algumas pequenas imperfeiÃ§Ãµes devido a erros de impressÃ£o.
A Figura mostra as imagens que foram impressas, nomea-se cada uma das imagens como ğ‘ƒ1, ğ‘ƒ2 e ğ‘ƒ3.
A cÃ¢mera utilizada para a captura foi uma Gopro Hero 3 Black edition. Cada imagem foi capturada em uma resoluÃ§Ã£o de 12 mega pixels(3000x4000).
5.1.2 Procedimento Foi decidido simular principalmente o efeito do fenÃ´meno de backscattering. Sabe-se que os motivos que levam a degradaÃ§Ã£o de uma imagem capturada em meio subaquÃ¡tico sÃ£o complexos (DUNTLEY, 1963). PorÃ©m, neste experimento tentou-se isolar o principal fenÃ´meno que causa a degradaÃ§Ã£o na imagem. Um estudo feito por Narasimhan et al. (2006) mostra que uma soluÃ§Ã£o de Ã¡gua e leite integral apresenta um alto grau de backscattering, apontado por alguns como a principal fonte de degradaÃ§Ã£o da imagem (TREIBITZ; SCHECHNER, 2006). Isso Ã© causado pelo maior tamanho das partÃ­culas do leite integral que fazem que o Ã¢ngulo de refraÃ§Ã£o seja maior, aumentando o backscattering.
Foi decidido dividir o experimento em 3 ensaios, cada um contendo uma imagem diferente.
Cada ensaio foi capturado com 19 nÃ­veis de turbidez diferentes, cada um contendo uma determinada quantidade de leite. Chamou-se cada nÃ­vel de turbidez de ğ‘‡1...ğ‘‡19.
Considera-se ğ‘‡0 como o nÃ­vel de turbidez com a imagem limpa. A Tabela 1 mostra os nÃ­veis de turbidez e suas respectivas quantidades de leite (Em uma caixa com aproximadamente 1000 litros de Ã¡gua).
Para capturar as imagens, a cÃ¢mera foi setada para capturar uma foto a cada 10 segundos. Para cada nÃ­vel de turbidez foi escolhido um grupo de fotos com o menor nÃ­vel de perturbaÃ§Ã£o. Como explicado no CapÃ­tulo 4, SeÃ§Ã£o 4.1, o meio subaquÃ¡tico Ã© 
CapÃ­tulo 5. Testes e Resultados 1: DetecÃ§Ã£o de Pontos de Interesse em Ambiente SubaquÃ¡tico Figura 22 â€“ As imagens utilizadas no teste. As trÃªs imagens foram capturadas nas Bahamas em condiÃ§Ãµes de turbidez prÃ³ximas do ideal em uma resoluÃ§Ã£o de 4928x3264 pixeis composto por uma certa quantidade de ruÃ­do. Em um ambiente controlado, como o que foi feito Ã© possÃ­vel, tendo uma seleÃ§Ã£o de fotos em um mesmo nÃ­vel de turbidez ğ‘‡ğ‘–, reduzir o ruÃ­do extraindo mediana entre as imagens iguais (GARCIA; GRACIAS, 2011). Desta forma busca-se reduzir a degradaÃ§Ã£o na imagem por ruÃ­dos que podem ter diversas causas 
5.2. Avaliando a degradaÃ§Ã£o causada pela turbidez Tabela 1 â€“ A quantidade de leite adicionada para cada nÃ­vel de turbidez simulado.
como erro no sensor da cÃ¢mera, partÃ­culas bloqueando totalmente a passagem da luz, etc.
Tenta-se de certa forma isolar significativamente a degradaÃ§Ã£o por turbidez (IDT), como o principal fenÃ´meno da cena.
A Figura 23 apresenta as imagens geradas pelo experimento. Neste caso fez-se a distinÃ§Ã£o entre diversos intervalos de turbidez. Na Figura 23 Ã© mostrado um nÃ­vel de turbidez por intervalo, para cada imagem.
5.2 Avaliando a degradaÃ§Ã£o causada pela turbidez Medir a quantidade de degradaÃ§Ã£o Ã© fundamental neste experimento de forma a comparar os detectores somente relativo a este fenÃ´meno. A degradaÃ§Ã£o causada pela turbidez Ã© dependende da quantidade de particulas em suspenÃ§Ã£o na Ã¡gua, e tambÃ©m os tipos de particulas em suspenÃ§Ã£o. AlÃ©m disso, a quantidade de iluminaÃ§Ã£o e a maneira como a cena Ã© iluminada Ã© tambÃ©m fundamental para determinaÃ§Ã£o da degradaÃ§Ã£o causada pela turbidez.
Este conceito difere do conceito de turbidez que esta relacionado somente com a quantidade de sedimentos flutuantes (SSC) na Ã¡gua os quais espalham a luz. A degradaÃ§Ã£o causada pela turbidez difere pois ela nÃ£o esta relacionado somente as partÃ­culas presentes na Ã¡gua e sim a degradaÃ§Ã£o que o SSC causa na cena, levando em conta os parÃ¢metros 
CapÃ­tulo 5. Testes e Resultados 1: DetecÃ§Ã£o de Pontos de Interesse em Ambiente SubaquÃ¡tico da cÃ¢mera e o volume de Ã¡gua iluminado.
Uma forma de medir a turbidez Ã© usando um turbidÃ­metro nefelÃ´metro, o qual mede a turbidez pela quantidade de luz espalhada ao emitir um feixe de laser numa porÃ§Ã£o da Ã¡gua.
Esta alternativas nÃ£o Ã© capaz de estimar a degradaÃ§Ã£o causada pela turbidez, que Ã© tambÃ©m dependente da cena. Com essas consideraÃ§Ãµes, Garcia e Gracias (2011) propuseram a utilizaÃ§Ã£o de uma variaÃ§Ã£o Structural Similarity Index (WANG et al., 2004), para avaliar a degradaÃ§Ã£o, chamado Structural Degradation Index (SDI). Essa abordagem avalia a degradaÃ§Ã£o pela perda de informaÃ§Ã£o estrutural, o que de fato esta relacionado 
5.3. Resultados com a turbidez. PorÃ©m, a mesma nÃ£o tenta isolar a mediÃ§Ã£o do fenÃ´meno de absorÃ§Ã£o e espalhamento como principais causadores da degradaÃ§Ã£o.
Neste trabalho utiliza-se a mÃ©trica proposta por (GARCIA; GRACIAS, 2011), porÃ©m normalizada em funÃ§Ã£o da imagem completamente turva pelo leite. Tal mÃ©trica Ã© capaz de medir a porcentagem de degradaÃ§Ã£o em funÃ§Ã£o da imagem onde teve sua informaÃ§Ã£o visual inicial completamente eliminada. O mÃ©todo Ã© explicado na secÃ§Ã£o 5.3.1 5.3 Resultados Nesta seÃ§Ã£o sÃ£o mostradas a comparaÃ§Ãµes entre os detectores. Foram comparados os seguintes detectores, previamente definidos no CapÃ­tulo 1. Para Ãºnica escala, Harris (HARRIS; STEPHENS, 1988), Hessian (BEAUDET, 1978) e Laplacian (TUYTELAARS; MIKOLAJCZYK, 2008). Com mÃºltiplas escalas avaliou-se Fast Hessian do SURF (BAY et al., 2008) e Difference of Gaussians do SIFT (LOWE, 2004). Foram avaliados tambÃ©m outros detectores com propriedades relevantes. Os trÃªs kernels baseados em difusÃ£o anisotrÃ³pica do detector KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) e o gerado pelo centro e arredores usando estruturas poligonais CenSurE (AGRAWAL; KONOLIGE; BLAS, 2008) usando tanto um polÃ­gono convexo de seis lados e um polÃ­gono estrelado de tambÃ©m seis lados.
5.3.1 Procedimento de AvaliaÃ§Ã£o Os resultados sÃ£o avaliados quanto ao critÃ©rio de repetibilidade descrito em (SCHMID; MOHR; BAUCKHAGE, 2000). Tal critÃ©rio indica a porcentagem dos pontos de interesse que se repetiram, ou seja, ainda foram encontrados apÃ³s a aplicaÃ§Ã£o da transformaÃ§Ã£o.
Primeiramente computa-se ğ‘ = 1000 pontos de interesse para cada detector na imagem com a turbidez ğ‘‡0 e para todos os nÃ­veis ğ‘‡1...ğ‘‡19. Os ğ‘ pontos de interesse selecionados sÃ£o os N melhores pontos de interesse segundo o critÃ©rio do detector, no caso Hessian ou Harris. Na imagem com turbidez ğ‘‡0 Ã© selecionada cada ponto-chave e Ã© testado se esse ponto Ã© resistente na presenÃ§a de turbidez. Para esse ponto-chave ser resistente Ã© necessÃ¡rio que o mesmo seja encontrado nas imagens turvas sem sofrer um deslocamento maior que um fator de ğ‘’ = 5 pixeis. Esse valor Ã© determinado de forma a escolher somente os melhores pontos de interesse. Subsequentemente, para determinar a repetibilidade de um certo detector, o nÃºmero de pontos chaves encontrados em cada imagem tÃºrbida sÃ£o contados. Considerando essa questÃ£o, a repetibilidade quanto ao degradaÃ§Ã£o por turbidez 
CapÃ­tulo 5. Testes e Resultados 1: DetecÃ§Ã£o de Pontos de Interesse em Ambiente SubaquÃ¡tico (ğ‘…) Ã© calculada como: (5.1) Onde ğ‘0 Ã© o nÃºmero de pontos de interesse na imagem limpa (capturada em ğ‘‡0) e ğ‘ğ‘– Ã© a imagem com a degradaÃ§Ã£o estimada.
Para medir a degradaÃ§Ã£o causada pela turbidez, foi usado uma versÃ£o diferente do SDI (WANG et al., 2004) (GARCIA; GRACIAS, 2011). O Ã­ndice SDI nÃ£o responde com os mesmos valores para as mesmas quantidades de turbidez. Por esta razÃ£o, foi utilizado uma versÃ£o normalizada do SDI. Considerando a imagem ğ‘‡19 como sendo totalmente degradada, pode-se medir o SDI como uma percentagem da degradaÃ§Ã£o mÃ¡xima, o que facilita a comparaÃ§Ã£o: (5.2) Onde ğ‘†ğ·ğ¼ğ‘ Ã© o Ã­ndice de degradaÃ§Ã£o da imagem ğ‘‡19.
5.3.2 ComparaÃ§Ã£o A Figura 24, mostra os grÃ¡ficos com os valores de repetibilidade para as trÃªs fotos impressas (ğ‘ƒ1,ğ‘ƒ2,ğ‘ƒ3) testando multiplos detectores. No eixo ğ‘¥ Ã© mostrado o indice ğ‘ ğ‘†ğ·ğ¼ e a quantidade de leite adicionada.
Da Figura 24, sÃ£o mostrados as analises para trÃªs intervalos diferentes de degradaÃ§Ã£o causada por turbidez baseado no NSDI . Desde 0 a 0.25 de ğ‘ ğ‘†ğ·ğ¼ foi considerado como um ambiente de Baixa Turbidez(Fig. 23 segunda linha). Nestes casos a maioria da informaÃ§Ã£o estrutural Ã© mantida e o backscattering Ã© mÃ­nimo. No intervalo de 0.25 atÃ© 0.75 foi considerado como imagens de parte de um intervalo de MÃ©dia Turbidez( Fig. 23 terceira linha). Nestes nÃ­veis, a informaÃ§Ã£o estrutural Ã© parcialmente mantidas, mas as bordas passam a ser mal definidas. Ao final, desde 0.75 atÃ© 1, em Alta Turbidez(Fig. 23 quarta linha), quase nenhuma informaÃ§Ã£o estrutural Ã© mantida. Nestes nÃ­veis, os detectores podem somente fazer uso de algumas poucas pistas visuais que ainda resistiram a turbidez.
Para todos os intervalos de turbidez, Ã© possÃ­vel separar claramente os detectores analisados em quatro grupos.
Os detectores baseados em Ãºnica escala (Azul Fig. 24) obtiveram os melhores resultados em todos os intervalos de turbidez. Comparado com outras comparaÃ§Ãµes de detectores de pontos de interesse (GIL et al., 2010) (CRISTINACCE; COOTES, 2006), a superioridade dos detectores nÃ£o invariantes a escala em comparaÃ§Ã£o a aqueles que sÃ£o 
5.3. Resultados 
CapÃ­tulo 5. Testes e Resultados 1: DetecÃ§Ã£o de Pontos de Interesse em Ambiente SubaquÃ¡tico invariantes a escala, em situaÃ§Ãµes onde a escala nÃ£o varia, Ã© mais expressiva. O detector Harris foi melhor para o caso de ğ‘ƒ1 (Fig. 24a) atÃ© um nÃ­vel mÃ©dio de turbidez. ApÃ³s isso o mesmo teve um decaimento maior, quando as estruturas comeÃ§aram a se perder.
O detector baseado em espaÃ§os de escala com difusÃ£o anisotrÃ³pica, obteve os piores resultados (Vermelho Fig. 24). Isso Ã© o oposto do que Ã© mostrado em cenas fora dâ€™Ã¡gua (ALCANTARILLA; BARTOLI; DAVISON, 2012). O algoritmo KAZE necessita calcular as respostas das bordas antes de obter o espaÃ§o de escala. Isso Ã© mais dificil em ambientes subaquÃ¡ticos devido a suas propriedades naturais. PorÃ©m, no intervalo de Baixa Turbidez, KAZE foi capaz de obter uma repetibilidade maior que o FastHessian e o DoG, dado que as bordas ainda estÃ£o bem definidas. Para o caso de MÃ©dia Turbidez, a taxa de acerto cai rapidamente, chegando a zero em Alta Turbidez.
Os melhores resultados para nÃ­veis de media e alta turbidez, foram, de fato, obtidos pelo detector DoG (LOWE, 2004). O detector Fast Hessian, possui uma aproximaÃ§Ã£o mais brusca do espaÃ§o de escala a qual tende a produzir artefatos. Por isso, tratou-se do pior resultado dentre os analisados.
CenSurPoly e o CenSurStar apresentaram resultados similares ao Kaze tendo piores resultados para nÃ­veis mais altos de turbidez.
A Figura 25 mostra a comparaÃ§Ã£o de um determinado nÃ­vel de espaÃ§o de escala gerado por um kernel gaussiano , um kernel baseado em caixas (FastHessian), um kernel baseado em polÃ­gonos estrelados (CenSurE) e um gerado pelo filtro anisotrÃ³pico (KAZE) ğ‘”2 da Eq. 1.12 . Tais kernels sÃ£o aplicados em mÃºltiplos nÃ­veis de turbidez, sendo que cada linha da figura apresenta um nÃ­vel de turbidez diferente.
Ã‰ possÃ­vel perceber que a informaÃ§Ã£o estrutural se mantÃ©m mais para o polÃ­gono estrelado. O que justifica o seu estudo, principalmente para o caso de maior turbidez. JÃ¡ o KAZE tambÃ©m possui um comportamento interessante, porÃ©m muito da informaÃ§Ã£o tende a se perder com a turbidez para um mesmo nÃ­vel de escala.
Como mostrado no CapÃ­tulo 4, SeÃ§Ã£o 4.1 , existe um comportamento de borramento regido por um certo fenÃ´meno. Ã‰ possÃ­vel que funÃ§Ãµes, como as utilizadas pelo CenSurE e o KAZE, as quais tendem a nÃ£o seguir o comportamento do borramento causado pelas propriedades do meio subaquÃ¡tico, tendam a manter as estruturas geomÃ©tricas , e , ao encontrar pontos que possuem mÃ¡ximo sobre escala, encontrem regiÃµes em que ainda existe informaÃ§Ã£o visual provida pela imagem.
5.4 ConclusÃµes finais Este capÃ­tulo apresentou a avaliaÃ§Ã£o a invariÃ¢ncia a degradaÃ§Ã£o em ambientes subaquÃ¡ticos para detectores de pontos de interesse mais utilizados na literatura. Foi 
5.4. ConclusÃµes finais proposto um novo dataset, completamente aberto, usando fotos impressas reais as quais tinham uma quantidade controlada de turbidez.
Foi concluÃ­do que para, imagens subaquÃ¡ticas, mÃ©todos de Ãºnica escala tem uma repetibilidade consideravelmente melhor que abordagens de multipla escala. Entre Harris (HARRIS; STEPHENS, 1988) e Hessian (BEAUDET, 1978), Hessian obteve resultados melhores principalmente para nÃ­veis mais altos de turbidez e em imagens onde hÃ¡ pouca informaÃ§Ã£o estrutural.

CapÃ­tulo 5. Testes e Resultados 1: DetecÃ§Ã£o de Pontos de Interesse em Ambiente SubaquÃ¡tico Considerando mÃºltipla escala, foram avaliados novos detectores os quais nÃ£o usam os espaÃ§os de escala Gaussianos. Foi proposto que nestes espaÃ§os diferentes, como os center surround ou os baseados em difusÃ£o anisotrÃ³pica, a difusÃ£o nÃ£o acontece com a mesma estrutura que o fenÃ´meno de degradaÃ§Ã£o da turbidez, assim entÃ£o produzindo melhores resultados, em alguns nÃ­veis de turbidez.
Os melhores resultados para mÃºltipla escala foram obtidos pelo DoG (LOWE, 2004) TambÃ©m mostrou-se que o KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) apresenta resultados relevantes mas tende a perder precisÃ£o em nÃ­veis mais altos de turbidez.
Finalmente, a avaliaÃ§Ã£o proposta mostra que um espaÃ§o de escala nÃ£o Gaussiano pode tambÃ©m produzir melhores resultados. Como trabalho futuro, buscar-se-Ã¡ explorar que espaÃ§os de escala que consideram a degradaÃ§Ã£o causada pela turbidez de forma a obter melhores resultados de repetibilidade.

6 Testes e Resultados 2: Contexto em ClassificaÃ§Ã£o SubaquÃ¡tica Aqui sÃ£o apresentados os resultados de aplicaÃ§Ã£o do mÃ©todo proposto baseado em GeoestatÃ­stica (no Cap. 3), comparado com outros mÃ©todos, com e sem a incorporaÃ§Ã£o do contexto.
O mÃ©todo serÃ¡ aplicado em mosaicos de imagens do assoalho oceÃ¢nico, para obtenÃ§Ã£o de mapas temÃ¡ticos. As imagens resultantes sÃ£o a representaÃ§Ã£o final de um mosaico, feito de forma visualmente interpretÃ¡vel, contendo a classificaÃ§Ã£o realizada de forma pixel-a-pixel.
O capÃ­tulo apresenta os datasets, compostos por mosaicos, utilizados como caso de teste para a classificaÃ§Ã£o e tambÃ©m as configuraÃ§Ãµes utilizadas para os testes e, por fim, os resultados da classificaÃ§Ã£o dos mosaicos sÃ£o mostrados.
6.1 Datasets Utilizados Para avaliaÃ§Ã£o dos resultados obtidos foi proposto utilizar dois datasets distintos de mosaicos de recifes de corais. Cada dataset Ã© composto por um mosaico obtido pela junÃ§Ã£o de centenas de imagens coletadas por especialistas da Universidade de Miami.
O dataset Redsea contÃ©m imagens do Mar Vermelho, capturadas em Ã¡guas bastante rasas perto da cidade de Eilat, como parte de uma pesquisa por ecologistas de recifes de corais (ZVULONI et al., 2009). Para a classificaÃ§Ã£o, foram considerado cinco classes: Urchin, Branching Coral, Brain Coral, Favid Coral e o Background. Os mosaicos utilizados foram capturados a uma resoluÃ§Ã£o de 1.1 ğ‘ğ‘–ğ‘¥ğ‘’ğ‘–ğ‘ /ğ‘šğ‘š2.
O segundo dataset chamado Marker, foi capturado nas Bahamas. Foi feita a divisÃ£o em quatro classes para classificaÃ§Ã£o. General Corals, Sea Gorgons, Sand e Background.
Os mosaicos utilizados foram capturado em uma resoluÃ§Ã£o de 2.2 ğ‘ğ‘–ğ‘¥ğ‘’ğ‘–ğ‘ /ğ‘šğ‘š2.
6.2 DescriÃ§Ã£o do Geral do Sistema Nesta seÃ§Ã£o Ã© descrito uma versÃ£o geral do sistema, tanto para a classificaÃ§Ã£o em nÃ­vel unÃ¡rio, quanto os tipos de classificaÃ§Ã£o integrando contexto.

CapÃ­tulo 6. Testes e Resultados 2: Contexto em ClassificaÃ§Ã£o SubaquÃ¡tica 6.2.1 PrÃ©-Processamento Tanto para os dados do dataset Redsea quanto para o caso do dataset Marker , a qualidade visual da imagem Ã© bastante satisfatÃ³ria, contendo baixa presenÃ§a de degradaÃ§Ã£o devido a turbidez. O principal tipo de degradaÃ§Ã£o encontrado Ã© a variaÃ§Ã£o de cor ao longo do datasets existentes durante a captura. Para resolver esta questÃ£o foi utilizado CLAHE (ZUIDERVELD, 1994) e uma normalizaÃ§Ã£o de cor em ambos os datasets.
6.2.2 SegmentaÃ§Ã£o e DescriÃ§Ã£o Os datasets foram segmentados como superpixeis baseados em TurboPixels (LEVINSHTEIN et al., 2009). O tamanho do pixel foi escolhido como que para caber em uma janela de tamanho de aproximadamente 32x32 pixeis.
Para cada superpixel, a combinaÃ§Ã£o entre trÃªs descritores de textura foi utilizada.
Filtros de Gabor, CLBP e GLCM. Um kernel mapping Ã© feito depois para tornar os descritores mais linearmente separÃ¡veis. O resultado Ã© tambÃ©m por fim, normalizado.
6.2.3 ClassificaÃ§Ã£o No caso, para todos os testes, foi utilizado um SVM configurado com um kernel linear.
6.2.4 AdiÃ§Ã£o de Contexto A adiÃ§Ã£o de contexto Ã© apresentada feita de duas formas distintas: utilizando os Conditional Random Fields (CRF) e utilizando o modelo de GeoestatÃ­stica, o quais foram explicados nos CapÃ­tulos 2 e 3.
Para o CRF utilizado o algoritmo de Loopy Belief Propagation(LBP) para realizar a inferÃªncia estatÃ­stica, dado a sua baixa taxa de erros e alta performance (WEISS, 2000).
6.3 Treinamento Aqui Ã© descrito como foi realizado o treinamento das partes do sistema onde o treinamento Ã© necessÃ¡rio.
6.3.1 Treinamento do Classificador O treinamento unÃ¡rio diz respeito ao treinamento da funÃ§Ã£o de discriminaÃ§Ã£o do classificador.

6.3. Treinamento Tanto para o dataset Redsea quanto para o Marker foram feitas diversas amostragens dos mosaicos existentes para o treinamento do classificador de cada uma das classes.
A Figura 26, mostra exemplos de segmentos usados para o treinamento do classificador para os dois datasets utilizados. Foram feitas amostras de por volta de 200 segmentos para cada classe sendo cada uma tendo 64x64 pixeis. As amostras foram indicadas por especialistas da universidade de Miami.
Figura 26 â€“ Partes manualmente segmentadas utilizadas para treinamento do classificador. A esquerda sÃ£o mostrados exemplos de nove amostras usadas para treinar o dataset Redsea. A direita sÃ£o apresentadas nove amostras do dataset Marker.
6.3.2 Treinamento UnÃ¡rio Para gerar a curva de confianÃ§a, usada para gerar os distribuiÃ§Ã£o de probabilidades unÃ¡ria tanto para o CRF, quanto para o modelo de GeoestÃ¡tistica, foram tambÃ©m utilizadas amostras do mosaico de treinamento da Figura 26.
As Figuras 27 e 28 mostram as curvas de confianÃ§a obtidas para cada um dos dois datasets em cada uma das classes. O processo de geraÃ§Ã£o das curvas Ã© descrito no CapÃ­tulo 3 SeÃ§Ã£o 3.2.
Pelos grÃ¡ficos das Figuras 27 e 28 percebe-se que determinadas classes se adaptam melhor que outras a uma curva de confianÃ§a, como a classe Sea Gorgon ( Fig. 28c) do dataset Marker. Para esta classe Ã© possÃ­vel saber quais distÃ¢ncias do classificador que existe uma grande probabilidade de se acertar a classe, enquanto para outras o modelo nÃ£o se adaptou tÃ£o adequadamente (Fig. 29b).
Entretanto, o principal erro em adaptaÃ§Ã£o da curva se da na classe Background para os dois casos (Fig. 27a e Fig. 29a). Isso se da devido a alta variabilidade intra-classe inerente a classe Background, a qual contÃ©m todos os tipos de objetos que nÃ£o sÃ£o de interesse para classificaÃ§Ã£o.

CapÃ­tulo 6. Testes e Resultados 2: Contexto em ClassificaÃ§Ã£o SubaquÃ¡tica Figura 27 â€“ Curvas de confianÃ§a geradas no treinamento unÃ¡rio de cada classe para o dataset Redsea. A curva de confianÃ§a ğ¶ğ‘™ğ‘– treinada para cada uma das classes Ã© mostrada, se bem como o grau de confianÃ§a obtido.
6.3.3 Treinamento Potenciais Locais Para treinamento dos potenciais locais foi utilizado cada dataset na sua totalidade.
Para o caso do CRF foi utilizado o algoritmo de treinamento descrito no CapÃ­tulo 2, SeÃ§Ã£o 2.2.2.2 .
As Tabelas 2 e 3 mostram a matriz de covariÃ¢ncia obtida para cada um dos dois datasets. Tal matriz estÃ¡ relacionada a uma indicaÃ§Ã£o de determinada classe estar prÃ³xima a outra.
Os resultados do treinamento dos vetores de transiÃ§Ã£o, necessÃ¡rios para a simulaÃ§Ã£o 
6.3. Treinamento Figura 28 â€“ Curvas de confianÃ§a geradas no treinamento unÃ¡rio de cada classe para o dataset Marker. A curva de confianÃ§a ğ¶ğ‘™ğ‘– treinada para cada uma das classes Ã© apresentada, bem como o grau de confianÃ§a obtido.
Tabela 3 â€“ Matriz de covariÃ¢ncia que mostra as relaÃ§Ãµes de proximidade entre as classes.
Tais medidas sÃ£o fatores que indicam correlaÃ§Ã£o e nÃ£o distribuiÃ§Ãµes de probabilidade. Este resultado Ã© normalizado ao final.
do mÃ©todo de GeoestatÃ­stica, sÃ£o mostrados na Figura 29 para ambos os datasets testados.
Para ambos os datasets analisados se observa a classe background como sendo predominante nas estatÃ­sticas medidas em ambos os treinamentos. No caso do treinamento dos vetores de transiÃ§Ã£o (GeoestatÃ­stica), tambÃ©m foi vista uma tendÃªncia de outras classes em transitar para o Background (Fig. 29). Algo que, para o treinamento dos potenciais locais do CRF, indicou principalmente uma tendÃªncia do Background ter proximidade consigo prÃ³prio.
Para o dataset Redsea, nas relaÃ§Ãµes locais treinadas pelo CRF se observa algumas tendÃªncias: 
CapÃ­tulo 6. Testes e Resultados 2: Contexto em ClassificaÃ§Ã£o SubaquÃ¡tica Figura 29 â€“ Vetores de transiÃ§Ã£o obtidos na etapa de treinamento para o mÃ©todo de GeoestatÃ­stica do CapÃ­tulo 3. Os vetores indicam a probabilidade de uma classe transitar para outra a uma determinada distÃ¢ncia. O eixo x apresenta a distÃ¢ncia em pixeis. O eixo ğ‘¦ dos grÃ¡ficos apresenta as probabilidades de transiÃ§Ã£o. Pode-se observar, por exemplo, uma certa tendÃªncia na classe Urchin em transitar para categoria de background.

6.4.
Sistemas Testados âˆ™ As classes Urchin tem uma grande possibilidade de estar prÃ³xima a classe Faviid Coral; âˆ™ Cada classe tem uma forte tendÃªncia de estar prÃ³xima a si prÃ³pria, o que enfatiza a pouca variabilidade de classes em espaÃ§os pequenos; âˆ™ Existe algumas tendÃªncias assimÃ©tricas treinadas, como a grande tendÃªncia da classe Faviid Coral estar prÃ³xima da classe Urchin, mas nÃ£o ao contrÃ¡rio.
As transiÃ§Ãµes assimÃ©tricas, ou seja, uma dada classe A estar prÃ³xima a classe B mas nÃ£o B prÃ³xima da A, nÃ£o sÃ£o incentivadas pelos potenciais treinados pelo mÃ©todo de GeoestatÃ­stica.
Considerando as relaÃ§Ãµes treinadas pelo mÃ©todo de GeoestatÃ­stica, existe uma tendÃªncia forte principalmente de transiÃ§Ã£o da classe Urchin para a classe Faviid Coral e a classe Background.
Para o dataset Marker, nenhuma outra tendÃªncia de proximidade foi obtida para o CRF, fora a tendÃªncia de background estar prÃ³ximo de si mesmo. As mesmas tendÃªncias sÃ£o observadas para o treinamento dos vetores de transiÃ§Ã£o para o caso da GeoestatÃ­stica.
6.4 Sistemas Testados Quatro sistemas sÃ£o testados quanto a sua taxa de acerto em relaÃ§Ã£o a classificaÃ§Ã£o de mosaicos de imagens. Isso foi feito principalmente de forma a avaliar a consideraÃ§Ã£o de contexto, juntamente com a nova proposta apresentada no CapÃ­tulo 3 Inicialmente foi avaliado o sistema UnÃ¡rio, proposto por Shihavuddin et al. (2013) onde somente as informaÃ§Ãµes unÃ¡rias sÃ£o consideradas, ou seja, dada a definiÃ§Ã£o de classificaÃ§Ã£o considerando uma segmentaÃ§Ã£o em regiÃµes (SHIHAVUDDIN et al., 2013). Somente a descriÃ§Ã£o da prÃ³pria regiÃ£o foi usada para classificaÃ§Ã£o, o sistema Ã© detalhado no Cap.
4 .
ApÃ³s foi testado e analisado o sistema UnÃ¡rio porÃ©m baseado em distribuiÃ§Ã£o de probabilidades. Em tal sistema foi feita a classificaÃ§Ã£o apenas considerando a parcela unÃ¡ria do sistema com base no modelo em GeoestatÃ­stica proposto no Cap. 3. A classificaÃ§Ã£o de um segmento foi escolhida como o rÃ³tulo com mÃ¡xima a probabilidade.
Apresenta-se tambÃ©m o sistema, GS, baseado em GeoestatÃ­stica proposto no Cap.
3. A classificaÃ§Ã£o de cada segmento (Superpixel) Ã© dada pela Eq. 3.1, do Cap. 3.
Por fim, apresenta-se os resultados do sistema CRF o qual Ã© uma implementaÃ§Ã£o dos Conditional Random Fields , tal qual explicada no Cap 2.

CapÃ­tulo 6. Testes e Resultados 2: Contexto em ClassificaÃ§Ã£o SubaquÃ¡tica Todos os sistemas foram implementados em Matlab, para o CRF, foi utilizada a biblioteca UGM para inferÃªncia estatÃ­stica (SCHMIDT et al., 2009).
6.5 ComputaÃ§Ã£o do Mapa TemÃ¡tico No dataset Redsea, um mosaico de 3256x2939 pixeis foi utilizado para testes. JÃ¡ para dataset Marker,foi utilizado um mosaico de 2592x3963.
As Figuras 30 e 31 mostram os mapas temÃ¡ticos completos computados para ambos os datasets.
Observa-se que num caso geral o CRF Ã© o mÃ©todo que obtÃ©m os melhores resulta-dos. O mÃ©todo de GeoestatÃ­stica Ã© capaz de melhorar um pouco, porÃ©m depende muito de um bom treinamento da distribuiÃ§Ã£o de probabilidades de cada segmento.
Para o caso do dataset Marker, a adiÃ§Ã£o de contexto foi mais eficaz para ambos os casos. Isso ocorre dado que muitas posiÃ§Ãµes geraram resultados com distribuiÃ§Ã£o unÃ¡ria uniforme, ou seja sem uma classe com alta probabilidade. O que contribuiu para adiÃ§Ã£o de contexto foi, que tais regiÃµes, estavam cercadas por locais onde existia uma classe predominante.
Ao se observar a configuraÃ§Ã£o do dataset Redsea se percebe uma tendÃªncia espacial em se ter "ilhas"de classes envolvidas pela classe background. Dado que a classe background tem uma alta variabilidade intra-classe, Ã© bastante complicado se ter uma tendÃªncia forte para uma classe na distribuiÃ§Ã£o unÃ¡ria. Isso dificulta a proliferaÃ§Ã£o da informaÃ§Ã£o de contexto na regiÃ£o.
De forma a analisar melhor as diferenÃ§as entre o CRF e o mÃ©todo de GeoestatÃ­stica, Ã© mostrado na Figura 32 duas Ã¡reas diferentes do mosaico do Redsea para mostrar algumas vantagens da abordagem com base em GS. Ã‰ apresentada a Ã¡rea original da imagem com a classificaÃ§Ã£o mostrada em cores. Na primeira linha, pode se perceber o grau de acerto maior para o CRF (Fig. 32c). O CRF tende a melhorar significativamente a suavizaÃ§Ã£o local das estruturas classificadas. Ou seja, impÃµe que Ã¡reas pequenas devam ter menos variaÃ§Ãµes de classes. Por esta razÃ£o o CRF teve uma boa classificaÃ§Ã£o especialmente para o caso da classe representada em azul (Faviid Corals).
Por outro lado, na segunda linha, GS (Fig. 32f) obteve um grau de acerto maior.
Dado que o CRF (Fig. 32g) impÃµe mais suavidade local, isso tende a eliminar classes menores (Fig. 32g). Este caso Ã© evitado pela GS pelo fato de que a abordagem baseada em GeostatÃ­stica usa estatÃ­sticas medidas em longas distÃ¢ncias e assim o tamanho da classe Ã© considerado. Na terceira linha da Figura 32, sÃ£o mostrados resultados similares para o dataset Marker.
TambÃ©m os algoritmos foram testados para mÃºltiplos segmentos diferentes extraÃ­do 
6.6. ConclusÃµes Tabela 4 â€“ Resultados para a taxa de acerto de diferentes segmentos para o dataset Redsea.
Foram testados diversos segmentos quadrados amostrados aleatoreamente nos mosaicos.
O tamanho do segmento Ã© especificado pelo lado do quadrado dos mosaicos. Foram recortadas amostras quadradas aleatÃ³rias de diferentes tamanhos.
Para cada tamanho recortado, a tabela 4 mostra a taxa de acerto mÃ©dia do mÃ©todo aplicado em 20 segmentos aleatÃ³rios. TambÃ©m foi testado um mÃ©todo simples de votaÃ§Ã£o onde um superpixel Ã© modificado caso a classe de todos os vizinhos seja differente.
No dataset Redsea, para todas as abordagens , nÃ£o foi percebido mais do que ganhos marginais quando comparados com a versÃ£o unitÃ¡ria. O mÃ©todo de votaÃ§Ã£o tambÃ©m obteve resultados similares.
6.6 ConclusÃµes Conclui-se que o uso de estatÃ­sticas mais ricas, inspiradas pelos conceitos de GeoestatÃ­sticas, Ã© benÃ©fico e pode conduzir a melhores resultados que o CRF tradicional em alguns casos.
As melhorias obtidas, foram, no entanto, de pequena magnitude, o que esta alinhado com o que Ã© discutido em (LUCCHI et al., 2011). Os resultados utilizando contexto normalmente nÃ£o melhoram mais do que a suavidade local dos resultados, ou seja, nÃ£o mais do que evitam grande variaÃ§Ã£o de classes em uma pequena Ã¡rea. PorÃ©m ainda Ã© possÃ­vel obter melhorias significativas, para alguns datasets como no caso do Marker.

CapÃ­tulo 6. Testes e Resultados 2: Contexto em ClassificaÃ§Ã£o SubaquÃ¡tica (a) UnitÃ¡rio 76.83% (b) UnitÃ¡rio com Curvas de ConfianÃ§a 75.779% (c) GeoestatÃ­stica 76.16% (d) CRF 77.32% Figura 30 â€“ Mapa temÃ¡tico dos Mosaicos para o dataset Redsea. As figuras mostram a porcentagem de acerto relativa ao GroundTruth. As classes sÃ£o representadas pelas seguintes cores: Verde Brain Coral; Amarelo Branchin Coral; Azul Faviid Coral; Magenta Urchin e sem cor Ã© o background. Os seguintes resultados sÃ£o mostrados.(30a) classificaÃ§Ã£o UnÃ¡ria. (30b) mostra a classificaÃ§Ã£o UnÃ¡ria baseada nas curvas de confianÃ§a. (30c) classificaÃ§Ã£o com adiÃ§Ã£o de contexto baseada em GeoestatÃ­stica. (30d) classificaÃ§Ã£o com adiÃ§Ã£o de contexto utilizando CRF.

6.6. ConclusÃµes Figura 31 â€“ Mapa temÃ¡tico dos Mosaicos para o dataset Marker. As figuras mostram a porcentagem de acerto relativa ao GroundTruth. As classes sÃ£o representadas pelas seguintes cores: Verde Sand; Amarelo Sea Gorgon; Azul Corals e sem cor Ã© o background.
Os seguintes resultados sÃ£o mostrados.(31a) classificaÃ§Ã£o UnÃ¡ria. (31b) mostra a classificaÃ§Ã£o UnÃ¡ria baseada nas curvas de confianÃ§a. (31c) classificaÃ§Ã£o com adiÃ§Ã£o de contexto baseada em GeoestatÃ­stica. (31d) classificaÃ§Ã£o com adiÃ§Ã£o de contexto utilizando CRF.

CapÃ­tulo 6. Testes e Resultados 2: Contexto em ClassificaÃ§Ã£o SubaquÃ¡tica Figura 32 â€“ Resultados de classificaÃ§Ã£o para os datasets Marker e os datasets Redsea. A primeira coluna apresenta a classificaÃ§Ã£o unitÃ¡ria. A segunda coluna apresenta os resulta-dos de GeoestatÃ­stica. A terceira coluna apresenta os resultados para o CRF. Por fim, a ultima coluna apresenta o GroundTruth. Foi utilizada como peso para o potencial local ğ‘¤ğ‘™ como sendo 0.4 para ambas as abordagens. Na primeira coluna foi possÃ­vel perceber um resultado melhor para o CRF devido a uma maior suavizaÃ§Ã£o local. Na segunda linha, o mÃ©todo de GeoestatÃ­stica obteve melhores resultados devido a suas medidas estatÃ­sticas de longa distÃ¢ncia. Na Ãºltima linha Ã© mostrado os resultados para o dataset Marker, onde ambas as abordagens tiveram melhores resultados para esse caso.

7 ConclusÃµes Finais Considerando o problema de estender a utilizaÃ§Ã£o de mÃ©todos de visÃ£o computacional para o cenÃ¡rio subaquÃ¡tico, esta dissertaÃ§Ã£o apresentou o estudo e tratamento para alguns dos principais problemas existentes no meio.
Foi feito um estudo sobre duas Ã¡reas distintas relevantes para o problema: A detecÃ§Ã£o de pontos de interesse e o uso da informaÃ§Ã£o de contexto na classificaÃ§Ã£o de imagens.
Nas seÃ§Ãµes que seguem serÃ£o apresentadas as contribuiÃ§Ãµes sobre as duas Ã¡reas distintas analisadas, como tambÃ©m as limitaÃ§Ãµes das propostas.
7.1 Detectores de Pontos de Interesse em Imagens SubaquÃ¡ticas Turvas No contexto subaquÃ¡tico, foi feito um estudo sobre como se comportam os mÃºltiplos detectores de pontos de interesse sobre a presenÃ§a da turbidez, fenÃ´meno o qual se faz presente no meio subaquÃ¡tico.
7.1.1 ContribuiÃ§Ãµes Obtidas As principais contribuiÃ§Ãµes obtidas foram: âˆ™ A proposta de um dataset novo contendo imagens reais do assoalho oceÃ¢nico porÃ©m com a turbidez controlada.
âˆ™ Uma anÃ¡lise geral da repetibilidade dos detectores em meios tÃºrbidos, dividindo a anÃ¡lise em intervalos de turbidez distintos.
âˆ™ Dentre os detectores estudados, foi apontado o DoG como o mais robusto detector para ambientes com presenÃ§a de turbidez. Tal detector contÃ©m tambÃ©m invariÃ¢ncia a escala.
âˆ™ Foi concluÃ­da a possibilidade do uso de espaÃ§os nÃ£o gaussianos para geraÃ§Ã£o de espaÃ§o de escala em meios subaquÃ¡ticos tÃºrbidos.
7.1.2 LimitaÃ§Ãµes e Trabalhos Futuros O estudo nÃ£o foi capaz de propor um mÃ©todo para medir de fato a degradaÃ§Ã£o causada pela turbidez. A medida utilizada Ã© capaz de verificar a degradaÃ§Ã£o estrutural o que nÃ£o necessariamente estÃ¡ associada a turbidez.

CapÃ­tulo 7. ConclusÃµes Finais Um outro ponto a ser tratado diz respeito a uma anÃ¡lise mais criteriosa com respeito a invariÃ¢ncia a outras transformaÃ§Ãµes como rotaÃ§Ã£o ou escala, juntamente com a robustez Ã  degradaÃ§Ã£o causada pela turbidez.
7.2 AdiÃ§Ã£o de Contexto Baseado em GeoestatÃ­stica Foi proposto um novo mÃ©todo para adicionar informaÃ§Ã£o espacial na classificaÃ§Ã£o de imagens. O mÃ©todo se baseou nos estudos da Ã¡rea de GeoestatÃ­stica. Tal mÃ©todo foi aplicado em imagens de mosaicos de recifes de corais. O mesmo foi comparado com as versÃµes sem a utilizaÃ§Ã£o de contexto e com o modelo dos Conditional Random Fields (CRF).
Apresentou-se que a adiÃ§Ã£o de contexto pode, em alguns casos, ser benÃ©fica para a classificaÃ§Ã£o de imagens subaquÃ¡ticas. Obtendo-se um ganho de atÃ© 5% a mais em taxa de acerto.
7.2.1 ContribuiÃ§Ãµes Obtidas O trabalho apresentou um novo mÃ©todo para adiÃ§Ã£o de contexto em imagens subaquÃ¡ticas. O uso de medidas estatÃ­sticas mais ricas, como as baseadas em GeoestatÃ­stica, mostrou-se Ãºtil em algumas situaÃ§Ãµes para adiÃ§Ã£o de informaÃ§Ã£o de contexto.
TambÃ©m essa dissertaÃ§Ã£o serve como uma conexÃ£o entre duas Ã¡reas distintas: a GeoestatÃ­stica e os Modelos ProbabilÃ­stico GrÃ¡ficos (MPGs). Acredita-se que atravÃ©s desta intersecÃ§Ã£o, as aplicaÃ§Ãµes que fazem uso de GeoestatÃ­stica podem tambÃ©m se beneficiar dos MPGs.
7.2.2 LimitaÃ§Ãµes e Trabalhos Futuros Coloca-se que a abordagem apresentada foi aplicada para um cenÃ¡rio subaquÃ¡tico especÃ­fico. Uma direÃ§Ã£o seria a aplicaÃ§Ã£o em dataset com classes mais genÃ©ricas, os da Pascal Visual Object Classes Challenge (VOC) (EVERINGHAM et al., 2010).
Os resultados para o mÃ©todo de GeoestatÃ­stica foram satisfatÃ³rios porÃ©m ficaram abaixo em taxa de acerto quando comparados ao CRF. Apesar da tendÃªncia de se usar os mÃ©todos de GeoestatÃ­stica para casos onde hÃ¡ pouca quantidade de informaÃ§Ãµes (CARLE; FOGG, 1996).
Existe ainda uma necessidade maior de alteraÃ§Ã£o no modelo original de GeoestatÃ­stica visando uma melhor adaptaÃ§Ã£o para o caso de imagens subaquÃ¡ticas.
