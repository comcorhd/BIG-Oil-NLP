Moreira, Rafael Nardes M837p Programação modular e computação de alto desempenho em um simulador de reservatórios não convencionais de gás em folhelhos / Rafael Nardes Moreira -- Petrópolis, RJ. : Laboratório Nacional de Computação Científica, 2016. 
xv, 117 p. : il. ; 29 cm. 
Orientadores:  Eduardo Lúcio Mendes Garcia e Sandra Mara Cardoso Malta. 
Dissertação (Mestrado) – Laboratório Nacional de Computação Científica, 2016. 
1. Programação modular 2. Programação orientada a objetos 3.Simulação dereservatórios 4. Gás de folhelhos  I. Garcia, Eduardo Lúcio Mendes II. Malta, Sandra Mara Cardoso III. MCT/LNCC; IV.Título CDD – 005.112 “Ladies and gentlemen, we have detectedgravitational waves. We did it!”
(David Reitze, Caltech physicist and LIGOlab director.)
“Until this moment, we had our eyes on thesky and we couldn’t hear the music. Theskies will never be the same.”
(Szabolcs Marka, Columbia Universityastrophysicist.)
ivDedicat´oriaDedico este trabalho a meus pais, Fernandoe Maria Helena.
vAgradecimentos`A minha fam´ılia e namorada, por oferecem a mim o todo incentivo ecompreens˜ao que se pudesse deles esperar.
Ao meu orientador, Bidu, pelo incentivo ao trabalho, disponibilidade eproximidade durante o ´ultimo ano.
`A minha coorientadora, Sandra Malta, pelo acompanhamento e opini˜oes emnossas reuni˜oes peri´odicas.
`A professora Carla Osthoﬀ, pelo acompanhamento do trabalho e pelointeresse em colaborar, sugerindo ferramentas de software e bibliograﬁa, muito´uteis ao trabalho.
`A colega Patr´ıcia Costa, pela paciˆencia em responder perguntas e, a cadauma delas, colocar-se a disposi¸c˜ao para a pr´oxima.
Ao professor Roberto Souto, pela disponibilidade sempre que solicitado epela prontid˜ao ao disponibilizar uma m´aquina para experimentos quanto isso defez necess´ario.
Aos demais professores do programa de p´os-gradua¸c˜ao do LNCC com osquais interagi e aprendi durante os dois ´ultimos anos.
`A ANP - Agencia Nacional do Petr´oleo, G´as Natural e Biocombust´ıveis peloapoio ﬁnanceiro.
viResumo da Disserta¸c˜ao apresentada ao LNCC/MCT como parte dos requisitosnecess´arios para a obten¸c˜ao do grau de Mestre em Ciˆencias (M.Sc.)
PROGRAMA ¸C ˜AO MODULAR E COMPUTA ¸C ˜AO DE ALTODESEMPENHO EM UM SIMULADOR DE RESERVAT ´ORIOS N ˜AOCONVENCIONAIS DE G ´AS EM FOLHELHOSRafael Nardes MoreiraMar¸co , 2016Orientador: Eduardo L´ucio Mendes Garcia, D.Sc
Co-orientador: Sandra Mara Cardoso Malta, D.Sc.
A modelagem computacional de reservat´orios ´e o instrumento que permitea descri¸c˜ao precisa dos fenˆomenos f´ısicos existentes no processo de recupera¸c˜ao de´oleo e g´as, tendo grande interesse tanto para a ind´ustria quanto para a ciˆencia.
Na ind´ustria de ´oleo e g´as, ´e grande a demanda por simuladores comerciais dereservat´orios. Por outro lado, simuladores cient´ıﬁcos s˜ao capazes de ofereceraos pesquisadores do dom´ınio, o controle e a liberdade necess´arios `a atividadeacadˆemica.
Dentre as principais demandas do software cient´ıﬁco em geral est˜ao (i) odesign escal´avel, relacionado ao desenvolvimento de c´odigo de maneira organizadae modular, contribuindo para sua evolu¸c˜ao e (ii) a execu¸c˜ao escal´avel, relacionada`a implementa¸c˜ao de t´ecnicas de computa¸c˜ao paralela e de alto desempenho,em raz˜ao das grandes massas de dados manipuladas e dos modelos num´ericoscomputacionalmente intensivos produzidos pela ciˆencia.
Este trabalho trata do emprego de t´ecnicas de programa¸c˜ao modular comorienta¸c˜ao a objetos e de computa¸c˜ao paralela com OpenMP e MPI em umsimulador cient´ıﬁco, escrito em Fortran e utilizado na modelagem num´erica deproblemas de escoamento em reservat´orios n˜ao convencionais de g´as em folhelhos.
viiAbstract of Dissertation presented to LNCC/MCT as a partial fulﬁllment of therequirements for the degree of Master of Sciences (M.Sc.)
MODULAR PROGRAMMING AND HIGH PERFORMANCECOMPUTING IN A GAS SHALE RESERVOIR SIMULATORRafael Nardes MoreiraMarch, 2016Advisor: Eduardo L´ucio Mendes Garcia, D.Sc
Co-advisor: Sandra Mara Cardoso Malta, D.Sc.
Computer modeling of reservoirs is the tool that provides the accuratedescription of the existing physical phenomena in the oil and gas recovery process,being of interest to both the industry and science. In oil and gas industry, thedemand of commercial simulators is remarkable. At the same time, scientiﬁcsimulators are able to provide researchers with the freedom and control neededby the academic activity.
Among the major demands of scientiﬁc software are: (i) the scalable design,which is correlated with organized and modular code development, and (ii) thescalable execution, related to the implementation of techniques for parallel andhigh performance computing, due to the large amount of manipulated data andthe compute-intensive numerical models produced by science.
This dissertation aims to the application of techniques for modular object-oriented programming and parallel computing, with OpenMP and MPI, in ascientiﬁc simulator, developed in Fortran and used in the numerical modeling ofproblems related to gas ﬂow on unconventional gas-shale reservoirs.
viiiSum´ario1 Introdu¸c˜ao11.1 O simula¸c˜ao de reservat´orios no LNCC . . . . . . . . . . . . . . . .
31.2 O modelo 2 escalas: Fratura e Bloco . . . . . . . . . . . . . . . . .
41.3 Programa¸c˜ao Modular com Orienta¸c˜ao a Objetos. . . . . . . . . .
71.4 Computa¸c˜ao paralela para desempenho do simulador. . . . . . . .
81.5 Organiza¸c˜ao da disserta¸c˜ao . . . . . . . . . . . . . . . . . . . . . . .
92 Demandas da evolu¸c˜ao do software cient´ıﬁco112.1 Programa¸c˜ao Modular. . . . . . . . . . . . . . . . . . . . . . . . .
132.1.1 Princ´ıpios da Programa¸c˜ao Modular. . . . . . . . . . . . .
152.1.2 Abstra¸c˜oes . . . . . . . . . . . . . . . . . . . . . . . . . . . .
172.1.3
Justiﬁcativas, vantagens e desvantagens da programa¸c˜aomodular . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
212.1.4 T´ecnicas de modulariza¸c˜ao . . . . . . . . . . . . . . . . . . .
252.1.5 Programa¸c˜ao Orientada a Objetos . . . . . . . . . . . . . . .
322.2 Computa¸c˜ao Paralela . . . . . . . . . . . . . . . . . . . . . . . . . .
372.2.1 Arquiteturas Paralelas . . . . . . . . . . . . . . . . . . . . .
382.2.2 Mem´oria compartilhada . . . . . . . . . . . . . . . . . . . .
412.2.3 Mem´oria Distribu´ıda . . . . . . . . . . . . . . . . . . . . . .
422.2.4 Ambientes de Computa¸c˜ao Paralela . . . . . . . . . . . . . .
433 Refatora¸c˜ao de um m´odulo do simulador com inclus˜ao do paradigmaixorientado a objetos483.1 Evolu¸c˜ao do simulador de escoamentos em meios porosos . . . . . .
493.2 Organiza¸c˜ao do simulador em arquivos para compila¸c˜ao separada .
573.3 Orienta¸c˜ao a Objetos no M´odulo dos Sistemas de Equa¸c˜oes . . . . .
603.3.1
Identiﬁca¸c˜ao das Entidades de Interesse . . . . . . . . . . . .
603.3.2
Introduzindo os Atributos e M´etodos das Classes. . . . . .
633.3.3
Implementa¸c˜ao de Orienta¸c˜ao a Objetos em Fortran: Heran¸ca 663.3.4
Implementa¸c˜ao do Polimorﬁsmo em Fortran: . . . . . . . . .
683.3.5 A nova organiza¸c˜ao do simulador com os novos m´oduloscontendo classes . . . . . . . . . . . . . . . . . . . . . . . . .
704 Paraleliza¸c˜ao do simulador 2 escalas de Shale Gas784.1 An´alise inicial do perﬁl serial de desempenho da aplica¸c˜ao com intelVTUNE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
784.2 A estrat´egia de paraleliza¸c˜ao com OpenMP . . . . . . . . . . . . . .
844.3 Testes de desempenho I: Paraleliza¸c˜ao com OpenMP . . . . . . . .
924.3.1 Ambiente de Execu¸c˜ao e Metodologia dos testes . . . . . . .
954.3.2 Resultados do experimento (A) com OpenMP . . . . . . . .
964.3.3 Resultados do experimento (B) com OpenMP . . . . . . . .
974.3.4 Discuss˜ao dos resultados e otimiza¸c˜ao com OpenMP . . . . .
984.4 A estrat´egia de paraleliza¸c˜ao com MPI. . . . . . . . . . . . . . . . 1044.5 Testes de desempenho II: Paraleliza¸c˜ao com OpenMP + MPI . . . . 1084.5.1 Ambiente de Execu¸c˜ao e Metodologia dos testes . . . . . . . 1084.5.2 Resultados do experimento (A) com OpenMP+MPI . . . . . 1094.5.3 Resultados do experimento (B) com OpenMP+MPI . . . . . 1114.5.4 Discuss˜ao dos resultados com MPI. . . . . . . . . . . . . . 1125 Conclus˜oes e perspectivas114Referˆencias Bibliogr´aﬁcas117xLista de FigurasFigura1.1 Geometria realista de um reservat´orio de g´as em folhelhos.
. . . . .
51.2 Geometria idealizada de um reservat´orio de g´as em folhelhos. . . . .
61.3 Modelo Fratura/Bloco . . . . . . . . . . . . . . . . . . . . . . . . .
72.1 A arquitetura SISD . . . . . . . . . . . . . . . . . . . . . . . . . . .
392.2 A arquitetura SIMD . . . . . . . . . . . . . . . . . . . . . . . . . .
402.3 A arquitetura MIMD . . . . . . . . . . . . . . . . . . . . . . . . . .
413.1 Vetor est´atico ´unico comportando m´ultiplos vetores menores dediferentes tamanhos deﬁnidos em tempo de execu¸c˜ao.
. . . . . . . .
503.2 Organiza¸c˜ao em 3 n´ıveis dos m´ultiplos arquivos de fonte. . . . . .
573.3 A organiza¸c˜ao do simulador em arquivos-fonte . . . . . . . . . . . .
593.4 A estrutura b´asica de classes: Sistemas e Estruturas de Dados . . .
633.5 A estrutura de classes de Sistemas de Equacoes com maiores detalhes. 64
3.6 A estrutura de classes de Estruturas de Dados com maiores detalhes. 65
3.7 Organiza¸c˜ao do simulador com os novos m´odulos fonte.
. . . . . . .
704.1 Percentual do tempo total de execu¸c˜ao por rotina com solver Gauss804.2 Percentual do tempo total de execu¸c˜ao por rotina com solver intelPardiso . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
804.3 Tempo total de execu¸c˜ao do caso experimental com solver Gauss . .
824.4 Tempo total de execu¸c˜ao do caso experimental com solver intel Pardiso 824.5 An´alise da rotina processadorBloco com solver Gauss . . . . .
83xi4.6 An´alise da rotina processadorBloco com solver Pardiso . . . .
834.7 An´alise de condi¸c˜oes de corrida feita com a ferramente Intel Inspector. 91
4.8 A organiza¸c˜ao de objetos de sistemas e estruturas de dados na vers˜aoparalelizada com OpenMP . . . . . . . . . . . . . . . . . . . . . . .
924.9 Perﬁs de press˜ao ao longo da fratura (30,5 metros) para: 1 mˆes, 6meses, 1, 5, 10, 20 e 30 anos. . . . . . . . . . . . . . . . . . . . . . .
954.10 Produ¸c˜ao acumulada em Kg . . . . . . . . . . . . . . . . . . . . . .
954.11 Speedups da vers˜ao com OpenMP para o experimento (A).
. . . . .
974.12 Speedups da vers˜ao com OpenMP para o experimento (B).
. . . . .
984.13 Tempos de execu¸c˜ao por cada problema do bloco para o experimento(A).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
994.14 Tempos de execu¸c˜ao por cada problema do bloco para o experimento(B).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99cl´ausula schedule(dynamic) para4.15 Speedupscom aoexperimento (A).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 101cl´ausula schedule(dynamic) para4.16 Speedupscom aoexperimento (B).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 1014.17 Tempos de execu¸c˜ao por cada problema do bloco (Fratura com 400elementos e malhas de 600 elementos no bloco) . . . . . . . . . . . . 1024.18 Inclina¸c˜oes das linhas de tendˆencia das ﬁguras 4.13 e 4.17 em fun¸c˜aodo tamanho das malhas do bloco.
. . . . . . . . . . . . . . . . . . . 102cl´ausula schedule(dynamic) para4.19 Speedupscom aoexperimento (A) com malhas do bloco aumentadas para 600elementos.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103cl´ausula schedule(dynamic) para4.20 Speedupscom aoexperimento (B) com malhas do bloco aumentadas para 600elementos.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1034.21 A estrat´egia de paraleliza¸c˜ao em processos com MPI.
. . . . . . . . 106xii4.22 M´edias dos tempos de execu¸c˜ao (em minutos) da vers˜ao comOpenMP+MPI para o experimento (A).
. . . . . . . . . . . . . . . 1104.23 Speedups da vers˜ao com OpenMP+MPI para o experimento (A). . . 1114.24 M´edias dos tempos de execu¸c˜ao (em minutos) da vers˜ao comOpenMP+MPI para o experimento (B).
. . . . . . . . . . . . . . . 1124.25 Speedups da vers˜ao com OpenMP+MPI para o experimento (B). . . 112xiiiLista de TabelasTabela4.1 Parˆametros f´ısicos relativos ao campo realista utilizado nos testes.
Adaptado de [Costa (2015)]. . . . . . . . . . . . . . . . . . . . . .
934.2 Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP para oexperimento (A).
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
964.3 Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP para oexperimento (B).
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
974.4 Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP+MPIpara o experimento (A).
. . . . . . . . . . . . . . . . . . . . . . . . 1104.5 Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP+MPIpara o experimento (B).
. . . . . . . . . . . . . . . . . . . . . . . . 111xivLista de Siglas e Abreviaturas• TAD: Tipo Abstrato de Dados• MEF: M´etodo dos Elementos Finitos• UC: Unidade de Controle• ULA: Unidade L´ogico-Atitm´etica• CPU: Central Processing Unit• VPU: Vector Processing Unit• GPU: Graphics Processing UnitxvCap´ıtulo 1Introdu¸c˜aoReservat´orios n˜ao convencionais de g´as em folhelhos, em inglˆes, shale gasreservoirs, representam atualmente uma fonte de energia altamente relevante paramuitos pa´ıses. Nos EUA, por exemplo, tais reservas podem representar importantepapel na autossuﬁciˆencia energ´etica do pa´ıs, dentro de alguns anos. A grandequantidade de potenciais reservas deste tipo existentes, inclusive no Brasil, motiva ejustiﬁca os estudos na ´area, os quais se fazem ainda mais relevantes em decorrˆenciada necessidade do emprego de t´ecnicas de explora¸c˜ao espec´ıﬁcas, adequadas `ascaracter´ısticas peculiares de tais reservat´orios, como a baixa permeabilidade deforma¸c˜oes geol´ogicas e a existˆencia de m´ultiplos n´ıveis de porosidade.
A modelagem computacional dos reservat´orios ´e o instrumento que permitea descri¸c˜ao precisa dos fenˆomenos f´ısicos existentes no processo de recupera¸c˜ao dog´as, tendo interesse tanto para a ind´ustria, que busca a explora¸c˜ao eﬁciente, comopara a ciˆencia, assistindo o desenvolvimento de modelos f´ısicos e matem´aticos,capazes de relacionar grandezas envolvidas nas equa¸c˜oes que regem os fenˆomenosf´ısicos.
Na ind´ustria de ´oleo e g´as, ´e grande a demanda por simuladores comerciaiscomo por exemplo o CMG (Computer Modeling Group) ou ECLIPSE. Entretanto,simuladores cient´ıﬁcos tˆem caracter´ısticas e importˆancia pr´oprias. Simuladorescient´ıﬁcos oferecem a cientistas e pesquisadores do dom´ınio das aplica¸c˜oes,ﬂexibilidade e possibilidades de ajustes que atendem de forma mais adequada suas1demandas espec´ıﬁcas.
Muitas vezes,simuladores comerciaiss˜ao produtos completos e queenglobam uma grande quantidade de componentes, alguns dos quais podemn˜ao ser de interesse dos trabalhos acadˆemicos.
Simuladores cient´ıﬁcos, emcontraste, frequentemente permitem maior liberdade na realiza¸c˜ao de experimentosespec´ıﬁcos, permitindo maior controle e, inclusive, maior precis˜ao em determinadoscasos de interesse.
Este trabalho trata do emprego de t´ecnicas de programa¸c˜ao modular ede computa¸c˜ao de alto desempenho em um simulador cient´ıﬁco, baseado naimplementa¸c˜ao computacional do m´etodo de elementos ﬁnitos proposta em Hughes(1987) e utilizado na simula¸c˜ao num´erica de problemas de escoamento monof´asicode g´as em reservat´orios n˜ao convencionais em folhelhos, de acordo com os modelosf´ısico e matem´atico propostos em Costa (2015).
Dentre as motiva¸c˜oes para o desenvolvimento deste trabalho est˜ao:(i)A relativa carˆencia, no ˆambito do desenvolvimento de software cient´ıﬁco,principalmente quando comparado ao software comercial e corporativo, de certoscuidados, conhecimentos e pr´aticas que suportem o desenvolvimento ordenado,modular, e escal´avel de software e (ii) O fato de que o software cient´ıﬁco emgeral demanda t´ecnicas de computa¸c˜ao de alto desempenho, tanto por manipulargrandes massas de dados quanto por estar associado frequentemente a modelosnum´ericos computacionalmente intensivos.
Segundo Rouson et al. (2011), s˜ao caracter´ısticas desej´aveis em um softwarecient´ıﬁco o design escal´avel, obtido com desenvolvimento ordenado de c´odigo,programa¸c˜ao modular e conceitos de projeto software, e a execu¸c˜ao escal´avel,obtida com uso de t´ecnicas de computa¸c˜ao paralela e de alto desempenho. A
contribui¸c˜ao que se deseja oferecer neste trabalho engloba, portanto, dois aspectos:(i) A organiza¸c˜ao est´atica do c´odigo-fonte e (ii) A sua execu¸c˜ao.
Quanto ao primeiro aspecto, este trabalho compreende a reestrutura¸c˜ao deum dos m´odulos do simulador, aquele referente `a constru¸c˜ao e `a solu¸c˜ao dos2sistemas de equa¸c˜oes lineares referentes ao m´etodo de elementos ﬁnitos. Paraisso s˜ao desenvolvidos novos m´odulos incorporando o paradigma de programa¸c˜aoorientado a objetos para substituir o m´odulo original. Com a incorpora¸c˜aode conceitos de orienta¸c˜ao a objetos, pretende-se promover a facilita¸c˜ao doentendimento humano e da usabilidade das funcionalidades providas pelos novosm´odulos, principalmente por meio do encapsulamento de dados e opera¸c˜oes,promovendo a abstra¸c˜ao de detalhes.
J´a em rela¸c˜ao `a contribui¸c˜ao do trabalho no que se refere `a computa¸c˜ao dealto desempenho, s˜ao utilizados padr˜oes de programa¸c˜ao paralela para sistemascomputacionais baseados em mem´oria uniﬁcada e distribu´ıda, respectivamenteo OpenMP e o MPI, no desenvolvimento de estrat´egias de paraleliza¸c˜ao para omodelo adotado neste simulador.
1.1
O simula¸c˜ao de reservat´orios no LNCCPesquisadores da ´area de m´etodos num´ericos para equa¸c˜oes diferenciaisdo LNCC tˆem trabalhado desde 1988 com implementa¸c˜oes do M´etodo deElementos Finitos (MEF) baseadas no c´odigo apresentado em Hughes (1987).
Suas implementa¸c˜oes atendem a demandas em diferentes aplica¸c˜oes cient´ıﬁcas,todas tendo como ponto comum modelos matem´aticos que recaem sobre a solu¸c˜aonum´erica de equa¸c˜oes diferenciais.
Dentre as aplica¸c˜oes que utilizam o m´etodo de elementos ﬁnitos no LNCC,est˜ao as desenvolvidas pelo grupo de simula¸c˜oes computacionais de reservat´oriosde petr´oleo e g´as. O grupo tem desenvolvido ao longo do tempo simuladoresrelacionados `a ciˆencia de escoamentos e transportes em meios porosos, atendendoa demandas internas espec´ıﬁcas, seguindo um processo continuamente evolutivo,incorporando aos poucos fenˆomenos relacionados, por exemplo, `a hidrodinˆamica,ao transporte de solutos e a processos geomecˆanicos.
Apesar da alta demanda por simuladores na ind´ustria, o LNCC, enquantoinstitui¸c˜ao atuante na ´area da ciˆencia, desenvolve simuladores cient´ıﬁcos, que3tratam de fenˆomenos espec´ıﬁcos, sendo mais precisos para esses casos. Emborasejam caracterizados pela existˆencia de limita¸c˜oes, simuladores cient´ıﬁcos s˜ao comobancadas de um laborat´orio, que servem a um grupo e permitem experimentos commaior liberdade.
O simulador de reservat´orios n˜ao convencionais de shale gas desenvolvido eutilizado no LNCC n˜ao possui um projeto de longo prazo.
Isso signiﬁca que ogrupo n˜ao tem a cria¸c˜ao de um grande simulador como meta. Entretanto, novasfuncionalidades tˆem sido incorporadas ao simulador com o passar do tempo, dandoorigem a diferentes vers˜oes que s˜ao adaptadas para atender a diferentes demandas.
Embora as contribui¸c˜oes deste trabalho possam ser incorporadas emdiferentes vers˜oes deste ou de outros simuladores similares, baseados na mesmaimplementa¸c˜ao original do MEF e que compartilham o mesmo m´odulo parasolu¸c˜ao de sistemas de equa¸c˜oes, a vers˜ao do simulador utilizada neste trabalhocompreende a simula¸c˜ao num´erica de problemas de escoamento monof´asico do g´asnos reservat´orios n˜ao convencionais em folhelhos, nos blocos de rocha matriz e nasfraturas hidr´aulicas induzidas, de acordo com modelo proposto em Costa (2015),cujas linhas gerais s˜ao abordadas na se¸c˜ao 1.2.
1.2
O modelo 2 escalas: Fratura e BlocoA baixa permeabilidade das forma¸c˜oes geol´ogicas onde ocorre o shale gasimplica na necessidade da indu¸c˜ao de fraturas pelo processo de faturamentohidr´aulico para que seja constitu´ıdo um meio suﬁcientemente perme´avel por ondeo g´as possa ﬂuir mais facilmente. Modelos hidrodinˆamicos considerando dois n´ıveisde porosidade (microblocos e ﬁssuras induzidas) constituem a base do estado daarte da modelagem de reservat´orios de shale gas.
No interior das ﬁssuras provocadas pelo faturamento (ﬁssuras induzidas),pode-se modelar o escoamento do g´as por meio das equa¸c˜oes diferenciais queregem o escoamento monof´asico de ﬂuido compress´ıvel (g´as) em um meio s´olidor´ıgido, conforme modelo em Costa (2015). Os microblocos da rocha matriz atuam4armazenando g´as e funcionam, em tal modelo, como fontes de massa para oproblema de escoamento nas fraturas induzidas.
O simulador tomado como ponto de partida neste trabalho obedece `amodelagem f´ısica e matem´atica do dom´ınio desenvolvida em Costa (2015).
Em linhas gerais, os reservat´orios de g´as em folhelhos, caracterizados pelaperfura¸c˜ao horizontal, s˜ao tratados nesse modelo como uma sequˆencia de blocosde rocha matriz com fraturas induzidas peri´odicas,igualmente espa¸cadas, aolongo de toda a extens˜ao do po¸co horizontal. Idealmente, as fraturas devem serconsideradas entidades bidimensionais, enquanto os blocos devem ser consideradostridimensionais, conforme ilustrado na ﬁgura 1.1, na qual pode-se observar oescoamento radial do g´as da fratura em dire¸c˜ao ao po¸co.
Figura 1.1: Geometria realista de um reservat´orio de g´as em folhelhos.
Entretanto, o modelo de Costa (2015) possui simpliﬁca¸c˜oes, considerandoum alongamento da interface entre fratura e po¸co por toda a largura da fratura,eliminando a hip´otese de escoamento radial do g´as. Considera-se que o g´as ﬂui dafratura para o po¸co em apenas uma dire¸c˜ao. A nova conﬁgura¸c˜ao ´e mostrada naﬁgura 1.2.
5Figura 1.2: Geometria idealizada de um reservat´orio de g´as em folhelhos.
Desconsiderando o escoamento radial nas fraturas, o modelo utiliza, ainda,uma redu¸c˜ao de dimens˜ao que passa tratar fraturas como linhas e blocos comoplanos. Para a simula¸c˜ao num´erica do escoamento na fratura, o modelo adotauma malha unidimensional de elementos ﬁnitos, ao passo que, para o bloco,adotam-se m´ultiplas malhas unidimensionais, como esquematizado na ﬁgura 1.3.
Blocos atuam como fontes de massa para o problema das fraturas. Em umdado bloco, cada um dos v´arios problemas unidimensionais est´a relacionado aum ponto da malha unidimensional do problema da fratura. O modelo, portanto,caracteriza-se pela resolu¸c˜ao de um n´umero elevado de problemas de elementosﬁnitos independentes nos blocos, o que resulta em m´ultiplos sistemas linearesindependentes. Esta caracter´ıstica, como ser´a visto no cap´ıtulo 4, ´e diretamenterelacionada `as estrat´egias de paraleliza¸c˜ao desenvolvidas.
6Figura 1.3: Modelo Fratura/Bloco1.3
Programa¸c˜ao Modular com Orienta¸c˜ao a ObjetosA vers˜ao do simulador tomada como ponto de partida neste trabalho, ap´osevolu¸c˜oes incrementais nos ´ultimos anos, possui algum n´ıvel de modularidade.
O c´odigo-fonte est´a subdividido em m´odulos que agrupam funcionalidadessuﬁcientemente relacionadas. Apesar disso, neste trabalho desejamos promovermais um passo evolutivo quanto `a modularidade deste simulador cient´ıﬁco eeste avan¸co est´a relacionado com a reformula¸c˜ao que incorpora o paradigma deorienta¸c˜ao a objetos em um de seus m´odulos.
De acordo com Rouson et al. (2011), grande parte dos conceitos de projetode software que norteiam o desenvolvimento ordenado e eﬁciente de programasest´a relacionada ao paradigma de programa¸c˜ao orientado a objetos. A refatora¸c˜aodo m´odulo em quest˜ao envolve encapsulamento de sistemas de equa¸c˜oes, solverse estruturas de dados relacionadas aos sistemas com um arcabou¸co orientado aobjetos, oferecendo facilidades para a utiliza¸c˜ao de diferentes op¸c˜oes de solvers,os quais podem ser internos, completamente implementados dentro da aplica¸c˜ao7cient´ıﬁca cliente, ou externos, com uso de bibliotecas matem´aticas desenvolvidaspor terceiros e que incluem solvers. Est´e ´e o caso do Intel Pardiso, parte dabiblioteca Intel MKL.
A maior modularidade, especialmente por manifestar-se sob a forma doparadigma de orienta¸c˜ao a objetos, contribuir´a para melhor usabilidade e paraa capacidade de evolu¸c˜ao deste simulador. Conceitos centrais de orienta¸c˜ao aobjetos como encapsulamento de dados e opera¸c˜oes, heran¸ca e polimorﬁsmo ser˜aoexplorados para que o m´odulo original dˆe origem a outros menores, sob forma declasses, as quais se relacionam de forma tal que se possa promover a facilita¸c˜aodo entendimento das funcionalidades e do comportamento de cada unidade desoftware.
Classes funcionar˜ao como entidades encapsuladoras, contribuindo para oagrupamento de dados e opera¸c˜oes relacionados `as entidades de interesse porelas representadas: os sistemas de equa¸c˜oes e as estruturas de dados paraarmazenamento de matrizes esparsas realtivas aos sistemas, cujos dados poder˜aoser manipulados por mais de um tipo de solver.
O novo conjunto de m´odulos com orienta¸c˜ao a objetos permitir´a a este e aoutros outros simuladores similares baseados na mesma implementa¸c˜ao originaldo MEF, maior facilidade para a substitui¸c˜ao dos solvers em uso por outrasop¸c˜oes, facilitando e promovendo maior isolamento nos trabalhos realizados paraa incorpora¸c˜ao de solvers externos ou mesmo para a implementa¸c˜ao de novasalternativas internas neste quesito.
1.4
Computa¸c˜ao paralela para desempenho do simuladorDo entendimento do modelo introduzido na se¸c˜ao 1.2, percebe-se que nestesimulador existe uma situa¸c˜ao convidativa ao desenvolvimento de estrat´egias deparaleliza¸c˜ao que se aproveitem da total independˆencia entre os m´ultiplos sistemasde equa¸c˜oes que precisam ser resolvidos para a simula¸c˜ao do escoamento nos blocos.
Assim sendo, neste trabalho s˜ao propostas duas solu¸c˜oes que se valem desse fato,8a serem discutidas com detalhes no cap´ıtulo 4.
A implementa¸c˜ao do paradigma de orienta¸c˜ao a objetos funcionar´a comofacilitadora para o desenvolvimento de tais solu¸c˜oes, as quais ir˜ao envolver acoexistˆencia de m´ultiplos sistemas de equa¸c˜oes independentes em mem´oria. As
classes tornar˜ao essa tarefa natural e intuitiva, dada a possibilidade de quetenhamos m´ultiplas instˆancias, ou objetos, da classe que representa os sistemasde equa¸c˜oes.
A ideia b´asica por tr´as da solu¸c˜oes paralelas desenvolvidas neste trabalhopoder´a ser enxergada como uma abordagem de granularidade grossa para aexecu¸c˜ao paralela de um modelo, uma vez que n˜ao tratar´a da paraleliza¸c˜aode solvers, mas sim da execu¸c˜ao simultˆanea de v´arias instˆancias de problemascompletos, cada qual demandando a solu¸c˜ao de um sistema independente.
O paralelismo estar´a, portanto, em um n´ıvel de abstra¸c˜ao acima dasimplementa¸c˜oes internas de solvers.
Isto signiﬁca que qualquer solver utilizadopoder´a beneﬁciar-se de uma estrat´egia de paraleliza¸c˜ao ´unica e previamentedesenvolvida.
As solu¸c˜oes paralelas desenvolvidas utilizam os padr˜oes de programa¸c˜aoparalela OpenMP e MPI, voltados a sistemas computacionais de mem´oria uniﬁcadae distribu´ıda, respectivamente. Ambas ter˜ao a mesma proposta b´asica: permitirque v´arias unidades de execu¸c˜ao (threads ou processos) resolvam, em paralelo,v´arios problemas referentes aos blocos, cada um dos quais compreende duas etapas:a constru¸c˜ao e a solu¸c˜ao dos sistemas de equa¸c˜oes referentes `a implementa¸c˜ao dom´etodo dos elementos ﬁnitos.
1.5
Organiza¸c˜ao da disserta¸c˜aoEste trabalho est´a organizado da seguinte forma:No cap´ıtulo 2apresentamos, de maneira conceitual, duas grandes demandas do softwarecient´ıﬁco em geral, a programa¸c˜ao modular e a computa¸c˜ao paralela, fornecendojustiﬁcativas para sua relevˆancia e explorando conceitualmente importantes9t´ecnicas de desenvolvimento de software que visam atendˆe-las.
No cap´ıtulo 3 descrevemos o processo de refatora¸c˜ao do m´odulo referente aossistemas de equa¸c˜oes lineares. S˜ao apresentadas evolu¸c˜oes da organiza¸c˜ao est´aticado c´odigo-fonte pelas quais o c´odigo do simulador de escoamentos passou desde suavers˜ao original e, em seguida, com maior detalhamento, as evolu¸c˜oes feitas nestetrabalho com a incorpora¸c˜ao do paradigma de orienta¸c˜ao a objetos.
No cap´ıtulo 4 ´e descrito o processo de desenvolvimento das solu¸c˜oes paralelasutilizando OpenMP e MPI para o simulador. S˜ao realizados, ainda, testes dedesempenho, interpreta¸c˜ao e cr´ıtica dos os resultados, seguidas de um ciclo deotimiza¸c˜ao.
Finalmente, no cap´ıtulo 5, s˜ao apresentadas as conclus˜oes do trabalho.
10Cap´ıtulo 2Demandas da evolu¸c˜ao do softwarecient´ıﬁcoNeste cap´ıtulo s˜ao tratados de forma geral duas grandes demandas e frentesde evolu¸c˜ao do software cient´ıﬁco: a modulariza¸c˜ao e o desempenho computacional.
Tais caracter´ısticas est˜ao relacionadas ao tempo de vida dos produtos de software.
Naturalmente, produtos efˆemeros n˜ao necessitam, em geral, apresentar taiscaracter´ısticas, mas, produtos de software da ciˆencia moderna cada vez menosfrequentemente se encaixam nessa categoria.
Rouson et al. (2011) deixa claro que os grandes problemas da ciˆencia modernarecaem no desenvolvimento de modelos f´ısicos e matem´aticos que combinamdinˆamicas de diversas esferas do conhecimento para resolver problemas que muitasvezes englobam fenˆomenos cujas escalas de tempo e espa¸co s˜ao separadas por v´ariasordens de magnitude.
Isso constitui desaﬁos do ponto de vista da estabilidade,consistˆencia e acur´acia das simula¸c˜oes computacionais cient´ıﬁcas. Sendo assim,nota-se que as caracter´ısticas, o tamanho e a complexidade dos problemas daciˆencia moderna fazem com que seus produtos de software tendam a possuir longavida e longos ciclos evolutivos.
A primeira classe de demandas do software cient´ıﬁco aparece ao notarmos quea ciˆencia se baseia em modelos que evoluem no tempo, incorporam mais detalhes,tornam-se mais completos e tamb´em mais complexos. Assim, o software cient´ıﬁcodeve ser um produto com certo n´ıvel de maleabilidade, adaptabilidade, facilidade11de incorpora¸c˜ao de funcionalidades e capacidade de evolu¸c˜ao. Tal tipo de demandastraz consigo desaﬁos relacionados diretamente `a organiza¸c˜ao est´atica e estruturaldo c´odigo-fonte.
Em adi¸c˜ao `asreferidas demandas estruturais,existem as demandasrelacionadas ao desempenho de execu¸c˜ao.
O software cient´ıﬁco est´a, emgeral, embasado em modelos num´ericos computacionalmente intensivos, osquais frequentemente possuem alto custo computacional. Entretanto, todas assimula¸c˜oes cient´ıﬁcas precisam ser realizadas dentro de um limite de tempoaceit´avel, que satisfa¸ca as expectativas de seus usu´arios. As demandas relacionadasao desempenho trazem desaﬁos relacionados `a utiliza¸c˜ao eﬁciente dos recursos dehardware dispon´ıveis.
Quer seja no projeto, no desenvolvimento ou na execu¸c˜ao dos programas, otermo “escalabilidade” tem ganhado importˆancia nas discuss˜oes acerca do softwarecient´ıﬁco. Dizemos que um software ´e escal´avel quando est´a preparado para evoluire crescer, seja pela incorpora¸c˜ao de novas funcionalidades ou pelo aumento doseu desempenho, o que lhe torna capaz de manipular com eﬁciˆencia uma cargacrescente de trabalho por meio da utiliza¸c˜ao do m´aximo poss´ıvel dos recursoscomputacionais dispon´ıveis. Nesse contexto Rouson et al. (2011) anuncia dois tiposde escalabilidade: a escalabilidade do design e a escalabilidade no desempenho ouexecu¸c˜ao.
A escalabilidade do design reﬂete-se em um projeto de software voltado parao crescimento e a evolu¸c˜ao. Projetar de maneira escal´avel resulta em um processode desenvolvimento escal´avel que, por sua vez, se faz notar no c´odigo-fonte. ´E
frequentemente desej´avel que o software cient´ıﬁco tenha c´odigo compreens´ıvel, comboa usabilidade, adaptabilidade e facilidade de expans˜ao. O c´odigo que apresentaesse tipo de escalabilidade ´e desenvolvido de forma ordenada e modular, oferecendofacilidades ao entendimento humano e aos trabalhos para sua evolu¸c˜ao e expans˜aofuturas.
Quanto `a execu¸c˜ao, desenvolver c´odigos com desempenho escal´avel signiﬁca12desenvolver c´odigos que s˜ao capazes de n˜ao apenas de beneﬁciar-se do m´aximoposs´ıvel dos recursos computacionais dispon´ıveis, mas tamb´em de ter ganhos dedesempenho, caso mais recursos de hardware sejam disponibilizados. Dadas ascaracter´ısticas do hardware atual, veremos que c´odigos com desempenho escal´avelexploram o paralelismo de forma eﬁciente.
Nas pr´oximas se¸c˜oes deste cap´ıtulo exploraremos conceitos de dois t´opicosdiretamente relacionados com as escalabilidades de design e de execu¸c˜ao: APrograma¸c˜ao Modular e A Computa¸c˜ao Paralela, respectivamente.
2.1
Programa¸c˜ao ModularO desenvolvimento de software na ´epoca dos primeiros computadores digitais,muito em fun¸c˜ao das enormes limita¸c˜oes da m´aquinas daquele tempo, eramarcado por t´ecnicas que visavam extrair o m´aximo dos recursos computacionaisdispon´ıveis. Todo o paradigma do desenvolvimento n˜ao privilegiava, e nem poderia,a boa ordena¸c˜ao e organiza¸c˜ao do ﬂuxo de execu¸c˜ao dos programas em detrimentode sua performance. Era pr´atica comum negligenciar as caracter´ısticas relacionadas`a ordena¸c˜ao e `a clareza do c´odigo escrito em fun¸c˜ao da necessidade de construir-seum ﬂuxo de execu¸c˜ao o mais eﬁciente poss´ıvel.
O n´umero de vari´aveis de um programa, por exemplo, precisava sercontrolado com muito mais rigor do que fazemos hoje em um programa moderno.
Precisava-se limitar o n´umero de vari´aveis por economia no uso de mem´oria.
Sabemos que, do ponto de vista puramente pr´atico, n˜ao h´a problema algum queuma mesma vari´avel assuma diferentes funcionalidades ao longo de um programa.
Entretanto, n˜ao ´e dif´ıcil perceber que o fato de uma vari´avel possuir v´ariasfun¸c˜oes ao longo do c´odigo pode representar um preju´ızo ao entendimento, umavez que impossibilita a utiliza¸c˜ao de um nome de vari´avel relacionado a umafuncionalidade espec´ıﬁca. Os programas da ´epoca dos primeiros computadoreseram, portanto, desenvolvidos quase inteiramente com foco na sua viabilidade emtermos de desempenho e na sua funcionalidade, o que para ´epoca j´a constitu´ıa um13grande desaﬁo. Um bloco monol´ıtico de c´odigo era a apresenta¸c˜ao mais comumde um programa de computador dessa ´epoca. Dividir um programa em v´ariosblocos ou por¸c˜oes de c´odigo j´a demandava um gerenciamento de mem´oria custoso `a´epoca. Essas caracter´ısticas faziam com que programas fossem escritos geralmentepor apenas um programador, uma vez que n˜ao se podia ter por¸c˜oes minimamenteindependentes.
`A medida que os computadores, ambientes de programa¸c˜ao e linguagensevolu´ıram, os programas tamb´em foram crescendo em tamanho e complexidade.
Cada vez problemas maiores e mais complexos podiam ser resolvidos por meioscomputacionais com menor esfor¸co. Ind´ustria, servi¸cos e ciˆencia passaram a n˜aosomente explorar, mas, inclusive, depender fortemente de sistemas de computa¸c˜aopara realiza¸c˜ao de muitas de suas atividades. Dessa forma, ﬁca claro que o softwarepassava a demandar n´ıveis mais altos de qualidade e conﬁabilidade para que osriscos relacionados `a sua utiliza¸c˜ao sejam controlados ou minimamente toler´aveis.
Acompanhando a evolu¸c˜ao dos recursos computacionais, veio uma mudan¸cano fator limitante ou fator inibidor do desenvolvimento de software (Varej˜ao, 2004).
Os recursos computacionais avan¸caram de forma a permitir certo conforto aosdesenvolvedores. N˜ao era mais necess´ario guiar o desenvolvimento de softwaremajoritariamente por quest˜oes relacionadas `a viabilidade t´ecnica. Recursoscomputacionais passaram a n˜ao ser mais t˜ao limitadores quanto a otimiza¸c˜ao dotrabalho dos pr´oprios programadores. A produtividade se tornava um fator chave.
Precisava-se buscar aperfei¸coamento no processo de desenvolvimento, o que trarian˜ao apenas maior produtividade, mas tamb´em maior conﬁabilidade ao produtodesenvolvido.
O conceito de um programa monol´ıtico e de um ´unico desenvolvedor passoua n˜ao ser mais adequado `a nova realidade. Os programas passavam a ser cadavez maiores, mais complexos e mais cr´ıticos. Grandes equipes de desenvolvimentoeram necess´arias e estas precisavam ser cada vez mais produtivas. Deviam buscart´ecnicas que permitissem a cria¸c˜ao de novos programas de forma eﬁciente, com14divis˜ao de trabalho e facilita¸c˜ao da reutiliza¸c˜ao do trabalho anterior.
Problemas complexos podem, em geral, ser reduzidos a um conjunto desubproblemas menores com solu¸c˜oes independentes. A essa estrat´egia ´e dado onome de “dividir para conquistar”. Sua ado¸c˜ao permite n˜ao apenas a divis˜ao dotrabalho entre os integrantes de uma equipe de desenvolvimento, mas tamb´emfavorece a reutiliza¸c˜ao de solu¸c˜oes j´a implementadas (Varej˜ao, 2004). Uma solu¸c˜ao´unica para um problema grande e complexo diﬁcilmente ser´a reutilizada, por´em assolu¸c˜oes de subproblemas associados podem ser reutilizadas com maior facilidade,dado que v´arios problemas complexos podem possuir passos intermedi´arios ousubproblemas em comum, cuja solu¸c˜ao j´a tenha sido implementada em ummomento anterior.
2.1.1
Princ´ıpios da Programa¸c˜ao ModularEmbora programas de computador possam ser simplesmente entendidoscomo sequˆencias de instru¸c˜oes, uma realidade bastante diferente se faz ver soba ´otica das linguagens de programa¸c˜ao de alto n´ıvel como C, Fortran ou Java.
Mais do que conjuntos instru¸c˜oes indivis´ıveis, programas s˜ao compostos porelementos com certo grau de complexidade e que possuem algum signiﬁcado parao entendimento humano. Tais elementos, por sua vez, podem ser compostospor outros menores. Todos combinados constituem um todo que chamamos deprograma ou sistema de software.
Considerando-se a grande variedade de linguagens e paradigmas deprograma¸c˜ao al´em de diferentes granularidades, os elementos componentes podemse apresentar sob diferentes formas como fun¸c˜oes, procedimentos, tipos de dados,classes ou arquivos de fonte, para citar alguns exemplos. Ao longo deste texto,utilizamos os termos “elementos de programa¸c˜ao (ou de software)” e“unidades de programa¸c˜ao (ou de software)” de maneira indistinta e numsentido muito generalizado, sem qualquer deﬁni¸c˜ao restritiva, de forma que possamse referir a quaisquer componentes de um sistema de software.
15Segundo von Staa (2000), programas de porte m´edio em diante necessitamser particionados em segmentos de c´odigo minimamente independentes. No
desenvolvimento de programas com porte suﬁcientemente grande, ´e essencial quese promova a organiza¸c˜ao do ambiente de trabalho, minimizando o n´umero defalhas e as consequentes perdas geradas com o retrabalho para corrigi-las. A
programa¸c˜ao modular ´e o instrumento capaz de oferecer maiores garantias deque o desenvolvimento se dar´a de maneira organizada (von Staa, 2000).
A ideia que deﬁne o princ´ıpio fundamental da programa¸c˜ao modular ´eo particionar o c´odigo-fonte e esta se aproxima da estrat´egia de “dividir paraconquistar”. Desenvolver software modular ´e basicamente desenvolver softwarepromovendo o particionamento de c´odigo e o encapsulamento1 de dados eprocessos em m´ultiplas unidades de software, cada uma correspondendo a umaparcela de c´odigo com certo grau de independˆencia em sua gera¸c˜ao, manipula¸c˜aoe edi¸c˜ao.
As unidades de software respons´aveis pela segmenta¸c˜ao do c´odigo-fontede um programa modular recebem o nome de m´odulos fonte. Mais adiante,exploraremos o conceito de m´odulo mais adotado na literatura e ser˜ao discutidascom mais detalhes as t´ecnicas de implementa¸c˜ao da programa¸c˜ao modular. Nessemomento estamos interessados apenas em promover o entendimento de m´odulosenquanto unidades que rompem com conceito de um programa monol´ıtico, ouindivis´ıvel, confrontando a programa¸c˜ao monol´ıtica com a programa¸c˜ao modular.
Por hora, ´e suﬁciente que pensemos conceitualmente em m´odulos como por¸c˜oes dec´odigo com certo grau de independˆencia que:(i) Encapsulam processos para a solu¸c˜ao de subproblemas(ii) Encapsulam dados que representam certos aspectos de um dom´ınio modeladoA forma de apresenta¸c˜ao dos m´odulostem car´atersecund´ario noentendimento e na conceitua¸c˜ao essencial da programa¸c˜ao modular. O fator mais1 Encapsulamento ´e a propriedade de certos elementos de programa¸c˜ao agruparem, em seuinterior, dados que sejam, em algum grau, logicamente relacionados e processos que operam sobreesses dados.
16relevante aqui n˜ao ´e a forma que cada m´odulo ter´a, uma vez que isso podeestar fortemente conectado a caracter´ısticas espec´ıﬁcas de certas tecnologias oulinguagens de programa¸c˜ao. O que deve, sim, ser observado com maior destaque ´eforma como o particionamento de c´odigo, associado ao encapsulamento promovidopelos m´odulos pode contribuir para a solu¸c˜ao eﬁciente de problemas grandes ecomplexos.
O particionamento de c´odigo faz com que a solu¸c˜ao de um problema complexopossa ser decomposto na solu¸c˜ao de muitos problemas menores e mais simples deforma coordenada, promovendo divis˜ao de trabalho, organiza¸c˜ao e facilita¸c˜ao doentendimento humano. O encapsulamento, por sua vez, ajuda a tornar invis´ıvelaos usu´arios detalhes desnecess´arios de implementa¸c˜ao, levando ao rompimentode barreiras de complexidade.
No estudo das linguagens de programa¸c˜ao, um m´odulo ´e frequentementedeﬁnido como um elemento de software que corresponde a uma unidadesuﬁcientemente individualizada, ao ponto de que possa ser desenvolvida ecompilada separadamente das demais partes que comp˜oem o sistema de softwarecomo um todo. Em (von Staa, 2000) e (Varej˜ao, 2004) as deﬁni¸c˜oes adotadasseguem o mesmo caminho, conceituando m´odulos como unidades compil´aveis deforma independente. Um m´odulo pode conter diversos elementos como classes,procedimentos, fun¸c˜oes, declara¸c˜oes de tipos, constituindo, todos juntos, uma´unica unidade de compila¸c˜ao. Embora ambos os autores tenham dado destaquesemelhante ao quesito compila¸c˜ao individual, von Staa (2000) deixa claro que n˜aoexiste consenso absoluto na literatura acerca do conceito de m´odulo.
2.1.2
Abstra¸c˜oesSegundo Varej˜ao (2004), a abstra¸c˜ao ´e um conceito muito importante evastamente utilizado em todas ´areas da ciˆencia, sendo de suma importˆancia paraa resolu¸c˜ao de problemas complexos. A modelagem e a representa¸c˜ao da realidadepara a posterior resolu¸c˜ao de um problema de interesse ´e tarefa comum na ciˆencia.
17Devemos perceber que a representa¸c˜ao da realidade jamais poder´a ser feita em todasua riqueza de detalhes. A abstra¸c˜ao nos permite representar de forma seletivaapenas os aspectos da realidade que s˜ao fundamentais na resolu¸c˜ao do problemade interesse, escondendo os detalhes irrelevantes em um determinado contexto.
Na ´area das linguagens de programa¸c˜ao, Varej˜ao (2004) estabelece duasperspectivas b´asicas nas quais a abstra¸c˜ao se insere. Primeiramente, a simplesutiliza¸c˜ao de uma linguagem de programa¸c˜ao de alto n´ıvel j´a representa um n´ıvelde abstra¸c˜ao. Para o trabalho de um programador, ´e suﬁciente que ele enxergue ocomputador como uma m´aquina capaz de entender comandos de uma linguagem deprograma¸c˜ao de alto n´ıvel, ainda que isso n˜ao seja verdade. O programador est´anesse momento abstraindo o hardware e as linguagens de baixo n´ıvel, dado queesses s˜ao detalhes irrelevantes em seu contexto de trabalho. A segunda perspectivaonde utiliza-se o conceito de abstra¸c˜ao ´e no entendimento de que as linguagens deprograma¸c˜ao oferecem ao programador os meios necess´arios para que ele tamb´emcrie as suas pr´oprias abstra¸c˜oes. ´E nessa perspectiva que se faz clara a forterela¸c˜ao entre abstra¸c˜oes e a programa¸c˜ao modular. Os m´odulos e seus elementoscomponentes s˜ao as entidades capazes de promover as abstra¸c˜oes.
As abstra¸c˜oes criadas pelo programador podem ser usadas por ele oupor outros programadores em diferentes momentos e na resolu¸c˜ao de diferentesproblemas. Deve-se perceber que o conhecimento da implementa¸c˜ao interna detodos m´odulos ou outros elementos de programa¸c˜ao que modelam a solu¸c˜ao desubproblemas muitas vezes n˜ao ´e fundamental para a resolu¸c˜ao do problema maiorde interesse. Assim, podemos dizer que m´odulos podem ter sua implementa¸c˜aointerna abstra´ıda pelos programadores. Um programador interessado em resolverdado problema computacional pode fazer uso de v´arios m´odulos, mesmo semconhecer coisa alguma sobre sua implementa¸c˜ao interna, desde que conhe¸ca bema funcionalidade oferecida por eles e a forma como eles devem se comunicar com o18mundo exterior, ou seja, sua interface2 .
Uma interface constitui um conjunto de regras ou padr˜oes para que se possaestabelecer a comunica¸c˜ao entre os elementos. A assinatura de uma fun¸c˜ao, porexemplo, estabelece um padr˜ao, por meio dos argumentos da fun¸c˜ao, de como elapoder´a trocar dados com meio exterior, representando, portanto, a sua interface.
De acordo com Varej˜ao (2004), programas de computador podem serdeﬁnidos como “conjuntos de instru¸c˜oes descrevendo como realizar processos paramanipular, alterar e produzir dados”. Considerando a deﬁni¸c˜ao anterior e sabendodo papel dos m´odulos enquanto elementos capazes de promover abstra¸c˜oes pormeio do encapsulamento de processos e de dados, podemos classiﬁcar as abstra¸c˜oescriadas pelo programador em dois tipos: Abstra¸c˜oes de processos e Abstra¸c˜oesde dados.
2.1.2.1
Abstra¸c˜oes de processosAs abstra¸c˜oes de processos se d˜ao sobre o ﬂuxo de controle dos programas etratam de encapsular as seq¨uˆencias de instru¸c˜oes e comandos que descrevem umprocesso. Os elementos de programa¸c˜ao utilizados para que seja feita a abstra¸c˜aode processos s˜ao os subprogramas. Al´em de encapsular c´odigo, eles deﬁnemregi˜oes limitados dentro de um programa onde podemos criar vari´aveis, constantese tipos para utiliza¸c˜ao em escopo local. Subprogramas podem ser do tipo fun¸c˜aoou procedimento. Fun¸c˜oes representam abstra¸c˜oes de express˜oes e possuem umvalor de retorno. J´a os procedimentos representam abstra¸c˜oes de comandos, umavez que apenas encapsulam um ﬂuxo de controle deﬁnindo um novo comando quepassa a ser dispon´ıvel aos usu´arios. Em contraste com as fun¸c˜oes, os procedimentosn˜ao retornam valores. O ponto comum ´e que subprogramas em geral atuam nosentido de aumentar o conjunto de instru¸c˜oes oferecidos por uma linguagem deprograma¸c˜ao com o uso do conceito de abstra¸c˜oes.
2 Interface ´e o meio ou o conjunto de regras e deﬁni¸c˜oes pelo qual os m´odulos ou seuselementos constituintes, como classes, procedimentos e fun¸c˜oes, se comunicam com o usu´ario ououtros elementos.
19Quando um programador escreve subprogramas, fun¸c˜oes ou procedimentos,ele est´a criando abstra¸c˜oes no sentido de que esconde ou encapsula os detalhesde implementa¸c˜ao de determinado ﬂuxo de execu¸c˜ao. Com isso est˜ao sendoprovidas novas funcionalidades com reutiliza¸c˜ao facilitada para o futuro. As
abstra¸c˜oes criadas pelo programador na forma de subprogramas acabam porestender as funcionalidades ou o conjunto de instru¸c˜oes oferecidos pela linguagemde programa¸c˜ao. Combinam comandos e express˜oes de forma a oferecer outrosnovos. Em qualquer momento futuro, o programador pode fazer uso das abstra¸c˜oespara pensar em resolver problemas maiores. Nesse momento, ele poder´a tersuas aten¸c˜oes focadas em um n´ıvel mais alto, na resolu¸c˜ao de seu problema deinteresse, cujas etapas de resolu¸c˜ao podem ser facilmente resolvidas com o uso desubprogramas.
2.1.2.2
Abstra¸c˜oes de dadosAbstra¸c˜oes de dados, de forma similar `as abstra¸c˜oes de processos, combinamv´arios dados de forma a oferecer um novo dado ou tipo de dado. Embora aindaem um n´ıvel bastante baixo, ao enxergarmos a mem´oria de um computador comoum conjunto de c´elulas de mem´oria, e as c´elulas de mem´oria, por sua vez, comocole¸c˜oes de bits, estamos fazendo abstra¸c˜ao de dados. Todas as linguagens deprograma¸c˜ao de alto n´ıvel oferecem abstra¸c˜oes de dados em um n´ıvel mais alto aofornecerem tipos de dados como inteiros, ponto ﬂutuante e vetores. Programadoresde linguagens de alto n´ıvel utilizam esses tipos de dados sem pensar na forma comode fato s˜ao armazenados em mem´oria.
O que podemos observar ´e que apenas as abstra¸c˜oes de dados oferecidas pelaslinguagens de programa¸c˜ao n˜ao se demonstraram suﬁcientes para a programa¸c˜aocom qualidade. ´E preciso permitir aos programadores que criem suas pr´opriasabstra¸c˜oes, combinando dados dispon´ıveis de forma a dar origem a seus pr´opriostipos de dados. Tipos de dados como listas, pilhas e ﬁlas s˜ao exemplos de abstra¸c˜oesde dados criadas pelo programador.
202.1.3
Justiﬁcativas, vantagens e desvantagens da programa¸c˜aomodularA programa¸c˜ao modular traz consigo uma s´erie de vantagens para o processode desenvolvimento de software. Nesta se¸c˜ao ser˜ao apresentadas justiﬁcativas qued˜ao suporte a seu emprego.
• Facilita o rompimento e barreiras de complexidade al´em de permitira distribui¸c˜ao de trabalho, por adotar a estrat´egia de “dividir paraconquistar”. Sabemos que problemas grandes e complexos tˆem muitasvezes sua solu¸c˜ao facilitada se forem pensados como uma s´erie de problemasmenores a serem solucionados por m´odulos independentes. M´odulosindependentes podem ser desenvolvidos por diversos programadorestrabalhando em paralelo.
Identiﬁca-se, nesse sentido, uma potencialeconomia de tempo de desenvolvimento, uma vez que v´arias pessoaspoder˜ao trabalhar paralelamente no desenvolvimento do programa.
• Permite o re´uso de c´odigo. M´odulos podem e idealmente devem serconstru´ıdos de forma que possam ser usados em outros programas. Se
os programadores desenvolvem m´odulos de forma bem documentada,deixando sua funcionalidade clara para potenciais clientes, pode-se´E comum queobter consider´avel economia de esfor¸co de trabalho.
programas e projetos diferentes podem se valer de m´odulos provedoresde funcionalidades demandadas recorrentemente no desenvolvimento deprogramas.
Se considerarmos programas pertencentes a um mesmodom´ınio de aplica¸c˜ao, a tendˆencia ´e de que o re´uso seja ainda mais´E comum que empresas ou institui¸c˜oes desenvolvam v´ariosvantajoso.
produtos de software dentro de um mesmo dom´ınio de aplica¸c˜ao.
Desenvolver software modular pode representar a constru¸c˜ao de um ativode software que permite `as corpora¸c˜oes serem mais velozes e competitivasno desenvolvimento de seus sistemas.
21• Permite o desenvolvimento incremental e o gerencimento do processode desenvolvimento de software. A programa¸c˜ao modular facilita oestabelecimento de muitas baselines de m´odulos fonte.
Isso signiﬁcater um maior grau de controle nas altera¸c˜oes realizadas. M´odulosentregues podem ter sua altera¸c˜ao suﬁcientemente controlada, evitandocontratempos advindos de altera¸c˜oes indisciplinadas no c´odigo. `A medidaque novos m´odulos ou m´odulos j´a existentes s˜ao alterados, o sistemade software como um todo evolui de maneira incremental. Cada novaitera¸c˜ao representa uma nova vers˜ao denominada construto. Dessa forma,a programa¸c˜ao modular torna mais natural a evolu¸c˜ao incremental dosprogramas.
• Reduz o custo de compila¸c˜ao. Se considerarmos que m´odulos s˜ao unidadesindependentemente compil´aveis, ﬁca claro que altera¸c˜oes pontuais emcertos m´odulos n˜ao ir˜ao requerer que todo o programa seja recompilado.
Em projetos de pequeno porte, a compila¸c˜ao pode n˜ao representar umatarefa custosa, mas em grandes projetos pode requerer grandes esfor¸cos econsumir tempo dos programadores.
• Permite que otimiza¸c˜oes de desempenho sejam feitas de maneira gradual.
Os m´odulos de um programa podem ser perfeitamente funcionais aindaque n˜ao sejam idealmente otimizados. Num primeiro momento, osdesenvolvedores podem estar interessados em desenvolver unicamente umavers˜ao funcional do programa. Cada um dos m´odulos pode ainda passar,individualmente, por um processo evolutivo no que diz respeito ao seudesempenho. A modulariza¸c˜ao oferece maior ﬂexibilidade na decis˜ao dequais m´odulos devem ser otimizados e em quais momentos ao longo doprocesso de desenvolvimento. Mais do que isso, oferece a possibilidade deque se decida se todos os m´odulos precisam realmente ser otimizados. ´E
comum que se depare com situa¸c˜oes nas quais poucas tarefas representamgrande parte do custo computacional do programa como um todo. Nesse22caso, os esfor¸cos de otimiza¸c˜ao podem ser concentrados nos m´odulos maiscustosos computacionalmente.
Existem, entretanto, contrapartidas advindas da utiliza¸c˜ao da programa¸c˜aomodular. Algumas responsabilidades e compromissos precisam ser assumidos pelosprogramadores:• ´E preciso pensar de forma modular e estar disposto a desenvolver c´odigocom isso em mente. Isso signiﬁca estar disposto a particionar o c´odigo,provendo funcionalidades, mesmo que isso n˜ao pare¸ca a forma mais r´apidade resolver um problema imediato.
• ´E necess´ario especiﬁcar os m´odulos e idealmente document´a-los de formaa facilitar o utiliza¸c˜ao dos mesmos por outros programadores. Se estamosinteressados em encapsulamento de c´odigo, n˜ao nos interessa que osusu´arios precisem ler o c´odigo-fonte para compreender a funcionalidadede cada m´odulo.
• ´E preciso tomar decis˜oes justiﬁcadas sobre como particionar o c´odigo, comoabstrair, por que abstrair. Saber identiﬁcar potenciais trechos de c´odigocom alta possibilidade de reutiliza¸c˜ao, ou cujo entendimento humano sejadif´ıcil, ´e fundamental nessa tarefa.
• ´E preciso saber dividir tarefas de forma eﬁciente, garantindo que o trabalhode um programador n˜ao afete as interven¸c˜oes dos demais integrantes deuma equipe.
• ´E preciso conhecer as interfaces dos m´odulos, bem como respeit´a-las.
Sobretudo, ´e necess´ario que haja um bom projeto de arquitetura paraque o processo de desenvolvimento se dˆe de forma ordenada e para quepossam ser auferidos os benef´ıcios esperados da programa¸c˜ao modular.
• ´E preciso sabe de que forma poder´a ser assegurada a qualidade de tudoaquilo que ´e produzido a partir da integra¸c˜ao de diversos m´odulos.
23Como visto, existem algumas responsabilidades a serem assumidas pelosprogramadores interessados em desenvolver software modular. Muitas vezes estespodem se questionar, por exemplo, sobre o qu˜ao justiﬁc´avel ´e a programa¸c˜aomodular, o qu˜ao dispendiosos ser˜ao os esfor¸cos para se determinar comoexatamente deve ser particionado o c´odigo do programa, quais ser˜ao as formasde apresenta¸c˜ao dos m´odulos, como deve ser especiﬁcado cada m´odulo, como devese dar a intera¸c˜ao entre os diversos m´odulos de um programa e quais ser˜ao as regraspara isso.
Nos casos em que o programa a ser desenvolvido objetiva resolvercomputacionalmente um problema de grande propor¸c˜ao e alta complexidade, ocen´ario ´e mais favor´avel `a programa¸c˜ao modular. Nesses casos, onde h´a barreiras decomplexidade que intimidam o programador, ´e praticamente natural que ele pensede maneira modular, dada a sua diﬁculdade em resolver o problema como um todode uma s´o vez. Em problemas menos complexos, no entanto, ´e compreens´ıvel queo programador se sinta tentado a seguir uma l´ogica monol´ıtica. Frequentementeele n˜ao deseja fazer decis˜oes de projeto ou mesmo pensar como a segmenta¸c˜ao doc´odigo deve se dar.
Apesar de nem sempre a programa¸c˜ao modular parecer atrativa aosprogramadores, as situa¸c˜oes nas quais ela realmente n˜ao vale a pena s˜aomuito restritas.
Por mais que o problema a ser resolvido n˜ao apresentemuita complexidade, a programa¸c˜ao modular oferece benef´ıcios que v˜ao al´em dasupera¸c˜ao de barreiras de complexidade.
Em von Staa (2000) ´e apresentada uma justiﬁcativa econˆomica para aprograma¸c˜ao modular, baseada em m´etodos de estima¸c˜ao de tamanho, esfor¸coe custo de desenvolvimento de programas. Os m´etodos empregados est˜ao baseadosem uma s´erie de parˆametros obtidos por meio de estat´ısticas colhidas de um granden´umero de projetos reais. O estudo confronta o esfor¸co de desenvolvimento modularcom o esfor¸co monol´ıtico, considerando diferentes parˆametros como, por exemplo,o tamanho do programa em linhas de c´odigo, o n´umero de m´odulos e o tamanho24m´edio dos m´odulos.
A conclus˜ao de tal estudo ´e que, exceto em programas muito pequenos,o esfor¸co de programa¸c˜ao modular ´e bastante menor que o esfor¸co monol´ıtico,mesmo quando consideramos os esfor¸cos adicionais advindos da necessidadede especiﬁca¸c˜ao e implementa¸c˜ao das interfaces e da integra¸c˜ao dos diferentesm´odulos. Soma-se a isso o fato de que, conforme o tamanho do programa aumenta,a diferen¸ca de esfor¸co entre as duas formas de desenvolvimento se torna muito maisevidente, sempre em favor da abordagem modular.
2.1.4
T´ecnicas de modulariza¸c˜aoProgramas de grande porte s˜ao caracterizados por envolver um granden´umero de linhas de c´odigo, grandes equipes de desenvolvimento e geralmenteconstituem uma solu¸c˜ao computacional complexa para problemas igualmentecomplexos. J´a foi exposto que o padr˜ao de um programa monol´ıtico n˜ao ´e adequadoa esse tipo de sistemas. ´E para assistir principalmente o desenvolvimento desse tipode programas que foram desenvolvidas as t´ecnicas de modulariza¸c˜ao.
As t´ecnicas tratam de implementar em c´odigo os conceitos da programa¸c˜aomodular discutidos at´e aqui,como a segmenta¸c˜ao do c´odigo-fonte,oencapsulamento e as abstra¸c˜oes. Embora tenham seu foco principal em assistiro desenvolvimento de grandes programas, muitas das t´ecnicas n˜ao deixam de ser´uteis mesmo a programas de pequeno porte.
Como visto anteriormente, no estudo das linguagens de programa¸c˜ao, osm´odulos s˜ao entendidos como unidades de software compil´aveis separadamente.
Cada m´odulo pode ser composto de v´arios elementos distintos como fun¸c˜oes,procedimentos, vari´aveis, constantes e tipos. Elementos como esses s˜ao reunidosem um m´odulo quando est˜ao de alguma forma relacionados e possuem objetivocomum. De acordo com Varej˜ao (2004) m´odulos bem projetados possuem um´unico objetivo claro, bem como uma boa deﬁni¸c˜ao de interface com os demaism´odulos.
25O entendimento do prop´osito de um m´odulo e o conhecimento exatodas funcionalidades oferecidas por ele ´e preocupa¸c˜ao do usu´ario. A formacomo o objetivo ´e atingido, entretanto, ´e preocupa¸c˜ao do implementador. Porusu´ario entendemos um programador que ir´a utilizar os recursos do m´odulo nodesenvolvimento de um outro elemento de software, que pode ser, por exemplo,outro m´odulo ou um programa completo. Podemos dizer que esses elementos s˜aoclientes3 do m´odulo em quest˜ao.
A seguir exploraremos algumas t´ecnicas de modulariza¸c˜ao, em umaabordagem independente de linguagem de programa¸c˜ao.
Ser˜ao apresentadasas principais estrat´egias de implementa¸c˜ao desenvolvidas para que se pudessedesenvolver programas de forma mais compartimentada, organizada e eﬁcientedo que com o uso da abordagem monol´ıtica. As estrat´egias podem se aplicarinternamente a um ´unico arquivo de c´odigo-fonte ou mesmo subdividir osprogramas em m´ultiplos arquivos com compila¸c˜ao separada.
2.1.4.1
SubprogramasO desenvolvimento do conceito de subprogramas (procedimentos e fun¸c˜oes)representou o primeiro passo para que o desenvolvimento de software pudessecaminhar na dire¸c˜ao da programa¸c˜ao modular.
Subprogramas permitemo particionamento do programa em diversas por¸c˜oes de c´odigo logicamenterelacionadas.
A ideia ´e que cada subprograma represente claramente uma funcionalidadebem deﬁnida, funcionando como um instrumento para a abstra¸c˜ao de processos,conforme visto na se¸c˜ao 2.1.2.
Subprogramas, portanto,jamais devem serentendidos como instrumentos de modulariza¸c˜ao que particionam o c´odigo levando-se em conta sua extens˜ao, o que resultaria em modulariza¸c˜ao de baixa qualidade.
N˜ao existe raz˜ao para que subprogramas tenham tamanhos semelhantes. O
que deve ser levado em conta ´e identiﬁca¸c˜ao de funcionalidades que possam ser3 Clientes s˜ao todos os elementos de programa¸c˜ao que fazem uso de funcionalidades ou dadosprovidos por outros elementos.
26abstra´ıdas.
O uso de subprogramas evita que trechos de c´odigo sejam exaustivamenterepetidos ao longo de um programa e facilita o re´uso de c´odigo. Se um determinadoprocesso ou ﬂuxo de execu¸c˜ao precisa ser realizado muitas vezes, ´e poss´ıvelter m´ultiplas chamadas a um ´unico subprograma.
Isso facilita n˜ao somente aimplementa¸c˜ao, mas tamb´em a manuten¸c˜ao do programa. No momento em queuma altera¸c˜ao no processo implementado no subprograma precisa ser feita, ser´aposs´ıvel alterar o c´odigo de forma localizada. Em contraste, programas com trechosde c´odigo exaustivamente repetidos demandariam uma busca exaustiva por todasas ocorrˆencias do trecho para sua altera¸c˜ao.
Subprogramas permitem, ainda, que o processo descrito pelos mesmos sejaaplicado sobre conjuntos de dados diferentes. Isso ´e poss´ıvel gra¸cas ao processode parametriza¸c˜ao, por meio do qual podemos fornecer dados aos subprogramas.
Dessa forma, procedimentos e fun¸c˜oes podem operar sobre dados diferentes emcada chamada, resultando, respectivamente, em comportamentos ou valores deretorno distintos.
2.1.4.2
PacotesNo desenvolvimento de grandes sistemas de software,implementar amodulariza¸c˜ao exclusivamente por meio de subprogramas n˜ao ´e, em geral, umaestrat´egia considerada suﬁciente. Esse tipo de modulariza¸c˜ao acaba promovendouma segmenta¸c˜ao de c´odigo com granularidade muito ﬁna. No caso de sistemasmuito grandes, isso faz com que se tenha um n´umero muito grande de elementos deprograma¸c˜ao espalhados pelo c´odigo. ´E necess´ario haver um n´ıvel de modulariza¸c˜aocom granularidade maior.
Al´em disso, dado que a programa¸c˜ao modular ´e marcada pelo re´uso de c´odigo,nota-se, especialmente em grandes sistemas, que existe uma grande possibilidadede conﬂitos de nomes entre os elementos das diversas fontes de c´odigo reutilizados.
´E preciso que haja alguma forma de solucionar os conﬂitos de nome.
27Pacotes s˜ao elementos de programa¸c˜ao com nome pr´oprio que agrupamdiversos outros elementos, sendo alguns vis´ıveis para os usu´arios e outros n˜ao. Ao
mesmo tempo em que representam uma forma de modulariza¸c˜ao de granularidadegrossa, s˜ao elementos capazes de resolver conﬂitos de nome, justamente pelo fatode possu´ırem nomes pr´oprios. Se existir um conﬂito de nomes entre elementosprovenientes de m´ultiplas fontes de c´odigo, sendo as fontes m´ultiplos pacotes, ´eposs´ıvel especiﬁcar corretamente de qual pacote ´e o elemento que se quer acessar.
Basta que se utilize a especiﬁca¸c˜ao completa do nome, que inclui o nome do pacotee o nome do elemento componente em quest˜ao.
2.1.4.3
Tipos de dadosComo discutido na se¸c˜ao 2.1.2, novos tipos de dados representam abstra¸c˜oesde dados feitas pelo programador. Re´unem uma cole¸c˜ao de dados relacionadosem um ´unico elemento de programa¸c˜ao. Os usu´arios desses tipos de dados podemenxerg´a-los como um todo coeso, sem que seja necess´ario pensar em como foramimplementados.
Dados do tipo registro, como o struct em C ou structure e record do Fortran(posteriormente substitu´ıdos pela declara¸c˜ao TYPE) s˜ao denominados tipos dedados simples. Esse tipo de modulariza¸c˜ao consiste em reunir e combinar umgrupo de dados relacionados em uma ´unica entidade encapsuladora nomeada. O
grupo de dados nomeado pode assim ser tratado como um todo e as vantagensincluem facilita¸c˜ao do re´uso e melhor legibilidade do c´odigo. O principal pontofraco desse tipo de modulariza¸c˜ao ´e n˜ao permitir o ocultamento da informa¸c˜ao,visto que o acesso aos dados internos do tipo ´e livre para os seus usu´arios. O
ocultamento dos dados ´e permitido pelos Tipos Abstratos de Dados e ser´a discutidoa seguir.
Por sua vez, os Tipos Abstratos de Dados (TADs) s˜ao elementos desoftware nos quais uma determinada estrutura de dados ´e criada para representarum novo tipo. Esta ´e tornada conhecida somente atrav´es das opera¸c˜oes realizadas28sobre seus dados. O implementador do TAD decide como ir´a representar os valoresdo tipo abstrato e implementa um conjunto de opera¸c˜oes, na forma de fun¸c˜oese procedimentos que operam sobre os dados do novo tipo. Para implementa¸c˜aode TADs, ´e necess´ario que a linguagem forne¸ca recursos para o ocultamento dainforma¸c˜ao, tornando a implementa¸c˜ao interna do TAD invis´ıvel para o usu´ario,o que normalmente ´e feito com a especiﬁca¸c˜ao de sua interface. Nela s˜ao expostossomente os componentes que devem ser p´ublicos, em geral apenas as opera¸c˜oesoferecidas pelo TAD, sendo os dados internos invis´ıveis aos usu´arios.
A estrat´egia de tornar p´ublicas apenas as opera¸c˜oes e manter os dadosinacess´ıveis aos usu´arios(information hiding)implica que o conjunto devalores internos do tipo ´e acessado e modiﬁcado sempre de maneira indireta,exclusivamente pela execu¸c˜ao de opera¸c˜oes consultoras e atualizadoras,respectivamente. Opera¸c˜oes atualizadoras podem ainda proteger os dados contraaltera¸c˜oes feitas de maneira incorreta, impedindo que os dados assumam valoresindevidos. Opera¸c˜oes consultoras/atualizadoras s˜ao frequentemente denominadasgetters/setters, mutators/accessors ou, de forma geral, fun¸c˜oes de acesso. O
usu´ario, portanto, apenas utiliza o TAD como uma caixa preta para resolver seuproblema, sem acesso direto aos dados.
Al´em das opera¸c˜oes de acesso, nos TADs frequentemente existem asopera¸c˜oes construtoras e destrutoras. De acordo com Varej˜ao (2004) asconstrutoras s˜ao respons´aveis por criar e inicializar os TADs e devem ser executadasantes de quaisquer outras opera¸c˜oes para que se garanta o perfeito funcionamentodas mesmas. As opera¸c˜oes destrutoras, utilizadas quando o uso do TAD n˜ao ´emais necess´ario, s˜ao respons´aveis por atividades de ﬁnaliza¸c˜ao, dentre as quaisdestaca-se a desaloca¸c˜ao da regi˜ao de mem´oria utilizada pelo TAD.
2.1.4.4
M´ultiplos arquivos e Compila¸c˜ao SeparadaAs t´ecnicas de modulariza¸c˜ao abordadas at´e o momento podem ser aplicadaspara a modulariza¸c˜ao de programas em um arquivo de fonte ´unico. Com o29crescimento dos programas, entretanto, esse tipo de abordagem come¸ca a tornar-seinvi´avel, uma vez que traz problemas pr´aticos tanto para o desenvolvimento quantopara a manuten¸c˜ao e re´uso de c´odigo.
Programadoresfrequentementeencontram diﬁculdadeetˆem suaprodutividade comprometida na escrita e na manuten¸c˜ao de programas comgrandes propor¸c˜oes, se estes estiverem completamente contidos em um ´unicoarquivo fonte. Todas as vezes em que se faz necess´aria uma altera¸c˜ao no c´odigo-fonte, o ´unico e extenso arquivo de fonte deve ser examinado pelo programador aﬁm de que se encontre a regi˜ao que precisa ser alterada. Se dois programadorespretendem alterar, cada um uma parte espec´ıﬁca do programa, eles precisar˜aoalterar o mesmo arquivo e ao ﬁm do trabalho, haver´a um esfor¸co adicionalpara que se possa unir as altera¸c˜oes feitas por ambos. Quando o trabalho deum programador precisa ser interrompido e depois retomado, tem-se um custoadicional para que, novamente, se vasculhe o extenso arquivo a ﬁm de encontrar olocal a partir do qual o trabalho deve continuar.
Outra quest˜ao relevante nesse contexto ´e o fato de que muitos elementosde programa¸c˜ao de um programa podem ser reutilizados n˜ao somente dentro deum programa ´unico, mas tamb´em em programas distintos. ´E comum, tanto nasempresas quanto na comunidade cient´ıﬁca, que grupos de pessoas interessadas emdesenvolver aplica¸c˜oes com algum grau de semelhan¸ca interajam entre si. Muitasaplica¸c˜oes diferentes podem compartilhar trechos em comum. Programas em um´unico arquivo fonte diﬁcultam o processo de re´uso, pois exigem que a funcionalidadea ser utilizada em outros programas seja localizada dentro de um extenso arquivoe copiada para o programa que far´a uso da mesma.
Naturalmente, dividir os programas em arquivos separados surge comosolu¸c˜ao para os problemas citados. Cada arquivo pode conter trechos de c´odigoassociados a uma funcionalidade ou a um grupo de funcionalidades suﬁcientementerelacionadas, segundo algum crit´erio l´ogico de divis˜ao que fa¸ca sentido paraa equipe de desenvolvedores. Os pr´oprios arquivos acabam funcionando como30indexadores para que os programadores encontrem mais rapidamente as regi˜oesdo c´odigo que desejam reaproveitar ou mesmo onde desejam realizar altera¸c˜oes.
Entretanto, os m´ultiplos arquivos, por si s´o, n˜ao resolvem um problemacomum a grandes projetos de software: o custo da compila¸c˜ao. Em programaspequenos, o custo em tempo com a compila¸c˜ao pode, muitas vezes,sernegligenciado. Em grandes projetos, por´em, o custo em tempo para a compila¸c˜aode todo o c´odigo se torna algo impactante na produtividade dos programadores.
Quando adota-se a estrutura de modulariza¸c˜ao por arquivos, o interesse ´e que sejaposs´ıvel a compila¸c˜ao em separado de cada um dos m´odulos fonte, de forma que,com altera¸c˜oes localizadas em m´odulos espec´ıﬁcos, n˜ao seja necess´ario recompilartodo o c´odigo-fonte, mas somente somente os m´odulos alterados.
Conforme destacado (Varej˜ao, 2004), para que se possa permitir a compila¸c˜aoem separado dos m´odulos, surge a necessidade de certo relaxamento na veriﬁca¸c˜aode erros por parte do compilador. Consideremos, a t´ıtulo de exemplo, que em umdeterminado arquivo fonte foi escrita uma cole¸c˜ao de procedimentos e fun¸c˜oes paraserem utilizadas em outros arquivos fontes clientes. Quando s˜ao feitas altera¸c˜oesnas unidades clientes, ´e interessante que estas possam ser recompiladas sem queseja requerida a recompila¸c˜ao do arquivo que cont´em a cole¸c˜ao de subprogramasutilizados. Com a recompila¸c˜ao sendo feita exclusivamente nas unidades clientesalteradas, o compilador n˜ao poder´a veriﬁcar se todas as sub-rotinas utilizadas porelas de fato existem nos m´odulos onde supostamente devem estar implementadas.
Mais do que isso, ´e preciso saber se as rotinas est˜ao sendo utilizadas da maneiracorreta quanto ao tipo dos argumentos passados, por exemplo.
Para que a compila¸c˜ao em separado possa coexistir com a veriﬁca¸c˜ao detipos, uma estrat´egia usada em muitas linguagens de programa¸c˜ao ´e subdividircada um dos m´odulos fonte em dois arquivos: arquivo de interface e arquivo deimplementa¸c˜ao.
Nos arquivos ou m´odulos de interface, tamb´em chamados de m´odulos de31deﬁni¸c˜ao4 , existem somente declara¸c˜oes e deﬁni¸c˜oes de elementos como vari´aveis,tipos e subprogramas que ser˜ao usados por arquivos/m´odulos clientes. Os arquivosde implementa¸c˜ao, ou m´odulos de implementa¸c˜ao5 , por sua vez, s˜ao onde est˜aocontidas todas as implementa¸c˜oes completas dos elementos de software declaradosno arquivo de interface.
Nos m´odulos clientes, o que se faz usualmente ´e importar apenas os arquivosde deﬁni¸c˜ao (header ﬁles). A inclus˜ao dos m´odulos de deﬁni¸c˜ao gera um impactopraticamente desprez´ıvel no custo de compila¸c˜ao das unidades clientes, visto quetais m´odulos correspondem apenas a deﬁni¸c˜oes de vari´aveis, constantes, tipos eassinaturas de subprogramas. Apesar do baixo custo de compila¸c˜ao, os arquivos dedeﬁni¸c˜ao possuem as informa¸c˜oes suﬁcientes para que se possa realizar a veriﬁca¸c˜aode tipos.
Sendo assim, com a inclus˜ao dos m´odulos de deﬁni¸c˜ao em todos os arquivosclientes, a compila¸c˜ao torna-se, al´em de r´apida, segura. A unidades clientes podemser recompiladas em separado, sem que seja preciso realizar a recompila¸c˜ao dosm´odulos de implementa¸c˜ao utilizados, cuja compila¸c˜ao ´e custosa, e sem tampoucoque seja necess´ario abrir m˜ao do rigor nas veriﬁca¸c˜oes de erro do compilador.
No processo de compila¸c˜ao de programas divididos em v´arios arquivos,quando os m´odulos de implementa¸c˜ao s˜ao fornecidos ao compilador, originam-se, para cada um dos m´odulos compilados, um correspondente m´odulo objeto.
Finalmente os m´odulos objeto s˜ao integrados por um programa especial ligador(linker), respons´avel por unir os arquivos objeto e gerar um ´unico arquivoexecut´avel.
2.1.5
Programa¸c˜ao Orientada a ObjetosOrienta¸c˜ao a Objetos ´e um paradigma para o desenvolvimento deprogramas particularmente interessante quando precisa-se modelar e resolver4 M´odulo de deﬁni¸c˜ao ´e o elemento que cont´em apenas o c´odigo de deﬁni¸c˜ao da interfacedo m´odulo fonte.
5 M´odulo de implementa¸c˜ao ´e o elemento que implementa de fato todas as funcionalidadesprovidas pelo m´odulo fonte, encapsulando todo c´odigo das mesmas.
32computacionalmente problemas que possam ser expressos em termos de diversosconjuntos de dados minimamente relacionados,submetidos a conjuntos deopera¸c˜oes.
Isso se deve ao fato de que a programa¸c˜ao Orientada a Objetos ´efortemente focalizada em entidades do mundo real e nos processos e opera¸c˜oesrealizados por tais entidades ou aos quais seus dados se sujeitam.
As classes podem representar de maneira eﬁciente entidades do mundo real.
Permitem a deﬁni¸c˜ao de novos tipos oferecendo meios para o encapsulamento dedados e de oprea¸c˜oes sobre esse dados. Os primeiros sob forma de seus atributos,e as ´ultimas na forma de seus procedimentos ou fun¸c˜oes, denominados m´etodos.
A estrutura de classes se assemelha da decomposi¸c˜ao de programas em m´odulos;entretanto, diferente de m´odulos, os quais podem ser simplesmente arquivoscontendo cole¸c˜oes de fun¸c˜oes, as classes podem ser instanciadas, correspondendocada instˆancia a um objeto6 em mem´oria. Classes funcionam como modelos quecont´em as informa¸c˜oes necess´arias para a aloca¸c˜ao dos dados dos objetos e para ainicializa¸c˜ao de seus atributos.
Na se¸c˜ao 2.1.4.3 vimos que, com os Tipos Abstratos de Dados (TADs), osprogramadores s˜ao capazes de criar novos tipos, promovendo encapsulamento dedados e processos, com ocultamento da informa¸c˜ao e prote¸c˜ao de dados. Em boaparte das linguagens de programa¸c˜ao, a estrutura de dividir m´odulos fonte emdois arquivos, um de interface e um outro de implementa¸c˜ao, discutida na se¸c˜ao2.1.4.4, ´e a estrat´egia adotada para a implementa¸c˜ao de TADs. Com o advento delinguagens de programa¸c˜ao Orientadas a Objetos, as classes surgiram como umanova maneira de se implementar os TADs.
As classes oferecem todos os recursos dos TADs, como encapsulamentode dados e processos, ocultamento da informa¸c˜ao, fun¸c˜oes de acesso, opera¸c˜oesconstrutoras e destrutoras. Al´em de oferecerem todos os mecanismos necess´ariospara a implementa¸c˜ao de um TAD, classes oferecem prote¸c˜ao de dados por meiode modiﬁcadores de acesso, apresentam benef´ıcios em legibilidade, redigibilidade e6 Um Objeto ´e uma instˆancia de uma classe. Pode-se instanciar (construir, criar) m´ultiplosobjetos em mem´oria a partir de uma ´unica classe33conﬁabilidade (Varej˜ao, 2004).
Segundo von Staa (2000), com utiliza¸c˜ao de linguagens de programa¸c˜aoorientadas a objetos e tomando-se algum cuidado ao projetar classes, ´e poss´ıvelque elas se tornem integralmente utiliz´aveis em diferentes programas, viabilizandoo re´uso de quantidades signiﬁcativas de c´odigo. O autor destaca que tal forma dere´uso verbatim7 est´a entre as principais formas de redu¸c˜ao de custos e melhoriana qualidade de software. Esta ´e uma motiva¸c˜ao para uma das contribui¸c˜oesdo presente trabalho: a cria¸c˜ao de um arcabou¸co com os recursos do paradigmade programa¸c˜ao orientada a objetos para um m´odulo de um simulador cient´ıﬁco,com potencial de re´uso em outros programas. No cap´ıtulo 3 ser´a abordada a arefatora¸c˜ao do m´odulo.
As classes tornam ainda especiais as opera¸c˜oes construtoras e destrutoras.
As opera¸c˜oes construtoras, nas classes chamadas de m´etodos construtores,s˜ao executadas quando da instˆancia de um objeto da classe e s˜ao respons´aveisbasicamente por inicializar os campos da classe com valores “neutros”, como, porexemplo, zero no caso de membros de valor num´erico, ou valor NULL para o casode ponteiros. Alternativamente, podem ser atribu´ıdos valores com signiﬁcadode “valor indeﬁnido” mais facilmente detect´aveis para a localiza¸c˜ao de erros deinicializa¸c˜ao, caso os campos venham a ser usados antes de que a eles sejaatribu´ıdo qualquer valor. Os m´etodos destrutores, por sua vez, s˜ao respons´aveis poropera¸c˜oes de ﬁnaliza¸c˜ao realizadas quando o uso das classes n˜ao ´e mais necess´ario.
Dentre tais opera¸c˜oes, a mais comum ´e a desaloca¸c˜ao das regi˜oes de mem´oria dosobjetos que n˜ao ser˜ao mais usados.
Com TADs, a modelagem de v´arias entidades do mundo real com aspectosem comum produz aspectos indesej´aveis que s˜ao resolvidos com o uso classes.
Para representar, por exemplo, as entidades Pessoa, Aluno e Professor com TADsprecisamos de 3 tipos de dados com muitos atributos em comum. Aluno e Professors˜ao, ambos, pessoas. No entanto, como o uso de TADs n˜ao podemos representar as7 Re´uso Verbatim ´e a forma de re´uso na qual n˜ao s˜ao feitas altera¸c˜oes na unidade reutilizada.
34entidades Aluno e Professor aproveitando aquilo que ´e comum `as duas e tamb´em`a entidade Pessoa. Isso cria enorme quantidade de replica¸c˜ao de c´odigo. Com aorienta¸c˜ao a objetos, pode-se criar estruturas de classe baseadas em heran¸ca, umdos conceitos mais fundamenais da orienta¸c˜ao a objetos ao lado do polimorﬁsmo.
2.1.5.1
Heran¸caA heran¸ca ´e um relacionamento entre classes onde uma classe denominadaherdeira, ou classe ﬁlha, especializa, reﬁna ou torna mais particulares aspropriedades de outra classe denominada superclasse, ou classe m˜ae. No exemplocitado anteriormente, as entidades Pessoa, Aluno e Professor, se representadaspor classes, poderiam conﬁgurar uma rela¸c˜ao de heran¸ca. As classes Alunoe Professor s˜ao herdeiras da classe Pessoa e por isso possuem os mesmosatributos e m´etodos da classe Pessoa. Diz-se que a rela¸c˜ao de heran¸ca ´e transitiva,pois uma classe herdeira pode, por sua vez, ser superclasse de outras herdeiras. Porexemplo, professor (que herda de Pessoa) pode ser superclasse das herdeirasProfessorSubstituto e ProfessorTitular.
Membros adicionais podem existir nas classes herdeiras, visto queespecializam as superclasses. No caso citado, tanto Aluno como Professorherdariam, por exemplo, os atributos nome e sobrenome da superclasse Pessoa.
Aluno poderia implementar mais membros como nota1, nota2, os m´etodosaprovar() e reprovar(); Professor, por sua vez, poderia implementar osmembros salario, dataDeAdmissão e o m´etodo calcularSalario().
Qualquer objeto instanciado de uma superclasse n˜ao pode ser reﬁnadopor imposi¸c˜ao de tipos (type casting) para um objeto de classe herdeira. Se
instanciarmos um objeto Pessoa1, da classe Pessoa, este n˜ao pode serespecializado por casting de tipos para um objeto do tipo Aluno, pois nem todosos membros de Aluno s˜ao conhecidos pelo objeto da classe Pessoa. Se criarmos,em vez disso, um objeto Aluno1 da classe Aluno, este poder´a ser promovido aum objeto da classe Pessoa e, inclusive, ser posteriormente reﬁnado novamente35para um Aluno, mas jamais para um Professor.
2.1.5.2
PolimorﬁsmoOutro conceito extremamente importante do paradigma orientado a objetos,diretamente relacionado com o conceito de heran¸ca, ´e o polimorﬁsmo, palavracujas origens gregas remetem `a ideia de ”muitas faces”. O conceito de heran¸capermite que m´etodos de superclasses sejam redeﬁnidos nas classes herdeiras.
Nesse contexto, redeﬁnir signiﬁca escrever novamente tais fun¸c˜oes, com assinaturasidˆenticas, por´em com implementa¸c˜oes internas peculiares, em cada uma das classesﬁlhas. Fun¸c˜oes dessa natureza s˜ao ditas fun¸c˜oes polimorfas, e constituem otipo de polimorﬁsmo mais comum implementado pela maioria das linguagens deprograma¸c˜ao, denominado polimorﬁsmo universal de subclasses.
Imaginemos uma estrutura com uma superclasse Pol´ıgono e duas classesherdeiras, Quadrado e Triangulo, as quais possuem implementa¸c˜oes distintas deum m´etodo calcularArea com assinatura idˆentica. A deﬁni¸c˜ao sobre qualimplementa¸c˜ao ser´a aplicada depende da classe do objeto em quest˜ao e ao qualo m´etodo se aplica. De acordo com von Staa (2000), essa propriedade promovefacilidades para a programa¸c˜ao, visto que o pr´oprio objeto determina como eledeve ser processado, retirando do programador a responsabilidade de determinara forma como os objetos devem ser processados, dependendo de sua classe.
Al´em do caso discutido, o polimorﬁsmo pode aparecer ainda de outrasmaneiras. Caso um m´etodo seja implementado v´arias vezes com assinaturasdiferentes, ocorre o tipo de polimorﬁsmo denominado sobrecarga de m´etodos.
Sr o comportamento dos m´etodos variar de acordo com convers˜oes impl´ıcitas detipos sobre os dados recebidos em seus parˆametros, o polimorﬁsmo ´e conhecidocomo polimorﬁsmo de coer¸c˜ao.
362.2
Computa¸c˜ao Paralela´E fatoqueassimula¸c˜oescomputacionaiscient´ıﬁcasutilizam-sefrequentemente de modelos numericamente intensivos. Visando validar teoriase fazer predi¸c˜oes acerca de seus objetos de estudo, ´e comum que os cientistasrealizem um grande n´umero de simula¸c˜oes com tais modelos, utilizando diferentesconjuntos de parˆametros de entrada. Dessa forma, ´e natural que existamdemandas de desempenho nos modelos computacionais cient´ıﬁcos, de forma queas simula¸c˜oes possam ser realizadas em tempos de execu¸c˜ao compat´ıveis com osinteresses da ciˆencia.
Os maiores e mais desﬁadores problemas da ciˆencia moderna geralmentelidam com combina¸c˜oes de fenˆomenos de diferentes ´areas do conhecimento,englobando uma enorme gama de escalas de tempo e espa¸co. Nas simula¸c˜oescomputacionais cient´ıﬁcas, as escalas maiores de tempo e espa¸co est˜ao relacionadascom a extens˜ao do dom´ınio dos problemas modelados, enquanto as menoresest˜ao relacionadas com a resolu¸c˜ao desejada ou necess´aria nos modelos.
Modelar problemas diminuindo a extens˜ao dos dom´ınios para que sejamequipar´aveis `as escalas dos m´ınimos detalhes, ou dos menores fenˆomenos f´ısicosque se possa descrever,frequentemente ´e algo que determina requisitos demem´oria. Por outro lado, reduzir as janelas de tempo das escalas temporaisaos menores intervalos ´e algo que implicar´a em desaﬁos relacionados ao tempo decomputa¸c˜ao.
Grande parte das discuss˜oes atuais no ˆambito da programa¸c˜ao cient´ıﬁca est˜aofocadas no desempenho escal´avel (Rouson et al., 2011). No in´ıcio desde cap´ıtulo,vimos que a escalabilidade de execu¸c˜ao est´a relacionada com o aproveitamentoeﬁciente do m´aximo dos recursos de hardware dispon´ıveis. Al´em disso, um c´odigoescal´avel, do ponto de vista de sua execu¸c˜ao, deve estar preparado para crescer noquesito desempenho de forma compat´ıvel com um eventual incremento nos recursoscomputacionais oferecidos.
Esses motivos deixam claro o porquˆe de a ciˆencia se importar tanto com37a m´axima utiliza¸c˜ao dos recursos computacionais dispon´ıveis. A evolu¸c˜ao dohardware nas ´ultimas d´ecadas tomou claramente a dire¸c˜ao do desenvolvimentode m´aquinas cada vez mais paralelas (Kirk e Hwu, 2013). A escalabilidade deexecu¸c˜ao dos programas est´a fortemente condicionada `a explora¸c˜ao eﬁciente dem´aquinas paralelas.
2.2.1
Arquiteturas Paralelas´E grande a variedade de arquiteturas de hardware para a computa¸c˜aoparalela. Redes de esta¸c˜oes de trabalho, clusters e esta¸c˜oes de trabalho comm´ultiplos processadores s˜ao alguns dos v´arios ambientes onde se pode explorar acomputa¸c˜ao paralela. No estudo da computa¸c˜ao paralela, a Taxonomia de Flynntem sido frequentemente utilizada ao longo das ´ultimas d´ecadas para classiﬁcar asarquiteturas dos computadores, as quais s˜ao divididas em quatro grupos de acordocom o n´umero ﬂuxos de instru¸c˜oes (instruction streams) e de dados (data streams)que podem ser operados simultaneamente pela m´aquina. Nas se¸c˜oes seguintesexploramos cada um dos grupos: SISD, SIMD, MISD e MIMD.
2.2.1.1
Single Instruction, Single Data (SISD)Em um sistema SISD, como mostrado na ﬁgura 2.1, um ´unico ﬂuxo deinstru¸c˜oes opera em um ´unico ﬂuxo de dados. Essa ´e a arquitetura de um sistemacl´assico de Von Neumman. A m´aquina executa apenas uma instru¸c˜ao por vez epode buscar ou armazenar um dado por vez.
2.2.1.2
Single Instruction, Multiple Data (SIMD)Nos sistemas com arquitetura SIMD, como mostrado na ﬁgura 2.2, um ´unicoﬂuxo de instru¸c˜oes ´e distribu´ıdo para v´arios processadores, cada qual com seuﬂuxo de dados. As mesmas instru¸c˜oes s˜ao, portanto, aplicadas, em paralelo,a conjuntos de dados diferentes. De acordo com Pacheco (2011), um sistemaSIMD ´e caracterizado pela presen¸ca de uma Unidade de Controle (UC) e m´ultiplas38Figura 2.1: A arquitetura SISDUnidades Logico-Aritm´eticas (ULAs). Cada instru¸c˜ao ´e distribu´ıda pela UC paratodas as ULAs que as aplicam a seus dados de entrada de forma s´ıncrona. SistemasSIMD s˜ao ideais para a paraliza¸c˜ao de loops simples que operam em longos arraysde dados. Este tipo de paralelismo obtido dividindo os dados pelos processadores eestes aplicando as mesmas instru¸c˜oes sobre seus subconjuntos dos dados ´e chamadode paralelismo de dados (data parallelism).
No in´ıcio dos anos 1990, uma fabricante de sistemas SIMD (ThinkingMachines) era a maior fabricante de m´aquinas paralelas do planeta. No ﬁnal dosanos 1990, os ´unicos sistemas SIMD produzidos passaram a ser os processadoresvetoriais (vector processors), ainda presentes em arquiteturas modernas de CPUs,sob a forma de unidades especializadas em opera¸c˜oes vetoriais: as chamadasVector Processing Units (VPUs), munidas de registradores e instru¸c˜oesvetoriais, al´em de unidades funcionais vetorizadas para o pipelining.
Mais recentemente as unidades de processamento gr´aﬁco (GPUs)tamb´em fazem uso da computa¸c˜ao SIMD. Segundo Pacheco (2011), aplica¸c˜oesgr´aﬁcas frequentemente utilizam fun¸c˜oes de shader que muitas vezes resultam emum ´unico ﬂuxo de controle aplicado a diferentes elementos e isso faz com que odesempenho de GPUs seja otimizado com a computa¸c˜ao SIMD. Isso ´e obtido com39a inclus˜ao de um grande n´umeros de ULAs em um ´unico core das GPUs.
Figura 2.2: A arquitetura SIMD2.2.1.3
Multiple Instruction, Single Data (MISD)N˜ao existem sistemas de computa¸c˜ao bem conhecidos que se enquadrem nomodelo MISD, o qual ´e citado na taxonomia de Flynn apenas por motivos decompletude.
2.2.1.4
Multiple Instruction, Multiple Data (MIMD)Em um sistema do modelo MIMD, mostrado na ﬁgura 2.3, cada processadortem seu pr´oprio ﬂuxo de instru¸c˜oes e opera sobre seus pr´oprios dados individuais.
40Figura 2.3: A arquitetura MIMDPara Mattson et al. (2004) o modelo MIMD ´e muito geral para ser ´utilno entendimento pr´atico de m´aquinas reais. Essa categoria ´e normalmentereclassiﬁcada de acordo com a organiza¸c˜ao de mem´oria. O modelo podeser decomposto em m´aquinas de mem´oria compartilhada e de mem´oriadistribu´ıda.
2.2.2
Mem´oria compartilhadaEm um sistema de mem´oria compartilhada,todos os processadorescompartilham um ´unico espa¸co de endere¸camento de mem´oria e se comunicamentre si pela escrita e leitura em vari´aveis compartilhadas. Os sistemas de mem´oriacompartilhada se subdividem em sistemas SMP (Symmetric Multiprocessors) esistemas NUMA (Non Uniform Memory Acess).
Nos sistemas SMP, todos os processadores acessam todas as regi˜oes damem´oria de maneira uniforme, ou seja, na mesma velocidade. S˜ao os sistemasmais f´aceis para se programar, pois os programadores n˜ao s˜ao respons´aveis peladistribui¸c˜ao das estruturas de dados entre os processadores. Um n´umero elevadode unidades de processamento aumenta a disputa pelo acesso `a mem´oria. Por essaraz˜ao, sistemas desse tipo costumam possuir um n´umero limitado de processadores,j´a que a largura de banda para o acesso `a mem´oria ´e um fator limitante para o41desempenho.
Nos sistemas NUMA, toda a mem´oria ´e ﬁsicamente acess´ıvel a todos asunidade de processamento, entretanto, alguns blocos de mem´oria podem estarmais diretamente associados a certos processadores do que a outros. Dessa formao acesso n˜ao ´e completamente uniforme em todas as regi˜oes da mem´oria. Isso podereduzir a disputa pelo acesso a mem´oria e diminuir os efeitos de um gargalo dedesempenho devido `a largura de banda da mem´oria. Por´em, os tempos de acessode um dado processador a diferentes regi˜oes de mem´oria podem sofrer varia¸c˜oes,sendo sens´ıveis ao qu˜ao pr´oxima cada regi˜ao est´a do processador.
Para diminuir os efeitos do acesso n˜ao uniforme, cada processador possuiuma mem´oria cache e um protocolo de coerˆencia entre as caches dos v´ariosprocessadores, o que faz com que o modelo receba frequentemente o nome deccNUMA (Cache Coherent Non Uniform Memory Acess). Programar para taissistemas ´e equivalente a programar par sistemas SMP, mas para que se extraia omelhor desempenho ´e necess´ario maior aten¸c˜ao `a localidade dos dados e aos efeitosda cache.
2.2.3
Mem´oria Distribu´ıdaNos sistemas de mem´oria distribu´ıda, cada processador possui seu pr´oprioespa¸co de endere¸camento individual.
Isso implica que a comunica¸c˜ao entre osprocessadores n˜ao se possa fazer por meio de vari´aveis compartilhadas, como nocaso anterior. Nos sistemas com mem´oria distribu´ıda a comunica¸c˜ao se d´a portroca de mensagens, as quais devem ser feitas explicitamente pelo programador.
Al´em disso, os programadores precisam se responsabilizar pela divis˜ao dos dadosentre as mem´orias dos processadores. Apesar de representar uma responsabilidade,isso tamb´em representa uma oportunidade. Em aplica¸c˜oes com estruturas de dadosmuito grandes, incapazes de residir inteiramente na mem´oria de uma m´aquina demem´oria compartilhada, ´e poss´ıvel utilizar ambientes de mem´oria distribu´ıda paraparticion´a-las.
42Dependendo da topologia e das tecnologias empregadas para a interconex˜aoentre os processadores dos sistemas de mem´oria distribu´ıda, a velocidade decomunica¸c˜ao pode variar drasticamente, desde praticamente t˜ao r´apidas quantomem´oria uniﬁcada at´e v´arias ordens de magnitude mais lenta, como no casode clusters de PCs conectados via redes ethernet. Clusters s˜ao sistemas decomputa¸c˜ao de mem´oria distribu´ıda compostos por computadores conectador poralguma infraestrutura de rede. Com a tecnologia de redes em cont´ınuo avan¸co ea comunica¸c˜ao cada vez mais r´apida, os clusters tˆem se tornado cada vez maiscomuns e mais poderosos, sendo a principal representa¸c˜ao pr´atica dessa classe desistemas.
2.2.4
Ambientes de Computa¸c˜ao ParalelaUm ambiente de computa¸c˜ao paralela conﬁgura um conjunto de tecnologias,ferramentas e recursos de linguagens de programa¸c˜ao, necess´arios para odesenvolvimento de aplica¸c˜oes paralelas. O produto ﬁnal provido pelo conjuntode todos os componentes do ambiente de programa¸c˜ao ´e um modelo deprograma¸c˜ao, o qualfornece uma abstra¸c˜ao do hardware sobre a qual osprogramadores atuam.
Nos computadores paralelos, existe uma grande variedade de modelos deprograma¸c˜ao, dependendo das caracter´ısticas particulares de hardware que deﬁnemcomo os processadores s˜ao integrados para formar um sistema ´unico. Os modelosde programa¸c˜ao mais utilizados, por´em, se baseiam em uma das classiﬁca¸c˜oes vistasnas se¸c˜oes anteriores: mem´oria compartilhada, mem´oria distribu´ıda com troca demensagens ou uma combina¸c˜ao de ambas.
Nesta se¸c˜ao faremos uma apresenta¸c˜ao dos dois mais difundidos modelosde programa¸c˜ao paralela existentes: O OpenMP (Open Multi-Processing), paramem´oria compartilhada e o MPI (Message Passing Interface), para mem´oriadistribu´ıda.
432.2.4.1
O modelo OpenMPO OpenMP ´e um conjunto de diretivas e fun¸c˜oes de biblioteca para odesenvolvimento de programas paralelos em ambientes de mem´oria compartilhada.
´E combinado com C, C++ ou Fortran para a cria¸c˜ao de uma linguagem multithread,ou seja, as unidades de execu¸c˜ao de programas em OpenMP s˜ao as threads, as quaiscompartilham um ´unico espa¸co de endere¸camento. Dessa forma, a comunica¸c˜ao sed´a atrav´es da manipula¸c˜ao de vari´aveis compartilhadas.
A deﬁni¸c˜ao formal do OpenMP cont´em duas especiﬁca¸c˜oes: uma paraFortran e outra para C e C++, embora sejam ambas bastante similares. Baseadosno modelo fork/join, os programas em OpenMP come¸cam sua execu¸c˜ao com uma´unica thread (master) e, em pontos espec´ıﬁcos do programa, criam-se threadsadicionais (fork ). As m´ultiplas threadsexecutam em paralelo em trechos dec´odigo denominados regi˜oes paralelas. Ao ﬁm das regi˜oes paralelas, cada threadaguarda que todas as demais tenham conclu´ıdo a execu¸c˜ao do trecho e voltam ase unir (join) em uma ´unica thread master.
O modelo OpenMP foi criado com o objetivo de ser simples para osdesenvolvedores de aplica¸c˜oes. Apesar de o melhor desempenho ser sempredesej´avel, ´e decis˜ao frequente abrir-se m˜ao do desempenho m´aximo, caso isso venhaa tornar dif´ıcil e custoso o desenvolvimento e a manuten¸c˜ao das aplica¸c˜oes. Porisso, o OpenMP foi desenvolvido com dois princ´ıpios b´asicos: a equivalˆenciasequencial e o paralelismo incremental.
Equivalˆencia sequencial signiﬁca que o programa paralelo deve gerar osmesmos resultados utilizando-se uma ou mais threads, ou seja, o resultado da vers˜aoparalela deve ser igual ao resultado da execu¸c˜ao serial. Segundo Mattson et al.
(2004), um programa com equivalˆencia sequencial ´e mais f´acil de manter e muitomais f´acil de desenvolver e compreender.
O paralelismo incremental ´e um estilo de programa¸c˜ao paralela ondeo programa evolui gradualmente de sua vers˜ao serial para a vers˜ao paralela.
O programador inicia seus trabalhos com uma vers˜ao serial da aplica¸c˜ao em44funcionamento. Em seguida,identiﬁca regi˜oes no c´odigo onde vale a penaexplorar o paralelismo (usualmente chamadas de hotspots). Assim, o paralelismo´e adicionado de forma incremental em cada uma dessas regi˜oes. Com essaabordagem, a cada fase do processo tem-se uma vers˜ao completamente funcional,que pode ser testada, aumentando a chance de sucesso.
Infelizmente, nem sempre ser´a poss´ıvel que o paralelismo incrementalconduza `a equivalˆencia sequencial. Muitas vezes um algoritmo paralelo precisarefatorar completamente o seu an´alogo serial.
Existem tamb´em algoritmosparalelos que simplesmente n˜ao funcionam com uma ´unica thread, de maneira serial.
Apesar das diﬁculdades, os dois conceitos, equivalˆencia sequencial e paralelismoincremental, guiaram o desenvolvimento do modelo OpenMP e s˜ao consideradosboas pr´aticas de programa¸c˜ao.
2.2.4.2
O modelo MPIO MPI (Message Passing Interface), criado no in´ıcio da d´ecada de 1990,´e o modelo de programa¸c˜ao padr˜ao para sistemas de computa¸c˜ao de mem´oriadistribu´ıda com troca de mensagens. A unidade de execu¸c˜ao do MPI s˜ao processose, naturalmente, cada um possui seu espa¸co de endere¸camento pr´oprio. O conceitocentral do MPI ´e a troca de mensagens. Cada processo precisa agrupar informa¸c˜oesem uma mensagem e envi´a-la a outros processos que devem estar preparados pararecebˆe-las. A comunica¸c˜ao ´e responsabilidade do programador.
O MPI ´e distribu´ıdo na forma de uma biblioteca, originalmente com vers˜oespara C e Fortran, apesar de outras linguagens tamb´em terem sido contempladas.
Existem muitas implementa¸c˜oes do MPI com uso difundido, por´em as duas maiscomuns s˜ao LAM/MPI e MPICH, ambas disponibilizadas gratuitamente pelosmantenedores. Mais do que um simples mecanismo para a troca de mensagens, oMPI oferece rotinas para sincroniza¸c˜ao de processos, distribui¸c˜ao dos dados para osdiferentes processos e muito mais funcionalidades que suportam o desenvolvimentode programas paralelos.
45A ideia b´asica de troca de mensagens levanta questionamentos sobre osdetalhes de como isso ´e feito na pr´atica. O que os processos podem fazer enquantoenviam mensagens, como as mensagens podem ser identiﬁcadas de forma que cadaenvio seja pareado com um respectivo recebimento s˜ao questionamentos comuns.
O MPI deﬁne solu¸c˜oes para essas e outras quest˜oes com os conceitos de gruposde processos e contextos de comunica¸c˜ao.
Um grupo de processos engloba todos os processos envolvidos em umacomputa¸c˜ao. No in´ıcio da execu¸c˜ao de um programa, todos os processos est˜aoagrupados em um ´unico grupo. Posteriormente, o programador pode subdividi-los, agrupando-os em grupos menores envolvidos em uma determinada atividade epode controlar como os grupos interagem.
J´a os contextos de comunica¸c˜ao fornecem um meio para que sejamagrupados conjuntos de comunica¸c˜oes relacionadas.
Em qualquer troca demensagens, ´e necess´ario que as mesmas sejam identiﬁcadas de forma que se saibaquem deve recebˆe-las e quem as enviou. Em MPI, as mensagens s˜ao identiﬁcadascom as IDs dos processos que as enviam e daqueles que devem recebˆe-las. Apesarde intuitivo, o conceito de identiﬁcar mensagens com IDs de processos pode n˜aofuncionar em certas situa¸c˜oes, especialmente em aplica¸c˜oes complexas que incluembibliotecas reutilizadas de outros programas.
Se as bibliotecas incluem chamadas ao MPI, existe o risco de que aaplica¸c˜ao cliente e as bibliotecas compartilhem IDs de processos de origeme destino acidentalmente. Ainda mais porque o programador da aplica¸c˜aonormalmente desconhece os detalhes das implementa¸c˜oes das bibliotecas utilizadas.
Os contextos de comunica¸c˜ao aparecem como solu¸c˜ao para esse problema. Cadaenvio e cada recebimento pertence a um ´unico contexto de comunica¸c˜ao. A cria¸c˜aode v´arios contextos pode evitar os problemas citados.
Os contextos de comunica¸c˜ao e os grupos de processos s˜ao encapsulados peloMPI em uma ´unica entidade denominada comunicador (communicator ). Apesarde n˜ao ser necess´ario lidar diretamente com comunicadores em todos os programas,46a maioria das fun¸c˜oes do MPI faz referˆencia a um comunicador e ´e essencial paraprogramadores interessados em desenvolver componentes de software reutiliz´aveisque manipulem comunicadores.
47Cap´ıtulo 3Refatora¸c˜ao de um m´odulo do simuladorcom inclus˜ao do paradigma orientado aobjetosNeste cap´ıtulo, s˜ao abordadas evolu¸c˜oes no c´odigo-fonte de um simuladorda ciˆencia de escoamentos em reservat´orios de g´as em folhelhos, desenvolvido eutilizado por pesquisadores e alunos do LNCC.
Com foco na organiza¸c˜ao est´atica e estrutural do c´odigo-fonte, o cap´ıtuloapresenta e analisa, primeiramente, a evolu¸c˜ao anterior a este trabalho pela qualo simulador passou desde sua vers˜ao inicial. Em seguida, o cap´ıtulo apresenta edescreve com maiores detalhes a contribui¸c˜ao espec´ıﬁca do presente trabalho nessequesito, a qual consiste em uma reestrutura¸c˜ao de um dos m´odulos do simuladorcom incorpora¸c˜ao do paradigma de orienta¸c˜ao a objetos.
Por ser um produto sem um projeto inicial de longo prazo e por terprop´osito cient´ıﬁco, o simulador tem passado por um processo evolutivo continuadoque atende a demandas pontuais de seus usu´arios, especialistas do dom´ınio deaplica¸c˜ao que, frequentemente, desejam incorporar novas funcionalidades e realizarexperimentos espec´ıﬁcos, dando origem a diferentes vers˜oes que passam a levar emconta diferentes fenˆomenos f´ısicos.
`A medida em que tais demandas espec´ıﬁcas foram atendidas, aspectosmodulares acabaram sendo gradativamente incorporadas ao c´odigo do simulador,48o que deixa clara a tendˆencia de que os programas cient´ıﬁcos em geral evoluamno sentido tornarem-se produtos cada vez mais ﬂex´ıveis, adapt´aveis e comcomponentes reaproveit´aveis. O m´odulo reestruturado neste trabalho corresponde`a por¸c˜ao do c´odigo-fonte do simulador respons´avel pela montagem e solu¸c˜ao dossistemas de equa¸c˜oes lineares do m´etodo de elementos ﬁnitos e possui componentescom alto potencial de re´uso neste ou em outros simuladores cient´ıﬁcos similares.
3.1
Evolu¸c˜ao do simulador de escoamentos em meios porososComo visto no cap´ıtulo 1,o simulador utilizado nestetrabalho,bem como outros desenvolvidos pelo no LNCC,tomam como ponto departida a implementa¸c˜ao do m´etodo deelementos ﬁnitos proposta emHughes (1987):o programa DLEARN, que pode ser encontrado no link :http://www.zsoil.com/dlearn/.
Escrito originalmente no padr˜ao Fortran 77, durante a d´ecada de 1980,quando tamb´em foram desenvolvidos outros programas semelhantes, como oADINA software (Bathe, 1982), o programa de elementos ﬁnitos DLEARN, deHughes (1987), se destacou em sua ´epoca, sendo um bom programa para o per´ıodono qual foi criado. O programa precisou lidar ou contornar limita¸c˜oes/restri¸c˜oesimpostas pelo pr´oprio padr˜ao da linguagem, como, por exemplo, a limita¸c˜ao don´umero de caracteres nos nomes de vari´aveis e subprogramas, que diﬁcultava alegibilidade e o entendimento humano; ou a ausˆencia de aloca¸c˜ao dinˆamica demem´oria, que, por sua vez, tornava dif´ıcil a tarefa de adequar o programa adiferentes tamanhos de problemas.
Devido ao tamanho vari´avel de diferentes estruturas de dados em diferentesproblemas, ´e algo ineﬁciente deﬁnir valores ﬁxos para estes tamanhos, o que podeocasionar erros ou, sen˜ao, desperd´ıcio de mem´oria. O programa original de Hughes(1987) contornava esse problema prevendo uma esp´ecie de emula¸c˜ao da aloca¸c˜aodinˆamica com o uso de um grande array est´atico, dentro do qual s˜ao virtualmente“alocados” m´ultiplos vetores menores em tempo de execu¸c˜ao com o aux´ılio de49vari´aveis que indicam o ponto de in´ıcio de cada um deles.
A ﬁgura 3.1 ilustra tal estrat´egia. Um grande vetor est´atico A, presente naimplementa¸c˜ao original de Hughes (1987), simula um espa¸co de aloca¸c˜ao dinˆamicaem mem´oria, no qual residem v´arios vetores menores, dentre eles alhs, brhs,lm, id, idiag, os quais podem ser localizados em seu interior por meio devari´aveis inteiras (mpalhs, mpbrhs, mplm, mpid, mpidiag) com os ´ındices doselementos de A nos quais iniciavam cada uma das ´areas reservadas aos vetorescorrespondentes.
Figura 3.1: Vetor est´atico ´unico comportando m´ultiplos vetores menores dediferentes tamanhos deﬁnidos em tempo de execu¸c˜ao.
Do ponto de vista de sua organiza¸c˜ao estrutural, embora seja concentradaem um ´unico arquivo de fonte, tal implementa¸c˜ao base j´a possui certo n´ıvel demodulariza¸c˜ao, gra¸cas `a sua organiza¸c˜ao em uma estrutura de subprogramas.
Hughes (1987) apresenta a organiza¸c˜ao do programa fornecendo um ´ındice compouco mais de uma centena de subprogramas, os quais s˜ao, em sua maioria, dotipo procedimento (SUBROUTINE) e, em sua minoria, do tipo fun¸c˜ao (FUNCTION).
Sabemos que, dentre os subprogramas, a forma padr˜ao para a troca deinforma¸c˜oes ´e a passagem de uma lista de parˆametros. Listas de parˆametrosfrequentemente se tornam grandes quando programas modulares crescem. Al´emdesta forma para a troca de informa¸c˜oes, o programa em quest˜ao utiliza outroconceito fornecido pela linguagem Fortran para esse mesmo ﬁm: Os blocosCOMMON, que s˜ao declara¸c˜oes de regi˜oes de mem´oria compartilhadas, acess´ıveisa qualquer unidade do programa que contenha o bloco COMMON de mesmo nome.
Eles representam uma forma de troca de informa¸c˜oes por meio da partilha de50dados.
Os blocos COMMON permitem que supbrogramas partilhem os dados por meiodo compartilhamento de uma regi˜ao de mem´oria comum. N˜ao ´e necess´ario quetodos os blocos COMMON de mesmo nome possuam o mesmo n´umero de vari´aveisou nomes iguais para as mesmas. Com base na ordena¸c˜ao e nos tipos dasvari´aveis o compilador estabelece as correspondˆencias entre as m´ultiplas vari´aveisque representam formas alternativas de referenciar uma mesma regi˜ao de mem´oria.
Na implementa¸c˜ao de Hughes (1987), os blocos COMMON s˜ao usados paraa implementa¸c˜ao da estrat´egia da simula¸c˜ao da aloca¸c˜ao dinˆamica mostradaanteriormente na ﬁgura 3.1. O grande vetor est´atico a e os os apontadores de in´ıciodos subvetores s˜ao compartilhados entre as diversas unidades do programa por meiodos blocos COMMON. A listagem 3.1 mostra o trecho de c´odigo correspondente naimplementa¸c˜ao original. Na linha 6 aparece o vetor A em um bloco COMMON semnome (Blank COMMON) e na linha 4 aparece o COMMON /Spoint/, que armazenaem posi¸c˜oes cont´ıguas de mem´oria as vari´aveis com os ´ındices de in´ıcio de cadasubvetor.
Listagem 3.1: Rotina driver, da implementa¸c˜ao original de Hughes (1987) e ouso de um bloco COMMON importante.
1 SUBROUTINE driver(ntstep,neq,nalhs)!c.... solution driver program2(...)
3COMMON /spoint/ mpd,mpx,mpid,mpf,mpg,mpg1,mpdiag,mpngrp,mpalhs,4mpbrhsinclude ’memory_size.inc’5COMMON A(MAX_SIZE)6(...)
78 END SUBROUTINE driverA partir do padr˜ao Fortran 90, os blocos COMMON deixaram de ser a principalforma para o compartilhamento de dados entre unidades de programa¸c˜ao, dando51lugar a uma forma alternativa, chamada MODULE, sobre a qual voltaremos a falarmais adiante.
Tendo como ponto de partida a referida implementa¸c˜ao do m´etodo deelementos ﬁnitos, muitas aplica¸c˜oes cient´ıﬁcas foram desenvolvidas no LNCC. No
ﬁnal da d´ecada de 1980, o programa Axis (Toledo et al., 1988), da ´area de an´alise detens˜oes em s´olidos sob rota¸c˜ao, desenvolvido no LNCC em projeto de colabora¸c˜aocom o COPESP, foi a primeira de tais aplica¸c˜oes a utilizar a separa¸c˜ao em arquivoscom compila¸c˜ao separada. O compartilhamento de dados com os blocos COMMONcontinuava a ser explorado, mesmo com m´ultiplos arquivos.
No grupo de pesquisas em reservat´orios petrol´ıferos, seguiu-se o mesmocaminho e o simuladores do grupo passaram a ser divididos em m´ultiplos arquivos,principalmente devido ao alto custo de compila¸c˜ao. O simulador deste trabalhotamb´em est´a dividido dessa forma e, mais adiante, ser˜ao dados mais detalhes sobresua organiza¸c˜ao. No ﬁnal da d´ecada de 2000, este simulador passou por um avan¸cosigniﬁcativo: a transi¸c˜ao para o padr˜ao Fortran 90, incluindo a aloca¸c˜ao dinˆamicade suas estruturas de dados em mem´oria.
Com as estruturas de dados dinˆamicas, surge um problema: a forma decompartilhamento de dados com blocos COMMON, usada at´e ent˜ao, n˜ao permite ocompartilhamento de vari´aveis alocadas dinamicamente.
Conforme j´a adiantado, a partir do Fortran 90, existe, alternativamenteao COMMON, um outro elemento de programa¸c˜ao, denominado MODULE. Os
MODULES s˜ao unidades independentemente compil´aveis que, al´em de promover amodulariza¸c˜ao e o encapsulamento de dados e processos, possuem importante papelno compartilhamento de dados, permitindo que sejam tamb´em compartilhadas asvari´aveis alocadas dinamicamente.
Em Fortran, um MODULE ´e uma entidade que cont´em uma s´erie dedeﬁni¸c˜oes e valores iniciais de dados e representa uma forma alternativa para ocompartilhamento de dados entre diferente unidades de programa¸c˜ao (Chapman,2004). Da mesma forma que ocorre nos blocos COMMON, as diferentes unidades52utilizam os mesmos dados e valores presentes em uma ´unica regi˜ao de mem´oria.
A motiva¸c˜ao para a inclus˜ao dos MODULES no simulador, entretanto,foi apossibilidade do compartilhamento das novas vari´aveis alocadas dinamicamente,o que era imposs´ıvel com os blocos COMMON.
As listagens 3.2 e 3.3 mostram trechos de dois m´odulos do simulador,mFratura e mBloco, os quais, como veremos mais adiante, s˜ao respons´aveis pelaformula¸c˜ao variacional relacionada aos problemas f´ısicos modelados no simulador.
Nos trechos, pode-se notar a existˆencia de vari´aveis para aloca¸c˜ao dinˆamica, coma anota¸c˜ao ALLOCATABLE, as quais s˜ao compartilhadas com outras unidades deprograma¸c˜ao por fazerem parte de um MODULE.
Listagem 3.2: Uso de MODULES para o Compartilhamento de vari´aveis alocadasdinamicamente: M´odulo mFratura.
1 MODULE mFratura(...)
2implicit none3(...)
4REAL*8, ALLOCATABLE :: solucao_F(:,:), solucaoTmpAnt_F(:,:),5solucaoNaoLinearAnt_F(:,:)REAL*8, ALLOCATABLE :: f_F(:,:), flux_F(:,:)6(...)
78 END MODULE mFraturaListagem 3.3: Uso de MODULES para o Compartilhamento de vari´aveis alocadasdinamicamente: m´odulo mBloco.
1 MODULE mBLoco(...)
2implicit none3(...)
4REAL*8, ALLOCATABLE :: solucao_B(:,:), solucaoTmpAnt_B(:,:),5solucaoNaoLinearAnt_B(:,:)REAL*8, ALLOCATABLE :: mSolucao_B(:,:,:), mSolucaoTmpAnt_B(:,:,:)653REAL*8, ALLOCATABLE :: f_B(:,:), flux_B(:,:)7(...)
89 END MODULE mBLocoNas unidades clientes, que usam os dados e processos encapsulados pelom´odulo, deve existir uma declara¸c˜ao USE seguida do nome do m´odulo Fortran.
Dessa forma, elas podem acessar os mesmos dados e valores presentes nom´odulo. Por isso, diz-se que os m´odulos em Fortran constituem uma forma decompartilhamento de dados alternativa `a lista de parˆametros de subprogramas.
A listagem 3.4 mostra uma subrotina processador2Escalas, doprograma principal, que faz uso de certas vari´aveis presentes nos m´odulosmFratura e mBloco mostrados anteriormente. Dentre as vari´aveis, est˜ao algumasalocadas dinamicamente como mostrado nas listagens 3.2 e 3.3.
Listagem 3.4: Uso de MODULES para o Compartilhamento de vari´aveis alocadasdinamicamente no simulador: rotina processador2Escalas (cliente).
1 SUBROUTINE processador2Escalas()USE mFratura, only : NITER_F, NDOF_F, NLVECT_F, flux_F2USE mFratura, only : DTEMPO_F, solucao_F, f_F, SUM_NUMITER_F;3(...)
4USE mBloco,only : mSolucao_B, mSolucaoTmpAnt_B, NDOF_B,5DTEMPO_B, NITER_B, SUM_NUMITER_B(...)
67 END SUBROUTINE processador2EscalasAl´em deencapsular dadose promoverseu compartilhamento,asunidades MODULE podem ainda conter procedimentos e fun¸c˜oes integralmenteimplementadas em seu interior. Esses procedimentos contidos em m´odulos s˜aochamados de Module Procedures em Fortran. Vimos na se¸c˜ao 2.1.4.4 a pr´aticacomum de dividir-se os m´odulos-fonte em m´odulo de interface e de implementa¸c˜ao.
Em Fortran, com o uso da unidade MODULE, n˜ao ´e necess´ario que se crieseparadamente os m´odulos de deﬁni¸c˜ao e implementa¸c˜ao. O MODULE engloba54simultaneamente os conceitos de m´odulo de implementa¸c˜ao e de deﬁni¸c˜ao.
Os module procedures se diferenciam dos procedimentos e fun¸c˜oes escritosfora de um MODULE pelo fato de que os primeiros tˆem sua interface sempredispon´ıvel para seus clientes. Quando sub-rotinas s˜ao escritas dentro de umMODULE e outra unidade de compila¸c˜ao faz uso desse MODULE com a declara¸c˜aoUSE, automaticamente a interface de tais sub-rotinas torna-se dispon´ıvel para asunidades clientes.
Em Chapman (2004) evidencia-se a diferen¸ca entre procedimentos forade um MODULE e os module procedures no que diz respeito `a classiﬁca¸c˜aode suas interfaces. Um module procedure, acessado pela declara¸c˜ao USE, ´edito possuir interface expl´ıcita, uma vez que todos os detalhes sobre seusparˆametros formais s˜ao explicitamente conhecidos pelo compilador Fortran. Poroutro lado, procedimentos fora de um MODULE possuem interface impl´ıcita,dado que o compilador Fortran n˜ao possui informa¸c˜oes sobre esses procedimentosquando est´a compilando qualquer uma das suas unidades clientes.
Nessemomento, o compilador simplesmente assume que o programador est´a utilizando osprocedimentos da maneira correta, quanto ao n´umero e aos tipos dos argumentospassados (Chapman, 2004).
Outra vantagem oferecida pelos MODULES est´a relacionada a uma exigˆenciada pr´opria linguagem: os procedimentos que possuem parˆametros do tipo ponteiro(POINTER) ou arrays alocados dinamicamente (ALLOCATABLE) precisam,obrigatoriamente, ter sua interface expl´ıcita e, portanto, vis´ıvel a seus clientes.
Sendo assim, os MODULES facilitam essa tarefa, visto que, por padr˜ao, explicitama interface de todos os seus procedimentos internos.
A listagem 3.5 mostra trechos do m´odulo mFratura, onde pode-se vera declara¸c˜ao da vari´avel solucao_F e sua aloca¸c˜ao dinˆamica em mem´oria nalinha 5. Pode-se ver ainda a rotina printsol_F. A vari´avel solucao_F ´eposteriormente utilizada como argumento na chamada desta subrotina, comoveremos mais adiante.
55Listagem 3.5: M´odulo contendo subrotina com parˆametro alocado dinamicamente.
1 MODULE mFratura(...)
2REAL*8, ALLOCATABLE :: solucao_F(:,:)3(...)
4ALLOCATE(solucao_F (ndof_F, numnp_F));5(...)
6SUBROUTINE printsol_F(solucao,X,NUMNP,TEMPO)7!Imprime a solução na fratura8(...)
9END SUBROUTINE printsol_F1011 END MODULE mFraturaA listagem 3.6 mostra a rotina processador2Escalas, pertencente aoprograma principal. A rotina faz uso da vari´avel solucao_F e a utiliza comoprimeiro argumento na chamada da rotina printsol_F. Isso s´o ´e poss´ıvel pois,como visto na listagem 3.5, printsol_F ´e um module procedure, j´a que faz partedo MODULE mFratura, e, como tal, tem sua interface vis´ıvel ao seu cliente.
Listagem 3.6: Chamada a uma subrotina com parametro alocado dinamicamente.
1 SUBROUTINE processador2Escalas()(...)
2use mFratura, only : solucao_F3use mFratura, only: printsol_F4(...)
5CALL printsol_F(solucao_F, x_F ,NUMNP_F, TEMPO)6(...)
78 END SUBROUTINE563.2
Organiza¸c˜ao do simulador em arquivos para compila¸c˜aoseparadaComo j´a adiantado, a vers˜ao do simulador tomada como base neste trabalhopossui modulariza¸c˜ao em arquivos para compila¸c˜ao separada. Com algumasimpliﬁca¸c˜ao, podemos enxergar tais arquivos organizados em uma estrutura de3 n´ıveis que deﬁnem diferentes potenciais de re´uso, como mostrado na ﬁgura 3.2.
Figura 3.2: Organiza¸c˜ao em 3 n´ıveis dos m´ultiplos arquivos de fonteExce¸c˜ao ´unica feita ao arquivo-fonte que cont´em a rotina principal(driver2Escalas.F90), cada arquivo compreende uma unidade MODULE doFortran. Tomamos a liberdade de nos referir a “arquivos” e “m´odulos” de formaindistinta, embora no caso do arquivo/m´odulo principal n˜ao exista de fato umaunidade MODULE.
No primeiro n´ıvel mostrado na ﬁgura 3.2, com baixo ou nenhum n´ıvel dere´uso, est´a o m´odulo principal, o qual desempenha apenas papel de cliente dosdemais m´odulos e descreve o ﬂuxo b´asico de execu¸c˜ao do simulador. As rotinas57deste m´odulo s˜ao usadas apenas em seu interior. O re´uso de c´odigo deste m´odulopode dar-se apenas na forma de adapta¸c˜ao, visto que outras vers˜oes do simuladorde reservat´orios podem ser desenvolvidas adaptando-se este m´odulo. Entretanto,devido `a sua natureza enquanto um m´odulo principal que guia a execu¸c˜ao daaplica¸c˜ao, sua reutiliza¸c˜ao ou de seus componentes internos na forma de re´usoverbatim ´e inexistente.
No segundo n´ıvel, est˜ao os m´odulos que desempenham papel de provedoresde funcionalidades, mas ao mesmo tempo s˜ao clientes de outros m´odulos. Nessacategoria, enquadram-se os m´odulos referentes aos problemas f´ısicos do simulador(fratura.F90 e bloco.F90). Tais m´odulos e seus componentes internos s˜aoreutilizados com alguma frequˆencia dentro do simulador.
No terceiro n´ıvel, encontram-se os m´odulos de base, provedores defuncionalidades com alto n´ıvel de re´uso e n˜ao relacionadas ao dom´ınio da aplica¸c˜ao.
Isso signiﬁca que tais m´odulos tˆem grande potencial de re´uso verbatim, n˜aosomente dentro do simulador, mas tamb´em em outras aplica¸c˜oes baseadas namesma implementa¸c˜ao do m´etodo de elementos ﬁnitos proposta em Hughes (1987),caso de v´arios outros simuladores cient´ıﬁcos desenvolvidos no LNCC.
58Figura 3.3: A organiza¸c˜ao do simulador em arquivos-fonteA ﬁgura 3.3 mostra os arquivos-fonte divididos nos 3 n´ıveis descritosanteriormente.
No n´ıvel 1,est´a o m´odulo do programa principal,(driver2escalas.F90). Nele est´a deﬁnido o ﬂuxo de execu¸c˜ao do programacomposto por:(i) leitura de dados de entrada, (ii) processamento e (iii) p´os-processamento, onde s˜ao apresentados os resultados. Para tanto, este m´oduloutiliza funcionalidades providas pelos outros dois n´ıveis.
No n´ıvel 2, os m´odulos s˜ao fratura.F90 e bloco.F90, respons´aveis pelaformula¸c˜ao variacional e sua implementa¸c˜ao num´erica para os problemas f´ısicos deescoamento na fratura hidr´aulica e no bloco da rocha matriz, respectivamente.
No n´ıvel 3, os m´odulos s˜ao: leituraEscrita.F90, respons´avel pelaleitura dos arquivos de entrada com informa¸c˜oes de malha e coordenadas, al´em deescrita dos resultados; malha.F90, repons´avel pela gera¸c˜ao de coordenadas nodaise conectividades e busca de vizinhos; funcoesDeForma, que inclui fun¸c˜oes deinterpola¸c˜ao lagrangeanas e informa¸c˜oes para integra¸c˜ao num´erica e, ﬁnalmente, o59m´odulo algMatricial.F90, respons´avel pela constru¸c˜ao e solu¸c˜ao dos sistemasde equa¸c˜oes lineares do m´etodo de elementos ﬁnitos, incluindo a montagem dasestruturas de dados e a implementa¸c˜ao de solver interno.
3.3
Orienta¸c˜ao a Objetos no M´odulo dos Sistemas de Equa¸c˜oesA contribui¸c˜ao deste trabalho no c´odigo do simulador ´e concentrada nom´odulo algMatricial.F90 e consiste em uma reformula¸c˜ao deste m´odulo,que passa a dar lugar a outros menores, incluindo o paradigma de orienta¸c˜ao aobjetos e alguns de seus conceitos como heran¸ca e polimorﬁsmo. Considerandoque o m´odulo em quest˜ao est´a no terceiro n´ıvel mostrado na ﬁgura 3.2 e possuialto potencial de re´uso, percebe-se que os benef´ıcios decorrentes da reestrutura¸c˜aopodem se estender a outras aplica¸c˜oes semelhantes dentro do LNCC.
Com essa reestrutura¸c˜ao, objetiva-se conferir ao simulador caracter´ısticasmais modulares, contribuindo para um melhor entendimento humano e capacidadede evolu¸c˜ao. Conforme visto no cap´ıtulo 2, c´odigos que implementam conceitosde modularidade e orienta¸c˜ao a objetos beneﬁciam-se de abstra¸c˜oes por meiodo encapsulamento de dados e opera¸c˜oes, ganhando em usabilidade. Entidadesencapsuladas encorajam e facilitam o uso de aplica¸c˜oes com c´odigo-fonte extenso.
3.3.1
Identiﬁca¸c˜ao das Entidades de InteresseO m´odulo refatorado compreende dados e opera¸c˜oes relativos `a constru¸c˜ao e`a solu¸c˜ao dos sistemas de equa¸c˜oes e tamb´em `as estruturas de dados capazesde tratar a esparsidade das matrizes relacionadas a tais sistemas. O m´odulo incluioriginalmente apenas uma op¸c˜ao de solver interno implementando elimina¸c˜ao deGauss.
Muitas aplica¸c˜oes cient´ıﬁcas fazem uso de solvers de bibliotecas de ´algebralinear, dentre as quais podemos citar para ﬁns de exemplo: LAPACK, PETSC,umfPACK ou Intel MKL. Alguns simuladores cient´ıﬁcos num´ericos desenvolvidosno LNCC, em determinado momento de sua evolu¸c˜ao, por for¸ca de iniciativas60individuais e de demandas espec´ıﬁcas, passaram a utilizar solvers externos comoo Pardiso (Intel MKL) ou HYPRE (Los Alamos).
Tais iniciativas demandaram que o m´odulo algMatricial.F90 fosseconsideravelmente modiﬁcado, passando a englobar n˜ao apenas novas op¸c˜oes desolvers, mas tamb´em diferentes estruturas de dados adequando-se aos diferentessolvers. Al´em de trabalhosos, processos de adapta¸c˜ao desse tipo frequentementeresultam em altera¸c˜oes feitas de maneira esparsa no c´odigo-fonte, o que impactanegativamente sua usabilidade e evolu¸c˜ao.
A reestrutura¸c˜ao feita neste trabalho funciona como uma camada desoftware com orienta¸c˜ao a objetos, que substitui o m´odulo citado e encapsula emdiferentes classes os dados e opera¸c˜oes relativos aos sistemas de equa¸c˜oes, suasestruturas de dados e solvers. Os novos m´odulos com classes permitem maiororganiza¸c˜ao do c´odigo e facilitam a troca e a inclus˜ao de novos solvers e estruturasde dados para sistemas de equa¸c˜oes neste ou em outros simuladores baseados namesma implementa¸c˜ao original.
O m´odulo algMatricial.F90, cuja implementa¸c˜ao original simpliﬁcada´e mostrada na listagem 3.7, re´une vari´aveis e subrotinas cuja an´alise cuidadosapermite a identiﬁca¸c˜ao de grupos de dados e opera¸c˜oes com certo n´ıvelde similaridade e que podem ser melhor distribu´ıdos em outras unidadesencapsuladoras para melhor modulariza¸c˜ao. O paradigma de orienta¸c˜ao a objetospermitir´a a realiza¸c˜ao desta tarefa com naturalidade e trar´a benef´ıcios n˜ao somente`a organiza¸c˜ao do c´odigo-fonte e `a sua evolu¸c˜ao futura, mas tamb´em facilitar´a aimplementa¸c˜ao de uma estrat´egia de paraleliza¸c˜ao para o c´odigo do simuladorcomo ser´a visto no cap´ıtulo 4.
Listagem 3.7: O m´odulo mAlgmatricial.
1 MODULE mAlgmatricialinteger:: neq_F, nalhs_F, ned_F2integer:: neq_B, nalhs_B, ned_B3real*8,allocatable :: alhs_F(:), brhs_F(:)461allocatable :: alhs_B(:), brhs_B(:)real*8,integer, allocatable :: id_F(:,:), idiag_F(:), lm_F(:,:,:)56integer, allocatable :: id_B(:,:), idiag_B(:), lm_B(:,:,:)7!Subrotinas8public :: back, factor9public :: diag, load, addnsl, addlhs, addrhs10public :: btod, kdbc, ftod, colht11(...)
1213 END MODULE mAlgmatricialAlgumas vari´aveis e rotinas mostradas listagem 3.7 est˜ao relacionadas com osistema propriamente dito e outras com as estruturas de dados utilizadas. Assim, aabordagem adotada neste trabalho estabelece a existˆencia de uma estrutura de duasclasses base que representam as entidades de interesse: Sistemas de Equa¸c˜oese suas Estruturas de Dados. Solvers podem ser vistos como conjuntos deopera¸c˜oes que atuam sobre os dados de um sistema. Um solver ser´a, portanto,entendido como um procedimento que faz parte de todo Sistema de Equa¸c˜oes ecuja fun¸c˜ao ´e resolvˆe-lo.
O trabalho inclui o provimento de duas op¸c˜oes de solver, sendo um delesinterno, implementando a elimina¸c˜ao de Gauss j´a presente no m´odulo original,e outro externo (Intel MKL Pardiso), ambos encapsulados pelo arcabou¸co daOrienta¸c˜ao a Objetos. Os tipos de solvers deﬁnem tipos de sistemas de equa¸c˜oes,de forma que temos sistemas do tipo Gauss e do tipo Pardiso, uma vez que ossistemas precisam incluir rotinas e vari´aveis espec´ıﬁcas para lidar com os tiposespec´ıﬁcos de solver.
Cada um dos solvers requer um tipo de estrutura de dados para tratar aesparsidade das matrizes de forma espec´ıﬁca. Tais estruturas de dados s˜ao do tipoSkyline para os sistemas do tipo Gauss, por´em do tipo CRS para sistemas dotipo Pardiso. A ﬁgura 3.4 mostra um diagrama UML simpliﬁcado da estrutura declasses adotada, onde se observa o conceito de heran¸ca tanto nos tipos de sistemasde equa¸c˜oes como nos tipos de estruturas de dados.
62Figura 3.4: A estrutura b´asica de classes: Sistemas e Estruturas de DadosSistemas do tipo Gauss e do tipo Pardiso possuem semelhan¸cas e diferen¸cas.
Os pontos em comum est˜ao encapsulados na classe m˜ae SistemaEquacoes.
Por isso as classes SistemaGauss e SistemaPardiso s˜ao ligadas `a primeirapor uma seta que indica o relacionamento de heran¸ca. As diferen¸cas s˜aoimplementadas nas classes ﬁlhas. Suas estruturas de dados, EstruturaSkylinee EstruturaCRS, respectivamente, tamb´em possuem pontos em comum e pontosde diferen¸ca, herdando os pontos em comum da classe m˜ae EstruturaDados esendo as diferen¸cas implementadas nas classes ﬁlhas.
3.3.2
Introduzindo os Atributos e M´etodos das ClassesA an´alise das vari´aveis e rotinas do m´odulo algMatricial.F90, bem comodas semelhan¸cas entre sistemas do tipo Gauss e Pardiso, permite observar que todossistemas em sua forma matricial A.x = B possuem como atributos em comum: umamatriz A (vari´avel ALHS), o vetor B (vari´avel BRHS), al´em uma estrutura de dados,que poder´a ser do tipo Skyline ou CRS.
Quanto `as opera¸c˜oes, ou m´etodos da classes, podemos observar que todos ossistemas possuem em comum uma opera¸c˜ao de solver, representada pelo m´etodosolver, al´em de outras opera¸c˜oes adicionais do m´etodo de elementos ﬁnitos,relacionadas, por exemplo, `a montagem das matrizes globais, como ´e o caso deaddlhs e addrhs, ou `a coloca¸c˜ao de condi¸c˜oes de contorno, como load e ftod.
A ﬁgura 3.5 mostra o diagrama em UML das classes de sistemas de equa¸c˜oes com63um n´ıvel maiores detalhes.
Figura 3.5: A estrutura de classes de Sistemas de Equacoes com maiores detalhes.
O entendimento de todas as rotinas do c´odigo ´e considerado irrelevante nessemomento em que estamos interessados em explorar a reestrutura¸c˜ao do m´odulooriginal com conceitos de orienta¸c˜ao a objetos como heran¸ca, polimorﬁsmo eencapsulamento. Dessa forma, concentrando-nos na explora¸c˜ao de tais conceitos,chamamos aten¸c˜ao para dois m´etodos em espec´ıﬁco: solver e addlhs.
Todos os sistemas possuem um m´etodo solver capaz de resolvˆe-lo.
Entretanto,temos tipos diferentes de sistemas com diferentes solvers que,naturalmente, devem se comportar de maneira diferente. Este cen´ario evocaautomaticamente o conceito de polimorﬁsmo, visto no cap´ıtulo 2. Algosemelhante ocorre com o m´etodo addlhs, respons´avel por adicionar a contribui¸c˜ao64das matrizes de elemento na matriz global do m´etodo de elementos ﬁnitos.
No caso das classes de estruturas de dados, ocorre um cen´ario similar e este´e mostrado no diagrama da ﬁgura 3.6. Podemos identiﬁcar que tanto estruturas dedados do tipo Skyline quanto as do tipo CRS possuem atributos em comum, comoo trio de vetores lm, id e idiag, que aparecem portanto na classe m˜ae. Todaestrutura de dados tamb´em possui o m´etodo montarEstruturaDados, embora elese comporte de maneira diversa nas classes ﬁlhas. Isso signiﬁca que tamb´em ´e umm´etodo onde aparece o conceito de polimorﬁsmo.
Figura 3.6: A estrutura de classes de Estruturas de Dados com maiores detalhes.
Nas se¸c˜oes seguintes, abordaremos a implementa¸c˜ao pr´atica, no c´odigo dosimulador, dos conceitos discutidos at´e aqui. Ser˜ao apresentados trechos de c´odigoem linguagem Fortran mostrando como foram implementadas as classes e osconceitos de heran¸ca e polimorﬁsmo discutidos at´e este ponto.
653.3.3
Implementa¸c˜ao de Orienta¸c˜ao a Objetos em Fortran: Heran¸caDe acordo com Chapman (2004), na linguagem Fortran, utilizada nestetrabalho, a orienta¸c˜ao a objetos ´e implementada com o uso de MODULES e detipos de dados derivados, deﬁnidos com a palavra TYPE, os quais podemconter opera¸c˜oes em seu interior e s˜ao implementados integralmente dentro de umaunidade MODULE. Na listagem 3.8, vemos como a classe m˜ae SistemaEquacoesfoi implementada. A classe ´e representada pelo tipo derivado SistemaEquacoes,deﬁnido na linha 3.
Listagem 3.8: Implementa¸c˜ao de uma classe em Fortran.
1 MODULE mSistemaEquacoes(...)
2TYPE, public, abstract :: SistemaEquacoes3real*8, public, allocatable :: alhs(:), brhs(:)class(EstruturaDados), pointer :: estDados45CONTAINS6!Métodos da classe SistemaEquacoes:7procedure(solverM_interface), public, deferred :: solverM8procedure(addlhsM_interface), public, deferred :: addlhsM9procedure, public :: addrhsM10procedure, public :: ftodM11(...)
12END TYPE SistemaEquacoes13(...)
14CONTAINS15!Implementação dos métodos da classe:16SUBROUTINE addrhsM (this, p_elresf, p_nel, p_nee, p_ndof, p_nen)17(...)
18END SUBROUTINE19(...)
2021 END MODULEAinda na listagem 3.8, vemos que, ap´os a palavra CONTAINS da linha 6, os66m´etodos da classe s˜ao listados como procedimentos do tipo (type bound procedures)e, em seguida, s˜ao implementados, ap´os a palava CONTAINS da linha 15, aindadentro do m´odulo mSistemaEquacoes.
A listagem 3.9 mostra como a classe ﬁlha SistemaPardiso foiimplementada. A deﬁni¸c˜ao ´e similar ao que foi feito para a classe m˜ae. Chamamosaten¸c˜ao para a anota¸c˜ao extends(SistemaEquacoes) feita na deﬁni¸c˜ao doIsso indica que a classe SistemaPardiso ´e ﬁlhatipo derivado na linha 3.
da classe SistemaEquacoes e, portanto, herda seus atributos e m´etodos,funcionando como uma especializa¸c˜ao.
Listagem 3.9: Implementa¸c˜ao de uma classe herdeira em Fortran.
1 MODULE mSistemaPardiso(...)
2TYPE, public, extends(SistemaEquacoes) :: SistemaPardiso3!Atributos do Sistema Pardiso:4INTEGER pt(64), iparm(64)5REAL*8 dparm(64)CONTAINS67!Métodos do Sistema Pardiso8procedure, public ::solverM9procedure, public ::addlhsM10procedure, public ::construtorSistemaPardiso11END TYPE SistemaPardiso12CONTAINS13!Implementação dos métodos da classe:14SUBROUTINE solverM(this, p_solucao, p_label)15(...)
16END SUBROUTINE solverM17(...)
1819 END MODULE673.3.4
Implementa¸c˜ao do Polimorﬁsmo em Fortran:Se repararmos no diagrama UML da ﬁgura 3.5, veremos que, na classeSistemaEquacoes, ao lado dos m´etodos solver e addlhs, existe a anota¸c˜aoabstract.
Isso quer dizer que estes s˜ao dois m´etodos abstratos, ou seja, semimplementa¸c˜ao deﬁnida na classe m˜ae, onde existe apenas a declara¸c˜ao desua interface. A implementa¸c˜ao completa dos m´etodos ´e feita nas classesﬁlhas (sistemaGauss e sistemaPardiso) que especializam a classe m˜ae eimplementam tais m´etodos de diferentes formas. A listagem 3.10 mostra a deﬁni¸c˜aode tais interfaces na classe SistemaEquacoes.
Listagem 3.10: Deﬁni¸c˜ao das interfaces dos m´etodos abstratos na classeSistemaEquacoes.
1 MODULE mSistemaEquacoes(...)
2ABSTRACT INTERFACE3SUBROUTINE solverM_interface(this, p_solucao, p_label)4import :: SistemaEquacoes5class (SistemaEquacoes) :: this6character(len=*) :: p_labelREAL*8, ALLOCATABLE :: p_solucao(:,:)78END SOUBROUTINE solverM_interface9(...)
10END INTERFACE11(...)
1213 END MODULE mSistemaEquacoesA seguir vemos na listagem 3.11 a implementa¸c˜ao do m´etodo solverna subclasse SistemaGauss. Vemos que o comportamento do m´etodo nestasubclasse ´e chamar os m´etodos factor e back nas linhas 7 e 8, respons´aveispela fatora¸c˜ao e substitui¸c˜ao retrocedida, etapas j´a existentes na implementa¸c˜aooriginal que possu´ıa apenas o solver baseado em elimina¸c˜ao de Gauss. Veremos aseguir que o comportamento do m´etodo ´e diferente na outra subclasse.
68Listagem 3.11: Polimorﬁsmo: A implementa¸c˜ao do m´etodo solver na classeSistemaGauss.
1 MODULE mSistemaGauss(...)
2SOUBROUTINE solverM(this, p_solucao, p_label)3implicit none4class(sistemaGauss) :: this5(...)
6CALL this%factorM()7CALL this%backM()8(...)
9CALL this%btodM(p_solucao,ndof,numnp)10END SOUBROUTINE solverM11(...)
1213 END MODULE mSistemaGaussComo adiantado, observa-se na listagem 3.12 o comportamento polim´orﬁcodo m´etodo solver, cuja implementa¸c˜ao interna ´e completamente diferente nasubclasse SistemaPardiso, chamando a rotina solverPardisoPPD_Nodal,que realiza opera¸c˜oes espec´ıﬁcas do solver Pardiso.
Listagem 3.12: Polimorﬁsmo: A implementa¸c˜ao do m´etodo solver na classeSistemaPardiso.
1 MODULE msistemaPardiso(...)
2SUBROUTINE solverM(this, p_solucao, p_label)3implicit none4class(sistemaPardiso) :: this5(...)
6CALL solverPardisoPPD_Nodal(this, simetria, p_label, etapa);7(...)
8CALL this%btodM(p_solucao,ndof,numnp)9END SUBROUTINE solverM1069(...)
1112 END MODULE msistemaPardiso3.3.5
A nova organiza¸c˜ao do simulador com os novos m´oduloscontendo classesComo visto ao longo da se¸c˜ao 3.3, o m´odulo original algMatricial.F90
deu lugar a outros seis m´odulos com classes, mostrados do n´ıvel 3 da ﬁgura 3.7.
Nesta se¸c˜ao, abordamos a forma como os seis m´odulos integram-se ao restante dosimulador e como s˜ao feitas as instˆancias dos objetos das classes citadas nas se¸c˜oesanteriores em c´odigo.
Figura 3.7: Organiza¸c˜ao do simulador com os novos m´odulos fonte.
Lembramos que, como visto na se¸c˜ao 3.2, os m´odulos fratura.F90 ebloco.F90 englobam aspectos relacionados aos problemas f´ısicos de escoamentona fratura hidr´aulica e no bloco matriz. Por essa raz˜ao, decidiu-se que os objetosdas classes de sistemas de equa¸c˜oes e de estruturas de dados devem existir dentro70desses m´odulos. Faz sentido pensar que fratura e bloco “possuem”sistemas deequa¸c˜oes e estruturas de dados para tais sistemas. Haveria, portanto, uma instˆanciade sistemaEquacoes para a fratura hidr´aulica e outra para o bloco. O mesmosendo v´alido para as estruturas de dados.
As listagens 3.13 e 3.14 mostram trechos dos m´odulos fratura.F90 ebloco.F90 onde s˜ao declaradas vari´aveis que na verdade s˜ao ponteiros, os quais,no momento apropriado, far˜ao referˆencia `as regi˜oes de mem´oria em que ser˜aoalocados os objetos das classes criadas. ´E interessante observar que os ponteiross˜ao para objetos do tipos SistemaEquacoes e EstruturaDados, que s˜ao assuperclasses mostradas nas se¸c˜oes anteriores. Ponteiros para um classe m˜ae podemapontar para objetos de suas classes ﬁlhas e isso ser´a feito em momento oportunoe de acordo com a escolha do usu´ario.
Listagem 3.13: Objetos das classes SistemaEquacoes e EstruturaDados nom´odulo mFratura1 MODULE mFratura(...)
2class(SistemaEquacoes), pointer :: umSistEqFratura3class(estruturaDados), pointer :: umaEstDadosFratura4(...)
56 END MODULE mFraturaListagem 3.14: Objetos das classes SistemaEquacoes e EstruturaDados nom´odulo mBloco1 MODULE mBloco(...)
2class(SistemaEquacoes), pointer :: umSistEqBloco3class(estruturaDados), pointer :: umaEstDadosBloco4(...)
56 END MODULE mBloco71No caso do bloco, ´e interessante lembrar que os dados referentes ao sistemaseriam sobrescritos a cada passo de um processo iterativo que resolve m´ultiplosproblemas unidimensionais de elementos ﬁnitos, como descrito no cap´ıtulo 1 emostrado na ﬁgura 1.3. No caso da fratura, existe apenas uma malha e, portanto,o sistema n˜ao ´e sobrescrito em momento algum.
No programa principal, reservoirSimulator,localizado no arquivodriver2Escalas.F90, ´e feita a decis˜ao sobre os tipos de sistema e de estruturasde dados a serem utilizados. A seguir ser˜ao mostrados alguns trechos deste arquivofonte e destacados alguns pontos relevantes.
Primeiramente destacamos que o programa principal faz uso dos ponteirospresentes em fratura.F90 e bloco.F90, mostrados anteriormente naslistagens 3.13 e 3.14. Isso pode ser visto na listagem 3.15, nas declara¸c˜oes USEdas linhas 4, 5, 7 e 8.
Listagem 3.15: Programa principal fazendo uso dos ponteiros declarados nosm´odulos fratura.F90 e bloco.F90
1 PROGRAM reservoirSimulator(...)
2!Sistemas de Equações presentes em mFratura e mBloco:3USE mFratura,only : umSistEqFratura4USE mBloco,only : umSistEqBloco,5!Estruturas de dados presentes em mFratura e mBloco:6USE mFratura,only : umaEstDadosFratura7USE mBloco,only : umaEstDadosBloco8(...)
910 END PROGRAM reservoirSimulatorEm seguida, ´e feita a decis˜ao sobre os tipos de sistemas estruturas de dadosutilizados. Isso ´e feito por meio das diretivas de compila¸c˜ao encontradas nas linhas4 e 12 da listagem 3.16. Se a ﬂag withPardiso n˜ao for deﬁnida devemos tersistemas do tipo Gauss e estruturas Skyline. Caso a ﬂag esteja deﬁnida, issosigniﬁca que a op¸c˜ao do usu´ario ´e pelo solver Pardiso e, ent˜ao, devemos ter sistemas72desse tipo e estruturas do tipo CRS.
O conceito utilizado aqui ´e o de Typed Allocation, aloca¸c˜ao tipada. Assim,podemos alocar os objetos das classes SistemaEquacoes e EstruturaDadosj´a deﬁnindo neste momento que desejamos alocar objetos de uma subclasseespec´ıﬁca. Isso ´e feito para sistemas do tipo Gauss e estruturas Skyline nas linhas6, 7, 9 e 10. Para os sistemas do tipo Pardiso e estruturas CRS isso ´e feito naslinhas 14, 15, 17 e 18.
Listagem 3.16: Aloca¸c˜ao dos objetos das classes de sistemas de equa¸c˜oes eestruturas de dados.
1 PROGRAM reservoirSimulator(...)
2implicit none34 #ifndef withPardiso !SOLVER GAUSS:!Fratura:5ALLOCATE (sistemaGauss :: umSistEqFratura)6ALLOCATE (estruturaSkyline :: umaEstDadosFratura)7!Bloco:8ALLOCATE (sistemaGauss :: umSistEqBloco)9ALLOCATE (estruturaSkyline :: umaEstDadosBloco)1011 #endif12 #ifdef withPardiso !SOLVER PARDISO:!Fratura:13ALLOCATE (sistemaPardiso :: umSistEqFratura)14ALLOCATE ( estruturaCRS :: umaEstDadosFratura)15!Bloco:16ALLOCATE (sistemaPardiso :: umSistEqBloco)17ALLOCATE (estruturaCRS::umaEstDadosBloco)1819 #endif!Ligando os ponteiros:20umSistEqFratura%estDados => umaEstDadosFratura21umSistEqBloco%estDados=> umaEstDadosBloco22(...)
2373CALL preprocessadorFratura()24CALL preprocessadorBloco()25(...)
2627 END PROGRAM reservoirSimulatorChamamos aten¸c˜ao para as opera¸c˜oes feitas nas linhas 21 e 22, tamb´em nalistagem 3.16, depois da aloca¸c˜ao dos objetos, onde estabelecemos a liga¸c˜ao entre oatributo estDados dos objetos das classes de sistema com as estruturas de dadosrec´em alocadas. ´E conveniente atentar para o diagrama da ﬁgura 3.5, onde vemosque todo sistema tem um atributo que ´e a sua estrutura de dados.
Ap´os esta etapa da cria¸c˜ao dos sistemas, aparecem, ainda na listagem3.16, nas linhas 24 e 25, chamadas `as rotinas preprocessadorFraturapreprocessadorBloco, repons´aveis por m´ultiplas tarefas de inicializa¸c˜aoreferentes aos modelos do bloco e da fratura. A listagem 3.17 mostra a rotinapreprocessadorFratura. A rotina preprocessadorBloco ´e similar e fazopera¸c˜oes an´alogas para o caso do bloco.
Listagem 3.17: A rotina preprocessadorFratura.
1 MODULE mFratura(...)
2SUBROUTINE preprocessadorFratura()3(...)
4ALLOCATE(umSistEqFratura%estDados%id(ndof_F,numnp_F))5umSistEqFratura%estDados%id = 06call leituraCodigosCondContorno(umSistEqFratura%estDados%id,7ndof_F,numnp_F,n,iin,iecho,iprtin)umSistEqFratura%estDados%NEQ = n8ALLOCATE(umsistEqFratura%estDados%idiag(umSistEqFratura%estDados%9neq))umSistEqFratura%estDados%idiag=010ALLOCATE(umSistEqFratura%estDados%lm(ndof_F,nen_F,numel_F))11(...)
12SELECT TYPE (umSistEqFratura)1374type is (sistemaGauss)14optSolver_F=’Gauss’15call umSistEqFratura%construtorSistemaGauss16type is (sistemaPardiso)17optSolver_F=’PardisoEsparso’18call umSistEqFratura%construtorSistemaPardiso(nsd_F,nen_F,19numConexoesPorElem)END SELECT20(...)
21END SUBROUTINE preprocessadorFratura()2223 END MODULE mFraturaNas linhas 5, 9 e 11 vemos, respectivamente a aloca¸c˜ao dinˆamica dos vetoresid, idiag e lm, pertencentes `as estruturas de dados para armazenamento dematrizes esparsas e mostrados no diagrama da ﬁgura 3.6. ´E interessante lembrarque estes eram alguns dos vetores da ﬁgura 3.1, os quais, na implementa¸c˜ao originalde Hughes (1987), estavam contidos dentro do grande vetor est´atico A.
Dentre as tarefas realizadas pelas rotinas preprocessadorFraturapreprocessadorBloco,edestacamos,ainda,aschamadasaconstrutorSistemaGaussduasnovasrotinasimportantes:ouconstrutorSistemaPardiso, de acordo com o tipo de sistemas escolhido.
As chamadas a tais rotinas, as quais s˜ao m´etodos das subclasses de sistemas,podem ser vistas nas linhas 16 e 19 da listagem 3.17. Estes m´etodos cumpremaproximadamente a fun¸c˜ao de m´etodos construtores, j´a que s˜ao respons´aveis poralgumas tarefas de inicializa¸c˜ao dos sistemas que devem ser feitas imediatamenteap´os a aloca¸c˜ao de um objeto.
A importˆancia de tais m´etodos est´a no fato de que neles ´e feita a aloca¸c˜aodinˆamica das matrizes e do vetor carga dos sistemas de equa¸c˜oes. Dessa forma,assim que um novo sistema ´e alocado, o m´etodo construtor correspondente ´echamado e faz a aloca¸c˜ao dinˆamica da matriz ALHS e do vetor BRHS, pertencentesaos sistemas de equa¸c˜oes. As listagens 3.18 e 3.19 mostram as rotinas em quest˜ao.
Destacamos a aloca¸c˜ao das vari´aveis ALHS e BRHS.
75Listagem 3.18: O m´etodo construtorSistemaGauss.
1 MODULE mSistemaGauss(...)
2SUBROUTINE construtorSistemaGauss(this)3implicit none4class(sistemaGauss) :: this5ALLOCATE(this%ALHS(this%estDados%nalhs))6ALLOCATE(this%BRHS(this%estDados%NEQ))7END SUBROUTINE construtorSistemaGauss89 END MODULE mSistemaGaussListagem 3.19: O m´etodo construtorSistemaPardiso.
1 MODULE mSistemaPardiso(...)
2SUBROUTINE construtorSistemaPardiso(this, p_nsd_F, p_nen_F,3p_numConexoesPorElem)use mMalha, only: numConexoesPorElem4implicit none5class(sistemaPardiso) :: this6integer, intent(in) :: p_nsd_F, p_nen_F7integer :: p_numConexoesPorElem8ALLOCATE(this%ALHS(this%estDados%nalhs))9ALLOCATE(this%BRHS(this%estDados%NEQ))10p_numConexoesPorElem=p_nen_F11END SUBROUTINE construtorSistemaPardiso12(...)
1314 END MODULE mSistemaPardisoFinalmente, ao ﬁm do programa principal, todos os sistemas e estrtuturas dedados s˜ao desalocados, como mostra a listagem 3.20.
76Listagem 3.20: Desaloca¸c˜ao dos sistemas e estruturas de dados1 PROGRAM reservoirSimulator(...)
2DEALLOCATE(umSistEqFratura)3DEALLOCATE(umaEstDadosFratura)4DEALLOCATE(umaEstDadosBloco)5DEALLOCATE(umSistEqBloco)67 END PROGRAM reservoirSimulatorNo pr´oximo cap´ıtulo, veremos que a reestrutura¸c˜ao com orienta¸c˜ao a objetosdesenvolvida nesse trabalho facilitou a implementa¸c˜ao de uma estrat´egia deparaleliza¸c˜ao para o simulador. O desenvolvimento da solu¸c˜ao paralela produziuuma altera¸c˜ao na aloca¸c˜ao do sistema de equa¸c˜oes do bloco, o qual deixa de ser´unico e passa a dar lugar a v´arios sistemas alocados dinamicamente convivendosimultaneamente em mem´oria, deixando de ser sobrescrito a cada itera¸c˜ao dola¸co que resolve os m´ultiplos problemas relativos ao bloco. Tal abordagem ser´adetalhada no cap´ıtulo 4.
77Cap´ıtulo 4Paraleliza¸c˜ao do simulador 2 escalas deShale GasNeste cap´ıtulo, abordamos o desenvolvimento de estrat´egias de paraleliza¸c˜aocom os padr˜oes OpenMP e MPI para o c´odigo do simulador de escoamentos emreservat´orios de g´as em folhelhos.
Inicialmente ´e feita uma an´alise do perﬁl dedesempenho serial da aplica¸c˜ao com uso de ferramenta especializada. Em seguida,s˜ao apresentadas evolu¸c˜oes no c´odigo necess´arias `a implementa¸c˜ao do paralelismo.
Por ﬁm s˜ao apresentados testes de desempenho e criticados os seus resultados.
4.1
An´alise inicial do perﬁl serial de desempenho da aplica¸c˜ao comintel VTUNEO primeiro passo para a formula¸c˜ao das estrat´egias de paraleliza¸c˜ao propostasneste trabalho envolveu uma fase de an´alise de desempenho para a identiﬁca¸c˜ao,no c´odigo do simulador, das regi˜oes que consomem mais tempo de execu¸c˜ao. A
avalia¸c˜ao correta do perﬁl de desempenho do c´odigo suporta o desenvolvimentode estrat´egias de paraleliza¸c˜ao, na medida em que os esfor¸cos de otimiza¸c˜aos˜ao direcionados `as regi˜oes mais demandantes do c´odigo, onde um aumento nodesempenho ter´a o maior impacto no desempenho geral da aplica¸c˜ao.
Para a obten¸c˜ao de um perﬁl de desempenho do c´odigo, foi utilizada aferramenta de perﬁlamento de c´odigo Intel VTune Ampliﬁer XE, dispon´ıvel nocluster Altix-xe do LNCC. De acordo com Jeﬀers e Reinders (2013), o VTune78´e uma ferramenta capaz de fornecer diversas m´etricas a respeito da execu¸c˜ao deum programa como, por exemplo, uso de mem´oria e de cache, al´em de ajudarna identiﬁca¸c˜ao das regi˜oes com maior custo de execu¸c˜ao, conhecidas como dehotspots.
O arcabou¸co de orienta¸c˜ao a objetos desenvolvido neste trabalho eincorporado ao simulador permite a utiliza¸c˜ao de dois diferentes solvers: o solverinterno, implementando elimina¸c˜ao de Gauss, al´em de um solver externo, intelPardiso, da biblioteca intel MKL.
Neste momento inicial, estamos interessados apenas em analisar o perﬁl dedesempenho da aplica¸c˜ao e confrontar dois solvers neste simulador. Para tanto,foram realizadas an´alises com Intel VTune, com execu¸c˜oes seriais do c´odigo dosimulador, com ambos os referidos solvers.
Nesta an´alise inicial comparativa de solvers, utilizamos, no caso da fratura,uma malha unidimensional de 400 elementos. No bloco, cada malha possui 135elementos e o tempo de simula¸c˜ao total foi de 20 meses. Apesar de tratar-se deum primeiro caso de teste experimental e ainda sem pretens˜oes de interpreta¸c˜ao deresultados f´ısicos, os tamanhos de malhas utilizados nesta etapa s˜ao compat´ıveisaos adotados em simula¸c˜oes semelhantes como em Costa (2015).
O tipo de an´alise feito com a ferramenta de perﬁlamento, denominado “BasicHotspot Analysis” ´e, segundo Jeﬀers e Reinders (2013), o mais recomendado parauma vis˜ao geral do perﬁl de desempenho, com identiﬁca¸c˜ao das subrotinas maiscustosas em tempo de execu¸c˜ao.
As ﬁguras 4.1 e 4.2 mostram, na aba “Caller/Callee”, a lista de todas asrotinas do c´odigo do simulador, ordenadas pelo seu tempo de execu¸c˜ao total,considerando a soma de todas as vezes em que foram chamadas e executadas.
Os n´umeros s˜ao percentuais em rela¸c˜ao ao tempo total de execu¸c˜ao da aplica¸c˜ao.
79Figura 4.1: Percentual do tempo total de execu¸c˜ao por rotina com solver GaussNa ﬁgura 4.1 ´e mostrada a execu¸c˜ao com o solver interno (Elimina¸c˜aode Gauss), ao passo que na ﬁgura 4.2 a execu¸c˜ao foifeita com o solverexerno, intel Pardiso. Em ambos os casos, nota-se uma semelhan¸ca: a rotinaprocessadorBloco, cuja linha est´a em destaque nas ﬁguras, corresponde a umgrande percentual do tempo de execu¸c˜ao total da aplica¸c˜ao (99,5% e 93,3%).
Figura 4.2: Percentual do tempo total de execu¸c˜ao por rotina com solver intelPardisoA rotina em destaque, processadorBloco, ´e respons´avel, em linhasgerais, por resolver um problema unidimensional dentre os v´arios relativos a umbloco, como exposto no cap´ıtulo 1. Tal rotina, cuja implementa¸c˜ao, antes dequalquer interven¸c˜ao para paraleliza¸c˜ao ´e mostrada na listagem 4.1, ´e respons´avelpor: (i) montar o problema matricial relacionado a um sistema de equa¸c˜oes linearescom a chamada `a rotina montarSistema_B e (ii) resolver o sistema com achamada ao m´etodo polimorfo solver, visto no cap´ıtulo 3, se¸c˜ao 3.3.
80A rotina processadorBloco do m´odulo principal,Listagem 4.1:
driver2Escalas.F90
1 SUBROUTINE processadorBloco(...)
(...)
2USE mBloco, only : umSistEqBloco3USE mBloco, only : umaEstDadosBloco4(...)
5umSistEqBloco%ALHS=0.d0
6umSistEqBloco%BRHS=0.d0
7(...)
8CALL montarSistema_B(umSistEqBloco, DT, solucaoTmpAnt_B_aux,9solucao_B_aux)CALL umSistEqBloco%solverM(solucao_B_aux, "Bloco")10(...)
1112 END SUBROUTINE processadorBlocoComo visto no cap´ıtulo 1, se¸c˜ao 1.2, para cada ponto da malha de elementosﬁnitos do problema da fratura, existe um problema relativo ao bloco. Dessa forma,a rotina processadorBloco ´e executada tantas vezes quantos forem os pontosna malha da fratura. O grande n´umero de chamadas a essa rotina, junto a seucusto por chamada, fazem com que ela corresponda a um alt´ıssimo percentual dotempo total de execu¸c˜ao da aplica¸c˜ao, como visto nas ﬁguras 4.1 e 4.2. O fato deque cada chamada a tal rotina resolve um sistema de equa¸c˜oes independente nospermite a considerar sua execu¸c˜ao em paralelo. Esta ´e a ideia b´asica da estrat´egiade paralelismo desenvolvida e que ser´a melhor detalhada em se¸c˜oes seguintes.
Voltemo-nos agora `as diferen¸cas entre os dois solvers. A experiˆencia anteriorde colegas dentro do LNCC em implementa¸c˜ao de simuladores similares ao destetrabalho mostra que, especiﬁcamente para o caso de problemas unidimensionaisde elementos ﬁnitos, a utiliza¸c˜ao do solver baseado em elimina¸c˜ao de Gauss ´emais vantajosa em tempo de execu¸c˜ao do que a utiliza¸c˜ao de alguns outros solversexternos, dentre eles o Pardiso.
A ﬁm de conﬁrmar tal hip´otese neste simulador em espec´ıﬁco, apresentamosdados, tamb´em obtidos na mesma an´alise com a ferramenta Intel VTune Ampliﬁer81XE, capazes de clariﬁcar a diferen¸ca pr´atica entre os dois solvers dispon´ıveis,especiﬁcamente nesta aplica¸c˜ao, que lida unicamente com malhas unidimensionais,de acordo com o modelo apresentado na se¸c˜ao 1.2.
Na ﬁgura 4.3, pode-se observar a aba “Summary” do VTune que mostrao tempo total de execu¸c˜ao da aplica¸c˜ao. Com a utiliza¸c˜ao do solver interno(elimina¸c˜ao de Gauss), o tempo total de execu¸c˜ao do simulador para o caso deteste foi de pouco mais de 30 segundos.
Figura 4.3: Tempo total de execu¸c˜ao do caso experimental com solver GaussCom o uso do solver Pardiso, entretanto, o tempo total se aproximou de 1minuto e 24 segundos segundos, o que refor¸ca a hip´otese de que a utiliza¸c˜ao dosolver Gauss, para problemas com malhas unidimensionais, ou seja, aqueles queestamos interessados em resolver neste momento com a vers˜ao atual do simulador,´e mais vantajosa em termos de dempo de execu¸c˜ao.
Figura 4.4: Tempo total de execu¸c˜ao do caso experimental com solver intel PardisoExaminando os resultados das ﬁguras 4.1 e 4.2 um pouco mais a fundo, nosconcentraremos na rotina processadorBloco, que aparece em destaque em nasﬁguras e ´e respons´avel por alt´ıssimo percentual do tempo de execu¸c˜ao da aplica¸c˜ao.
As ﬁguras 4.5 e 4.6 s˜ao detalhamentos das ﬁguras 4.1 e 4.2, respectivamente.
Analisam especiﬁcamente a rotina processadorBloco, mostrando quais s˜aosuas rotinas “ﬁlhas”, ou seja, chamadas em seu interior, desmembrando o tempo82de execu¸c˜ao gasto em cada uma delas. Nas duas ﬁguras, destacamos a linha darotina solver, pois estamos interessados em confrontar os dois solvers.
Na ﬁgura 4.5 obervam-se dados da execu¸c˜ao com o solver interno (Gauss).
Nota-se que, dos 29,85 segundos gastos na rotina processadorBloco, apenas3,571 segundos foram gastos na rotina do solver propriamente dito, na linhadestacada na ﬁgura.
Figura 4.5: An´alise da rotina processadorBloco com solver GaussEm contraste, na ﬁgura 4.6, onde s˜ao mostrados resultados da execu¸c˜aocom solver Pardiso, percebe-se que, do total de 82,012 segundos gastos na rotinaprocessadorBloco, mais de 50 segundos foram gastos na rotina referente aosolver, sendo esta, neste caso, mais impactante do que a montagem do sistema.
Figura 4.6: An´alise da rotina processadorBloco com solver PardisoEsta ´ultima an´alise, portanto, conﬁrma a hip´otese de a execu¸c˜ao tornou-semais lenta com o solver Pardiso, especiﬁcamente em raz˜ao do custo de execu¸c˜aorotina do solver propriamente dito, e n˜ao por qualquer outro tipo de processamentoa ele relacionado. Dessa forma, consideramos o solver interno mais adequado aomodelo f´ısico e matem´atico atual utilizado por este simulador. O provimento deum solver externo, entretanto, n˜ao deixa de ser justiﬁc´avel e de representar umavan¸co para o simulador.
83Embora atualmente o modelo desenvolvido em Costa (2015) e utilizado nosimulador fa¸ca uso apenas de malhas unidimensionais, qualquer itera¸c˜ao futura quecontemple a utiliza¸c˜ao de malhas bidimensionais ou tridimensionais poder´a fazercom que o usu´ario deste simulador necessite lan¸car m˜ao de um solver externo maisadequado a tais situa¸c˜oes. Seja este o intel Pardiso, j´a disponibilizado, ou mesmoum outro que decida implementar, o que seria facilitado pelo uso do arcabou¸co deorienta¸c˜ao a objetos desenvolvido neste trabalho. Implementar uma nova classe desistemas de equa¸c˜oes e integr´a-la ao simulador ´e uma tarefa mais convidativa doque integrar um novo solver ao antigo m´odulo mAlgMatricial, visto no cap´ıtulo3.
4.2
A estrat´egia de paraleliza¸c˜ao com OpenMPNeste momento, ´e conveniente retomar uma caracter´ıstica do modelo f´ısicoe matem´atico proposto em Costa (2015), adotado no simulador. Conforme vistono cap´ıtulo 1 e na ﬁgura 1.3, o modelo para a simula¸c˜ao de escoamento do g´as noreservat´orio n˜ao convencional (composto por bloco e fratura induzida) ´e baseadoem m´ultiplos problemas unidimensionais de elementos ﬁnitos referentes ao bloco,os quais est˜ao relacionados aos pontos da malha unidimensional do problema nafratura, fornecendo termo de fonte de massa a este ´ultimo.
O modelo confere ao c´odigo a caracter´ıstica de ser naturalmente paraleliz´avel,visto que as solu¸c˜oes dos m´ultiplos problemas do bloco, originalmente feitasde forma serial, n˜ao apesentam qualquer tipo de dependˆencia entre si. Estacaracter´ıstica ´e conhecida, em inglˆes, como embarassing parallelism, o que sugereser constrangedor que n˜ao se explore oportunidade t˜ao convidativa `a execu¸c˜aoparalela de tais atividades. A estrat´egia de paralelismo desenvolvida neste trabalhoexplora, portanto, a solu¸c˜ao em paralelo de m´ultiplos problemas unidimensionaisde elementos ﬁnitos referentes ao bloco.
N˜ao ´e proposta aqui a paraleliza¸c˜ao de um solver, mas sim o desenvolvimentode uma estrat´egia para tornar paralela a execu¸c˜ao de um modelo, o qual inclui84a solu¸c˜ao de m´ultiplos problemas independentes para o bloco. Trata-se de umaestrat´egia de paraleliza¸c˜ao em um n´ıvel mais alto de abstra¸c˜ao e com granularidadegrossa, no sentido de que cada uma das unidades de execu¸c˜ao do OpenMP, asthreads, resolvem problemas completos.
Considerando que o m´odulo refatorado neste trabalho visa disponibilizarsolvers diferentes e,inclusive,facilitar a inclus˜ao de outros, ele confere aoc´odigo certo grau de heterogeneidade no seu ﬂuxo de execu¸c˜ao. A estrat´egia deparaleliza¸c˜ao desenvolvida ´e adequada a essa caracter´ıstica, na medida em quepermite que o simulador se beneﬁcie do paralelismo e tenha escalabilidade deexecu¸c˜ao independente de qual seja o solver em uso.
A ideia ´e que cada thread do OpenMP resolva um subconjunto do n´umerototal de problemas unidimensionais do bloco.
Cada um destes problemascorresponde basicamente a uma chamada `a rotina processadorBloco, a qual,como visto na se¸c˜ao 4.1, monta o problema matricial relacionado a um sistema eo resolve.
No c´odigo do simulador,em sua vers˜ao serial,existe uma rotinarespons´avel porresolver, um a um,todos os problemas relacionados aobloco: resolverProbVariosBlocos, mostrada na listagem 4.2. Na linha6, ´e poss´ıvel observar o loop que resolve cada problema, um ap´os outro,chamando a rotina processadorBloco v´arias vezes, al´em de armazenar,em cada itera¸c˜ao, a contribui¸c˜ao de um problema em uma posi¸c˜ao do vetorfluxoMassicoDeBlocoParaFratura a ser utilizado no problema da fratura.
Listagem 4.2: Rotina serial que resolve os m´ultiplos problemas do Bloco.
1 SUBROUTINE resolverProbVariosBlocos(...)
(...)
2INTEGER :: numBlocos3REAL*8 :: fluxoMassicoDeBlocoParaFratura(numBlocos), fluxoMolM2SINTEGER :: iBlocos45DO iBlocos=1, numBlocos685CALL processadorBloco(...)
7fluxoMassicoDeBlocoParaFratura(iBlocos) = fluxoMolM2S;8END DO! fim do loop do problema micro (blocos)910 END SUBROUTINE resolverProbVariosBlocos´E nesta rotina, resolverProbVariosBlocos, que ser˜ao inseridas asdiretivas de compila¸c˜ao do padr˜ao OpenMP, para a pareliza¸c˜ao do loop que queresolve os v´arios sistemas de equa¸c˜oes. Entretanto, ´e muito importante observarque, na vers˜ao serial do c´odigo, o objeto da classe SistemaEqua¸c˜oes possui seusdados sobrescritos a cada itera¸c˜ao do loop mostrado na linha 6 da listagem 4.2.
A listagem 4.1 mostra que a rotina processadorBloco, a cada vez que ´eexecutada, reconstr´oi as matrizes dos sistemas que resolve. As linhas 6 e 7 mostramas vari´aveis ALHS e BRHS sendo reinicializadas com valor zero pela rotina.
Neste momento percebe-se uma grande utilidade para os novos m´odulos´E preciso que tenhamos v´ariosbaseados no paradigma orientado a objetos.
sistemas coexistindo simultaneamente em mem´oria para que a estrat´egia deparaleliza¸c˜ao funcione e cada thread OpenMP seja capaz de operar em um sistemadiferente. Com a classe SistemaEquacoes,isso pode ser alcan¸cado comnaturalidade, uma vez que podemos instanciar m´ultiplos objetos da classe. Um
novo objeto dever´a ser criado a cada chamada da rotina processadorBloco.
Uma reformula¸c˜ao da rotina processadorBloco foi feita para que osobjetos da classe SistemaEquacoes referentes ao bloco fossem criados em seuinterior. A listagem 4.3 mostra parte da nova vers˜ao da rotina. Na linha 6, vemoso ponteiro umSistEqBloco para a classe m˜ae SistemaEquacoes, enquantonas linhas 8 ou 11 o objeto propriamente dito ´e criado (alocado em mem´oria) erelacionado ao ponteiro da linha 6. Na linha 14, o atributo do estDados dosistema ´e ralacionado `a estrutura de dados presente no m´odulo mBloco.
Listagem 4.3: Reformula¸c˜ao da rotina processadorBloco1 SUBROUTINE processadorBloco(...)
86(...)
2use mBloco, only : umaEstDadosBloco3(...)
4!Ponteiro para sistema:5pointerclass(SistemaEquacoes),:: umSistEqBloco67 #ifndef withPardisoALLOCATE (sistemaGauss :: umSistEqBloco)89 #endif10 #ifdef withPardisoALLOCATE(sistemaPardiso::umSistEqBloco)1112 #endif!Ligando os ponteiros:13umSistEqBloco%estDados => umaEstDadosBloco14(...)
15SELECT TYPE (umSistEqBloco)16type is (sistemaGauss)17optSolver_B_aux=’Gauss’18call umSistEqBloco%construtorSistemaGauss19type is (sistemaPardiso)20optSolver_B_aux=’PardisoEsparso’21call umSistEqBloco%construtorSistemaPardiso(nsd_B,nen_B,22numConexoesPorElem_aux)END SELECT23(...)
24umSistEqBloco%ALHS=0.d0
25umSistEqBloco%BRHS=0.d0
26(...)
27CALL montarSistema_B(umSistEqBloco, DT, solucaoTmpAnt_B_aux,28solucao_B_aux)CALL umSistEqBloco%solverM(solucao_B_aux, "Bloco")29(...)
30DEALLOCATE(umSistEqBloco)3132 END SUBROUTINE processadorBloco87O processo descrito anteriormente ´e exatamente o mesmo que antes era feitono m´odulo principal driver2Escalas.F90 mas, naquela situa¸c˜ao, utilizandoo ponteiro umSistEqBloco presente no m´odulo mBloco. O ponteiro apontavapara o objeto do tipo sistema de equa¸c˜oes alocado no programa principal. Isso foimostrado em detalhes nos trechos de c´odigo exibidos cap´ıtulo 3, se¸c˜ao 3.3.5. Na
nova vers˜ao, tanto o ponteiro para sistema como a aloca¸c˜ao do objeto em mem´oriaest˜ao dentro da rotina processadorBloco.
Chamamos aten¸c˜ao para o fato de que, ap´os a aloca¸c˜ao do sistema,ainda dentro da rotina processadorBloco, aparece agora a chamada aosm´etodos construtorSistemaGauss ou construtorSistemaPardiso, osquais, conforme discutido no cap´ıtulo 3, se¸c˜ao 3.3.5, fazem a aloca¸c˜ao dinˆamicadas matrizes dos sistemas de equa¸c˜oes.
Finalmente, ao ﬁnal da rotinaprocessadorBloco, na linha 31, o sistema ´e desalocado.
A compara¸c˜ao entre as listagens 4.1 e 4.3 permite, portanto, a identiﬁca¸c˜aode evolu¸c˜oes feitas na rotina processadorBloco que ser˜ao necess´arias aodesenvolvimento da estrat´egia de paraleliza¸c˜ao desenvolvida. Resumidamente,duas diferen¸cas mais importantes s˜ao:(i) O ponteiro para objetos da classe SistemaEquacoes referentes ao blocodeixa de estar no m´odulo mBloco e, portanto, deixa de ser ´unico, passando aser uma vari´avel de fun¸c˜ao, interna `a rotina processadorBloco, residindona pilha (stack ). A cada vez que ´e chamada, essa essa rotina cria um novoponteiro para sistema de equa¸c˜oes.
(ii) A aloca¸c˜ao dinˆamica dos objetos a serem apontados por tais ponteirostamb´em ´e feita no interior da rotina.
Isso signiﬁca que, a cada chamada`a mesma, um novo objeto ´e alocado e referenciado pelo ponteiro local.
De (i) e (ii) conslui-se que, caso a rotina processadorBloco seja chamadav´arias vezes em paralelo, teremos m´ultiplos ponteiros para sistemas e m´ultiplosobjetos da classe SistemaEquacoes coexistindo em mem´oria e apontados por88tais ponteiros.
Isso nos pertimitir´a a paralelizar o loop que resolve os v´ariosproblemas do bloco.
As altera¸c˜oes reﬂetiram-se no programa principal, anteriormente mostradona listagem3.15, onde havia quatro decla¸c˜oes USE para ponteiros nos m´odulosmFratura e mBloco (linhas 4, 5, 7 e 8). A listagem 4.4 mostra altera¸c˜oesrelevantes no programa principal. Das referidas quatro declara¸c˜oes USE, restaramapenas trˆes, sendo duas delas para ponteiros no m´odulo mFratura (linhas 4 e5), referentes ao sistema e `a estrutura de dados da fratura; para o caso do blocorestou apenas uma, na linha 7, fazendo uso do ponteiro para estrutura de dadosdo m´odulo mBloco.
Listagem 4.4: Altera¸c˜oes no programa principal.
1 PROGRAM reservoirSimulator(...)
2!Sistema de Equações e Estrutura de dados em mFratura:3use mFratura,only : umSistEqFratura4use mFratura,only : umaEstDadosFratura5!Apenas Estrutura de dados presente em mBloco:6use mBloco,only : umaEstDadosBloco7(...)
89 END PROGRAM reservoirSimulatorComo visto, para o caso da fratura, n˜ao houve altera¸c˜ao, uma vez que oparalelismo tratar´a unicamente dos problemas do bloco. Continuaremos tendoapenas um sistema de equa¸c˜oes para a fratura, al´em de uma estrutura de dados.
No caso do bloco, teremos m´ultiplos sistemas, por´em apenas uma ´unica estruturade dados para todos eles. Esta ser´a apontada por um ´unico ponteiro em mBloco.
Lembramos que estruturas de dados tratam de deﬁnir a forma espec´ıﬁca comoos dados referentes `as matrizes dos sistemas ser˜ao armazenados, considerandosua esparsidade; por´em, as estruturas n˜ao contˆem as matrizes dos sistemaspropriamente ditas, as quais s˜ao atributos da classe sistemaEquacoes.
89As altera¸c˜oes descritas at´eeste ponto, nos permitem, ﬁnalmente,aplicarasdiretivasdecompila¸c˜aodopadr˜ao OpenMP `arotinaresolverProbVariosBlocos, cuja vers˜ao serial foi apresentada na listagem4.2. No trecho de c´odigo mostrado na listagem 4.5, pode-se ver uma nova vers˜aoda rotina resolverProbVariosBlocos com as diretivas OpenMP para aparaleliza¸c˜ao do loop da linha 9 que resolve os v´arios problemas do bloco.
Listagem 4.5: Vers˜ao da rotina resolverProbVariosBlocos paralelizada comOpenMP1 SUBROUTINE resolverProbVariosBlocos(...)
implicit none2INTEGER :: numBlocos, NUSTEP3REAL*8 :: fluxoMassicoDeBlocoParaFratura(numBlocos), fluxoMolM2S4, DTINTEGER :: iBlocos5integer :: omp_get_thread_num6!Loop paralelizado com OpenMP:7!$omp parallel do firstprivate(NUSTEP, TEMPO, fluxoMolM2S,8condContorno, DT)DO iBlocos=1, numBlocos9CALL processadorBloco(...)
10fluxoMassicoDeBlocoParaFratura(iBlocos) = fluxoMolM2S;11END DO! fim do loop do problema micro (blocos)12!$omp end parallel do1314 END SUBROUTINE resolverProbVariosBlocosNas linhas 8 e 13 ´e poss´ıvel observar as diretivas $omp parallel do e$omp end parallel do utilizadas para a divis˜ao das itera¸c˜oes do loop entreas threads. Tamb´em na linha 8, observa-se a cl´ausula firstprivate seguida deuma s´erie de vari´aveis.
Isto foi necess´ario para corrigir e erros de execu¸c˜ao emdecorrˆencia de condi¸c˜oes de corrida causadas pelo paralelismo. Alguns recursos(vari´aveis) eram compartilhados pelas threads quando n˜ao deveriam sˆe-lo. As
escritas simultˆaneas causavam erros nos resultados obtidos com a vers˜ao paralela.
90Os defeitos puderam ser corrigidos com a utiliza¸c˜ao de uma ferrmentaespecialida em thread debugging. Trata-se do Intel Inspector, dispon´ıvel nosrecursos computacionais do LNCC. A ferramenta ´e capaz de apontar vari´aveis queest˜ao causando condi¸c˜ao de corrida. Sua utiliza¸c˜ao guiou a remo¸c˜ao de erros nestaaplica¸c˜ao e a tela de uma das an´alises feitas com ferramenta ´e mostrada na ﬁgura4.7, a t´ıtulo de ilustra¸c˜ao. De posse das informa¸c˜oes obtidas com a ferramenta, foiposs´ıvel utilizar com assertividade a cl´ausula firstprivate, que faz com que asvari´aveis listadas possuam c´opias privadas em cada thread, evitando as condi¸c˜oesde corrida.
Figura 4.7: An´alise de condi¸c˜oes de corrida feita com a ferramente Intel Inspector.
Em linhas gerais, a ideia da solu¸c˜ao paralela ´e que cada thread do OpenMPinstancie um sistema de equa¸c˜oes para um dos problemas do bloco, o resolva eo desaloque ao ﬁnal de sua solu¸c˜ao. O processo segue se repetindo at´e que osproblemas se esgotem, uma vez que o n´umero de problemas ´e, invariavelmente,ordens de grandeza maior do que o n´umero de threads. As threads podeminstanciar novos sistemas de equa¸c˜oes simplesmente chamando a nova vers˜ao darotina processadorBloco, como feito na linha 10.
´E importante lembrar neste momento, que a rotina processadorBlocon˜ao corresponde apenas `a solu¸c˜ao dos sistemas lineares propriamente ditos. Inclui,al´em do solver, a chamada `a rotina montarSistema_B, como visto nas ﬁguras4.5 e 4.6. Isso signiﬁca que a estrat´egia de paraleliza¸c˜ao engloba tanto a montagemdas matrizes dos sistemas quanto a solu¸c˜ao dos mesmos e nos permite ter ganhosnas duas frentes, o que n˜ao ocorreria com a paraleliza¸c˜ao de um solver.
91A organiza¸c˜ao ﬁnal dos ponteiros e objetos de sistemas e estruturas ap´osa implementa¸c˜ao da estrat´egia de paraleliza¸c˜ao descrita funcionasse corretamentetem a forma como ilustrado na ﬁgura 4.8.
Figura 4.8: A organiza¸c˜ao de objetos de sistemas e estruturas de dados na vers˜aoparalelizada com OpenMPS˜ao mostrados na ﬁgura 4.8: (i) o m´odulo mFratura, com dois ponteirospara dois objetos referentes `a fratura: um sistema e uma estrutura de dados, (ii)o m´odulo mBloco, com apenas um ponteiro para uma estrutura de dados a serutilizada em todos os problemas do bloco e (iii) uma s´erie de ponteiros na pilha(stack ) referentes `as chamadas da fun¸c˜ao processadorBloco que ocorrem emparalelo.
4.3
Testes de desempenho I: Paraleliza¸c˜ao com OpenMPNesta se¸c˜ao ser˜ao abordados testes de desempenho realizados com a aplica¸c˜aoparalela. Nas simula¸c˜oes realizadas foram adotados dados f´ısicos realistas, baseados92em um campo real. A tabela 4.1, adaptada de (Costa, 2015), mostra os parˆametrosf´ısicos utilizados nas simula¸c˜oes realizadas.
Tabela 4.1: Parˆametros f´ısicos relativos ao campo realista utilizado nos testes.
Adaptado de [Costa (2015)]1 × 10−19/1000.06
26.2/38006.89/1000355/18070%4.48/35096/5.18
Permeabilidade (K∗)(m2/nD)Porosidade na matriz (φP )Press˜ao inicial no reserv. (M P a/psi)Press˜ao no po¸co (M P a/psi)Temperatura no reserv. (K/F )Satura¸c˜ao do g´asPL(M P a/psi)VL(scf /ton)/((kg/m3)Foram adotadas nos experimentos duas conﬁgura¸c˜oes de tamanhos de malhaspara fratura e bloco:• Experimento (A): Malha de 400 elementos para a fratura e 135 elementospara o bloco, algo compat´ıvel com os tamanhos utilizados em Costa (2015),ambas com reﬁnamento em sua por¸c˜ao inicial. No caso da fratura, naregi˜ao mais pr´oxima ao po¸co e, no caso do bloco, na regi˜ao mais pr´oxima`a fratura.
• Experimento (B): Neste experimento a malhas do bloco s˜ao idˆenticas aoanterior. A ﬁm de aumentar o n´umero de sistemas de equa¸c˜oes referentesao bloco para observar o comportamento da vers˜ao paralelizada e compararresultados f´ısicos e de desempenho computacional, foi adotada para afratura uma malha maior, desta vez uniforme. Apesar de tratar-se deuma malha uniforme, o espa¸camento entre os pontos da malha existenteno experimento (A) para a regi˜ao reﬁnada foi mantido, o que nos faz chegarao n´umero de 2200 elementos para uma malha uniforme a ser adotada nafratura. Este experimento nos permitir´a avaliar se a solu¸c˜ao paralela ´esens´ıvel ao reﬁnamento das malhas.
Para ambas as conﬁgura¸c˜oes de tamanhos de malha,foram realizadas93simula¸c˜oes com tempo total de 30 anos. No experimento (A), com 400 elementosna malha da fratura foi obtida a seguinte sa´ıda:--> Pressão no reservatório:--> Pressão no poço:--> Quantidade de gás total:--> Quantidade de gás recuperável:--> Quantidade de gás produzido:--> Quantidade de gás produzido:--> Valor da pressão no último nó:--> Tempo de simulação--> Fator de recuperação (sobre gás total):--> Fator de recuperação (sobre gás recuperável):2.62000E+07(Pa)6.89000E+06(Pa)6.43831E+03(kg)4.26160E+03(kg)3.53262E+03(kg)2.35508E+06(kg/m^2)6.91931E+06(Pa)3.00000E+01(anos)5.48688E-018.28942E-01resultado para todo reservatorio--> Quantidade de gás total:--> Quantidade de gás recuperável:--> Quantidade de gás produzido:2.71087E+01(MMscf)1.79436E+01(MMscf)1.48742E+01(MMscf)Para o experimento (B), com 2200 elementos na malha uniforme da fratura,foi obtida a sa´ıda a seguir, sem diferen¸cas relevantes nos resultados, como esperado:--> Pressão no reservatório:--> Pressão no poço:--> Quantidade de gás total:--> Quantidade de gás recuperável:--> Quantidade de gás produzido:--> Quantidade de gás produzido:--> Valor da pressão no último nó:--> Tempo de simulação--> Fator de recuperação (sobre gás total):--> Fator de recuperação (sobre gás recuperável):2.62000E+07(Pa)6.89000E+06(Pa)6.43831E+03(kg)4.26160E+03(kg)3.53270E+03(kg)2.35514E+06(kg/m^2)6.91931E+06(Pa)3.00000E+01(anos)5.48701E-018.28961E-01resultado para todo reservatorio--> Quantidade de gás total:--> Quantidade de gás recuperável:--> Quantidade de gás produzido:2.71087E+01(MMscf)1.79436E+01(MMscf)1.48745E+01(MMscf)A valida¸c˜ao dos resultados obtidos tamb´em foi feita por compara¸c˜ao com assa´ıdas da vers˜ao do simulador utilizada em Costa (2015). As ﬁguras 4.9 e 4.10
mostram gr´aﬁcos relativos ao exeperimento (A) com 400 elementos na malha dafratura. Tais gr´aﬁcos n˜ao apresentam diferen¸cas vis´ıveis em rela¸c˜ao aos obtidospara o experimento (B), dada a semelhan¸ca dos resultados. Na ﬁgura 4.9, vemosos perﬁs de press˜ao ao longo dos 30,5 metros de dimens˜ao da fratura em 7 temposespec´ıﬁcos: 1 mˆes, 6 meses, 1, 5, 10, 20 e 30 anos.
94Figura 4.9: Perﬁs de press˜ao ao longo da fratura (30,5 metros) para: 1 mˆes, 6meses, 1, 5, 10, 20 e 30 anos.
A ﬁgura 4.10 mostra a produ¸c˜ao acumulada em Kg para o reservat´orio.
Figura 4.10: Produ¸c˜ao acumulada em Kg4.3.1
Ambiente de Execu¸c˜ao e Metodologia dos testesOs testes da aplica¸c˜ao paralelizada com OpenMP foram realizados e umam´aquina com duas CPUs multi-core com as seguintes especiﬁca¸c˜oes:• 2 Processadores Quad-Core Intel(R) Xeon(R) CPU X5550 @ 2.67GHz(Total de 8 cores)95• 12GB de mem´oria RAM DDR3• Sistema Operacional Ubuntu 12.04.5 LTSO compilador utilizado foi o gfortran vers˜ao 4.6.3 e todos os experimentosparalelos para a tomada de tempo foram repetidos 6 vezes para cada conﬁgura¸c˜aode n´umero de unidades de execu¸c˜ao, ou threads. Ao ﬁm de cada experimento,foram consideradas as m´edias das 6 execu¸c˜oes de cada caso: 1, 2, 4, 6 e 8 threads.
Nas se¸c˜oes seguintes apresentamos os resultados das tomadas de tempo para aaplica¸c˜ao paralelizada com OpenMP.
4.3.2
Resultados do experimento (A) com OpenMPNesta se¸c˜ao apresentamos os resultados das tomadas de tempo com a vers˜aoparalelizada com OpenMP. A tabela 4.2 mostra os tempos totais de execu¸c˜ao daaplica¸c˜ao (em minutos) para 1, 3, 4, 6 e 8 threads. Para cada n´umero de threads aaplica¸c˜ao foi executada 6 vezes. Na linha em destaque na tabela s˜ao apresentadasas m´edias dos tempos de execu¸c˜ao. A ´ultima linha apresenta o speedup obtido emcada caso onde:T empo serialT empo paraleloSpeedU p =Tabela 4.2: Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP para oexperimento (A).
1 Thread 2 Threads4.48
4.48
4.48
4.5
4.58
4.57
4.52
1x4 Threads1.37
1.37
1.37
1.37
1.37
1.4
1.37
3.29x
6 Threads0.98
0.95
0.92
0.92
0.93
0.92
0.94
4.82x
8 Threads0.75
0.72
0.73
0.75
0.72
0.72
0.73
6.18x
Execu¸c˜ao #1Execu¸c˜ao #2Execu¸c˜ao #3Execu¸c˜ao #4Execu¸c˜ao #5Execu¸c˜ao #6M´edia (minutos)SpeedUp Obtido2.55
2.53
2.53
2.52
2.65
2.53
2.55
1.77x
Na ﬁgura 4.11 ´e mostrado o gr´aﬁco dos speedups obtidos com OpenMP (emverde) em compara¸c˜ao ao caso ideal, speedup linear (em vermelho).
96Figura 4.11: Speedups da vers˜ao com OpenMP para o experimento (A).
4.3.3
Resultados do experimento (B) com OpenMPOs testes realizados para os experimento (A) foram repetidos para oexperimento (B), com malha uniforme de 2200 elementos na fratura. A seguir s˜aoexibidos: a tabela de tempos obtidos e o gr´aﬁco de speedups, os mesmos exibidosanteriormente para o experimento (A).
Tabela 4.3: Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP para oexperimento (B).
1 Thread 2 Threads25.47
24.93
24.40
24.97
24.95
25.52
25.04
1x4 Threads7.22
7.35
7.32
7.23
7.18
7.20
7.25
3.45x
6 Threads5.27
5.30
5.53
5.27
5.25
5.32
5.32
4.70x
8 Threads4.12
4.37
3.95
4.33
4.15
4.07
4.16
6.01x
Execu¸c˜ao #1Execu¸c˜ao #2Execu¸c˜ao #3Execu¸c˜ao #4Execu¸c˜ao #5Execu¸c˜ao #6M´edia (minutos)SpeedUp Obtido14.33
14.52
14.32
14.32
14.33
14.30
14.35
1.74x
97Figura 4.12: Speedups da vers˜ao com OpenMP para o experimento (B).
4.3.4
Discuss˜ao dos resultados e otimiza¸c˜ao com OpenMPAo ﬁm dos testes anteriores, foi poss´ıvel observar que a paraleliza¸c˜ao comOpenMP apresentou signiﬁcativos ganhos de desempenho, atingindo, para 8threads, speedups de 6,18x para o experimento (A) e de 6,01x para o experimento(B).
Speedups s˜ao m´etricas afetadas pelo balanceamento de carga, ou seja,pela forma como ´e feita a distribui¸c˜ao da carga de processamento entre asdiferentes threads ou unidades de execu¸c˜ao. Se o balanceamento ´e insuﬁciente,algumas threads terminam seu trabalho muito antes das demais e precisam esperarociosamente pelas outras, quando poderiam estar realizando parte do trabalhoextra que est´a destinado `as demais. Isso impacta negativamente o speedup obtido.
Sabe-se que, em nosso modelo, os problemas relativos ao bloco em sua parteinferior (mais pr´oximos ao po¸co) s˜ao problemas mais demorados que os localizadosna parte superior. Se isso for um fato, signiﬁcaria que as threads respons´aveis pelosproblemas superiores terminariam seu trabalho primeiro e ter´ıamos uma situa¸c˜aodesbalanceamento, ainda n˜ao mensurada, que poderia estar afetando o speedupobtido.
A ﬁm de conﬁrmar a hip´otese de que os problemas inferiores s˜ao mais98custosos, avaliamos, separadamente, os tempos totais de execu¸c˜ao gastos em cadaum dos problemas do bloco, para que o desbalanceamento de carga pudesseser visualizado em termos pr´aticos. As ﬁgura 4.13 e 4.14 mostram, para osexperimentos (A) e (B), os tempos de execu¸c˜ao, acumulados em todos os passos detempo da simula¸c˜ao, de cada um dos problemas do bloco, sendo os valores mais `aesquerda aqueles relativos aos problemas superiores (afastados do po¸co) e os mais`a direita, relativos aos problemas mais pr´oximos do po¸co.
Figura 4.13: Tempos de execu¸c˜ao por cada problema do bloco para o experimento(A).
Figura 4.14: Tempos de execu¸c˜ao por cada problema do bloco para o experimento(B).
Ambos os resultados s˜ao parecidos. As ﬁguras 4.13 e 4.14. Mostram umaoscila¸c˜ao consider´avel dos custos dos problemas do bloco ao longo de toda aexterns˜ao da fratura, por´em ambos os casos apresentam uma linha de tendˆenciacom uma inclina¸c˜ao a qual, embora pequena, ´e capaz de demonstrar que, de fato,99os problemas mais pr´oximos ao po¸co tendem a ser mais lentos, gerando algumdesbalanceamento de carga.
O padr˜ao OpenMP oferece recursos para o melhor balanceamento da cargaentre as threads. A cl´ausula schedule, quando usada na paraleliza¸c˜ao de um loop,pode deﬁnir, de diversas formas, como as itera¸c˜oes do loop ser˜ao divididas entre asthreads para promover melhor balanceamento de carga. A forma padr˜ao utilizadacom a omiss˜ao da cl´ausula schedule ´e chamada de escalonamento est´atico edivide todo o espa¸co de itera¸c˜oes do loop em blocos de itera¸c˜oes de tamanhoaproximadamente igual ao quociente entre o n´umero total de itera¸c˜oes do loope o n´umero de threads. Tais blocos de itera¸c˜oes, ou chunks, s˜ao ent˜ao designadospara as threads, ainda em tempo de compila¸c˜ao.
Os resultados expostos at´e aqui utilizam o escalonamento est´atico. Os testesdas se¸c˜oes 4.3.2 e 4.3.3 foram repetidos com a cl´ausula schedule deﬁnindouma nova maneira de dividir o espa¸co de itera¸c˜oes entre as threads capaz dediminuir os efeitos do desbalanceamento: o escalonamento dinˆamico. No loopparalelizado em nosso simulador, mostrado na listagem 4.5,
foi adicionada acl´ausula schedule(dynamic).
Com a utiliza¸c˜ao do escalonamento dinˆamico, recomendado para situa¸c˜oesonde o custo das itera¸c˜oes do loop n˜ao ´e constante, todas as itera¸c˜oes s˜aoorganizadas em uma esp´ecie de ﬁla de trabalho interna, por meio da qual s˜aodistribu´ıdas para as threads `a medida em que estas terminam seu trabalho. Dessaforma, evita-se que tenhamos threads ociosas por muito tempo.
A ﬁguras 4.15 e 4.16 mostram os novos speedups obtidos para o experimento(A) e para o experimento (B), por´em utilizando a cl´ausula schedule(dynamic).
100Figura 4.15: Speedups com a cl´ausula schedule(dynamic) para o experimento(A).
Figura 4.16: Speedups com a cl´ausula schedule(dynamic) para o experimento(B).
Com essesresultados,´eposs´ıvelperceberqueacl´ausulaschedule(dynamic) elevou consideravelmente os speedups obtidos, apesar deas inclina¸c˜oes da linhas de tendˆencia das ﬁguras 4.13 e 4.14 serem pequenas.
Neste momento ´e interessante saber o que ocorreria em situa¸c˜oes onde asinclina¸c˜oes s˜ao mais pronunciadas. Para o mesmo n´umero de tarefas, mantendoa malha da fratura com 400 elementos, foram aumentadas as malhas do bloco de135 para 600 elementos. A ﬁgura 4.17 mostra os resultados das tomadas de tempo101similares `as da ﬁgura 4.13, por´em com 600 elementos nas malhas do bloco.
Figura 4.17: Tempos de execu¸c˜ao por cada problema do bloco (Fratura com 400elementos e malhas de 600 elementos no bloco)Pode-se observar que as varia¸c˜oes diminu´ıram consideralvemnte. A linha detendˆencia continua apontando um maior custo nos problemas pr´oximos ao po¸co e,dessa vez com uma inclina¸c˜ao maior. A diferen¸ca percebida nas inclina¸c˜oes indicaque no caso com 600 elementos nas malhas do bloco, h´a uma maior diferen¸ca entreos custos dos problemas pr´oximos ao po¸co e aqueles mais distantes. Os valores detais inclina¸c˜oes s˜ao mostrados na ﬁgura 4.18 como fun¸c˜ao do n´umero de elementosnas malhas do bloco. Foi inclu´ıdo um experimento adicional e intermedi´ario com300 elementos nas malhas do bloco.
Figura 4.18: Inclina¸c˜oes das linhas de tendˆencia das ﬁguras 4.13 e 4.17 em fun¸c˜aodo tamanho das malhas do bloco.
Esses resultados indicam que, com malhas maiores no bloco, maiores ser˜ao102os problemas de desbalanceamento caso seja omitida a cl´ausula schedule e,portanto, utilizado o escalonamento est´atico. Nesses casos, espera-se que aeﬁc´acia da cl´ausula schedule(dynamic) seja maior, sendo maiores tamb´emos speedups com sua utiliza¸c˜ao. Apresentamos a seguir os resultados de speedupdos experimentos (A) e (B) por´em com as malhas do bloco aumentadas para 600elementos e uso da cl´ausula schedule(dynamic).
Figura 4.19: Speedups com a cl´ausula schedule(dynamic) para o experimento(A) com malhas do bloco aumentadas para 600 elementos..
Figura 4.20: Speedups com a cl´ausula schedule(dynamic) para o experimento(B) com malhas do bloco aumentadas para 600 elementos.
Osresultados mostram que, na verdade, os benef´ıcios da cl´ausula103schedule(dynamic) tiveram menor impacto nesses casos. Mesmo com umamaior inclina¸c˜ao na linha de tendˆencia da ﬁgura 4.17, que indica maior diferen¸caentre os custos dos problemas da parte inferior do bloco e os da parte superior,os ganhos em speedup atribu´ıdos ao uso do escalonamento dinˆamico foram menosimportantes do que nos casos dos experimentos (A) e (B), mostrados nas ﬁguras4.15 e 4.16, onde nota-se uma maior distˆancia entre static e dynamic.
Estas observa¸c˜oes nos permitem concluir que a eﬁc´acia da cl´ausulaschedule(dynamic) esteve muito mais relacionada com uma grande oscila¸c˜aonos custos de cada problema do que com a conhecida tendˆencia de que eles sejammais custosos pr´oximo ao po¸co.
Testes adicionais com todos os outros tipos de escalonamento oferecidos pelopadr˜ao OpenMP foram realizados para os experimentos padr˜ao (A) e (B), sendo osmelhores resultados obtidos com a cl´ausula schedule(dynamic). Levantamosa hip´otese de que, nos casos com malhas maiores no bloco, como os ´ultimoscasos testados, outros tipos de scheduling possam levar a melhores resultados.
Em raz˜ao da menor oscila¸c˜ao dos tempos de cada problema, nesses casos, oscustos inerentes ao dynamic scheduling, relacionados `a constru¸c˜ao da ﬁla quecontrola a distribui¸c˜ao da itera¸c˜oes para as threads, provavelmente n˜ao est˜ao sendosuﬁcientemente sobrepujados pela pouca melhoria de balanceamento oferecida.
4.4
A estrat´egia de paraleliza¸c˜ao com MPINas se¸c˜oes anteriores j´a foi poss´ıvel observar ganhos signiﬁcativos nodesempenho do simulador com a estret´egia de paraleliza¸c˜ao desenvolvida comuso do padr˜ao OpenMP. Como visto no cap´ıtulo 2, o padr˜ao OpenMP ´evoltado aos sistemas de mem´oria compartilhada, sendo aplicado frequentemente naparaleliza¸c˜ao de aplica¸c˜oes executadas em ambientes com CPUs multicore como osexistentes em cada um dos n´os do cluster Altix-xe, descrito mais adiante e utilizadoem testes com MPI neste trabalho.
A aplica¸c˜ao de uma estrat´egia utilizando a padr˜ao MPI, permitiria a104utiliza¸c˜ao de v´arios n´os do cluster, uma vez que tal padr˜ao ´e destinado a sistemasde mem´oria distribu´ıda. Com objetivo de expandir os resultados obtidos comOpenMP em um ´unica m´aquina, ou n´o, foi desenvolvida, com uso do MPI, umasegunda estrat´egia de paraleliza¸c˜ao para funcionar em conjunto com a primeira.
Para a implementa¸c˜ao da estrat´egia com MPI, nos concentramos novamentena rotina resolverProbVariosBlocos, j´a mostrada na se¸c˜ao 4.2 em suasvers˜oes serial (listagem 4.2) e com OpenMP (listagem 4.5) A seguir apresentaremospor partes, em trˆes trechos de c´odigo as altera¸c˜oes feitas na rotina para a inclus˜aoda paraleliza¸c˜ao com MPI.
Primeiramente, na listagem 4.6 observamos uma s´erie novas vari´aveis, apartir da linha 7, a serem usadas neste e nos pr´oximos dois trechos mostrados.
Destacamos as vari´aveis numProcs e meuId, na linha 8, que servir˜ao paraarmazenar, respectivamente, o tamanho do comunicador MPI (quantos processosestar˜ao executando em paralelo) e a identiﬁca¸c˜ao de cada processo. A essas duasvari´aveis s˜ao atribu´ıdos valores com uso de duas rotinas do MPI: MPI_Comm_sizee MPI_Comm_rank, cujas chamadas podem ser vistas nas linhas 13 e 14.
Listagem 4.6: Vers˜ao da rotina resolverProbVariosBlocos paralelizada comOpenMP+MPI.
1 SUBROUTINE resolverProbVariosBlocos(...)
USE mpi2implicit none3INTEGER :: numBlocos, NUSTEP4REAL*8 :: fluxoMassicoDeBlocoParaFratura(numBlocos), fluxoMolM2S5, DTINTEGER :: iBlocos6INTEGER :: error7INTEGER :: numProcs, meuId8INTEGER :: meuComeco, meuFim, meuTamanho, resto, parteInteira9INTEGER :: tamanho, cont !Tamanho do comunicador MPI10REAL*8 :: receiveBuffer(numBlocos)ALLOCATABLE :: sendArray(:)REAL*8,1112105call MPI_Comm_size (mpi_comm_world, numProcs, error )13call MPI_Comm_rank (mpi_comm_world, meuId, error )14(...)
1516 END SUBROUTINE resolverProbVariosBlocosA id´eia b´asica da paraleliza¸c˜ao com MPI, que ir´a conviver com aquilo quefoi feito com OpenMP, ´e ilustrada na ﬁgura 4.21 e consiste em dividir inicialmentea fratura em um n´umero N de partes de tamanho igual e destinar, a cada n´o deexecu¸c˜ao, todos os problemas do bloco relacionados a uma por¸c˜ao da fratura.
Cada processo MPI, tratar´a, portanto, de resolver um n´umero predeﬁnido deproblemas do bloco, relativos `a sua parcela da fratura.
Isso assemelha-se aoque era feito automaticamente pelo padr˜ao OpenMP na paraleliza¸c˜ao no loopem quest˜ao com escalonamento est´atico. Internamente, cada processo continuar´autilizando o paralelismo multithread com OpenMP para resolver o seu subconjuntode problemas, visto que cada n´o ´e dotado de CPUs multicore.
Figura 4.21: A estrat´egia de paraleliza¸c˜ao em processos com MPI.
Mais adiante no c´odigo da fun¸c˜ao resolverProbVariosBlocos, ap´oso trecho exibido na listagem 4.6, existe o loop que resolve os v´arios problemas106do bloco. Esta parte ´e mostrada na listagem 4.7. Chamamos aten¸c˜ao paraa linha 14, onde percebe-se que cada processo s´o realizar´a uma parte do looporiginal, resolvendo apenas uma parcela dos problemas do bloco, como ilustradona ﬁgura 4.21 e portanto, atribuindo valores a apenas uma parte do vetorfluxoMassicoDeBlocoParaFratura na linha 16.
Listagem 4.7: Vers˜ao da rotina resolverProbVariosBlocos paralelizada comOpenMP+MPI.
1 SUBROUTINE resolverProbVariosBlocos(..)
(...)
2resto = MOD(numBlocos, numProcs)3parteInteira=(numBlocos / numProcs)4meuComeco = parteInteira * meuId + 1;5if (resto .gt. meuId) then6meuComeco = meuComeco + meuId7meuFim = meuComeco + parteInteira8else9meuComeco = meuComeco + resto10meuFim = meuComeco + parteInteira - 111endif12!$omp parallel do firstprivate(NUSTEP, TEMPO, fluxoMolM2S,13condContorno, DT)DO iBlocos=meuComeco, meuFim14CALL processadorBloco(iBlocos, NUSTEP, TEMPO, fluxoMolM2S15, condContorno(iBlocos), DT)fluxoMassicoDeBlocoParaFratura(iBlocos) = fluxoMolM2S;16END DO! fim do loop do problema micro (blocos)17!$omp end parallel do18(...)
1920 END SUBROUTINE resolverProbVariosBlocosFinalmente, ap´os o trecho apresentado na listagem 4.7 cada processo possuiapenas uma parte do vetor fluxoMassicoDeBlocoParaFratura devidamentecalculada. ´E necess´ario que, nesse momento, exista uma comunica¸c˜ao entre osprocessos para que cada um possa enviar aos demais a sua parcela do vetor. Para107isso, ´e feito uso de mais uma rotina do MPI: MPI_AllGather, cuja chamada podeser vista na listagem 4.8, linha 9. Ao ﬁm da rotina, todos os processos possuem ovetor fluxoMassicoDeBlocoParaFratura completo, com a contribui¸c˜ao dosdemais.
Listagem 4.8: Vers˜ao da rotina resolverProbVariosBlocos paralelizada comOpenMP+MPI1 SUBROUTINE resolverProbVariosBlocos (...)
(...)
2!Comunicação entre os processos:3meuTamanho = (meuFim - meuComeco) + 14if (.not. ALLOCATED(sendArray)) then5allocate(sendArray(meuTamanho))6endif7sendArray(1:meuTamanho) = fluxoMassicoDeBlocoParaFratura(8meuComeco:meufim)call MPI_AllGather(sendArray, meuTamanho, MPI_REAL8,9receiveBuffer,meuTamanho, MPI_REAL8, MPI_COMM_WORLD, error)fluxoMassicoDeBlocoParaFratura(1:numBlocos) = receiveBuffer(1:10numBlocos)11 END SUBROUTINE resolverProbVariosBlocos4.5
Testes de desempenho II: Paraleliza¸c˜ao com OpenMP + MPINesta se¸c˜ao abordamos os testes de desempenho feitos com a segundaestrat´egia de paraleliza¸c˜ao desenvolvida, utilizando OpenMP e MPI em conjunto.
Os casos de teste s˜ao os mesmos experimentos (A) e (B) utilizados para os testescom OpenMP e descritos na se¸c˜ao 4.3.
4.5.1
Ambiente de Execu¸c˜ao e Metodologia dos testesTodos os testes realizados para a paraleliza¸c˜ao com OpenMP+MPI foramexecutados no cluster Altix-xe, do LNCC. O cluster ´e composto por 30 n´os de108execu¸c˜ao, cada um com a seguinte especiﬁca¸c˜ao:• Modelo Altix-XE 340• 2 Processadores Quad Core Intel(R) Xeon(R) CPU E5520 @ 2.27GHz(Total de 8 cores)• 24GB de mem´oria DDR3O compilador utilizado foi o gfortran vers˜ao 4.7.2. A implementa¸c˜ao do MPIutilizada foi o OpenMPI 1.8.5 e a metodologia de testes utilizada foi a mesma dase¸c˜ao 4.3.
Para os testes com MPI, foram submetidos jobs ao gerenciador de ﬁlas SunGrid Engine (SGE) e a aplica¸c˜ao foi testada em uma ﬁla que d´a acesso a 8 n´os comconﬁgura¸c˜ao descrita anteriormente. Por esta raz˜ao, os testes foram feitos com om´aximo de 8 processos, cada um utilizando 8 threads OpenMP internamente aon´o.
4.5.2
Resultados do experimento (A) com OpenMP+MPINesta se¸c˜ao apresentamos os resultados das tomadas de tempo com a vers˜aoparalelizada via OpenMP e MPI, para o experimento (A). A tabela 4.4 exibe, naparte esquerda, os tempos totais de execu¸c˜ao da aplica¸c˜ao (em minutos) para1, 3, 4, 6 e 8 threads (somente OpenMP) e, na parte direita, os tempos deexecu¸c˜ao utilizando a vers˜ao h´ıbrida (OpenMP e MPI), sempre com 8 threads,por´em variando o n´umero de processos. Para cada caso, a aplica¸c˜ao foi executada6 vezes. Na linha em destaque na tabelaa s˜ao apresentadas as m´edias dos temposde execu¸c˜ao. A ´ultima linha apresenta o speedup obtido em cada caso.
109Tabela 4.4: Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP+MPI parao experimento (A).
(P) Processos MPI(T) Threads OpenMP(T) Threads OpenMP2T3.50
3.47
3.37
3.52
3.43
3.43
3.45
1T6.40
6.42
6.43
6.28
6.28
6.03
6.31
1.00x 1.83x 3.38x 4.87x 6.07x 6.04x
1P 8T 2P 8T 4P 8T 8P 8T1.03
1.05
1.05
1.03
1.05
1.05
1.04
4T1.85
1.88
1.88
1.88
1.83
1.87
1.87
6T1.32
1.30
1.28
1.32
1.28
1.27
1.29
8T1.02
1.05
1.03
1.05
1.05
1.03
1.04
Execu¸c˜ao #1Execu¸c˜ao #2Execu¸c˜ao #3Execu¸c˜ao #4Execu¸c˜ao #5Execu¸c˜ao #6M´edia (minutos)SpeedUp Obtido0.30
0.30
0.30
0.30
0.30
0.30
0.30
21.03x 30.69x
0.62
0.65
0.65
0.65
0.65
0.63
0.64
9.83x
0.20
0.23
0.20
0.20
0.20
0.20
0.21
O gr´aﬁco da ﬁgura 4.22 mostra as m´edias dos tempos de execu¸c˜ao destacadasna tabela 4.4.
Figura 4.22: M´edias dos tempos de execu¸c˜ao (em minutos) da vers˜ao comOpenMP+MPI para o experimento (A).
Na ﬁgura 4.23 ´e mostrado o gr´aﬁco de speedups.
S˜ao exibidos, paravisualiza¸c˜ao comparativa, os speedups obtidos com a vers˜ao que inclui somenteOpenMP (em verde), aos quais juntam-se os speedups da vers˜ao h´ıbrida (em azul),ambos em compara¸c˜ao ao caso ideal, speedup linear, (em vermelho).
110Figura 4.23: Speedups da vers˜ao com OpenMP+MPI para o experimento (A).
4.5.3
Resultados do experimento (B) com OpenMP+MPIOs testes realizados para os experimento (A) foram repetidos para oexperimento (B), com malha uniforme de 2200 elementos na fratura. A seguirs˜ao exibidos: a tabela de tempos obtidos, o gr´aﬁco com as m´edias de tempo e ogr´aﬁco de speedup, os mesmos exibidos anteriormente para o experimento (A).
Tabela 4.5: Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP+MPI parao experimento (B).
(P) Processos MPI(T) Threads OpenMP(T) Threads OpenMP1T2T4T1P 8T 2P 8T 4P 8T 8P 8T5.77
5.77
5.68
5.78
5.75
5.75
5.75
6T7.10
7.43
7.27
7.23
7.02
7.25
7.22
8T5.68
5.68
5.77
5.80
5.75
5.70
5.73
Execu¸c˜ao #1Execu¸c˜ao #2Execu¸c˜ao #3Execu¸c˜ao #4Execu¸c˜ao #5Execu¸c˜ao #6M´edia (minutos)SpeedUp Obtido19.28
19.65
19.62
19.68
19.25
19.10
19.43
37.67
36.93
36.48
37.22
37.70
37.18
37.20
1.00x 1.91x 3.74x 5.15x 6.49x 6.47x
10.07
9.92
9.95
9.75
10.20
9.87
9.96
2.95
2.95
2.93
2.93
2.95
2.97
2.95
12.62x 20.20x 37.62x
1.90
1.75
1.82
1.87
1.85
1.87
1.84
1.00
1.02
1.00
1.02
0.98
0.92
0.99
111Figura 4.24: M´edias dos tempos de execu¸c˜ao (em minutos) da vers˜ao comOpenMP+MPI para o experimento (B).
Figura 4.25: Speedups da vers˜ao com OpenMP+MPI para o experimento (B).
4.5.4
Discuss˜ao dos resultados com MPIQuanto `a estrat´egia de paraleliza¸c˜ao h´ıbrida com OpenMP e MPI, obtivemosresultados de speedup de at´e 30,69x para o experimento (A) e 37,62x para oexperimento (B). Embora tais n´umeros estejam mais distantes do speedup linear,consideramos esta uma boa aproxima¸c˜ao inicial para uma paraleliza¸c˜ao do modeloem m´aquinas de mem´oria distribu´ıda que ainda pode ser aperfei¸coada. Sem aparaleliza¸c˜ao com MPI, estar´ıamos limitados a apenas um n´o de execu¸c˜ao.
112Os problemas quanto ao balanceamento de carga vistos para o OpenMPtamb´em ocorrem na paraleliza¸c˜ao com MPI, neste caso com um agravante: adivis˜ao inicial da fratura em por¸c˜oes de tamanho pr´e-deﬁnido foi a ideia centralda estrat´egia de paraleliza¸c˜ao para a divis˜ao de trabalho, o que se assemelha aoescalonamento est´atico do OpenMP. Espera-se que o desbalanceamento n˜ao possaser corrigido com a mesma facilidade encontrada no caso do OpenMP, que oferecemais ﬂexibilidade nesse sentido, com pouca altera¸c˜ao de c´odigo, por meio do usoda cl´ausula schedule.
O balanceamento de carga com MPI dever´a envolver t´ecnicas desenvolvidaspelo programador a ﬁm de que se divida os problemas do bloco entre os processosde forma mais adequada. Uma solu¸c˜ao paralela mais avan¸cada com MPI dever´adividir o espa¸co de itera¸c˜oes do loop mostrado na listagem 4.7 entre os processosde forma mais elaborada do que aquela mostrada na ﬁgura 4.21.
Um ponto de melhoria aqui identiﬁcado ´e a utiliza¸c˜ao de uma alternativa`a rotina MPI_AllGather,cuja chamada foi mostrada na listagem 4.8.
A rotina promovecomunica¸c˜oes desnecess´ariasentretodos os processospara que cada um envie a todos os demais a sua parcela do vetorfluxoMassicoDeBlocoParaFratura. ´E necess´ario que apenas um processocontenha o vetor completo para que prossiga com a execu¸c˜ao do programa. A
economia de comunica¸c˜oes entre os processos poder´a beneﬁciar consider´avelmenteo desempenho geral da aplica¸c˜ao.
113Cap´ıtulo 5Conclus˜oes e perspectivasNesta disserta¸c˜ao descrevemos um trabalho centrado em aspectoscomputacionais, realizado com um simulador relacionado `a ciˆencia de escoamentosem meios porosos. Baseado em uma implementa¸c˜ao original da d´ecada de 1980que se destacou em sua ´epoca como um poderoso programa de elementos ﬁnitos,o simulador pode, atualmente, beneﬁciar-se de algumas t´ecnicas de programa¸c˜aomais modernas. Este trabalho representou um passo evolutivo deste simulador quese manifestou de duas formas: (i) o emprego da programa¸c˜ao orientada a objetosem um de seus m´odulos e (ii) o desenvolvimento de estrat´egias de computa¸c˜aoparalela para reduzir o seu tempo de execu¸c˜ao.
Quanto ao primeiro aspecto, desenvolvemos uma reformula¸c˜ao do m´odulode sistemas de equa¸c˜oes deste simulador, conferindo ao mesmo caracter´ısticas maismodernas com a inclus˜ao do paradigma de orienta¸c˜ao a objetos, visando contribuirpara sua melhor organiza¸c˜ao, entendimento humano e capacidade de evolu¸c˜ao. Os
novos m´odulos com classes facilitam e encorajam a troca ou incorpora¸c˜ao de novossolvers neste ou em outros simuladores semelhantes. Al´em disso, a reformula¸c˜aofuncionou como facilitadora para o desenvolvimento de estrat´egias de paraleliza¸c˜aopara este simulador.
Quanto ao desempenho de execu¸c˜ao, desenvolvemos estrat´egias com ospadr˜oes OpenMP e MPI para a solu¸c˜ao em paralelo de m´ultiplos problemas deelementos ﬁnitos. A refatora¸c˜ao do m´odulo referente aos sistemas de equa¸c˜oes,114descrita no cap´ıtulo 3, facilitou essa tarefa. A inclus˜ao do paradigma de orienta¸c˜aoa objetos tornou mais natural a tarefa de criar m´ultiplas instˆancias em mem´oriade uma mesma entidade denominada sistema de equa¸c˜oes, para sua solu¸c˜ao emparalelo.
Nesse momento foi poss´ıvel observar como a escalabilidade do designpˆode contribuir para a escalabilidade de execu¸c˜ao. A organiza¸c˜ao est´atica doc´odigo-fonte de forma modular, a qual promoveu o agrupamento de elementosrelacionados, o encapsulamento e as abstra¸c˜oes, acabou, tamb´em, por contribuirpara a facilita¸c˜ao do desenvolvimento de solu¸c˜oes paralelas, que melhoraram odesempenho do simulador.
Beneﬁciando-se dos resultados obtidos neste trabalho, s˜ao algumas asperspectivas de trabalhos futuros.
Em primeiro lugar, ´e importante reconhecer que, embora os novos m´oduloscom orienta¸c˜ao objetos tenham trazido benef´ıcios ao simulador, contribuindopara sua melhor organiza¸c˜ao e capacidade de evolu¸c˜ao, estes s˜ao resultado deuma interven¸c˜ao localizada, restrita ao m´odulo de sistemas de equa¸c˜oes. Assim,ressaltamos que o simulador n˜ao apresenta, neste momento, caracter´ısticas deum produto ﬁnal desenvolvido com orienta¸c˜ao a objetos e n˜ao explora todos osrecursos deste paradigma, como, por exemplo, a prote¸c˜ao de dados. Dessa forma, aexpans˜ao do emprego da orienta¸c˜ao a objetos para outros m´odulos deste simulador,bem como a maior e mais profunda explora¸c˜ao dos recursos oferecidos por talparadigma, surgem como perspectivas para a continua¸c˜ao dos trabalhos.
Quanto `as estrat´egias de paraleliza¸c˜ao, especialmente `aquela desenvolvidacom o padr˜ao MPI, pode-se dizer que a continua¸c˜ao dos trabalhos envolve ciclosde otimiza¸c˜ao que podem melhorar o desempenho obtido at´e o presente momento.
Ainda que os testes de desempenho aqui realizados tenham utilizado o solverbaseado em elimina¸c˜ao de Gauss, mais adequado ao nosso modelo em espec´ıﬁco,a solu¸c˜ao paralela desenvolvida ´e independente de solver. Isso signiﬁca que, emoutras situa¸c˜oes, nas quais o uso de um solver mais robusto como o Intel Pardiso115se fa¸ca necess´ario, como, por exemplo, simula¸c˜oes com malhas bidimensionais outridimensionais, a mesma estrat´egia de paraleliza¸c˜ao poder´a ser utilizada, aindaque sejam demandados, provavelmente, esfor¸cos de otimiza¸c˜ao.
Tamb´em merece lembran¸ca o fato de que a refatora¸c˜ao do m´odulo de sistemasde equa¸c˜oes com inclus˜ao de orienta¸c˜ao a objetos possui potencial de re´uso emoutros simuladores similares que utilizam a mesma implementa¸c˜ao base do MEF.
Portanto, estender os benef´ıcios das classes a outros programas tamb´em ´e umaperspectiva de trabalho e pode representar novas possibilidades para os mesmos.
Alguns simuladores utilizados no LNCC contam apenas com uma op¸c˜ao de solver.
A inclus˜ao dos novos m´odulos com classes poder´a oferecer, com certa facilidade,nova op¸c˜oes em tal quesito.
116Referˆencias Bibliogr´aﬁcasK.J. Bathe. Finite Element Procedures in Engineering Analysis. Prentice-Hall, 1982.
Stephen J. Chapman. Fortran 95/2003 for Scientists and Engineers.
McGraw-Hill, 3 edi¸c˜ao, 2004.
Patr´ıcia A. Pereira Costa. Modelagem Computacional Multiescala deReservat´orios n˜ao Convencionais de G´as em Folhelhos. Tese deDoutorado, LNCC, 2015.
Thomas J. R. Hughes. The ﬁnite element method :linear static anddynamic ﬁnite element analysis. Englewood Cliﬀs, N.J. Prentice-HallInternational, 1 edi¸c˜ao, 1987.
James Jeﬀers e James Reinders.
Intel Xeon Phi Coprocessor High-Performance Programming. Morgan Kaufmann, 1 edi¸c˜ao, 2013.
ISBN9780124104143.
David Kirk e Wen-Mei. Hwu. Programming Massively Parallel Processors:A Hands-on Approach. Morgan-Kaufmann, 2013.
T. G. Mattson, B. A. SANDERS, e B. L. MASSINGILL. Patterns for ParallelProgramming. Addison Wesley, 2004. ISBN 0321228111.
Peter S. Pacheco. An Introduction to Parallel Programming. MorganKaumann, 2011.
117Moreira, Rafael Nardes M837p Programação modular e computação de alto desempenho em um simulador de reservatórios não convencionais de gás em folhelhos / Rafael Nardes Moreira -- Petrópolis, RJ. : Laboratório Nacional de Computação Científica, 2016. 
xv, 117 p. : il. ; 29 cm. 
Orientadores:  Eduardo Lúcio Mendes Garcia e Sandra Mara Cardoso Malta. 
Dissertação (Mestrado) – Laboratório Nacional de Computação Científica, 2016. 
1. Programação modular 2. Programação orientada a objetos 3.Simulação dereservatórios 4. Gás de folhelhos  I. Garcia, Eduardo Lúcio Mendes II. Malta, Sandra Mara Cardoso III. MCT/LNCC; IV.Título CDD – 005.112 “Ladies and gentlemen, we have detectedgravitational waves. We did it!”
(David Reitze, Caltech physicist and LIGOlab director.)
“Until this moment, we had our eyes on thesky and we couldn’t hear the music. Theskies will never be the same.”
(Szabolcs Marka, Columbia Universityastrophysicist.)
ivDedicat´oriaDedico este trabalho a meus pais, Fernandoe Maria Helena.
vAgradecimentos`A minha fam´ılia e namorada, por oferecem a mim o todo incentivo ecompreens˜ao que se pudesse deles esperar.
Ao meu orientador, Bidu, pelo incentivo ao trabalho, disponibilidade eproximidade durante o ´ultimo ano.
`A minha coorientadora, Sandra Malta, pelo acompanhamento e opini˜oes emnossas reuni˜oes peri´odicas.
`A professora Carla Osthoﬀ, pelo acompanhamento do trabalho e pelointeresse em colaborar, sugerindo ferramentas de software e bibliograﬁa, muito´uteis ao trabalho.
`A colega Patr´ıcia Costa, pela paciˆencia em responder perguntas e, a cadauma delas, colocar-se a disposi¸c˜ao para a pr´oxima.
Ao professor Roberto Souto, pela disponibilidade sempre que solicitado epela prontid˜ao ao disponibilizar uma m´aquina para experimentos quanto isso defez necess´ario.
Aos demais professores do programa de p´os-gradua¸c˜ao do LNCC com osquais interagi e aprendi durante os dois ´ultimos anos.
`A ANP - Agencia Nacional do Petr´oleo, G´as Natural e Biocombust´ıveis peloapoio ﬁnanceiro.
viResumo da Disserta¸c˜ao apresentada ao LNCC/MCT como parte dos requisitosnecess´arios para a obten¸c˜ao do grau de Mestre em Ciˆencias (M.Sc.)
PROGRAMA ¸C ˜AO MODULAR E COMPUTA ¸C ˜AO DE ALTODESEMPENHO EM UM SIMULADOR DE RESERVAT ´ORIOS N ˜AOCONVENCIONAIS DE G ´AS EM FOLHELHOSRafael Nardes MoreiraMar¸co , 2016Orientador: Eduardo L´ucio Mendes Garcia, D.Sc
Co-orientador: Sandra Mara Cardoso Malta, D.Sc.
A modelagem computacional de reservat´orios ´e o instrumento que permitea descri¸c˜ao precisa dos fenˆomenos f´ısicos existentes no processo de recupera¸c˜ao de´oleo e g´as, tendo grande interesse tanto para a ind´ustria quanto para a ciˆencia.
Na ind´ustria de ´oleo e g´as, ´e grande a demanda por simuladores comerciais dereservat´orios. Por outro lado, simuladores cient´ıﬁcos s˜ao capazes de ofereceraos pesquisadores do dom´ınio, o controle e a liberdade necess´arios `a atividadeacadˆemica.
Dentre as principais demandas do software cient´ıﬁco em geral est˜ao (i) odesign escal´avel, relacionado ao desenvolvimento de c´odigo de maneira organizadae modular, contribuindo para sua evolu¸c˜ao e (ii) a execu¸c˜ao escal´avel, relacionada`a implementa¸c˜ao de t´ecnicas de computa¸c˜ao paralela e de alto desempenho,em raz˜ao das grandes massas de dados manipuladas e dos modelos num´ericoscomputacionalmente intensivos produzidos pela ciˆencia.
Este trabalho trata do emprego de t´ecnicas de programa¸c˜ao modular comorienta¸c˜ao a objetos e de computa¸c˜ao paralela com OpenMP e MPI em umsimulador cient´ıﬁco, escrito em Fortran e utilizado na modelagem num´erica deproblemas de escoamento em reservat´orios n˜ao convencionais de g´as em folhelhos.
viiAbstract of Dissertation presented to LNCC/MCT as a partial fulﬁllment of therequirements for the degree of Master of Sciences (M.Sc.)
MODULAR PROGRAMMING AND HIGH PERFORMANCECOMPUTING IN A GAS SHALE RESERVOIR SIMULATORRafael Nardes MoreiraMarch, 2016Advisor: Eduardo L´ucio Mendes Garcia, D.Sc
Co-advisor: Sandra Mara Cardoso Malta, D.Sc.
Computer modeling of reservoirs is the tool that provides the accuratedescription of the existing physical phenomena in the oil and gas recovery process,being of interest to both the industry and science. In oil and gas industry, thedemand of commercial simulators is remarkable. At the same time, scientiﬁcsimulators are able to provide researchers with the freedom and control neededby the academic activity.
Among the major demands of scientiﬁc software are: (i) the scalable design,which is correlated with organized and modular code development, and (ii) thescalable execution, related to the implementation of techniques for parallel andhigh performance computing, due to the large amount of manipulated data andthe compute-intensive numerical models produced by science.
This dissertation aims to the application of techniques for modular object-oriented programming and parallel computing, with OpenMP and MPI, in ascientiﬁc simulator, developed in Fortran and used in the numerical modeling ofproblems related to gas ﬂow on unconventional gas-shale reservoirs.
viiiSum´ario1 Introdu¸c˜ao11.1 O simula¸c˜ao de reservat´orios no LNCC . . . . . . . . . . . . . . . .
31.2 O modelo 2 escalas: Fratura e Bloco . . . . . . . . . . . . . . . . .
41.3 Programa¸c˜ao Modular com Orienta¸c˜ao a Objetos. . . . . . . . . .
71.4 Computa¸c˜ao paralela para desempenho do simulador. . . . . . . .
81.5 Organiza¸c˜ao da disserta¸c˜ao . . . . . . . . . . . . . . . . . . . . . . .
92 Demandas da evolu¸c˜ao do software cient´ıﬁco112.1 Programa¸c˜ao Modular. . . . . . . . . . . . . . . . . . . . . . . . .
132.1.1 Princ´ıpios da Programa¸c˜ao Modular. . . . . . . . . . . . .
152.1.2 Abstra¸c˜oes . . . . . . . . . . . . . . . . . . . . . . . . . . . .
172.1.3
Justiﬁcativas, vantagens e desvantagens da programa¸c˜aomodular . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
212.1.4 T´ecnicas de modulariza¸c˜ao . . . . . . . . . . . . . . . . . . .
252.1.5 Programa¸c˜ao Orientada a Objetos . . . . . . . . . . . . . . .
322.2 Computa¸c˜ao Paralela . . . . . . . . . . . . . . . . . . . . . . . . . .
372.2.1 Arquiteturas Paralelas . . . . . . . . . . . . . . . . . . . . .
382.2.2 Mem´oria compartilhada . . . . . . . . . . . . . . . . . . . .
412.2.3 Mem´oria Distribu´ıda . . . . . . . . . . . . . . . . . . . . . .
422.2.4 Ambientes de Computa¸c˜ao Paralela . . . . . . . . . . . . . .
433 Refatora¸c˜ao de um m´odulo do simulador com inclus˜ao do paradigmaixorientado a objetos483.1 Evolu¸c˜ao do simulador de escoamentos em meios porosos . . . . . .
493.2 Organiza¸c˜ao do simulador em arquivos para compila¸c˜ao separada .
573.3 Orienta¸c˜ao a Objetos no M´odulo dos Sistemas de Equa¸c˜oes . . . . .
603.3.1
Identiﬁca¸c˜ao das Entidades de Interesse . . . . . . . . . . . .
603.3.2
Introduzindo os Atributos e M´etodos das Classes. . . . . .
633.3.3
Implementa¸c˜ao de Orienta¸c˜ao a Objetos em Fortran: Heran¸ca 663.3.4
Implementa¸c˜ao do Polimorﬁsmo em Fortran: . . . . . . . . .
683.3.5 A nova organiza¸c˜ao do simulador com os novos m´oduloscontendo classes . . . . . . . . . . . . . . . . . . . . . . . . .
704 Paraleliza¸c˜ao do simulador 2 escalas de Shale Gas784.1 An´alise inicial do perﬁl serial de desempenho da aplica¸c˜ao com intelVTUNE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
784.2 A estrat´egia de paraleliza¸c˜ao com OpenMP . . . . . . . . . . . . . .
844.3 Testes de desempenho I: Paraleliza¸c˜ao com OpenMP . . . . . . . .
924.3.1 Ambiente de Execu¸c˜ao e Metodologia dos testes . . . . . . .
954.3.2 Resultados do experimento (A) com OpenMP . . . . . . . .
964.3.3 Resultados do experimento (B) com OpenMP . . . . . . . .
974.3.4 Discuss˜ao dos resultados e otimiza¸c˜ao com OpenMP . . . . .
984.4 A estrat´egia de paraleliza¸c˜ao com MPI. . . . . . . . . . . . . . . . 1044.5 Testes de desempenho II: Paraleliza¸c˜ao com OpenMP + MPI . . . . 1084.5.1 Ambiente de Execu¸c˜ao e Metodologia dos testes . . . . . . . 1084.5.2 Resultados do experimento (A) com OpenMP+MPI . . . . . 1094.5.3 Resultados do experimento (B) com OpenMP+MPI . . . . . 1114.5.4 Discuss˜ao dos resultados com MPI. . . . . . . . . . . . . . 1125 Conclus˜oes e perspectivas114Referˆencias Bibliogr´aﬁcas117xLista de FigurasFigura1.1 Geometria realista de um reservat´orio de g´as em folhelhos.
. . . . .
51.2 Geometria idealizada de um reservat´orio de g´as em folhelhos. . . . .
61.3 Modelo Fratura/Bloco . . . . . . . . . . . . . . . . . . . . . . . . .
72.1 A arquitetura SISD . . . . . . . . . . . . . . . . . . . . . . . . . . .
392.2 A arquitetura SIMD . . . . . . . . . . . . . . . . . . . . . . . . . .
402.3 A arquitetura MIMD . . . . . . . . . . . . . . . . . . . . . . . . . .
413.1 Vetor est´atico ´unico comportando m´ultiplos vetores menores dediferentes tamanhos deﬁnidos em tempo de execu¸c˜ao.
. . . . . . . .
503.2 Organiza¸c˜ao em 3 n´ıveis dos m´ultiplos arquivos de fonte. . . . . .
573.3 A organiza¸c˜ao do simulador em arquivos-fonte . . . . . . . . . . . .
593.4 A estrutura b´asica de classes: Sistemas e Estruturas de Dados . . .
633.5 A estrutura de classes de Sistemas de Equacoes com maiores detalhes. 64
3.6 A estrutura de classes de Estruturas de Dados com maiores detalhes. 65
3.7 Organiza¸c˜ao do simulador com os novos m´odulos fonte.
. . . . . . .
704.1 Percentual do tempo total de execu¸c˜ao por rotina com solver Gauss804.2 Percentual do tempo total de execu¸c˜ao por rotina com solver intelPardiso . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
804.3 Tempo total de execu¸c˜ao do caso experimental com solver Gauss . .
824.4 Tempo total de execu¸c˜ao do caso experimental com solver intel Pardiso 824.5 An´alise da rotina processadorBloco com solver Gauss . . . . .
83xi4.6 An´alise da rotina processadorBloco com solver Pardiso . . . .
834.7 An´alise de condi¸c˜oes de corrida feita com a ferramente Intel Inspector. 91
4.8 A organiza¸c˜ao de objetos de sistemas e estruturas de dados na vers˜aoparalelizada com OpenMP . . . . . . . . . . . . . . . . . . . . . . .
924.9 Perﬁs de press˜ao ao longo da fratura (30,5 metros) para: 1 mˆes, 6meses, 1, 5, 10, 20 e 30 anos. . . . . . . . . . . . . . . . . . . . . . .
954.10 Produ¸c˜ao acumulada em Kg . . . . . . . . . . . . . . . . . . . . . .
954.11 Speedups da vers˜ao com OpenMP para o experimento (A).
. . . . .
974.12 Speedups da vers˜ao com OpenMP para o experimento (B).
. . . . .
984.13 Tempos de execu¸c˜ao por cada problema do bloco para o experimento(A).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
994.14 Tempos de execu¸c˜ao por cada problema do bloco para o experimento(B).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99cl´ausula schedule(dynamic) para4.15 Speedupscom aoexperimento (A).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 101cl´ausula schedule(dynamic) para4.16 Speedupscom aoexperimento (B).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 1014.17 Tempos de execu¸c˜ao por cada problema do bloco (Fratura com 400elementos e malhas de 600 elementos no bloco) . . . . . . . . . . . . 1024.18 Inclina¸c˜oes das linhas de tendˆencia das ﬁguras 4.13 e 4.17 em fun¸c˜aodo tamanho das malhas do bloco.
. . . . . . . . . . . . . . . . . . . 102cl´ausula schedule(dynamic) para4.19 Speedupscom aoexperimento (A) com malhas do bloco aumentadas para 600elementos.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103cl´ausula schedule(dynamic) para4.20 Speedupscom aoexperimento (B) com malhas do bloco aumentadas para 600elementos.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1034.21 A estrat´egia de paraleliza¸c˜ao em processos com MPI.
. . . . . . . . 106xii4.22 M´edias dos tempos de execu¸c˜ao (em minutos) da vers˜ao comOpenMP+MPI para o experimento (A).
. . . . . . . . . . . . . . . 1104.23 Speedups da vers˜ao com OpenMP+MPI para o experimento (A). . . 1114.24 M´edias dos tempos de execu¸c˜ao (em minutos) da vers˜ao comOpenMP+MPI para o experimento (B).
. . . . . . . . . . . . . . . 1124.25 Speedups da vers˜ao com OpenMP+MPI para o experimento (B). . . 112xiiiLista de TabelasTabela4.1 Parˆametros f´ısicos relativos ao campo realista utilizado nos testes.
Adaptado de [Costa (2015)]. . . . . . . . . . . . . . . . . . . . . .
934.2 Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP para oexperimento (A).
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
964.3 Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP para oexperimento (B).
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
974.4 Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP+MPIpara o experimento (A).
. . . . . . . . . . . . . . . . . . . . . . . . 1104.5 Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP+MPIpara o experimento (B).
. . . . . . . . . . . . . . . . . . . . . . . . 111xivLista de Siglas e Abreviaturas• TAD: Tipo Abstrato de Dados• MEF: M´etodo dos Elementos Finitos• UC: Unidade de Controle• ULA: Unidade L´ogico-Atitm´etica• CPU: Central Processing Unit• VPU: Vector Processing Unit• GPU: Graphics Processing UnitxvCap´ıtulo 1Introdu¸c˜aoReservat´orios n˜ao convencionais de g´as em folhelhos, em inglˆes, shale gasreservoirs, representam atualmente uma fonte de energia altamente relevante paramuitos pa´ıses. Nos EUA, por exemplo, tais reservas podem representar importantepapel na autossuﬁciˆencia energ´etica do pa´ıs, dentro de alguns anos. A grandequantidade de potenciais reservas deste tipo existentes, inclusive no Brasil, motiva ejustiﬁca os estudos na ´area, os quais se fazem ainda mais relevantes em decorrˆenciada necessidade do emprego de t´ecnicas de explora¸c˜ao espec´ıﬁcas, adequadas `ascaracter´ısticas peculiares de tais reservat´orios, como a baixa permeabilidade deforma¸c˜oes geol´ogicas e a existˆencia de m´ultiplos n´ıveis de porosidade.
A modelagem computacional dos reservat´orios ´e o instrumento que permitea descri¸c˜ao precisa dos fenˆomenos f´ısicos existentes no processo de recupera¸c˜ao dog´as, tendo interesse tanto para a ind´ustria, que busca a explora¸c˜ao eﬁciente, comopara a ciˆencia, assistindo o desenvolvimento de modelos f´ısicos e matem´aticos,capazes de relacionar grandezas envolvidas nas equa¸c˜oes que regem os fenˆomenosf´ısicos.
Na ind´ustria de ´oleo e g´as, ´e grande a demanda por simuladores comerciaiscomo por exemplo o CMG (Computer Modeling Group) ou ECLIPSE. Entretanto,simuladores cient´ıﬁcos tˆem caracter´ısticas e importˆancia pr´oprias. Simuladorescient´ıﬁcos oferecem a cientistas e pesquisadores do dom´ınio das aplica¸c˜oes,ﬂexibilidade e possibilidades de ajustes que atendem de forma mais adequada suas1demandas espec´ıﬁcas.
Muitas vezes,simuladores comerciaiss˜ao produtos completos e queenglobam uma grande quantidade de componentes, alguns dos quais podemn˜ao ser de interesse dos trabalhos acadˆemicos.
Simuladores cient´ıﬁcos, emcontraste, frequentemente permitem maior liberdade na realiza¸c˜ao de experimentosespec´ıﬁcos, permitindo maior controle e, inclusive, maior precis˜ao em determinadoscasos de interesse.
Este trabalho trata do emprego de t´ecnicas de programa¸c˜ao modular ede computa¸c˜ao de alto desempenho em um simulador cient´ıﬁco, baseado naimplementa¸c˜ao computacional do m´etodo de elementos ﬁnitos proposta em Hughes(1987) e utilizado na simula¸c˜ao num´erica de problemas de escoamento monof´asicode g´as em reservat´orios n˜ao convencionais em folhelhos, de acordo com os modelosf´ısico e matem´atico propostos em Costa (2015).
Dentre as motiva¸c˜oes para o desenvolvimento deste trabalho est˜ao:(i)A relativa carˆencia, no ˆambito do desenvolvimento de software cient´ıﬁco,principalmente quando comparado ao software comercial e corporativo, de certoscuidados, conhecimentos e pr´aticas que suportem o desenvolvimento ordenado,modular, e escal´avel de software e (ii) O fato de que o software cient´ıﬁco emgeral demanda t´ecnicas de computa¸c˜ao de alto desempenho, tanto por manipulargrandes massas de dados quanto por estar associado frequentemente a modelosnum´ericos computacionalmente intensivos.
Segundo Rouson et al. (2011), s˜ao caracter´ısticas desej´aveis em um softwarecient´ıﬁco o design escal´avel, obtido com desenvolvimento ordenado de c´odigo,programa¸c˜ao modular e conceitos de projeto software, e a execu¸c˜ao escal´avel,obtida com uso de t´ecnicas de computa¸c˜ao paralela e de alto desempenho. A
contribui¸c˜ao que se deseja oferecer neste trabalho engloba, portanto, dois aspectos:(i) A organiza¸c˜ao est´atica do c´odigo-fonte e (ii) A sua execu¸c˜ao.
Quanto ao primeiro aspecto, este trabalho compreende a reestrutura¸c˜ao deum dos m´odulos do simulador, aquele referente `a constru¸c˜ao e `a solu¸c˜ao dos2sistemas de equa¸c˜oes lineares referentes ao m´etodo de elementos ﬁnitos. Paraisso s˜ao desenvolvidos novos m´odulos incorporando o paradigma de programa¸c˜aoorientado a objetos para substituir o m´odulo original. Com a incorpora¸c˜aode conceitos de orienta¸c˜ao a objetos, pretende-se promover a facilita¸c˜ao doentendimento humano e da usabilidade das funcionalidades providas pelos novosm´odulos, principalmente por meio do encapsulamento de dados e opera¸c˜oes,promovendo a abstra¸c˜ao de detalhes.
J´a em rela¸c˜ao `a contribui¸c˜ao do trabalho no que se refere `a computa¸c˜ao dealto desempenho, s˜ao utilizados padr˜oes de programa¸c˜ao paralela para sistemascomputacionais baseados em mem´oria uniﬁcada e distribu´ıda, respectivamenteo OpenMP e o MPI, no desenvolvimento de estrat´egias de paraleliza¸c˜ao para omodelo adotado neste simulador.
1.1
O simula¸c˜ao de reservat´orios no LNCCPesquisadores da ´area de m´etodos num´ericos para equa¸c˜oes diferenciaisdo LNCC tˆem trabalhado desde 1988 com implementa¸c˜oes do M´etodo deElementos Finitos (MEF) baseadas no c´odigo apresentado em Hughes (1987).
Suas implementa¸c˜oes atendem a demandas em diferentes aplica¸c˜oes cient´ıﬁcas,todas tendo como ponto comum modelos matem´aticos que recaem sobre a solu¸c˜aonum´erica de equa¸c˜oes diferenciais.
Dentre as aplica¸c˜oes que utilizam o m´etodo de elementos ﬁnitos no LNCC,est˜ao as desenvolvidas pelo grupo de simula¸c˜oes computacionais de reservat´oriosde petr´oleo e g´as. O grupo tem desenvolvido ao longo do tempo simuladoresrelacionados `a ciˆencia de escoamentos e transportes em meios porosos, atendendoa demandas internas espec´ıﬁcas, seguindo um processo continuamente evolutivo,incorporando aos poucos fenˆomenos relacionados, por exemplo, `a hidrodinˆamica,ao transporte de solutos e a processos geomecˆanicos.
Apesar da alta demanda por simuladores na ind´ustria, o LNCC, enquantoinstitui¸c˜ao atuante na ´area da ciˆencia, desenvolve simuladores cient´ıﬁcos, que3tratam de fenˆomenos espec´ıﬁcos, sendo mais precisos para esses casos. Emborasejam caracterizados pela existˆencia de limita¸c˜oes, simuladores cient´ıﬁcos s˜ao comobancadas de um laborat´orio, que servem a um grupo e permitem experimentos commaior liberdade.
O simulador de reservat´orios n˜ao convencionais de shale gas desenvolvido eutilizado no LNCC n˜ao possui um projeto de longo prazo.
Isso signiﬁca que ogrupo n˜ao tem a cria¸c˜ao de um grande simulador como meta. Entretanto, novasfuncionalidades tˆem sido incorporadas ao simulador com o passar do tempo, dandoorigem a diferentes vers˜oes que s˜ao adaptadas para atender a diferentes demandas.
Embora as contribui¸c˜oes deste trabalho possam ser incorporadas emdiferentes vers˜oes deste ou de outros simuladores similares, baseados na mesmaimplementa¸c˜ao original do MEF e que compartilham o mesmo m´odulo parasolu¸c˜ao de sistemas de equa¸c˜oes, a vers˜ao do simulador utilizada neste trabalhocompreende a simula¸c˜ao num´erica de problemas de escoamento monof´asico do g´asnos reservat´orios n˜ao convencionais em folhelhos, nos blocos de rocha matriz e nasfraturas hidr´aulicas induzidas, de acordo com modelo proposto em Costa (2015),cujas linhas gerais s˜ao abordadas na se¸c˜ao 1.2.
1.2
O modelo 2 escalas: Fratura e BlocoA baixa permeabilidade das forma¸c˜oes geol´ogicas onde ocorre o shale gasimplica na necessidade da indu¸c˜ao de fraturas pelo processo de faturamentohidr´aulico para que seja constitu´ıdo um meio suﬁcientemente perme´avel por ondeo g´as possa ﬂuir mais facilmente. Modelos hidrodinˆamicos considerando dois n´ıveisde porosidade (microblocos e ﬁssuras induzidas) constituem a base do estado daarte da modelagem de reservat´orios de shale gas.
No interior das ﬁssuras provocadas pelo faturamento (ﬁssuras induzidas),pode-se modelar o escoamento do g´as por meio das equa¸c˜oes diferenciais queregem o escoamento monof´asico de ﬂuido compress´ıvel (g´as) em um meio s´olidor´ıgido, conforme modelo em Costa (2015). Os microblocos da rocha matriz atuam4armazenando g´as e funcionam, em tal modelo, como fontes de massa para oproblema de escoamento nas fraturas induzidas.
O simulador tomado como ponto de partida neste trabalho obedece `amodelagem f´ısica e matem´atica do dom´ınio desenvolvida em Costa (2015).
Em linhas gerais, os reservat´orios de g´as em folhelhos, caracterizados pelaperfura¸c˜ao horizontal, s˜ao tratados nesse modelo como uma sequˆencia de blocosde rocha matriz com fraturas induzidas peri´odicas,igualmente espa¸cadas, aolongo de toda a extens˜ao do po¸co horizontal. Idealmente, as fraturas devem serconsideradas entidades bidimensionais, enquanto os blocos devem ser consideradostridimensionais, conforme ilustrado na ﬁgura 1.1, na qual pode-se observar oescoamento radial do g´as da fratura em dire¸c˜ao ao po¸co.
Figura 1.1: Geometria realista de um reservat´orio de g´as em folhelhos.
Entretanto, o modelo de Costa (2015) possui simpliﬁca¸c˜oes, considerandoum alongamento da interface entre fratura e po¸co por toda a largura da fratura,eliminando a hip´otese de escoamento radial do g´as. Considera-se que o g´as ﬂui dafratura para o po¸co em apenas uma dire¸c˜ao. A nova conﬁgura¸c˜ao ´e mostrada naﬁgura 1.2.
5Figura 1.2: Geometria idealizada de um reservat´orio de g´as em folhelhos.
Desconsiderando o escoamento radial nas fraturas, o modelo utiliza, ainda,uma redu¸c˜ao de dimens˜ao que passa tratar fraturas como linhas e blocos comoplanos. Para a simula¸c˜ao num´erica do escoamento na fratura, o modelo adotauma malha unidimensional de elementos ﬁnitos, ao passo que, para o bloco,adotam-se m´ultiplas malhas unidimensionais, como esquematizado na ﬁgura 1.3.
Blocos atuam como fontes de massa para o problema das fraturas. Em umdado bloco, cada um dos v´arios problemas unidimensionais est´a relacionado aum ponto da malha unidimensional do problema da fratura. O modelo, portanto,caracteriza-se pela resolu¸c˜ao de um n´umero elevado de problemas de elementosﬁnitos independentes nos blocos, o que resulta em m´ultiplos sistemas linearesindependentes. Esta caracter´ıstica, como ser´a visto no cap´ıtulo 4, ´e diretamenterelacionada `as estrat´egias de paraleliza¸c˜ao desenvolvidas.
6Figura 1.3: Modelo Fratura/Bloco1.3
Programa¸c˜ao Modular com Orienta¸c˜ao a ObjetosA vers˜ao do simulador tomada como ponto de partida neste trabalho, ap´osevolu¸c˜oes incrementais nos ´ultimos anos, possui algum n´ıvel de modularidade.
O c´odigo-fonte est´a subdividido em m´odulos que agrupam funcionalidadessuﬁcientemente relacionadas. Apesar disso, neste trabalho desejamos promovermais um passo evolutivo quanto `a modularidade deste simulador cient´ıﬁco eeste avan¸co est´a relacionado com a reformula¸c˜ao que incorpora o paradigma deorienta¸c˜ao a objetos em um de seus m´odulos.
De acordo com Rouson et al. (2011), grande parte dos conceitos de projetode software que norteiam o desenvolvimento ordenado e eﬁciente de programasest´a relacionada ao paradigma de programa¸c˜ao orientado a objetos. A refatora¸c˜aodo m´odulo em quest˜ao envolve encapsulamento de sistemas de equa¸c˜oes, solverse estruturas de dados relacionadas aos sistemas com um arcabou¸co orientado aobjetos, oferecendo facilidades para a utiliza¸c˜ao de diferentes op¸c˜oes de solvers,os quais podem ser internos, completamente implementados dentro da aplica¸c˜ao7cient´ıﬁca cliente, ou externos, com uso de bibliotecas matem´aticas desenvolvidaspor terceiros e que incluem solvers. Est´e ´e o caso do Intel Pardiso, parte dabiblioteca Intel MKL.
A maior modularidade, especialmente por manifestar-se sob a forma doparadigma de orienta¸c˜ao a objetos, contribuir´a para melhor usabilidade e paraa capacidade de evolu¸c˜ao deste simulador. Conceitos centrais de orienta¸c˜ao aobjetos como encapsulamento de dados e opera¸c˜oes, heran¸ca e polimorﬁsmo ser˜aoexplorados para que o m´odulo original dˆe origem a outros menores, sob forma declasses, as quais se relacionam de forma tal que se possa promover a facilita¸c˜aodo entendimento das funcionalidades e do comportamento de cada unidade desoftware.
Classes funcionar˜ao como entidades encapsuladoras, contribuindo para oagrupamento de dados e opera¸c˜oes relacionados `as entidades de interesse porelas representadas: os sistemas de equa¸c˜oes e as estruturas de dados paraarmazenamento de matrizes esparsas realtivas aos sistemas, cujos dados poder˜aoser manipulados por mais de um tipo de solver.
O novo conjunto de m´odulos com orienta¸c˜ao a objetos permitir´a a este e aoutros outros simuladores similares baseados na mesma implementa¸c˜ao originaldo MEF, maior facilidade para a substitui¸c˜ao dos solvers em uso por outrasop¸c˜oes, facilitando e promovendo maior isolamento nos trabalhos realizados paraa incorpora¸c˜ao de solvers externos ou mesmo para a implementa¸c˜ao de novasalternativas internas neste quesito.
1.4
Computa¸c˜ao paralela para desempenho do simuladorDo entendimento do modelo introduzido na se¸c˜ao 1.2, percebe-se que nestesimulador existe uma situa¸c˜ao convidativa ao desenvolvimento de estrat´egias deparaleliza¸c˜ao que se aproveitem da total independˆencia entre os m´ultiplos sistemasde equa¸c˜oes que precisam ser resolvidos para a simula¸c˜ao do escoamento nos blocos.
Assim sendo, neste trabalho s˜ao propostas duas solu¸c˜oes que se valem desse fato,8a serem discutidas com detalhes no cap´ıtulo 4.
A implementa¸c˜ao do paradigma de orienta¸c˜ao a objetos funcionar´a comofacilitadora para o desenvolvimento de tais solu¸c˜oes, as quais ir˜ao envolver acoexistˆencia de m´ultiplos sistemas de equa¸c˜oes independentes em mem´oria. As
classes tornar˜ao essa tarefa natural e intuitiva, dada a possibilidade de quetenhamos m´ultiplas instˆancias, ou objetos, da classe que representa os sistemasde equa¸c˜oes.
A ideia b´asica por tr´as da solu¸c˜oes paralelas desenvolvidas neste trabalhopoder´a ser enxergada como uma abordagem de granularidade grossa para aexecu¸c˜ao paralela de um modelo, uma vez que n˜ao tratar´a da paraleliza¸c˜aode solvers, mas sim da execu¸c˜ao simultˆanea de v´arias instˆancias de problemascompletos, cada qual demandando a solu¸c˜ao de um sistema independente.
O paralelismo estar´a, portanto, em um n´ıvel de abstra¸c˜ao acima dasimplementa¸c˜oes internas de solvers.
Isto signiﬁca que qualquer solver utilizadopoder´a beneﬁciar-se de uma estrat´egia de paraleliza¸c˜ao ´unica e previamentedesenvolvida.
As solu¸c˜oes paralelas desenvolvidas utilizam os padr˜oes de programa¸c˜aoparalela OpenMP e MPI, voltados a sistemas computacionais de mem´oria uniﬁcadae distribu´ıda, respectivamente. Ambas ter˜ao a mesma proposta b´asica: permitirque v´arias unidades de execu¸c˜ao (threads ou processos) resolvam, em paralelo,v´arios problemas referentes aos blocos, cada um dos quais compreende duas etapas:a constru¸c˜ao e a solu¸c˜ao dos sistemas de equa¸c˜oes referentes `a implementa¸c˜ao dom´etodo dos elementos ﬁnitos.
1.5
Organiza¸c˜ao da disserta¸c˜aoEste trabalho est´a organizado da seguinte forma:No cap´ıtulo 2apresentamos, de maneira conceitual, duas grandes demandas do softwarecient´ıﬁco em geral, a programa¸c˜ao modular e a computa¸c˜ao paralela, fornecendojustiﬁcativas para sua relevˆancia e explorando conceitualmente importantes9t´ecnicas de desenvolvimento de software que visam atendˆe-las.
No cap´ıtulo 3 descrevemos o processo de refatora¸c˜ao do m´odulo referente aossistemas de equa¸c˜oes lineares. S˜ao apresentadas evolu¸c˜oes da organiza¸c˜ao est´aticado c´odigo-fonte pelas quais o c´odigo do simulador de escoamentos passou desde suavers˜ao original e, em seguida, com maior detalhamento, as evolu¸c˜oes feitas nestetrabalho com a incorpora¸c˜ao do paradigma de orienta¸c˜ao a objetos.
No cap´ıtulo 4 ´e descrito o processo de desenvolvimento das solu¸c˜oes paralelasutilizando OpenMP e MPI para o simulador. S˜ao realizados, ainda, testes dedesempenho, interpreta¸c˜ao e cr´ıtica dos os resultados, seguidas de um ciclo deotimiza¸c˜ao.
Finalmente, no cap´ıtulo 5, s˜ao apresentadas as conclus˜oes do trabalho.
10Cap´ıtulo 2Demandas da evolu¸c˜ao do softwarecient´ıﬁcoNeste cap´ıtulo s˜ao tratados de forma geral duas grandes demandas e frentesde evolu¸c˜ao do software cient´ıﬁco: a modulariza¸c˜ao e o desempenho computacional.
Tais caracter´ısticas est˜ao relacionadas ao tempo de vida dos produtos de software.
Naturalmente, produtos efˆemeros n˜ao necessitam, em geral, apresentar taiscaracter´ısticas, mas, produtos de software da ciˆencia moderna cada vez menosfrequentemente se encaixam nessa categoria.
Rouson et al. (2011) deixa claro que os grandes problemas da ciˆencia modernarecaem no desenvolvimento de modelos f´ısicos e matem´aticos que combinamdinˆamicas de diversas esferas do conhecimento para resolver problemas que muitasvezes englobam fenˆomenos cujas escalas de tempo e espa¸co s˜ao separadas por v´ariasordens de magnitude.
Isso constitui desaﬁos do ponto de vista da estabilidade,consistˆencia e acur´acia das simula¸c˜oes computacionais cient´ıﬁcas. Sendo assim,nota-se que as caracter´ısticas, o tamanho e a complexidade dos problemas daciˆencia moderna fazem com que seus produtos de software tendam a possuir longavida e longos ciclos evolutivos.
A primeira classe de demandas do software cient´ıﬁco aparece ao notarmos quea ciˆencia se baseia em modelos que evoluem no tempo, incorporam mais detalhes,tornam-se mais completos e tamb´em mais complexos. Assim, o software cient´ıﬁcodeve ser um produto com certo n´ıvel de maleabilidade, adaptabilidade, facilidade11de incorpora¸c˜ao de funcionalidades e capacidade de evolu¸c˜ao. Tal tipo de demandastraz consigo desaﬁos relacionados diretamente `a organiza¸c˜ao est´atica e estruturaldo c´odigo-fonte.
Em adi¸c˜ao `asreferidas demandas estruturais,existem as demandasrelacionadas ao desempenho de execu¸c˜ao.
O software cient´ıﬁco est´a, emgeral, embasado em modelos num´ericos computacionalmente intensivos, osquais frequentemente possuem alto custo computacional. Entretanto, todas assimula¸c˜oes cient´ıﬁcas precisam ser realizadas dentro de um limite de tempoaceit´avel, que satisfa¸ca as expectativas de seus usu´arios. As demandas relacionadasao desempenho trazem desaﬁos relacionados `a utiliza¸c˜ao eﬁciente dos recursos dehardware dispon´ıveis.
Quer seja no projeto, no desenvolvimento ou na execu¸c˜ao dos programas, otermo “escalabilidade” tem ganhado importˆancia nas discuss˜oes acerca do softwarecient´ıﬁco. Dizemos que um software ´e escal´avel quando est´a preparado para evoluire crescer, seja pela incorpora¸c˜ao de novas funcionalidades ou pelo aumento doseu desempenho, o que lhe torna capaz de manipular com eﬁciˆencia uma cargacrescente de trabalho por meio da utiliza¸c˜ao do m´aximo poss´ıvel dos recursoscomputacionais dispon´ıveis. Nesse contexto Rouson et al. (2011) anuncia dois tiposde escalabilidade: a escalabilidade do design e a escalabilidade no desempenho ouexecu¸c˜ao.
A escalabilidade do design reﬂete-se em um projeto de software voltado parao crescimento e a evolu¸c˜ao. Projetar de maneira escal´avel resulta em um processode desenvolvimento escal´avel que, por sua vez, se faz notar no c´odigo-fonte. ´E
frequentemente desej´avel que o software cient´ıﬁco tenha c´odigo compreens´ıvel, comboa usabilidade, adaptabilidade e facilidade de expans˜ao. O c´odigo que apresentaesse tipo de escalabilidade ´e desenvolvido de forma ordenada e modular, oferecendofacilidades ao entendimento humano e aos trabalhos para sua evolu¸c˜ao e expans˜aofuturas.
Quanto `a execu¸c˜ao, desenvolver c´odigos com desempenho escal´avel signiﬁca12desenvolver c´odigos que s˜ao capazes de n˜ao apenas de beneﬁciar-se do m´aximoposs´ıvel dos recursos computacionais dispon´ıveis, mas tamb´em de ter ganhos dedesempenho, caso mais recursos de hardware sejam disponibilizados. Dadas ascaracter´ısticas do hardware atual, veremos que c´odigos com desempenho escal´avelexploram o paralelismo de forma eﬁciente.
Nas pr´oximas se¸c˜oes deste cap´ıtulo exploraremos conceitos de dois t´opicosdiretamente relacionados com as escalabilidades de design e de execu¸c˜ao: APrograma¸c˜ao Modular e A Computa¸c˜ao Paralela, respectivamente.
2.1
Programa¸c˜ao ModularO desenvolvimento de software na ´epoca dos primeiros computadores digitais,muito em fun¸c˜ao das enormes limita¸c˜oes da m´aquinas daquele tempo, eramarcado por t´ecnicas que visavam extrair o m´aximo dos recursos computacionaisdispon´ıveis. Todo o paradigma do desenvolvimento n˜ao privilegiava, e nem poderia,a boa ordena¸c˜ao e organiza¸c˜ao do ﬂuxo de execu¸c˜ao dos programas em detrimentode sua performance. Era pr´atica comum negligenciar as caracter´ısticas relacionadas`a ordena¸c˜ao e `a clareza do c´odigo escrito em fun¸c˜ao da necessidade de construir-seum ﬂuxo de execu¸c˜ao o mais eﬁciente poss´ıvel.
O n´umero de vari´aveis de um programa, por exemplo, precisava sercontrolado com muito mais rigor do que fazemos hoje em um programa moderno.
Precisava-se limitar o n´umero de vari´aveis por economia no uso de mem´oria.
Sabemos que, do ponto de vista puramente pr´atico, n˜ao h´a problema algum queuma mesma vari´avel assuma diferentes funcionalidades ao longo de um programa.
Entretanto, n˜ao ´e dif´ıcil perceber que o fato de uma vari´avel possuir v´ariasfun¸c˜oes ao longo do c´odigo pode representar um preju´ızo ao entendimento, umavez que impossibilita a utiliza¸c˜ao de um nome de vari´avel relacionado a umafuncionalidade espec´ıﬁca. Os programas da ´epoca dos primeiros computadoreseram, portanto, desenvolvidos quase inteiramente com foco na sua viabilidade emtermos de desempenho e na sua funcionalidade, o que para ´epoca j´a constitu´ıa um13grande desaﬁo. Um bloco monol´ıtico de c´odigo era a apresenta¸c˜ao mais comumde um programa de computador dessa ´epoca. Dividir um programa em v´ariosblocos ou por¸c˜oes de c´odigo j´a demandava um gerenciamento de mem´oria custoso `a´epoca. Essas caracter´ısticas faziam com que programas fossem escritos geralmentepor apenas um programador, uma vez que n˜ao se podia ter por¸c˜oes minimamenteindependentes.
`A medida que os computadores, ambientes de programa¸c˜ao e linguagensevolu´ıram, os programas tamb´em foram crescendo em tamanho e complexidade.
Cada vez problemas maiores e mais complexos podiam ser resolvidos por meioscomputacionais com menor esfor¸co. Ind´ustria, servi¸cos e ciˆencia passaram a n˜aosomente explorar, mas, inclusive, depender fortemente de sistemas de computa¸c˜aopara realiza¸c˜ao de muitas de suas atividades. Dessa forma, ﬁca claro que o softwarepassava a demandar n´ıveis mais altos de qualidade e conﬁabilidade para que osriscos relacionados `a sua utiliza¸c˜ao sejam controlados ou minimamente toler´aveis.
Acompanhando a evolu¸c˜ao dos recursos computacionais, veio uma mudan¸cano fator limitante ou fator inibidor do desenvolvimento de software (Varej˜ao, 2004).
Os recursos computacionais avan¸caram de forma a permitir certo conforto aosdesenvolvedores. N˜ao era mais necess´ario guiar o desenvolvimento de softwaremajoritariamente por quest˜oes relacionadas `a viabilidade t´ecnica. Recursoscomputacionais passaram a n˜ao ser mais t˜ao limitadores quanto a otimiza¸c˜ao dotrabalho dos pr´oprios programadores. A produtividade se tornava um fator chave.
Precisava-se buscar aperfei¸coamento no processo de desenvolvimento, o que trarian˜ao apenas maior produtividade, mas tamb´em maior conﬁabilidade ao produtodesenvolvido.
O conceito de um programa monol´ıtico e de um ´unico desenvolvedor passoua n˜ao ser mais adequado `a nova realidade. Os programas passavam a ser cadavez maiores, mais complexos e mais cr´ıticos. Grandes equipes de desenvolvimentoeram necess´arias e estas precisavam ser cada vez mais produtivas. Deviam buscart´ecnicas que permitissem a cria¸c˜ao de novos programas de forma eﬁciente, com14divis˜ao de trabalho e facilita¸c˜ao da reutiliza¸c˜ao do trabalho anterior.
Problemas complexos podem, em geral, ser reduzidos a um conjunto desubproblemas menores com solu¸c˜oes independentes. A essa estrat´egia ´e dado onome de “dividir para conquistar”. Sua ado¸c˜ao permite n˜ao apenas a divis˜ao dotrabalho entre os integrantes de uma equipe de desenvolvimento, mas tamb´emfavorece a reutiliza¸c˜ao de solu¸c˜oes j´a implementadas (Varej˜ao, 2004). Uma solu¸c˜ao´unica para um problema grande e complexo diﬁcilmente ser´a reutilizada, por´em assolu¸c˜oes de subproblemas associados podem ser reutilizadas com maior facilidade,dado que v´arios problemas complexos podem possuir passos intermedi´arios ousubproblemas em comum, cuja solu¸c˜ao j´a tenha sido implementada em ummomento anterior.
2.1.1
Princ´ıpios da Programa¸c˜ao ModularEmbora programas de computador possam ser simplesmente entendidoscomo sequˆencias de instru¸c˜oes, uma realidade bastante diferente se faz ver soba ´otica das linguagens de programa¸c˜ao de alto n´ıvel como C, Fortran ou Java.
Mais do que conjuntos instru¸c˜oes indivis´ıveis, programas s˜ao compostos porelementos com certo grau de complexidade e que possuem algum signiﬁcado parao entendimento humano. Tais elementos, por sua vez, podem ser compostospor outros menores. Todos combinados constituem um todo que chamamos deprograma ou sistema de software.
Considerando-se a grande variedade de linguagens e paradigmas deprograma¸c˜ao al´em de diferentes granularidades, os elementos componentes podemse apresentar sob diferentes formas como fun¸c˜oes, procedimentos, tipos de dados,classes ou arquivos de fonte, para citar alguns exemplos. Ao longo deste texto,utilizamos os termos “elementos de programa¸c˜ao (ou de software)” e“unidades de programa¸c˜ao (ou de software)” de maneira indistinta e numsentido muito generalizado, sem qualquer deﬁni¸c˜ao restritiva, de forma que possamse referir a quaisquer componentes de um sistema de software.
15Segundo von Staa (2000), programas de porte m´edio em diante necessitamser particionados em segmentos de c´odigo minimamente independentes. No
desenvolvimento de programas com porte suﬁcientemente grande, ´e essencial quese promova a organiza¸c˜ao do ambiente de trabalho, minimizando o n´umero defalhas e as consequentes perdas geradas com o retrabalho para corrigi-las. A
programa¸c˜ao modular ´e o instrumento capaz de oferecer maiores garantias deque o desenvolvimento se dar´a de maneira organizada (von Staa, 2000).
A ideia que deﬁne o princ´ıpio fundamental da programa¸c˜ao modular ´eo particionar o c´odigo-fonte e esta se aproxima da estrat´egia de “dividir paraconquistar”. Desenvolver software modular ´e basicamente desenvolver softwarepromovendo o particionamento de c´odigo e o encapsulamento1 de dados eprocessos em m´ultiplas unidades de software, cada uma correspondendo a umaparcela de c´odigo com certo grau de independˆencia em sua gera¸c˜ao, manipula¸c˜aoe edi¸c˜ao.
As unidades de software respons´aveis pela segmenta¸c˜ao do c´odigo-fontede um programa modular recebem o nome de m´odulos fonte. Mais adiante,exploraremos o conceito de m´odulo mais adotado na literatura e ser˜ao discutidascom mais detalhes as t´ecnicas de implementa¸c˜ao da programa¸c˜ao modular. Nessemomento estamos interessados apenas em promover o entendimento de m´odulosenquanto unidades que rompem com conceito de um programa monol´ıtico, ouindivis´ıvel, confrontando a programa¸c˜ao monol´ıtica com a programa¸c˜ao modular.
Por hora, ´e suﬁciente que pensemos conceitualmente em m´odulos como por¸c˜oes dec´odigo com certo grau de independˆencia que:(i) Encapsulam processos para a solu¸c˜ao de subproblemas(ii) Encapsulam dados que representam certos aspectos de um dom´ınio modeladoA forma de apresenta¸c˜ao dos m´odulostem car´atersecund´ario noentendimento e na conceitua¸c˜ao essencial da programa¸c˜ao modular. O fator mais1 Encapsulamento ´e a propriedade de certos elementos de programa¸c˜ao agruparem, em seuinterior, dados que sejam, em algum grau, logicamente relacionados e processos que operam sobreesses dados.
16relevante aqui n˜ao ´e a forma que cada m´odulo ter´a, uma vez que isso podeestar fortemente conectado a caracter´ısticas espec´ıﬁcas de certas tecnologias oulinguagens de programa¸c˜ao. O que deve, sim, ser observado com maior destaque ´eforma como o particionamento de c´odigo, associado ao encapsulamento promovidopelos m´odulos pode contribuir para a solu¸c˜ao eﬁciente de problemas grandes ecomplexos.
O particionamento de c´odigo faz com que a solu¸c˜ao de um problema complexopossa ser decomposto na solu¸c˜ao de muitos problemas menores e mais simples deforma coordenada, promovendo divis˜ao de trabalho, organiza¸c˜ao e facilita¸c˜ao doentendimento humano. O encapsulamento, por sua vez, ajuda a tornar invis´ıvelaos usu´arios detalhes desnecess´arios de implementa¸c˜ao, levando ao rompimentode barreiras de complexidade.
No estudo das linguagens de programa¸c˜ao, um m´odulo ´e frequentementedeﬁnido como um elemento de software que corresponde a uma unidadesuﬁcientemente individualizada, ao ponto de que possa ser desenvolvida ecompilada separadamente das demais partes que comp˜oem o sistema de softwarecomo um todo. Em (von Staa, 2000) e (Varej˜ao, 2004) as deﬁni¸c˜oes adotadasseguem o mesmo caminho, conceituando m´odulos como unidades compil´aveis deforma independente. Um m´odulo pode conter diversos elementos como classes,procedimentos, fun¸c˜oes, declara¸c˜oes de tipos, constituindo, todos juntos, uma´unica unidade de compila¸c˜ao. Embora ambos os autores tenham dado destaquesemelhante ao quesito compila¸c˜ao individual, von Staa (2000) deixa claro que n˜aoexiste consenso absoluto na literatura acerca do conceito de m´odulo.
2.1.2
Abstra¸c˜oesSegundo Varej˜ao (2004), a abstra¸c˜ao ´e um conceito muito importante evastamente utilizado em todas ´areas da ciˆencia, sendo de suma importˆancia paraa resolu¸c˜ao de problemas complexos. A modelagem e a representa¸c˜ao da realidadepara a posterior resolu¸c˜ao de um problema de interesse ´e tarefa comum na ciˆencia.
17Devemos perceber que a representa¸c˜ao da realidade jamais poder´a ser feita em todasua riqueza de detalhes. A abstra¸c˜ao nos permite representar de forma seletivaapenas os aspectos da realidade que s˜ao fundamentais na resolu¸c˜ao do problemade interesse, escondendo os detalhes irrelevantes em um determinado contexto.
Na ´area das linguagens de programa¸c˜ao, Varej˜ao (2004) estabelece duasperspectivas b´asicas nas quais a abstra¸c˜ao se insere. Primeiramente, a simplesutiliza¸c˜ao de uma linguagem de programa¸c˜ao de alto n´ıvel j´a representa um n´ıvelde abstra¸c˜ao. Para o trabalho de um programador, ´e suﬁciente que ele enxergue ocomputador como uma m´aquina capaz de entender comandos de uma linguagem deprograma¸c˜ao de alto n´ıvel, ainda que isso n˜ao seja verdade. O programador est´anesse momento abstraindo o hardware e as linguagens de baixo n´ıvel, dado queesses s˜ao detalhes irrelevantes em seu contexto de trabalho. A segunda perspectivaonde utiliza-se o conceito de abstra¸c˜ao ´e no entendimento de que as linguagens deprograma¸c˜ao oferecem ao programador os meios necess´arios para que ele tamb´emcrie as suas pr´oprias abstra¸c˜oes. ´E nessa perspectiva que se faz clara a forterela¸c˜ao entre abstra¸c˜oes e a programa¸c˜ao modular. Os m´odulos e seus elementoscomponentes s˜ao as entidades capazes de promover as abstra¸c˜oes.
As abstra¸c˜oes criadas pelo programador podem ser usadas por ele oupor outros programadores em diferentes momentos e na resolu¸c˜ao de diferentesproblemas. Deve-se perceber que o conhecimento da implementa¸c˜ao interna detodos m´odulos ou outros elementos de programa¸c˜ao que modelam a solu¸c˜ao desubproblemas muitas vezes n˜ao ´e fundamental para a resolu¸c˜ao do problema maiorde interesse. Assim, podemos dizer que m´odulos podem ter sua implementa¸c˜aointerna abstra´ıda pelos programadores. Um programador interessado em resolverdado problema computacional pode fazer uso de v´arios m´odulos, mesmo semconhecer coisa alguma sobre sua implementa¸c˜ao interna, desde que conhe¸ca bema funcionalidade oferecida por eles e a forma como eles devem se comunicar com o18mundo exterior, ou seja, sua interface2 .
Uma interface constitui um conjunto de regras ou padr˜oes para que se possaestabelecer a comunica¸c˜ao entre os elementos. A assinatura de uma fun¸c˜ao, porexemplo, estabelece um padr˜ao, por meio dos argumentos da fun¸c˜ao, de como elapoder´a trocar dados com meio exterior, representando, portanto, a sua interface.
De acordo com Varej˜ao (2004), programas de computador podem serdeﬁnidos como “conjuntos de instru¸c˜oes descrevendo como realizar processos paramanipular, alterar e produzir dados”. Considerando a deﬁni¸c˜ao anterior e sabendodo papel dos m´odulos enquanto elementos capazes de promover abstra¸c˜oes pormeio do encapsulamento de processos e de dados, podemos classiﬁcar as abstra¸c˜oescriadas pelo programador em dois tipos: Abstra¸c˜oes de processos e Abstra¸c˜oesde dados.
2.1.2.1
Abstra¸c˜oes de processosAs abstra¸c˜oes de processos se d˜ao sobre o ﬂuxo de controle dos programas etratam de encapsular as seq¨uˆencias de instru¸c˜oes e comandos que descrevem umprocesso. Os elementos de programa¸c˜ao utilizados para que seja feita a abstra¸c˜aode processos s˜ao os subprogramas. Al´em de encapsular c´odigo, eles deﬁnemregi˜oes limitados dentro de um programa onde podemos criar vari´aveis, constantese tipos para utiliza¸c˜ao em escopo local. Subprogramas podem ser do tipo fun¸c˜aoou procedimento. Fun¸c˜oes representam abstra¸c˜oes de express˜oes e possuem umvalor de retorno. J´a os procedimentos representam abstra¸c˜oes de comandos, umavez que apenas encapsulam um ﬂuxo de controle deﬁnindo um novo comando quepassa a ser dispon´ıvel aos usu´arios. Em contraste com as fun¸c˜oes, os procedimentosn˜ao retornam valores. O ponto comum ´e que subprogramas em geral atuam nosentido de aumentar o conjunto de instru¸c˜oes oferecidos por uma linguagem deprograma¸c˜ao com o uso do conceito de abstra¸c˜oes.
2 Interface ´e o meio ou o conjunto de regras e deﬁni¸c˜oes pelo qual os m´odulos ou seuselementos constituintes, como classes, procedimentos e fun¸c˜oes, se comunicam com o usu´ario ououtros elementos.
19Quando um programador escreve subprogramas, fun¸c˜oes ou procedimentos,ele est´a criando abstra¸c˜oes no sentido de que esconde ou encapsula os detalhesde implementa¸c˜ao de determinado ﬂuxo de execu¸c˜ao. Com isso est˜ao sendoprovidas novas funcionalidades com reutiliza¸c˜ao facilitada para o futuro. As
abstra¸c˜oes criadas pelo programador na forma de subprogramas acabam porestender as funcionalidades ou o conjunto de instru¸c˜oes oferecidos pela linguagemde programa¸c˜ao. Combinam comandos e express˜oes de forma a oferecer outrosnovos. Em qualquer momento futuro, o programador pode fazer uso das abstra¸c˜oespara pensar em resolver problemas maiores. Nesse momento, ele poder´a tersuas aten¸c˜oes focadas em um n´ıvel mais alto, na resolu¸c˜ao de seu problema deinteresse, cujas etapas de resolu¸c˜ao podem ser facilmente resolvidas com o uso desubprogramas.
2.1.2.2
Abstra¸c˜oes de dadosAbstra¸c˜oes de dados, de forma similar `as abstra¸c˜oes de processos, combinamv´arios dados de forma a oferecer um novo dado ou tipo de dado. Embora aindaem um n´ıvel bastante baixo, ao enxergarmos a mem´oria de um computador comoum conjunto de c´elulas de mem´oria, e as c´elulas de mem´oria, por sua vez, comocole¸c˜oes de bits, estamos fazendo abstra¸c˜ao de dados. Todas as linguagens deprograma¸c˜ao de alto n´ıvel oferecem abstra¸c˜oes de dados em um n´ıvel mais alto aofornecerem tipos de dados como inteiros, ponto ﬂutuante e vetores. Programadoresde linguagens de alto n´ıvel utilizam esses tipos de dados sem pensar na forma comode fato s˜ao armazenados em mem´oria.
O que podemos observar ´e que apenas as abstra¸c˜oes de dados oferecidas pelaslinguagens de programa¸c˜ao n˜ao se demonstraram suﬁcientes para a programa¸c˜aocom qualidade. ´E preciso permitir aos programadores que criem suas pr´opriasabstra¸c˜oes, combinando dados dispon´ıveis de forma a dar origem a seus pr´opriostipos de dados. Tipos de dados como listas, pilhas e ﬁlas s˜ao exemplos de abstra¸c˜oesde dados criadas pelo programador.
202.1.3
Justiﬁcativas, vantagens e desvantagens da programa¸c˜aomodularA programa¸c˜ao modular traz consigo uma s´erie de vantagens para o processode desenvolvimento de software. Nesta se¸c˜ao ser˜ao apresentadas justiﬁcativas qued˜ao suporte a seu emprego.
• Facilita o rompimento e barreiras de complexidade al´em de permitira distribui¸c˜ao de trabalho, por adotar a estrat´egia de “dividir paraconquistar”. Sabemos que problemas grandes e complexos tˆem muitasvezes sua solu¸c˜ao facilitada se forem pensados como uma s´erie de problemasmenores a serem solucionados por m´odulos independentes. M´odulosindependentes podem ser desenvolvidos por diversos programadorestrabalhando em paralelo.
Identiﬁca-se, nesse sentido, uma potencialeconomia de tempo de desenvolvimento, uma vez que v´arias pessoaspoder˜ao trabalhar paralelamente no desenvolvimento do programa.
• Permite o re´uso de c´odigo. M´odulos podem e idealmente devem serconstru´ıdos de forma que possam ser usados em outros programas. Se
os programadores desenvolvem m´odulos de forma bem documentada,deixando sua funcionalidade clara para potenciais clientes, pode-se´E comum queobter consider´avel economia de esfor¸co de trabalho.
programas e projetos diferentes podem se valer de m´odulos provedoresde funcionalidades demandadas recorrentemente no desenvolvimento deprogramas.
Se considerarmos programas pertencentes a um mesmodom´ınio de aplica¸c˜ao, a tendˆencia ´e de que o re´uso seja ainda mais´E comum que empresas ou institui¸c˜oes desenvolvam v´ariosvantajoso.
produtos de software dentro de um mesmo dom´ınio de aplica¸c˜ao.
Desenvolver software modular pode representar a constru¸c˜ao de um ativode software que permite `as corpora¸c˜oes serem mais velozes e competitivasno desenvolvimento de seus sistemas.
21• Permite o desenvolvimento incremental e o gerencimento do processode desenvolvimento de software. A programa¸c˜ao modular facilita oestabelecimento de muitas baselines de m´odulos fonte.
Isso signiﬁcater um maior grau de controle nas altera¸c˜oes realizadas. M´odulosentregues podem ter sua altera¸c˜ao suﬁcientemente controlada, evitandocontratempos advindos de altera¸c˜oes indisciplinadas no c´odigo. `A medidaque novos m´odulos ou m´odulos j´a existentes s˜ao alterados, o sistemade software como um todo evolui de maneira incremental. Cada novaitera¸c˜ao representa uma nova vers˜ao denominada construto. Dessa forma,a programa¸c˜ao modular torna mais natural a evolu¸c˜ao incremental dosprogramas.
• Reduz o custo de compila¸c˜ao. Se considerarmos que m´odulos s˜ao unidadesindependentemente compil´aveis, ﬁca claro que altera¸c˜oes pontuais emcertos m´odulos n˜ao ir˜ao requerer que todo o programa seja recompilado.
Em projetos de pequeno porte, a compila¸c˜ao pode n˜ao representar umatarefa custosa, mas em grandes projetos pode requerer grandes esfor¸cos econsumir tempo dos programadores.
• Permite que otimiza¸c˜oes de desempenho sejam feitas de maneira gradual.
Os m´odulos de um programa podem ser perfeitamente funcionais aindaque n˜ao sejam idealmente otimizados. Num primeiro momento, osdesenvolvedores podem estar interessados em desenvolver unicamente umavers˜ao funcional do programa. Cada um dos m´odulos pode ainda passar,individualmente, por um processo evolutivo no que diz respeito ao seudesempenho. A modulariza¸c˜ao oferece maior ﬂexibilidade na decis˜ao dequais m´odulos devem ser otimizados e em quais momentos ao longo doprocesso de desenvolvimento. Mais do que isso, oferece a possibilidade deque se decida se todos os m´odulos precisam realmente ser otimizados. ´E
comum que se depare com situa¸c˜oes nas quais poucas tarefas representamgrande parte do custo computacional do programa como um todo. Nesse22caso, os esfor¸cos de otimiza¸c˜ao podem ser concentrados nos m´odulos maiscustosos computacionalmente.
Existem, entretanto, contrapartidas advindas da utiliza¸c˜ao da programa¸c˜aomodular. Algumas responsabilidades e compromissos precisam ser assumidos pelosprogramadores:• ´E preciso pensar de forma modular e estar disposto a desenvolver c´odigocom isso em mente. Isso signiﬁca estar disposto a particionar o c´odigo,provendo funcionalidades, mesmo que isso n˜ao pare¸ca a forma mais r´apidade resolver um problema imediato.
• ´E necess´ario especiﬁcar os m´odulos e idealmente document´a-los de formaa facilitar o utiliza¸c˜ao dos mesmos por outros programadores. Se estamosinteressados em encapsulamento de c´odigo, n˜ao nos interessa que osusu´arios precisem ler o c´odigo-fonte para compreender a funcionalidadede cada m´odulo.
• ´E preciso tomar decis˜oes justiﬁcadas sobre como particionar o c´odigo, comoabstrair, por que abstrair. Saber identiﬁcar potenciais trechos de c´odigocom alta possibilidade de reutiliza¸c˜ao, ou cujo entendimento humano sejadif´ıcil, ´e fundamental nessa tarefa.
• ´E preciso saber dividir tarefas de forma eﬁciente, garantindo que o trabalhode um programador n˜ao afete as interven¸c˜oes dos demais integrantes deuma equipe.
• ´E preciso conhecer as interfaces dos m´odulos, bem como respeit´a-las.
Sobretudo, ´e necess´ario que haja um bom projeto de arquitetura paraque o processo de desenvolvimento se dˆe de forma ordenada e para quepossam ser auferidos os benef´ıcios esperados da programa¸c˜ao modular.
• ´E preciso sabe de que forma poder´a ser assegurada a qualidade de tudoaquilo que ´e produzido a partir da integra¸c˜ao de diversos m´odulos.
23Como visto, existem algumas responsabilidades a serem assumidas pelosprogramadores interessados em desenvolver software modular. Muitas vezes estespodem se questionar, por exemplo, sobre o qu˜ao justiﬁc´avel ´e a programa¸c˜aomodular, o qu˜ao dispendiosos ser˜ao os esfor¸cos para se determinar comoexatamente deve ser particionado o c´odigo do programa, quais ser˜ao as formasde apresenta¸c˜ao dos m´odulos, como deve ser especiﬁcado cada m´odulo, como devese dar a intera¸c˜ao entre os diversos m´odulos de um programa e quais ser˜ao as regraspara isso.
Nos casos em que o programa a ser desenvolvido objetiva resolvercomputacionalmente um problema de grande propor¸c˜ao e alta complexidade, ocen´ario ´e mais favor´avel `a programa¸c˜ao modular. Nesses casos, onde h´a barreiras decomplexidade que intimidam o programador, ´e praticamente natural que ele pensede maneira modular, dada a sua diﬁculdade em resolver o problema como um todode uma s´o vez. Em problemas menos complexos, no entanto, ´e compreens´ıvel queo programador se sinta tentado a seguir uma l´ogica monol´ıtica. Frequentementeele n˜ao deseja fazer decis˜oes de projeto ou mesmo pensar como a segmenta¸c˜ao doc´odigo deve se dar.
Apesar de nem sempre a programa¸c˜ao modular parecer atrativa aosprogramadores, as situa¸c˜oes nas quais ela realmente n˜ao vale a pena s˜aomuito restritas.
Por mais que o problema a ser resolvido n˜ao apresentemuita complexidade, a programa¸c˜ao modular oferece benef´ıcios que v˜ao al´em dasupera¸c˜ao de barreiras de complexidade.
Em von Staa (2000) ´e apresentada uma justiﬁcativa econˆomica para aprograma¸c˜ao modular, baseada em m´etodos de estima¸c˜ao de tamanho, esfor¸coe custo de desenvolvimento de programas. Os m´etodos empregados est˜ao baseadosem uma s´erie de parˆametros obtidos por meio de estat´ısticas colhidas de um granden´umero de projetos reais. O estudo confronta o esfor¸co de desenvolvimento modularcom o esfor¸co monol´ıtico, considerando diferentes parˆametros como, por exemplo,o tamanho do programa em linhas de c´odigo, o n´umero de m´odulos e o tamanho24m´edio dos m´odulos.
A conclus˜ao de tal estudo ´e que, exceto em programas muito pequenos,o esfor¸co de programa¸c˜ao modular ´e bastante menor que o esfor¸co monol´ıtico,mesmo quando consideramos os esfor¸cos adicionais advindos da necessidadede especiﬁca¸c˜ao e implementa¸c˜ao das interfaces e da integra¸c˜ao dos diferentesm´odulos. Soma-se a isso o fato de que, conforme o tamanho do programa aumenta,a diferen¸ca de esfor¸co entre as duas formas de desenvolvimento se torna muito maisevidente, sempre em favor da abordagem modular.
2.1.4
T´ecnicas de modulariza¸c˜aoProgramas de grande porte s˜ao caracterizados por envolver um granden´umero de linhas de c´odigo, grandes equipes de desenvolvimento e geralmenteconstituem uma solu¸c˜ao computacional complexa para problemas igualmentecomplexos. J´a foi exposto que o padr˜ao de um programa monol´ıtico n˜ao ´e adequadoa esse tipo de sistemas. ´E para assistir principalmente o desenvolvimento desse tipode programas que foram desenvolvidas as t´ecnicas de modulariza¸c˜ao.
As t´ecnicas tratam de implementar em c´odigo os conceitos da programa¸c˜aomodular discutidos at´e aqui,como a segmenta¸c˜ao do c´odigo-fonte,oencapsulamento e as abstra¸c˜oes. Embora tenham seu foco principal em assistiro desenvolvimento de grandes programas, muitas das t´ecnicas n˜ao deixam de ser´uteis mesmo a programas de pequeno porte.
Como visto anteriormente, no estudo das linguagens de programa¸c˜ao, osm´odulos s˜ao entendidos como unidades de software compil´aveis separadamente.
Cada m´odulo pode ser composto de v´arios elementos distintos como fun¸c˜oes,procedimentos, vari´aveis, constantes e tipos. Elementos como esses s˜ao reunidosem um m´odulo quando est˜ao de alguma forma relacionados e possuem objetivocomum. De acordo com Varej˜ao (2004) m´odulos bem projetados possuem um´unico objetivo claro, bem como uma boa deﬁni¸c˜ao de interface com os demaism´odulos.
25O entendimento do prop´osito de um m´odulo e o conhecimento exatodas funcionalidades oferecidas por ele ´e preocupa¸c˜ao do usu´ario. A formacomo o objetivo ´e atingido, entretanto, ´e preocupa¸c˜ao do implementador. Porusu´ario entendemos um programador que ir´a utilizar os recursos do m´odulo nodesenvolvimento de um outro elemento de software, que pode ser, por exemplo,outro m´odulo ou um programa completo. Podemos dizer que esses elementos s˜aoclientes3 do m´odulo em quest˜ao.
A seguir exploraremos algumas t´ecnicas de modulariza¸c˜ao, em umaabordagem independente de linguagem de programa¸c˜ao.
Ser˜ao apresentadasas principais estrat´egias de implementa¸c˜ao desenvolvidas para que se pudessedesenvolver programas de forma mais compartimentada, organizada e eﬁcientedo que com o uso da abordagem monol´ıtica. As estrat´egias podem se aplicarinternamente a um ´unico arquivo de c´odigo-fonte ou mesmo subdividir osprogramas em m´ultiplos arquivos com compila¸c˜ao separada.
2.1.4.1
SubprogramasO desenvolvimento do conceito de subprogramas (procedimentos e fun¸c˜oes)representou o primeiro passo para que o desenvolvimento de software pudessecaminhar na dire¸c˜ao da programa¸c˜ao modular.
Subprogramas permitemo particionamento do programa em diversas por¸c˜oes de c´odigo logicamenterelacionadas.
A ideia ´e que cada subprograma represente claramente uma funcionalidadebem deﬁnida, funcionando como um instrumento para a abstra¸c˜ao de processos,conforme visto na se¸c˜ao 2.1.2.
Subprogramas, portanto,jamais devem serentendidos como instrumentos de modulariza¸c˜ao que particionam o c´odigo levando-se em conta sua extens˜ao, o que resultaria em modulariza¸c˜ao de baixa qualidade.
N˜ao existe raz˜ao para que subprogramas tenham tamanhos semelhantes. O
que deve ser levado em conta ´e identiﬁca¸c˜ao de funcionalidades que possam ser3 Clientes s˜ao todos os elementos de programa¸c˜ao que fazem uso de funcionalidades ou dadosprovidos por outros elementos.
26abstra´ıdas.
O uso de subprogramas evita que trechos de c´odigo sejam exaustivamenterepetidos ao longo de um programa e facilita o re´uso de c´odigo. Se um determinadoprocesso ou ﬂuxo de execu¸c˜ao precisa ser realizado muitas vezes, ´e poss´ıvelter m´ultiplas chamadas a um ´unico subprograma.
Isso facilita n˜ao somente aimplementa¸c˜ao, mas tamb´em a manuten¸c˜ao do programa. No momento em queuma altera¸c˜ao no processo implementado no subprograma precisa ser feita, ser´aposs´ıvel alterar o c´odigo de forma localizada. Em contraste, programas com trechosde c´odigo exaustivamente repetidos demandariam uma busca exaustiva por todasas ocorrˆencias do trecho para sua altera¸c˜ao.
Subprogramas permitem, ainda, que o processo descrito pelos mesmos sejaaplicado sobre conjuntos de dados diferentes. Isso ´e poss´ıvel gra¸cas ao processode parametriza¸c˜ao, por meio do qual podemos fornecer dados aos subprogramas.
Dessa forma, procedimentos e fun¸c˜oes podem operar sobre dados diferentes emcada chamada, resultando, respectivamente, em comportamentos ou valores deretorno distintos.
2.1.4.2
PacotesNo desenvolvimento de grandes sistemas de software,implementar amodulariza¸c˜ao exclusivamente por meio de subprogramas n˜ao ´e, em geral, umaestrat´egia considerada suﬁciente. Esse tipo de modulariza¸c˜ao acaba promovendouma segmenta¸c˜ao de c´odigo com granularidade muito ﬁna. No caso de sistemasmuito grandes, isso faz com que se tenha um n´umero muito grande de elementos deprograma¸c˜ao espalhados pelo c´odigo. ´E necess´ario haver um n´ıvel de modulariza¸c˜aocom granularidade maior.
Al´em disso, dado que a programa¸c˜ao modular ´e marcada pelo re´uso de c´odigo,nota-se, especialmente em grandes sistemas, que existe uma grande possibilidadede conﬂitos de nomes entre os elementos das diversas fontes de c´odigo reutilizados.
´E preciso que haja alguma forma de solucionar os conﬂitos de nome.
27Pacotes s˜ao elementos de programa¸c˜ao com nome pr´oprio que agrupamdiversos outros elementos, sendo alguns vis´ıveis para os usu´arios e outros n˜ao. Ao
mesmo tempo em que representam uma forma de modulariza¸c˜ao de granularidadegrossa, s˜ao elementos capazes de resolver conﬂitos de nome, justamente pelo fatode possu´ırem nomes pr´oprios. Se existir um conﬂito de nomes entre elementosprovenientes de m´ultiplas fontes de c´odigo, sendo as fontes m´ultiplos pacotes, ´eposs´ıvel especiﬁcar corretamente de qual pacote ´e o elemento que se quer acessar.
Basta que se utilize a especiﬁca¸c˜ao completa do nome, que inclui o nome do pacotee o nome do elemento componente em quest˜ao.
2.1.4.3
Tipos de dadosComo discutido na se¸c˜ao 2.1.2, novos tipos de dados representam abstra¸c˜oesde dados feitas pelo programador. Re´unem uma cole¸c˜ao de dados relacionadosem um ´unico elemento de programa¸c˜ao. Os usu´arios desses tipos de dados podemenxerg´a-los como um todo coeso, sem que seja necess´ario pensar em como foramimplementados.
Dados do tipo registro, como o struct em C ou structure e record do Fortran(posteriormente substitu´ıdos pela declara¸c˜ao TYPE) s˜ao denominados tipos dedados simples. Esse tipo de modulariza¸c˜ao consiste em reunir e combinar umgrupo de dados relacionados em uma ´unica entidade encapsuladora nomeada. O
grupo de dados nomeado pode assim ser tratado como um todo e as vantagensincluem facilita¸c˜ao do re´uso e melhor legibilidade do c´odigo. O principal pontofraco desse tipo de modulariza¸c˜ao ´e n˜ao permitir o ocultamento da informa¸c˜ao,visto que o acesso aos dados internos do tipo ´e livre para os seus usu´arios. O
ocultamento dos dados ´e permitido pelos Tipos Abstratos de Dados e ser´a discutidoa seguir.
Por sua vez, os Tipos Abstratos de Dados (TADs) s˜ao elementos desoftware nos quais uma determinada estrutura de dados ´e criada para representarum novo tipo. Esta ´e tornada conhecida somente atrav´es das opera¸c˜oes realizadas28sobre seus dados. O implementador do TAD decide como ir´a representar os valoresdo tipo abstrato e implementa um conjunto de opera¸c˜oes, na forma de fun¸c˜oese procedimentos que operam sobre os dados do novo tipo. Para implementa¸c˜aode TADs, ´e necess´ario que a linguagem forne¸ca recursos para o ocultamento dainforma¸c˜ao, tornando a implementa¸c˜ao interna do TAD invis´ıvel para o usu´ario,o que normalmente ´e feito com a especiﬁca¸c˜ao de sua interface. Nela s˜ao expostossomente os componentes que devem ser p´ublicos, em geral apenas as opera¸c˜oesoferecidas pelo TAD, sendo os dados internos invis´ıveis aos usu´arios.
A estrat´egia de tornar p´ublicas apenas as opera¸c˜oes e manter os dadosinacess´ıveis aos usu´arios(information hiding)implica que o conjunto devalores internos do tipo ´e acessado e modiﬁcado sempre de maneira indireta,exclusivamente pela execu¸c˜ao de opera¸c˜oes consultoras e atualizadoras,respectivamente. Opera¸c˜oes atualizadoras podem ainda proteger os dados contraaltera¸c˜oes feitas de maneira incorreta, impedindo que os dados assumam valoresindevidos. Opera¸c˜oes consultoras/atualizadoras s˜ao frequentemente denominadasgetters/setters, mutators/accessors ou, de forma geral, fun¸c˜oes de acesso. O
usu´ario, portanto, apenas utiliza o TAD como uma caixa preta para resolver seuproblema, sem acesso direto aos dados.
Al´em das opera¸c˜oes de acesso, nos TADs frequentemente existem asopera¸c˜oes construtoras e destrutoras. De acordo com Varej˜ao (2004) asconstrutoras s˜ao respons´aveis por criar e inicializar os TADs e devem ser executadasantes de quaisquer outras opera¸c˜oes para que se garanta o perfeito funcionamentodas mesmas. As opera¸c˜oes destrutoras, utilizadas quando o uso do TAD n˜ao ´emais necess´ario, s˜ao respons´aveis por atividades de ﬁnaliza¸c˜ao, dentre as quaisdestaca-se a desaloca¸c˜ao da regi˜ao de mem´oria utilizada pelo TAD.
2.1.4.4
M´ultiplos arquivos e Compila¸c˜ao SeparadaAs t´ecnicas de modulariza¸c˜ao abordadas at´e o momento podem ser aplicadaspara a modulariza¸c˜ao de programas em um arquivo de fonte ´unico. Com o29crescimento dos programas, entretanto, esse tipo de abordagem come¸ca a tornar-seinvi´avel, uma vez que traz problemas pr´aticos tanto para o desenvolvimento quantopara a manuten¸c˜ao e re´uso de c´odigo.
Programadoresfrequentementeencontram diﬁculdadeetˆem suaprodutividade comprometida na escrita e na manuten¸c˜ao de programas comgrandes propor¸c˜oes, se estes estiverem completamente contidos em um ´unicoarquivo fonte. Todas as vezes em que se faz necess´aria uma altera¸c˜ao no c´odigo-fonte, o ´unico e extenso arquivo de fonte deve ser examinado pelo programador aﬁm de que se encontre a regi˜ao que precisa ser alterada. Se dois programadorespretendem alterar, cada um uma parte espec´ıﬁca do programa, eles precisar˜aoalterar o mesmo arquivo e ao ﬁm do trabalho, haver´a um esfor¸co adicionalpara que se possa unir as altera¸c˜oes feitas por ambos. Quando o trabalho deum programador precisa ser interrompido e depois retomado, tem-se um custoadicional para que, novamente, se vasculhe o extenso arquivo a ﬁm de encontrar olocal a partir do qual o trabalho deve continuar.
Outra quest˜ao relevante nesse contexto ´e o fato de que muitos elementosde programa¸c˜ao de um programa podem ser reutilizados n˜ao somente dentro deum programa ´unico, mas tamb´em em programas distintos. ´E comum, tanto nasempresas quanto na comunidade cient´ıﬁca, que grupos de pessoas interessadas emdesenvolver aplica¸c˜oes com algum grau de semelhan¸ca interajam entre si. Muitasaplica¸c˜oes diferentes podem compartilhar trechos em comum. Programas em um´unico arquivo fonte diﬁcultam o processo de re´uso, pois exigem que a funcionalidadea ser utilizada em outros programas seja localizada dentro de um extenso arquivoe copiada para o programa que far´a uso da mesma.
Naturalmente, dividir os programas em arquivos separados surge comosolu¸c˜ao para os problemas citados. Cada arquivo pode conter trechos de c´odigoassociados a uma funcionalidade ou a um grupo de funcionalidades suﬁcientementerelacionadas, segundo algum crit´erio l´ogico de divis˜ao que fa¸ca sentido paraa equipe de desenvolvedores. Os pr´oprios arquivos acabam funcionando como30indexadores para que os programadores encontrem mais rapidamente as regi˜oesdo c´odigo que desejam reaproveitar ou mesmo onde desejam realizar altera¸c˜oes.
Entretanto, os m´ultiplos arquivos, por si s´o, n˜ao resolvem um problemacomum a grandes projetos de software: o custo da compila¸c˜ao. Em programaspequenos, o custo em tempo com a compila¸c˜ao pode, muitas vezes,sernegligenciado. Em grandes projetos, por´em, o custo em tempo para a compila¸c˜aode todo o c´odigo se torna algo impactante na produtividade dos programadores.
Quando adota-se a estrutura de modulariza¸c˜ao por arquivos, o interesse ´e que sejaposs´ıvel a compila¸c˜ao em separado de cada um dos m´odulos fonte, de forma que,com altera¸c˜oes localizadas em m´odulos espec´ıﬁcos, n˜ao seja necess´ario recompilartodo o c´odigo-fonte, mas somente somente os m´odulos alterados.
Conforme destacado (Varej˜ao, 2004), para que se possa permitir a compila¸c˜aoem separado dos m´odulos, surge a necessidade de certo relaxamento na veriﬁca¸c˜aode erros por parte do compilador. Consideremos, a t´ıtulo de exemplo, que em umdeterminado arquivo fonte foi escrita uma cole¸c˜ao de procedimentos e fun¸c˜oes paraserem utilizadas em outros arquivos fontes clientes. Quando s˜ao feitas altera¸c˜oesnas unidades clientes, ´e interessante que estas possam ser recompiladas sem queseja requerida a recompila¸c˜ao do arquivo que cont´em a cole¸c˜ao de subprogramasutilizados. Com a recompila¸c˜ao sendo feita exclusivamente nas unidades clientesalteradas, o compilador n˜ao poder´a veriﬁcar se todas as sub-rotinas utilizadas porelas de fato existem nos m´odulos onde supostamente devem estar implementadas.
Mais do que isso, ´e preciso saber se as rotinas est˜ao sendo utilizadas da maneiracorreta quanto ao tipo dos argumentos passados, por exemplo.
Para que a compila¸c˜ao em separado possa coexistir com a veriﬁca¸c˜ao detipos, uma estrat´egia usada em muitas linguagens de programa¸c˜ao ´e subdividircada um dos m´odulos fonte em dois arquivos: arquivo de interface e arquivo deimplementa¸c˜ao.
Nos arquivos ou m´odulos de interface, tamb´em chamados de m´odulos de31deﬁni¸c˜ao4 , existem somente declara¸c˜oes e deﬁni¸c˜oes de elementos como vari´aveis,tipos e subprogramas que ser˜ao usados por arquivos/m´odulos clientes. Os arquivosde implementa¸c˜ao, ou m´odulos de implementa¸c˜ao5 , por sua vez, s˜ao onde est˜aocontidas todas as implementa¸c˜oes completas dos elementos de software declaradosno arquivo de interface.
Nos m´odulos clientes, o que se faz usualmente ´e importar apenas os arquivosde deﬁni¸c˜ao (header ﬁles). A inclus˜ao dos m´odulos de deﬁni¸c˜ao gera um impactopraticamente desprez´ıvel no custo de compila¸c˜ao das unidades clientes, visto quetais m´odulos correspondem apenas a deﬁni¸c˜oes de vari´aveis, constantes, tipos eassinaturas de subprogramas. Apesar do baixo custo de compila¸c˜ao, os arquivos dedeﬁni¸c˜ao possuem as informa¸c˜oes suﬁcientes para que se possa realizar a veriﬁca¸c˜aode tipos.
Sendo assim, com a inclus˜ao dos m´odulos de deﬁni¸c˜ao em todos os arquivosclientes, a compila¸c˜ao torna-se, al´em de r´apida, segura. A unidades clientes podemser recompiladas em separado, sem que seja preciso realizar a recompila¸c˜ao dosm´odulos de implementa¸c˜ao utilizados, cuja compila¸c˜ao ´e custosa, e sem tampoucoque seja necess´ario abrir m˜ao do rigor nas veriﬁca¸c˜oes de erro do compilador.
No processo de compila¸c˜ao de programas divididos em v´arios arquivos,quando os m´odulos de implementa¸c˜ao s˜ao fornecidos ao compilador, originam-se, para cada um dos m´odulos compilados, um correspondente m´odulo objeto.
Finalmente os m´odulos objeto s˜ao integrados por um programa especial ligador(linker), respons´avel por unir os arquivos objeto e gerar um ´unico arquivoexecut´avel.
2.1.5
Programa¸c˜ao Orientada a ObjetosOrienta¸c˜ao a Objetos ´e um paradigma para o desenvolvimento deprogramas particularmente interessante quando precisa-se modelar e resolver4 M´odulo de deﬁni¸c˜ao ´e o elemento que cont´em apenas o c´odigo de deﬁni¸c˜ao da interfacedo m´odulo fonte.
5 M´odulo de implementa¸c˜ao ´e o elemento que implementa de fato todas as funcionalidadesprovidas pelo m´odulo fonte, encapsulando todo c´odigo das mesmas.
32computacionalmente problemas que possam ser expressos em termos de diversosconjuntos de dados minimamente relacionados,submetidos a conjuntos deopera¸c˜oes.
Isso se deve ao fato de que a programa¸c˜ao Orientada a Objetos ´efortemente focalizada em entidades do mundo real e nos processos e opera¸c˜oesrealizados por tais entidades ou aos quais seus dados se sujeitam.
As classes podem representar de maneira eﬁciente entidades do mundo real.
Permitem a deﬁni¸c˜ao de novos tipos oferecendo meios para o encapsulamento dedados e de oprea¸c˜oes sobre esse dados. Os primeiros sob forma de seus atributos,e as ´ultimas na forma de seus procedimentos ou fun¸c˜oes, denominados m´etodos.
A estrutura de classes se assemelha da decomposi¸c˜ao de programas em m´odulos;entretanto, diferente de m´odulos, os quais podem ser simplesmente arquivoscontendo cole¸c˜oes de fun¸c˜oes, as classes podem ser instanciadas, correspondendocada instˆancia a um objeto6 em mem´oria. Classes funcionam como modelos quecont´em as informa¸c˜oes necess´arias para a aloca¸c˜ao dos dados dos objetos e para ainicializa¸c˜ao de seus atributos.
Na se¸c˜ao 2.1.4.3 vimos que, com os Tipos Abstratos de Dados (TADs), osprogramadores s˜ao capazes de criar novos tipos, promovendo encapsulamento dedados e processos, com ocultamento da informa¸c˜ao e prote¸c˜ao de dados. Em boaparte das linguagens de programa¸c˜ao, a estrutura de dividir m´odulos fonte emdois arquivos, um de interface e um outro de implementa¸c˜ao, discutida na se¸c˜ao2.1.4.4, ´e a estrat´egia adotada para a implementa¸c˜ao de TADs. Com o advento delinguagens de programa¸c˜ao Orientadas a Objetos, as classes surgiram como umanova maneira de se implementar os TADs.
As classes oferecem todos os recursos dos TADs, como encapsulamentode dados e processos, ocultamento da informa¸c˜ao, fun¸c˜oes de acesso, opera¸c˜oesconstrutoras e destrutoras. Al´em de oferecerem todos os mecanismos necess´ariospara a implementa¸c˜ao de um TAD, classes oferecem prote¸c˜ao de dados por meiode modiﬁcadores de acesso, apresentam benef´ıcios em legibilidade, redigibilidade e6 Um Objeto ´e uma instˆancia de uma classe. Pode-se instanciar (construir, criar) m´ultiplosobjetos em mem´oria a partir de uma ´unica classe33conﬁabilidade (Varej˜ao, 2004).
Segundo von Staa (2000), com utiliza¸c˜ao de linguagens de programa¸c˜aoorientadas a objetos e tomando-se algum cuidado ao projetar classes, ´e poss´ıvelque elas se tornem integralmente utiliz´aveis em diferentes programas, viabilizandoo re´uso de quantidades signiﬁcativas de c´odigo. O autor destaca que tal forma dere´uso verbatim7 est´a entre as principais formas de redu¸c˜ao de custos e melhoriana qualidade de software. Esta ´e uma motiva¸c˜ao para uma das contribui¸c˜oesdo presente trabalho: a cria¸c˜ao de um arcabou¸co com os recursos do paradigmade programa¸c˜ao orientada a objetos para um m´odulo de um simulador cient´ıﬁco,com potencial de re´uso em outros programas. No cap´ıtulo 3 ser´a abordada a arefatora¸c˜ao do m´odulo.
As classes tornam ainda especiais as opera¸c˜oes construtoras e destrutoras.
As opera¸c˜oes construtoras, nas classes chamadas de m´etodos construtores,s˜ao executadas quando da instˆancia de um objeto da classe e s˜ao respons´aveisbasicamente por inicializar os campos da classe com valores “neutros”, como, porexemplo, zero no caso de membros de valor num´erico, ou valor NULL para o casode ponteiros. Alternativamente, podem ser atribu´ıdos valores com signiﬁcadode “valor indeﬁnido” mais facilmente detect´aveis para a localiza¸c˜ao de erros deinicializa¸c˜ao, caso os campos venham a ser usados antes de que a eles sejaatribu´ıdo qualquer valor. Os m´etodos destrutores, por sua vez, s˜ao respons´aveis poropera¸c˜oes de ﬁnaliza¸c˜ao realizadas quando o uso das classes n˜ao ´e mais necess´ario.
Dentre tais opera¸c˜oes, a mais comum ´e a desaloca¸c˜ao das regi˜oes de mem´oria dosobjetos que n˜ao ser˜ao mais usados.
Com TADs, a modelagem de v´arias entidades do mundo real com aspectosem comum produz aspectos indesej´aveis que s˜ao resolvidos com o uso classes.
Para representar, por exemplo, as entidades Pessoa, Aluno e Professor com TADsprecisamos de 3 tipos de dados com muitos atributos em comum. Aluno e Professors˜ao, ambos, pessoas. No entanto, como o uso de TADs n˜ao podemos representar as7 Re´uso Verbatim ´e a forma de re´uso na qual n˜ao s˜ao feitas altera¸c˜oes na unidade reutilizada.
34entidades Aluno e Professor aproveitando aquilo que ´e comum `as duas e tamb´em`a entidade Pessoa. Isso cria enorme quantidade de replica¸c˜ao de c´odigo. Com aorienta¸c˜ao a objetos, pode-se criar estruturas de classe baseadas em heran¸ca, umdos conceitos mais fundamenais da orienta¸c˜ao a objetos ao lado do polimorﬁsmo.
2.1.5.1
Heran¸caA heran¸ca ´e um relacionamento entre classes onde uma classe denominadaherdeira, ou classe ﬁlha, especializa, reﬁna ou torna mais particulares aspropriedades de outra classe denominada superclasse, ou classe m˜ae. No exemplocitado anteriormente, as entidades Pessoa, Aluno e Professor, se representadaspor classes, poderiam conﬁgurar uma rela¸c˜ao de heran¸ca. As classes Alunoe Professor s˜ao herdeiras da classe Pessoa e por isso possuem os mesmosatributos e m´etodos da classe Pessoa. Diz-se que a rela¸c˜ao de heran¸ca ´e transitiva,pois uma classe herdeira pode, por sua vez, ser superclasse de outras herdeiras. Porexemplo, professor (que herda de Pessoa) pode ser superclasse das herdeirasProfessorSubstituto e ProfessorTitular.
Membros adicionais podem existir nas classes herdeiras, visto queespecializam as superclasses. No caso citado, tanto Aluno como Professorherdariam, por exemplo, os atributos nome e sobrenome da superclasse Pessoa.
Aluno poderia implementar mais membros como nota1, nota2, os m´etodosaprovar() e reprovar(); Professor, por sua vez, poderia implementar osmembros salario, dataDeAdmissão e o m´etodo calcularSalario().
Qualquer objeto instanciado de uma superclasse n˜ao pode ser reﬁnadopor imposi¸c˜ao de tipos (type casting) para um objeto de classe herdeira. Se
instanciarmos um objeto Pessoa1, da classe Pessoa, este n˜ao pode serespecializado por casting de tipos para um objeto do tipo Aluno, pois nem todosos membros de Aluno s˜ao conhecidos pelo objeto da classe Pessoa. Se criarmos,em vez disso, um objeto Aluno1 da classe Aluno, este poder´a ser promovido aum objeto da classe Pessoa e, inclusive, ser posteriormente reﬁnado novamente35para um Aluno, mas jamais para um Professor.
2.1.5.2
PolimorﬁsmoOutro conceito extremamente importante do paradigma orientado a objetos,diretamente relacionado com o conceito de heran¸ca, ´e o polimorﬁsmo, palavracujas origens gregas remetem `a ideia de ”muitas faces”. O conceito de heran¸capermite que m´etodos de superclasses sejam redeﬁnidos nas classes herdeiras.
Nesse contexto, redeﬁnir signiﬁca escrever novamente tais fun¸c˜oes, com assinaturasidˆenticas, por´em com implementa¸c˜oes internas peculiares, em cada uma das classesﬁlhas. Fun¸c˜oes dessa natureza s˜ao ditas fun¸c˜oes polimorfas, e constituem otipo de polimorﬁsmo mais comum implementado pela maioria das linguagens deprograma¸c˜ao, denominado polimorﬁsmo universal de subclasses.
Imaginemos uma estrutura com uma superclasse Pol´ıgono e duas classesherdeiras, Quadrado e Triangulo, as quais possuem implementa¸c˜oes distintas deum m´etodo calcularArea com assinatura idˆentica. A deﬁni¸c˜ao sobre qualimplementa¸c˜ao ser´a aplicada depende da classe do objeto em quest˜ao e ao qualo m´etodo se aplica. De acordo com von Staa (2000), essa propriedade promovefacilidades para a programa¸c˜ao, visto que o pr´oprio objeto determina como eledeve ser processado, retirando do programador a responsabilidade de determinara forma como os objetos devem ser processados, dependendo de sua classe.
Al´em do caso discutido, o polimorﬁsmo pode aparecer ainda de outrasmaneiras. Caso um m´etodo seja implementado v´arias vezes com assinaturasdiferentes, ocorre o tipo de polimorﬁsmo denominado sobrecarga de m´etodos.
Sr o comportamento dos m´etodos variar de acordo com convers˜oes impl´ıcitas detipos sobre os dados recebidos em seus parˆametros, o polimorﬁsmo ´e conhecidocomo polimorﬁsmo de coer¸c˜ao.
362.2
Computa¸c˜ao Paralela´E fatoqueassimula¸c˜oescomputacionaiscient´ıﬁcasutilizam-sefrequentemente de modelos numericamente intensivos. Visando validar teoriase fazer predi¸c˜oes acerca de seus objetos de estudo, ´e comum que os cientistasrealizem um grande n´umero de simula¸c˜oes com tais modelos, utilizando diferentesconjuntos de parˆametros de entrada. Dessa forma, ´e natural que existamdemandas de desempenho nos modelos computacionais cient´ıﬁcos, de forma queas simula¸c˜oes possam ser realizadas em tempos de execu¸c˜ao compat´ıveis com osinteresses da ciˆencia.
Os maiores e mais desﬁadores problemas da ciˆencia moderna geralmentelidam com combina¸c˜oes de fenˆomenos de diferentes ´areas do conhecimento,englobando uma enorme gama de escalas de tempo e espa¸co. Nas simula¸c˜oescomputacionais cient´ıﬁcas, as escalas maiores de tempo e espa¸co est˜ao relacionadascom a extens˜ao do dom´ınio dos problemas modelados, enquanto as menoresest˜ao relacionadas com a resolu¸c˜ao desejada ou necess´aria nos modelos.
Modelar problemas diminuindo a extens˜ao dos dom´ınios para que sejamequipar´aveis `as escalas dos m´ınimos detalhes, ou dos menores fenˆomenos f´ısicosque se possa descrever,frequentemente ´e algo que determina requisitos demem´oria. Por outro lado, reduzir as janelas de tempo das escalas temporaisaos menores intervalos ´e algo que implicar´a em desaﬁos relacionados ao tempo decomputa¸c˜ao.
Grande parte das discuss˜oes atuais no ˆambito da programa¸c˜ao cient´ıﬁca est˜aofocadas no desempenho escal´avel (Rouson et al., 2011). No in´ıcio desde cap´ıtulo,vimos que a escalabilidade de execu¸c˜ao est´a relacionada com o aproveitamentoeﬁciente do m´aximo dos recursos de hardware dispon´ıveis. Al´em disso, um c´odigoescal´avel, do ponto de vista de sua execu¸c˜ao, deve estar preparado para crescer noquesito desempenho de forma compat´ıvel com um eventual incremento nos recursoscomputacionais oferecidos.
Esses motivos deixam claro o porquˆe de a ciˆencia se importar tanto com37a m´axima utiliza¸c˜ao dos recursos computacionais dispon´ıveis. A evolu¸c˜ao dohardware nas ´ultimas d´ecadas tomou claramente a dire¸c˜ao do desenvolvimentode m´aquinas cada vez mais paralelas (Kirk e Hwu, 2013). A escalabilidade deexecu¸c˜ao dos programas est´a fortemente condicionada `a explora¸c˜ao eﬁciente dem´aquinas paralelas.
2.2.1
Arquiteturas Paralelas´E grande a variedade de arquiteturas de hardware para a computa¸c˜aoparalela. Redes de esta¸c˜oes de trabalho, clusters e esta¸c˜oes de trabalho comm´ultiplos processadores s˜ao alguns dos v´arios ambientes onde se pode explorar acomputa¸c˜ao paralela. No estudo da computa¸c˜ao paralela, a Taxonomia de Flynntem sido frequentemente utilizada ao longo das ´ultimas d´ecadas para classiﬁcar asarquiteturas dos computadores, as quais s˜ao divididas em quatro grupos de acordocom o n´umero ﬂuxos de instru¸c˜oes (instruction streams) e de dados (data streams)que podem ser operados simultaneamente pela m´aquina. Nas se¸c˜oes seguintesexploramos cada um dos grupos: SISD, SIMD, MISD e MIMD.
2.2.1.1
Single Instruction, Single Data (SISD)Em um sistema SISD, como mostrado na ﬁgura 2.1, um ´unico ﬂuxo deinstru¸c˜oes opera em um ´unico ﬂuxo de dados. Essa ´e a arquitetura de um sistemacl´assico de Von Neumman. A m´aquina executa apenas uma instru¸c˜ao por vez epode buscar ou armazenar um dado por vez.
2.2.1.2
Single Instruction, Multiple Data (SIMD)Nos sistemas com arquitetura SIMD, como mostrado na ﬁgura 2.2, um ´unicoﬂuxo de instru¸c˜oes ´e distribu´ıdo para v´arios processadores, cada qual com seuﬂuxo de dados. As mesmas instru¸c˜oes s˜ao, portanto, aplicadas, em paralelo,a conjuntos de dados diferentes. De acordo com Pacheco (2011), um sistemaSIMD ´e caracterizado pela presen¸ca de uma Unidade de Controle (UC) e m´ultiplas38Figura 2.1: A arquitetura SISDUnidades Logico-Aritm´eticas (ULAs). Cada instru¸c˜ao ´e distribu´ıda pela UC paratodas as ULAs que as aplicam a seus dados de entrada de forma s´ıncrona. SistemasSIMD s˜ao ideais para a paraliza¸c˜ao de loops simples que operam em longos arraysde dados. Este tipo de paralelismo obtido dividindo os dados pelos processadores eestes aplicando as mesmas instru¸c˜oes sobre seus subconjuntos dos dados ´e chamadode paralelismo de dados (data parallelism).
No in´ıcio dos anos 1990, uma fabricante de sistemas SIMD (ThinkingMachines) era a maior fabricante de m´aquinas paralelas do planeta. No ﬁnal dosanos 1990, os ´unicos sistemas SIMD produzidos passaram a ser os processadoresvetoriais (vector processors), ainda presentes em arquiteturas modernas de CPUs,sob a forma de unidades especializadas em opera¸c˜oes vetoriais: as chamadasVector Processing Units (VPUs), munidas de registradores e instru¸c˜oesvetoriais, al´em de unidades funcionais vetorizadas para o pipelining.
Mais recentemente as unidades de processamento gr´aﬁco (GPUs)tamb´em fazem uso da computa¸c˜ao SIMD. Segundo Pacheco (2011), aplica¸c˜oesgr´aﬁcas frequentemente utilizam fun¸c˜oes de shader que muitas vezes resultam emum ´unico ﬂuxo de controle aplicado a diferentes elementos e isso faz com que odesempenho de GPUs seja otimizado com a computa¸c˜ao SIMD. Isso ´e obtido com39a inclus˜ao de um grande n´umeros de ULAs em um ´unico core das GPUs.
Figura 2.2: A arquitetura SIMD2.2.1.3
Multiple Instruction, Single Data (MISD)N˜ao existem sistemas de computa¸c˜ao bem conhecidos que se enquadrem nomodelo MISD, o qual ´e citado na taxonomia de Flynn apenas por motivos decompletude.
2.2.1.4
Multiple Instruction, Multiple Data (MIMD)Em um sistema do modelo MIMD, mostrado na ﬁgura 2.3, cada processadortem seu pr´oprio ﬂuxo de instru¸c˜oes e opera sobre seus pr´oprios dados individuais.
40Figura 2.3: A arquitetura MIMDPara Mattson et al. (2004) o modelo MIMD ´e muito geral para ser ´utilno entendimento pr´atico de m´aquinas reais. Essa categoria ´e normalmentereclassiﬁcada de acordo com a organiza¸c˜ao de mem´oria. O modelo podeser decomposto em m´aquinas de mem´oria compartilhada e de mem´oriadistribu´ıda.
2.2.2
Mem´oria compartilhadaEm um sistema de mem´oria compartilhada,todos os processadorescompartilham um ´unico espa¸co de endere¸camento de mem´oria e se comunicamentre si pela escrita e leitura em vari´aveis compartilhadas. Os sistemas de mem´oriacompartilhada se subdividem em sistemas SMP (Symmetric Multiprocessors) esistemas NUMA (Non Uniform Memory Acess).
Nos sistemas SMP, todos os processadores acessam todas as regi˜oes damem´oria de maneira uniforme, ou seja, na mesma velocidade. S˜ao os sistemasmais f´aceis para se programar, pois os programadores n˜ao s˜ao respons´aveis peladistribui¸c˜ao das estruturas de dados entre os processadores. Um n´umero elevadode unidades de processamento aumenta a disputa pelo acesso `a mem´oria. Por essaraz˜ao, sistemas desse tipo costumam possuir um n´umero limitado de processadores,j´a que a largura de banda para o acesso `a mem´oria ´e um fator limitante para o41desempenho.
Nos sistemas NUMA, toda a mem´oria ´e ﬁsicamente acess´ıvel a todos asunidade de processamento, entretanto, alguns blocos de mem´oria podem estarmais diretamente associados a certos processadores do que a outros. Dessa formao acesso n˜ao ´e completamente uniforme em todas as regi˜oes da mem´oria. Isso podereduzir a disputa pelo acesso a mem´oria e diminuir os efeitos de um gargalo dedesempenho devido `a largura de banda da mem´oria. Por´em, os tempos de acessode um dado processador a diferentes regi˜oes de mem´oria podem sofrer varia¸c˜oes,sendo sens´ıveis ao qu˜ao pr´oxima cada regi˜ao est´a do processador.
Para diminuir os efeitos do acesso n˜ao uniforme, cada processador possuiuma mem´oria cache e um protocolo de coerˆencia entre as caches dos v´ariosprocessadores, o que faz com que o modelo receba frequentemente o nome deccNUMA (Cache Coherent Non Uniform Memory Acess). Programar para taissistemas ´e equivalente a programar par sistemas SMP, mas para que se extraia omelhor desempenho ´e necess´ario maior aten¸c˜ao `a localidade dos dados e aos efeitosda cache.
2.2.3
Mem´oria Distribu´ıdaNos sistemas de mem´oria distribu´ıda, cada processador possui seu pr´oprioespa¸co de endere¸camento individual.
Isso implica que a comunica¸c˜ao entre osprocessadores n˜ao se possa fazer por meio de vari´aveis compartilhadas, como nocaso anterior. Nos sistemas com mem´oria distribu´ıda a comunica¸c˜ao se d´a portroca de mensagens, as quais devem ser feitas explicitamente pelo programador.
Al´em disso, os programadores precisam se responsabilizar pela divis˜ao dos dadosentre as mem´orias dos processadores. Apesar de representar uma responsabilidade,isso tamb´em representa uma oportunidade. Em aplica¸c˜oes com estruturas de dadosmuito grandes, incapazes de residir inteiramente na mem´oria de uma m´aquina demem´oria compartilhada, ´e poss´ıvel utilizar ambientes de mem´oria distribu´ıda paraparticion´a-las.
42Dependendo da topologia e das tecnologias empregadas para a interconex˜aoentre os processadores dos sistemas de mem´oria distribu´ıda, a velocidade decomunica¸c˜ao pode variar drasticamente, desde praticamente t˜ao r´apidas quantomem´oria uniﬁcada at´e v´arias ordens de magnitude mais lenta, como no casode clusters de PCs conectados via redes ethernet. Clusters s˜ao sistemas decomputa¸c˜ao de mem´oria distribu´ıda compostos por computadores conectador poralguma infraestrutura de rede. Com a tecnologia de redes em cont´ınuo avan¸co ea comunica¸c˜ao cada vez mais r´apida, os clusters tˆem se tornado cada vez maiscomuns e mais poderosos, sendo a principal representa¸c˜ao pr´atica dessa classe desistemas.
2.2.4
Ambientes de Computa¸c˜ao ParalelaUm ambiente de computa¸c˜ao paralela conﬁgura um conjunto de tecnologias,ferramentas e recursos de linguagens de programa¸c˜ao, necess´arios para odesenvolvimento de aplica¸c˜oes paralelas. O produto ﬁnal provido pelo conjuntode todos os componentes do ambiente de programa¸c˜ao ´e um modelo deprograma¸c˜ao, o qualfornece uma abstra¸c˜ao do hardware sobre a qual osprogramadores atuam.
Nos computadores paralelos, existe uma grande variedade de modelos deprograma¸c˜ao, dependendo das caracter´ısticas particulares de hardware que deﬁnemcomo os processadores s˜ao integrados para formar um sistema ´unico. Os modelosde programa¸c˜ao mais utilizados, por´em, se baseiam em uma das classiﬁca¸c˜oes vistasnas se¸c˜oes anteriores: mem´oria compartilhada, mem´oria distribu´ıda com troca demensagens ou uma combina¸c˜ao de ambas.
Nesta se¸c˜ao faremos uma apresenta¸c˜ao dos dois mais difundidos modelosde programa¸c˜ao paralela existentes: O OpenMP (Open Multi-Processing), paramem´oria compartilhada e o MPI (Message Passing Interface), para mem´oriadistribu´ıda.
432.2.4.1
O modelo OpenMPO OpenMP ´e um conjunto de diretivas e fun¸c˜oes de biblioteca para odesenvolvimento de programas paralelos em ambientes de mem´oria compartilhada.
´E combinado com C, C++ ou Fortran para a cria¸c˜ao de uma linguagem multithread,ou seja, as unidades de execu¸c˜ao de programas em OpenMP s˜ao as threads, as quaiscompartilham um ´unico espa¸co de endere¸camento. Dessa forma, a comunica¸c˜ao sed´a atrav´es da manipula¸c˜ao de vari´aveis compartilhadas.
A deﬁni¸c˜ao formal do OpenMP cont´em duas especiﬁca¸c˜oes: uma paraFortran e outra para C e C++, embora sejam ambas bastante similares. Baseadosno modelo fork/join, os programas em OpenMP come¸cam sua execu¸c˜ao com uma´unica thread (master) e, em pontos espec´ıﬁcos do programa, criam-se threadsadicionais (fork ). As m´ultiplas threadsexecutam em paralelo em trechos dec´odigo denominados regi˜oes paralelas. Ao ﬁm das regi˜oes paralelas, cada threadaguarda que todas as demais tenham conclu´ıdo a execu¸c˜ao do trecho e voltam ase unir (join) em uma ´unica thread master.
O modelo OpenMP foi criado com o objetivo de ser simples para osdesenvolvedores de aplica¸c˜oes. Apesar de o melhor desempenho ser sempredesej´avel, ´e decis˜ao frequente abrir-se m˜ao do desempenho m´aximo, caso isso venhaa tornar dif´ıcil e custoso o desenvolvimento e a manuten¸c˜ao das aplica¸c˜oes. Porisso, o OpenMP foi desenvolvido com dois princ´ıpios b´asicos: a equivalˆenciasequencial e o paralelismo incremental.
Equivalˆencia sequencial signiﬁca que o programa paralelo deve gerar osmesmos resultados utilizando-se uma ou mais threads, ou seja, o resultado da vers˜aoparalela deve ser igual ao resultado da execu¸c˜ao serial. Segundo Mattson et al.
(2004), um programa com equivalˆencia sequencial ´e mais f´acil de manter e muitomais f´acil de desenvolver e compreender.
O paralelismo incremental ´e um estilo de programa¸c˜ao paralela ondeo programa evolui gradualmente de sua vers˜ao serial para a vers˜ao paralela.
O programador inicia seus trabalhos com uma vers˜ao serial da aplica¸c˜ao em44funcionamento. Em seguida,identiﬁca regi˜oes no c´odigo onde vale a penaexplorar o paralelismo (usualmente chamadas de hotspots). Assim, o paralelismo´e adicionado de forma incremental em cada uma dessas regi˜oes. Com essaabordagem, a cada fase do processo tem-se uma vers˜ao completamente funcional,que pode ser testada, aumentando a chance de sucesso.
Infelizmente, nem sempre ser´a poss´ıvel que o paralelismo incrementalconduza `a equivalˆencia sequencial. Muitas vezes um algoritmo paralelo precisarefatorar completamente o seu an´alogo serial.
Existem tamb´em algoritmosparalelos que simplesmente n˜ao funcionam com uma ´unica thread, de maneira serial.
Apesar das diﬁculdades, os dois conceitos, equivalˆencia sequencial e paralelismoincremental, guiaram o desenvolvimento do modelo OpenMP e s˜ao consideradosboas pr´aticas de programa¸c˜ao.
2.2.4.2
O modelo MPIO MPI (Message Passing Interface), criado no in´ıcio da d´ecada de 1990,´e o modelo de programa¸c˜ao padr˜ao para sistemas de computa¸c˜ao de mem´oriadistribu´ıda com troca de mensagens. A unidade de execu¸c˜ao do MPI s˜ao processose, naturalmente, cada um possui seu espa¸co de endere¸camento pr´oprio. O conceitocentral do MPI ´e a troca de mensagens. Cada processo precisa agrupar informa¸c˜oesem uma mensagem e envi´a-la a outros processos que devem estar preparados pararecebˆe-las. A comunica¸c˜ao ´e responsabilidade do programador.
O MPI ´e distribu´ıdo na forma de uma biblioteca, originalmente com vers˜oespara C e Fortran, apesar de outras linguagens tamb´em terem sido contempladas.
Existem muitas implementa¸c˜oes do MPI com uso difundido, por´em as duas maiscomuns s˜ao LAM/MPI e MPICH, ambas disponibilizadas gratuitamente pelosmantenedores. Mais do que um simples mecanismo para a troca de mensagens, oMPI oferece rotinas para sincroniza¸c˜ao de processos, distribui¸c˜ao dos dados para osdiferentes processos e muito mais funcionalidades que suportam o desenvolvimentode programas paralelos.
45A ideia b´asica de troca de mensagens levanta questionamentos sobre osdetalhes de como isso ´e feito na pr´atica. O que os processos podem fazer enquantoenviam mensagens, como as mensagens podem ser identiﬁcadas de forma que cadaenvio seja pareado com um respectivo recebimento s˜ao questionamentos comuns.
O MPI deﬁne solu¸c˜oes para essas e outras quest˜oes com os conceitos de gruposde processos e contextos de comunica¸c˜ao.
Um grupo de processos engloba todos os processos envolvidos em umacomputa¸c˜ao. No in´ıcio da execu¸c˜ao de um programa, todos os processos est˜aoagrupados em um ´unico grupo. Posteriormente, o programador pode subdividi-los, agrupando-os em grupos menores envolvidos em uma determinada atividade epode controlar como os grupos interagem.
J´a os contextos de comunica¸c˜ao fornecem um meio para que sejamagrupados conjuntos de comunica¸c˜oes relacionadas.
Em qualquer troca demensagens, ´e necess´ario que as mesmas sejam identiﬁcadas de forma que se saibaquem deve recebˆe-las e quem as enviou. Em MPI, as mensagens s˜ao identiﬁcadascom as IDs dos processos que as enviam e daqueles que devem recebˆe-las. Apesarde intuitivo, o conceito de identiﬁcar mensagens com IDs de processos pode n˜aofuncionar em certas situa¸c˜oes, especialmente em aplica¸c˜oes complexas que incluembibliotecas reutilizadas de outros programas.
Se as bibliotecas incluem chamadas ao MPI, existe o risco de que aaplica¸c˜ao cliente e as bibliotecas compartilhem IDs de processos de origeme destino acidentalmente. Ainda mais porque o programador da aplica¸c˜aonormalmente desconhece os detalhes das implementa¸c˜oes das bibliotecas utilizadas.
Os contextos de comunica¸c˜ao aparecem como solu¸c˜ao para esse problema. Cadaenvio e cada recebimento pertence a um ´unico contexto de comunica¸c˜ao. A cria¸c˜aode v´arios contextos pode evitar os problemas citados.
Os contextos de comunica¸c˜ao e os grupos de processos s˜ao encapsulados peloMPI em uma ´unica entidade denominada comunicador (communicator ). Apesarde n˜ao ser necess´ario lidar diretamente com comunicadores em todos os programas,46a maioria das fun¸c˜oes do MPI faz referˆencia a um comunicador e ´e essencial paraprogramadores interessados em desenvolver componentes de software reutiliz´aveisque manipulem comunicadores.
47Cap´ıtulo 3Refatora¸c˜ao de um m´odulo do simuladorcom inclus˜ao do paradigma orientado aobjetosNeste cap´ıtulo, s˜ao abordadas evolu¸c˜oes no c´odigo-fonte de um simuladorda ciˆencia de escoamentos em reservat´orios de g´as em folhelhos, desenvolvido eutilizado por pesquisadores e alunos do LNCC.
Com foco na organiza¸c˜ao est´atica e estrutural do c´odigo-fonte, o cap´ıtuloapresenta e analisa, primeiramente, a evolu¸c˜ao anterior a este trabalho pela qualo simulador passou desde sua vers˜ao inicial. Em seguida, o cap´ıtulo apresenta edescreve com maiores detalhes a contribui¸c˜ao espec´ıﬁca do presente trabalho nessequesito, a qual consiste em uma reestrutura¸c˜ao de um dos m´odulos do simuladorcom incorpora¸c˜ao do paradigma de orienta¸c˜ao a objetos.
Por ser um produto sem um projeto inicial de longo prazo e por terprop´osito cient´ıﬁco, o simulador tem passado por um processo evolutivo continuadoque atende a demandas pontuais de seus usu´arios, especialistas do dom´ınio deaplica¸c˜ao que, frequentemente, desejam incorporar novas funcionalidades e realizarexperimentos espec´ıﬁcos, dando origem a diferentes vers˜oes que passam a levar emconta diferentes fenˆomenos f´ısicos.
`A medida em que tais demandas espec´ıﬁcas foram atendidas, aspectosmodulares acabaram sendo gradativamente incorporadas ao c´odigo do simulador,48o que deixa clara a tendˆencia de que os programas cient´ıﬁcos em geral evoluamno sentido tornarem-se produtos cada vez mais ﬂex´ıveis, adapt´aveis e comcomponentes reaproveit´aveis. O m´odulo reestruturado neste trabalho corresponde`a por¸c˜ao do c´odigo-fonte do simulador respons´avel pela montagem e solu¸c˜ao dossistemas de equa¸c˜oes lineares do m´etodo de elementos ﬁnitos e possui componentescom alto potencial de re´uso neste ou em outros simuladores cient´ıﬁcos similares.
3.1
Evolu¸c˜ao do simulador de escoamentos em meios porososComo visto no cap´ıtulo 1,o simulador utilizado nestetrabalho,bem como outros desenvolvidos pelo no LNCC,tomam como ponto departida a implementa¸c˜ao do m´etodo deelementos ﬁnitos proposta emHughes (1987):o programa DLEARN, que pode ser encontrado no link :http://www.zsoil.com/dlearn/.
Escrito originalmente no padr˜ao Fortran 77, durante a d´ecada de 1980,quando tamb´em foram desenvolvidos outros programas semelhantes, como oADINA software (Bathe, 1982), o programa de elementos ﬁnitos DLEARN, deHughes (1987), se destacou em sua ´epoca, sendo um bom programa para o per´ıodono qual foi criado. O programa precisou lidar ou contornar limita¸c˜oes/restri¸c˜oesimpostas pelo pr´oprio padr˜ao da linguagem, como, por exemplo, a limita¸c˜ao don´umero de caracteres nos nomes de vari´aveis e subprogramas, que diﬁcultava alegibilidade e o entendimento humano; ou a ausˆencia de aloca¸c˜ao dinˆamica demem´oria, que, por sua vez, tornava dif´ıcil a tarefa de adequar o programa adiferentes tamanhos de problemas.
Devido ao tamanho vari´avel de diferentes estruturas de dados em diferentesproblemas, ´e algo ineﬁciente deﬁnir valores ﬁxos para estes tamanhos, o que podeocasionar erros ou, sen˜ao, desperd´ıcio de mem´oria. O programa original de Hughes(1987) contornava esse problema prevendo uma esp´ecie de emula¸c˜ao da aloca¸c˜aodinˆamica com o uso de um grande array est´atico, dentro do qual s˜ao virtualmente“alocados” m´ultiplos vetores menores em tempo de execu¸c˜ao com o aux´ılio de49vari´aveis que indicam o ponto de in´ıcio de cada um deles.
A ﬁgura 3.1 ilustra tal estrat´egia. Um grande vetor est´atico A, presente naimplementa¸c˜ao original de Hughes (1987), simula um espa¸co de aloca¸c˜ao dinˆamicaem mem´oria, no qual residem v´arios vetores menores, dentre eles alhs, brhs,lm, id, idiag, os quais podem ser localizados em seu interior por meio devari´aveis inteiras (mpalhs, mpbrhs, mplm, mpid, mpidiag) com os ´ındices doselementos de A nos quais iniciavam cada uma das ´areas reservadas aos vetorescorrespondentes.
Figura 3.1: Vetor est´atico ´unico comportando m´ultiplos vetores menores dediferentes tamanhos deﬁnidos em tempo de execu¸c˜ao.
Do ponto de vista de sua organiza¸c˜ao estrutural, embora seja concentradaem um ´unico arquivo de fonte, tal implementa¸c˜ao base j´a possui certo n´ıvel demodulariza¸c˜ao, gra¸cas `a sua organiza¸c˜ao em uma estrutura de subprogramas.
Hughes (1987) apresenta a organiza¸c˜ao do programa fornecendo um ´ındice compouco mais de uma centena de subprogramas, os quais s˜ao, em sua maioria, dotipo procedimento (SUBROUTINE) e, em sua minoria, do tipo fun¸c˜ao (FUNCTION).
Sabemos que, dentre os subprogramas, a forma padr˜ao para a troca deinforma¸c˜oes ´e a passagem de uma lista de parˆametros. Listas de parˆametrosfrequentemente se tornam grandes quando programas modulares crescem. Al´emdesta forma para a troca de informa¸c˜oes, o programa em quest˜ao utiliza outroconceito fornecido pela linguagem Fortran para esse mesmo ﬁm: Os blocosCOMMON, que s˜ao declara¸c˜oes de regi˜oes de mem´oria compartilhadas, acess´ıveisa qualquer unidade do programa que contenha o bloco COMMON de mesmo nome.
Eles representam uma forma de troca de informa¸c˜oes por meio da partilha de50dados.
Os blocos COMMON permitem que supbrogramas partilhem os dados por meiodo compartilhamento de uma regi˜ao de mem´oria comum. N˜ao ´e necess´ario quetodos os blocos COMMON de mesmo nome possuam o mesmo n´umero de vari´aveisou nomes iguais para as mesmas. Com base na ordena¸c˜ao e nos tipos dasvari´aveis o compilador estabelece as correspondˆencias entre as m´ultiplas vari´aveisque representam formas alternativas de referenciar uma mesma regi˜ao de mem´oria.
Na implementa¸c˜ao de Hughes (1987), os blocos COMMON s˜ao usados paraa implementa¸c˜ao da estrat´egia da simula¸c˜ao da aloca¸c˜ao dinˆamica mostradaanteriormente na ﬁgura 3.1. O grande vetor est´atico a e os os apontadores de in´ıciodos subvetores s˜ao compartilhados entre as diversas unidades do programa por meiodos blocos COMMON. A listagem 3.1 mostra o trecho de c´odigo correspondente naimplementa¸c˜ao original. Na linha 6 aparece o vetor A em um bloco COMMON semnome (Blank COMMON) e na linha 4 aparece o COMMON /Spoint/, que armazenaem posi¸c˜oes cont´ıguas de mem´oria as vari´aveis com os ´ındices de in´ıcio de cadasubvetor.
Listagem 3.1: Rotina driver, da implementa¸c˜ao original de Hughes (1987) e ouso de um bloco COMMON importante.
1 SUBROUTINE driver(ntstep,neq,nalhs)!c.... solution driver program2(...)
3COMMON /spoint/ mpd,mpx,mpid,mpf,mpg,mpg1,mpdiag,mpngrp,mpalhs,4mpbrhsinclude ’memory_size.inc’5COMMON A(MAX_SIZE)6(...)
78 END SUBROUTINE driverA partir do padr˜ao Fortran 90, os blocos COMMON deixaram de ser a principalforma para o compartilhamento de dados entre unidades de programa¸c˜ao, dando51lugar a uma forma alternativa, chamada MODULE, sobre a qual voltaremos a falarmais adiante.
Tendo como ponto de partida a referida implementa¸c˜ao do m´etodo deelementos ﬁnitos, muitas aplica¸c˜oes cient´ıﬁcas foram desenvolvidas no LNCC. No
ﬁnal da d´ecada de 1980, o programa Axis (Toledo et al., 1988), da ´area de an´alise detens˜oes em s´olidos sob rota¸c˜ao, desenvolvido no LNCC em projeto de colabora¸c˜aocom o COPESP, foi a primeira de tais aplica¸c˜oes a utilizar a separa¸c˜ao em arquivoscom compila¸c˜ao separada. O compartilhamento de dados com os blocos COMMONcontinuava a ser explorado, mesmo com m´ultiplos arquivos.
No grupo de pesquisas em reservat´orios petrol´ıferos, seguiu-se o mesmocaminho e o simuladores do grupo passaram a ser divididos em m´ultiplos arquivos,principalmente devido ao alto custo de compila¸c˜ao. O simulador deste trabalhotamb´em est´a dividido dessa forma e, mais adiante, ser˜ao dados mais detalhes sobresua organiza¸c˜ao. No ﬁnal da d´ecada de 2000, este simulador passou por um avan¸cosigniﬁcativo: a transi¸c˜ao para o padr˜ao Fortran 90, incluindo a aloca¸c˜ao dinˆamicade suas estruturas de dados em mem´oria.
Com as estruturas de dados dinˆamicas, surge um problema: a forma decompartilhamento de dados com blocos COMMON, usada at´e ent˜ao, n˜ao permite ocompartilhamento de vari´aveis alocadas dinamicamente.
Conforme j´a adiantado, a partir do Fortran 90, existe, alternativamenteao COMMON, um outro elemento de programa¸c˜ao, denominado MODULE. Os
MODULES s˜ao unidades independentemente compil´aveis que, al´em de promover amodulariza¸c˜ao e o encapsulamento de dados e processos, possuem importante papelno compartilhamento de dados, permitindo que sejam tamb´em compartilhadas asvari´aveis alocadas dinamicamente.
Em Fortran, um MODULE ´e uma entidade que cont´em uma s´erie dedeﬁni¸c˜oes e valores iniciais de dados e representa uma forma alternativa para ocompartilhamento de dados entre diferente unidades de programa¸c˜ao (Chapman,2004). Da mesma forma que ocorre nos blocos COMMON, as diferentes unidades52utilizam os mesmos dados e valores presentes em uma ´unica regi˜ao de mem´oria.
A motiva¸c˜ao para a inclus˜ao dos MODULES no simulador, entretanto,foi apossibilidade do compartilhamento das novas vari´aveis alocadas dinamicamente,o que era imposs´ıvel com os blocos COMMON.
As listagens 3.2 e 3.3 mostram trechos de dois m´odulos do simulador,mFratura e mBloco, os quais, como veremos mais adiante, s˜ao respons´aveis pelaformula¸c˜ao variacional relacionada aos problemas f´ısicos modelados no simulador.
Nos trechos, pode-se notar a existˆencia de vari´aveis para aloca¸c˜ao dinˆamica, coma anota¸c˜ao ALLOCATABLE, as quais s˜ao compartilhadas com outras unidades deprograma¸c˜ao por fazerem parte de um MODULE.
Listagem 3.2: Uso de MODULES para o Compartilhamento de vari´aveis alocadasdinamicamente: M´odulo mFratura.
1 MODULE mFratura(...)
2implicit none3(...)
4REAL*8, ALLOCATABLE :: solucao_F(:,:), solucaoTmpAnt_F(:,:),5solucaoNaoLinearAnt_F(:,:)REAL*8, ALLOCATABLE :: f_F(:,:), flux_F(:,:)6(...)
78 END MODULE mFraturaListagem 3.3: Uso de MODULES para o Compartilhamento de vari´aveis alocadasdinamicamente: m´odulo mBloco.
1 MODULE mBLoco(...)
2implicit none3(...)
4REAL*8, ALLOCATABLE :: solucao_B(:,:), solucaoTmpAnt_B(:,:),5solucaoNaoLinearAnt_B(:,:)REAL*8, ALLOCATABLE :: mSolucao_B(:,:,:), mSolucaoTmpAnt_B(:,:,:)653REAL*8, ALLOCATABLE :: f_B(:,:), flux_B(:,:)7(...)
89 END MODULE mBLocoNas unidades clientes, que usam os dados e processos encapsulados pelom´odulo, deve existir uma declara¸c˜ao USE seguida do nome do m´odulo Fortran.
Dessa forma, elas podem acessar os mesmos dados e valores presentes nom´odulo. Por isso, diz-se que os m´odulos em Fortran constituem uma forma decompartilhamento de dados alternativa `a lista de parˆametros de subprogramas.
A listagem 3.4 mostra uma subrotina processador2Escalas, doprograma principal, que faz uso de certas vari´aveis presentes nos m´odulosmFratura e mBloco mostrados anteriormente. Dentre as vari´aveis, est˜ao algumasalocadas dinamicamente como mostrado nas listagens 3.2 e 3.3.
Listagem 3.4: Uso de MODULES para o Compartilhamento de vari´aveis alocadasdinamicamente no simulador: rotina processador2Escalas (cliente).
1 SUBROUTINE processador2Escalas()USE mFratura, only : NITER_F, NDOF_F, NLVECT_F, flux_F2USE mFratura, only : DTEMPO_F, solucao_F, f_F, SUM_NUMITER_F;3(...)
4USE mBloco,only : mSolucao_B, mSolucaoTmpAnt_B, NDOF_B,5DTEMPO_B, NITER_B, SUM_NUMITER_B(...)
67 END SUBROUTINE processador2EscalasAl´em deencapsular dadose promoverseu compartilhamento,asunidades MODULE podem ainda conter procedimentos e fun¸c˜oes integralmenteimplementadas em seu interior. Esses procedimentos contidos em m´odulos s˜aochamados de Module Procedures em Fortran. Vimos na se¸c˜ao 2.1.4.4 a pr´aticacomum de dividir-se os m´odulos-fonte em m´odulo de interface e de implementa¸c˜ao.
Em Fortran, com o uso da unidade MODULE, n˜ao ´e necess´ario que se crieseparadamente os m´odulos de deﬁni¸c˜ao e implementa¸c˜ao. O MODULE engloba54simultaneamente os conceitos de m´odulo de implementa¸c˜ao e de deﬁni¸c˜ao.
Os module procedures se diferenciam dos procedimentos e fun¸c˜oes escritosfora de um MODULE pelo fato de que os primeiros tˆem sua interface sempredispon´ıvel para seus clientes. Quando sub-rotinas s˜ao escritas dentro de umMODULE e outra unidade de compila¸c˜ao faz uso desse MODULE com a declara¸c˜aoUSE, automaticamente a interface de tais sub-rotinas torna-se dispon´ıvel para asunidades clientes.
Em Chapman (2004) evidencia-se a diferen¸ca entre procedimentos forade um MODULE e os module procedures no que diz respeito `a classiﬁca¸c˜aode suas interfaces. Um module procedure, acessado pela declara¸c˜ao USE, ´edito possuir interface expl´ıcita, uma vez que todos os detalhes sobre seusparˆametros formais s˜ao explicitamente conhecidos pelo compilador Fortran. Poroutro lado, procedimentos fora de um MODULE possuem interface impl´ıcita,dado que o compilador Fortran n˜ao possui informa¸c˜oes sobre esses procedimentosquando est´a compilando qualquer uma das suas unidades clientes.
Nessemomento, o compilador simplesmente assume que o programador est´a utilizando osprocedimentos da maneira correta, quanto ao n´umero e aos tipos dos argumentospassados (Chapman, 2004).
Outra vantagem oferecida pelos MODULES est´a relacionada a uma exigˆenciada pr´opria linguagem: os procedimentos que possuem parˆametros do tipo ponteiro(POINTER) ou arrays alocados dinamicamente (ALLOCATABLE) precisam,obrigatoriamente, ter sua interface expl´ıcita e, portanto, vis´ıvel a seus clientes.
Sendo assim, os MODULES facilitam essa tarefa, visto que, por padr˜ao, explicitama interface de todos os seus procedimentos internos.
A listagem 3.5 mostra trechos do m´odulo mFratura, onde pode-se vera declara¸c˜ao da vari´avel solucao_F e sua aloca¸c˜ao dinˆamica em mem´oria nalinha 5. Pode-se ver ainda a rotina printsol_F. A vari´avel solucao_F ´eposteriormente utilizada como argumento na chamada desta subrotina, comoveremos mais adiante.
55Listagem 3.5: M´odulo contendo subrotina com parˆametro alocado dinamicamente.
1 MODULE mFratura(...)
2REAL*8, ALLOCATABLE :: solucao_F(:,:)3(...)
4ALLOCATE(solucao_F (ndof_F, numnp_F));5(...)
6SUBROUTINE printsol_F(solucao,X,NUMNP,TEMPO)7!Imprime a solução na fratura8(...)
9END SUBROUTINE printsol_F1011 END MODULE mFraturaA listagem 3.6 mostra a rotina processador2Escalas, pertencente aoprograma principal. A rotina faz uso da vari´avel solucao_F e a utiliza comoprimeiro argumento na chamada da rotina printsol_F. Isso s´o ´e poss´ıvel pois,como visto na listagem 3.5, printsol_F ´e um module procedure, j´a que faz partedo MODULE mFratura, e, como tal, tem sua interface vis´ıvel ao seu cliente.
Listagem 3.6: Chamada a uma subrotina com parametro alocado dinamicamente.
1 SUBROUTINE processador2Escalas()(...)
2use mFratura, only : solucao_F3use mFratura, only: printsol_F4(...)
5CALL printsol_F(solucao_F, x_F ,NUMNP_F, TEMPO)6(...)
78 END SUBROUTINE563.2
Organiza¸c˜ao do simulador em arquivos para compila¸c˜aoseparadaComo j´a adiantado, a vers˜ao do simulador tomada como base neste trabalhopossui modulariza¸c˜ao em arquivos para compila¸c˜ao separada. Com algumasimpliﬁca¸c˜ao, podemos enxergar tais arquivos organizados em uma estrutura de3 n´ıveis que deﬁnem diferentes potenciais de re´uso, como mostrado na ﬁgura 3.2.
Figura 3.2: Organiza¸c˜ao em 3 n´ıveis dos m´ultiplos arquivos de fonteExce¸c˜ao ´unica feita ao arquivo-fonte que cont´em a rotina principal(driver2Escalas.F90), cada arquivo compreende uma unidade MODULE doFortran. Tomamos a liberdade de nos referir a “arquivos” e “m´odulos” de formaindistinta, embora no caso do arquivo/m´odulo principal n˜ao exista de fato umaunidade MODULE.
No primeiro n´ıvel mostrado na ﬁgura 3.2, com baixo ou nenhum n´ıvel dere´uso, est´a o m´odulo principal, o qual desempenha apenas papel de cliente dosdemais m´odulos e descreve o ﬂuxo b´asico de execu¸c˜ao do simulador. As rotinas57deste m´odulo s˜ao usadas apenas em seu interior. O re´uso de c´odigo deste m´odulopode dar-se apenas na forma de adapta¸c˜ao, visto que outras vers˜oes do simuladorde reservat´orios podem ser desenvolvidas adaptando-se este m´odulo. Entretanto,devido `a sua natureza enquanto um m´odulo principal que guia a execu¸c˜ao daaplica¸c˜ao, sua reutiliza¸c˜ao ou de seus componentes internos na forma de re´usoverbatim ´e inexistente.
No segundo n´ıvel, est˜ao os m´odulos que desempenham papel de provedoresde funcionalidades, mas ao mesmo tempo s˜ao clientes de outros m´odulos. Nessacategoria, enquadram-se os m´odulos referentes aos problemas f´ısicos do simulador(fratura.F90 e bloco.F90). Tais m´odulos e seus componentes internos s˜aoreutilizados com alguma frequˆencia dentro do simulador.
No terceiro n´ıvel, encontram-se os m´odulos de base, provedores defuncionalidades com alto n´ıvel de re´uso e n˜ao relacionadas ao dom´ınio da aplica¸c˜ao.
Isso signiﬁca que tais m´odulos tˆem grande potencial de re´uso verbatim, n˜aosomente dentro do simulador, mas tamb´em em outras aplica¸c˜oes baseadas namesma implementa¸c˜ao do m´etodo de elementos ﬁnitos proposta em Hughes (1987),caso de v´arios outros simuladores cient´ıﬁcos desenvolvidos no LNCC.
58Figura 3.3: A organiza¸c˜ao do simulador em arquivos-fonteA ﬁgura 3.3 mostra os arquivos-fonte divididos nos 3 n´ıveis descritosanteriormente.
No n´ıvel 1,est´a o m´odulo do programa principal,(driver2escalas.F90). Nele est´a deﬁnido o ﬂuxo de execu¸c˜ao do programacomposto por:(i) leitura de dados de entrada, (ii) processamento e (iii) p´os-processamento, onde s˜ao apresentados os resultados. Para tanto, este m´oduloutiliza funcionalidades providas pelos outros dois n´ıveis.
No n´ıvel 2, os m´odulos s˜ao fratura.F90 e bloco.F90, respons´aveis pelaformula¸c˜ao variacional e sua implementa¸c˜ao num´erica para os problemas f´ısicos deescoamento na fratura hidr´aulica e no bloco da rocha matriz, respectivamente.
No n´ıvel 3, os m´odulos s˜ao: leituraEscrita.F90, respons´avel pelaleitura dos arquivos de entrada com informa¸c˜oes de malha e coordenadas, al´em deescrita dos resultados; malha.F90, repons´avel pela gera¸c˜ao de coordenadas nodaise conectividades e busca de vizinhos; funcoesDeForma, que inclui fun¸c˜oes deinterpola¸c˜ao lagrangeanas e informa¸c˜oes para integra¸c˜ao num´erica e, ﬁnalmente, o59m´odulo algMatricial.F90, respons´avel pela constru¸c˜ao e solu¸c˜ao dos sistemasde equa¸c˜oes lineares do m´etodo de elementos ﬁnitos, incluindo a montagem dasestruturas de dados e a implementa¸c˜ao de solver interno.
3.3
Orienta¸c˜ao a Objetos no M´odulo dos Sistemas de Equa¸c˜oesA contribui¸c˜ao deste trabalho no c´odigo do simulador ´e concentrada nom´odulo algMatricial.F90 e consiste em uma reformula¸c˜ao deste m´odulo,que passa a dar lugar a outros menores, incluindo o paradigma de orienta¸c˜ao aobjetos e alguns de seus conceitos como heran¸ca e polimorﬁsmo. Considerandoque o m´odulo em quest˜ao est´a no terceiro n´ıvel mostrado na ﬁgura 3.2 e possuialto potencial de re´uso, percebe-se que os benef´ıcios decorrentes da reestrutura¸c˜aopodem se estender a outras aplica¸c˜oes semelhantes dentro do LNCC.
Com essa reestrutura¸c˜ao, objetiva-se conferir ao simulador caracter´ısticasmais modulares, contribuindo para um melhor entendimento humano e capacidadede evolu¸c˜ao. Conforme visto no cap´ıtulo 2, c´odigos que implementam conceitosde modularidade e orienta¸c˜ao a objetos beneﬁciam-se de abstra¸c˜oes por meiodo encapsulamento de dados e opera¸c˜oes, ganhando em usabilidade. Entidadesencapsuladas encorajam e facilitam o uso de aplica¸c˜oes com c´odigo-fonte extenso.
3.3.1
Identiﬁca¸c˜ao das Entidades de InteresseO m´odulo refatorado compreende dados e opera¸c˜oes relativos `a constru¸c˜ao e`a solu¸c˜ao dos sistemas de equa¸c˜oes e tamb´em `as estruturas de dados capazesde tratar a esparsidade das matrizes relacionadas a tais sistemas. O m´odulo incluioriginalmente apenas uma op¸c˜ao de solver interno implementando elimina¸c˜ao deGauss.
Muitas aplica¸c˜oes cient´ıﬁcas fazem uso de solvers de bibliotecas de ´algebralinear, dentre as quais podemos citar para ﬁns de exemplo: LAPACK, PETSC,umfPACK ou Intel MKL. Alguns simuladores cient´ıﬁcos num´ericos desenvolvidosno LNCC, em determinado momento de sua evolu¸c˜ao, por for¸ca de iniciativas60individuais e de demandas espec´ıﬁcas, passaram a utilizar solvers externos comoo Pardiso (Intel MKL) ou HYPRE (Los Alamos).
Tais iniciativas demandaram que o m´odulo algMatricial.F90 fosseconsideravelmente modiﬁcado, passando a englobar n˜ao apenas novas op¸c˜oes desolvers, mas tamb´em diferentes estruturas de dados adequando-se aos diferentessolvers. Al´em de trabalhosos, processos de adapta¸c˜ao desse tipo frequentementeresultam em altera¸c˜oes feitas de maneira esparsa no c´odigo-fonte, o que impactanegativamente sua usabilidade e evolu¸c˜ao.
A reestrutura¸c˜ao feita neste trabalho funciona como uma camada desoftware com orienta¸c˜ao a objetos, que substitui o m´odulo citado e encapsula emdiferentes classes os dados e opera¸c˜oes relativos aos sistemas de equa¸c˜oes, suasestruturas de dados e solvers. Os novos m´odulos com classes permitem maiororganiza¸c˜ao do c´odigo e facilitam a troca e a inclus˜ao de novos solvers e estruturasde dados para sistemas de equa¸c˜oes neste ou em outros simuladores baseados namesma implementa¸c˜ao original.
O m´odulo algMatricial.F90, cuja implementa¸c˜ao original simpliﬁcada´e mostrada na listagem 3.7, re´une vari´aveis e subrotinas cuja an´alise cuidadosapermite a identiﬁca¸c˜ao de grupos de dados e opera¸c˜oes com certo n´ıvelde similaridade e que podem ser melhor distribu´ıdos em outras unidadesencapsuladoras para melhor modulariza¸c˜ao. O paradigma de orienta¸c˜ao a objetospermitir´a a realiza¸c˜ao desta tarefa com naturalidade e trar´a benef´ıcios n˜ao somente`a organiza¸c˜ao do c´odigo-fonte e `a sua evolu¸c˜ao futura, mas tamb´em facilitar´a aimplementa¸c˜ao de uma estrat´egia de paraleliza¸c˜ao para o c´odigo do simuladorcomo ser´a visto no cap´ıtulo 4.
Listagem 3.7: O m´odulo mAlgmatricial.
1 MODULE mAlgmatricialinteger:: neq_F, nalhs_F, ned_F2integer:: neq_B, nalhs_B, ned_B3real*8,allocatable :: alhs_F(:), brhs_F(:)461allocatable :: alhs_B(:), brhs_B(:)real*8,integer, allocatable :: id_F(:,:), idiag_F(:), lm_F(:,:,:)56integer, allocatable :: id_B(:,:), idiag_B(:), lm_B(:,:,:)7!Subrotinas8public :: back, factor9public :: diag, load, addnsl, addlhs, addrhs10public :: btod, kdbc, ftod, colht11(...)
1213 END MODULE mAlgmatricialAlgumas vari´aveis e rotinas mostradas listagem 3.7 est˜ao relacionadas com osistema propriamente dito e outras com as estruturas de dados utilizadas. Assim, aabordagem adotada neste trabalho estabelece a existˆencia de uma estrutura de duasclasses base que representam as entidades de interesse: Sistemas de Equa¸c˜oese suas Estruturas de Dados. Solvers podem ser vistos como conjuntos deopera¸c˜oes que atuam sobre os dados de um sistema. Um solver ser´a, portanto,entendido como um procedimento que faz parte de todo Sistema de Equa¸c˜oes ecuja fun¸c˜ao ´e resolvˆe-lo.
O trabalho inclui o provimento de duas op¸c˜oes de solver, sendo um delesinterno, implementando a elimina¸c˜ao de Gauss j´a presente no m´odulo original,e outro externo (Intel MKL Pardiso), ambos encapsulados pelo arcabou¸co daOrienta¸c˜ao a Objetos. Os tipos de solvers deﬁnem tipos de sistemas de equa¸c˜oes,de forma que temos sistemas do tipo Gauss e do tipo Pardiso, uma vez que ossistemas precisam incluir rotinas e vari´aveis espec´ıﬁcas para lidar com os tiposespec´ıﬁcos de solver.
Cada um dos solvers requer um tipo de estrutura de dados para tratar aesparsidade das matrizes de forma espec´ıﬁca. Tais estruturas de dados s˜ao do tipoSkyline para os sistemas do tipo Gauss, por´em do tipo CRS para sistemas dotipo Pardiso. A ﬁgura 3.4 mostra um diagrama UML simpliﬁcado da estrutura declasses adotada, onde se observa o conceito de heran¸ca tanto nos tipos de sistemasde equa¸c˜oes como nos tipos de estruturas de dados.
62Figura 3.4: A estrutura b´asica de classes: Sistemas e Estruturas de DadosSistemas do tipo Gauss e do tipo Pardiso possuem semelhan¸cas e diferen¸cas.
Os pontos em comum est˜ao encapsulados na classe m˜ae SistemaEquacoes.
Por isso as classes SistemaGauss e SistemaPardiso s˜ao ligadas `a primeirapor uma seta que indica o relacionamento de heran¸ca. As diferen¸cas s˜aoimplementadas nas classes ﬁlhas. Suas estruturas de dados, EstruturaSkylinee EstruturaCRS, respectivamente, tamb´em possuem pontos em comum e pontosde diferen¸ca, herdando os pontos em comum da classe m˜ae EstruturaDados esendo as diferen¸cas implementadas nas classes ﬁlhas.
3.3.2
Introduzindo os Atributos e M´etodos das ClassesA an´alise das vari´aveis e rotinas do m´odulo algMatricial.F90, bem comodas semelhan¸cas entre sistemas do tipo Gauss e Pardiso, permite observar que todossistemas em sua forma matricial A.x = B possuem como atributos em comum: umamatriz A (vari´avel ALHS), o vetor B (vari´avel BRHS), al´em uma estrutura de dados,que poder´a ser do tipo Skyline ou CRS.
Quanto `as opera¸c˜oes, ou m´etodos da classes, podemos observar que todos ossistemas possuem em comum uma opera¸c˜ao de solver, representada pelo m´etodosolver, al´em de outras opera¸c˜oes adicionais do m´etodo de elementos ﬁnitos,relacionadas, por exemplo, `a montagem das matrizes globais, como ´e o caso deaddlhs e addrhs, ou `a coloca¸c˜ao de condi¸c˜oes de contorno, como load e ftod.
A ﬁgura 3.5 mostra o diagrama em UML das classes de sistemas de equa¸c˜oes com63um n´ıvel maiores detalhes.
Figura 3.5: A estrutura de classes de Sistemas de Equacoes com maiores detalhes.
O entendimento de todas as rotinas do c´odigo ´e considerado irrelevante nessemomento em que estamos interessados em explorar a reestrutura¸c˜ao do m´odulooriginal com conceitos de orienta¸c˜ao a objetos como heran¸ca, polimorﬁsmo eencapsulamento. Dessa forma, concentrando-nos na explora¸c˜ao de tais conceitos,chamamos aten¸c˜ao para dois m´etodos em espec´ıﬁco: solver e addlhs.
Todos os sistemas possuem um m´etodo solver capaz de resolvˆe-lo.
Entretanto,temos tipos diferentes de sistemas com diferentes solvers que,naturalmente, devem se comportar de maneira diferente. Este cen´ario evocaautomaticamente o conceito de polimorﬁsmo, visto no cap´ıtulo 2. Algosemelhante ocorre com o m´etodo addlhs, respons´avel por adicionar a contribui¸c˜ao64das matrizes de elemento na matriz global do m´etodo de elementos ﬁnitos.
No caso das classes de estruturas de dados, ocorre um cen´ario similar e este´e mostrado no diagrama da ﬁgura 3.6. Podemos identiﬁcar que tanto estruturas dedados do tipo Skyline quanto as do tipo CRS possuem atributos em comum, comoo trio de vetores lm, id e idiag, que aparecem portanto na classe m˜ae. Todaestrutura de dados tamb´em possui o m´etodo montarEstruturaDados, embora elese comporte de maneira diversa nas classes ﬁlhas. Isso signiﬁca que tamb´em ´e umm´etodo onde aparece o conceito de polimorﬁsmo.
Figura 3.6: A estrutura de classes de Estruturas de Dados com maiores detalhes.
Nas se¸c˜oes seguintes, abordaremos a implementa¸c˜ao pr´atica, no c´odigo dosimulador, dos conceitos discutidos at´e aqui. Ser˜ao apresentados trechos de c´odigoem linguagem Fortran mostrando como foram implementadas as classes e osconceitos de heran¸ca e polimorﬁsmo discutidos at´e este ponto.
653.3.3
Implementa¸c˜ao de Orienta¸c˜ao a Objetos em Fortran: Heran¸caDe acordo com Chapman (2004), na linguagem Fortran, utilizada nestetrabalho, a orienta¸c˜ao a objetos ´e implementada com o uso de MODULES e detipos de dados derivados, deﬁnidos com a palavra TYPE, os quais podemconter opera¸c˜oes em seu interior e s˜ao implementados integralmente dentro de umaunidade MODULE. Na listagem 3.8, vemos como a classe m˜ae SistemaEquacoesfoi implementada. A classe ´e representada pelo tipo derivado SistemaEquacoes,deﬁnido na linha 3.
Listagem 3.8: Implementa¸c˜ao de uma classe em Fortran.
1 MODULE mSistemaEquacoes(...)
2TYPE, public, abstract :: SistemaEquacoes3real*8, public, allocatable :: alhs(:), brhs(:)class(EstruturaDados), pointer :: estDados45CONTAINS6!Métodos da classe SistemaEquacoes:7procedure(solverM_interface), public, deferred :: solverM8procedure(addlhsM_interface), public, deferred :: addlhsM9procedure, public :: addrhsM10procedure, public :: ftodM11(...)
12END TYPE SistemaEquacoes13(...)
14CONTAINS15!Implementação dos métodos da classe:16SUBROUTINE addrhsM (this, p_elresf, p_nel, p_nee, p_ndof, p_nen)17(...)
18END SUBROUTINE19(...)
2021 END MODULEAinda na listagem 3.8, vemos que, ap´os a palavra CONTAINS da linha 6, os66m´etodos da classe s˜ao listados como procedimentos do tipo (type bound procedures)e, em seguida, s˜ao implementados, ap´os a palava CONTAINS da linha 15, aindadentro do m´odulo mSistemaEquacoes.
A listagem 3.9 mostra como a classe ﬁlha SistemaPardiso foiimplementada. A deﬁni¸c˜ao ´e similar ao que foi feito para a classe m˜ae. Chamamosaten¸c˜ao para a anota¸c˜ao extends(SistemaEquacoes) feita na deﬁni¸c˜ao doIsso indica que a classe SistemaPardiso ´e ﬁlhatipo derivado na linha 3.
da classe SistemaEquacoes e, portanto, herda seus atributos e m´etodos,funcionando como uma especializa¸c˜ao.
Listagem 3.9: Implementa¸c˜ao de uma classe herdeira em Fortran.
1 MODULE mSistemaPardiso(...)
2TYPE, public, extends(SistemaEquacoes) :: SistemaPardiso3!Atributos do Sistema Pardiso:4INTEGER pt(64), iparm(64)5REAL*8 dparm(64)CONTAINS67!Métodos do Sistema Pardiso8procedure, public ::solverM9procedure, public ::addlhsM10procedure, public ::construtorSistemaPardiso11END TYPE SistemaPardiso12CONTAINS13!Implementação dos métodos da classe:14SUBROUTINE solverM(this, p_solucao, p_label)15(...)
16END SUBROUTINE solverM17(...)
1819 END MODULE673.3.4
Implementa¸c˜ao do Polimorﬁsmo em Fortran:Se repararmos no diagrama UML da ﬁgura 3.5, veremos que, na classeSistemaEquacoes, ao lado dos m´etodos solver e addlhs, existe a anota¸c˜aoabstract.
Isso quer dizer que estes s˜ao dois m´etodos abstratos, ou seja, semimplementa¸c˜ao deﬁnida na classe m˜ae, onde existe apenas a declara¸c˜ao desua interface. A implementa¸c˜ao completa dos m´etodos ´e feita nas classesﬁlhas (sistemaGauss e sistemaPardiso) que especializam a classe m˜ae eimplementam tais m´etodos de diferentes formas. A listagem 3.10 mostra a deﬁni¸c˜aode tais interfaces na classe SistemaEquacoes.
Listagem 3.10: Deﬁni¸c˜ao das interfaces dos m´etodos abstratos na classeSistemaEquacoes.
1 MODULE mSistemaEquacoes(...)
2ABSTRACT INTERFACE3SUBROUTINE solverM_interface(this, p_solucao, p_label)4import :: SistemaEquacoes5class (SistemaEquacoes) :: this6character(len=*) :: p_labelREAL*8, ALLOCATABLE :: p_solucao(:,:)78END SOUBROUTINE solverM_interface9(...)
10END INTERFACE11(...)
1213 END MODULE mSistemaEquacoesA seguir vemos na listagem 3.11 a implementa¸c˜ao do m´etodo solverna subclasse SistemaGauss. Vemos que o comportamento do m´etodo nestasubclasse ´e chamar os m´etodos factor e back nas linhas 7 e 8, respons´aveispela fatora¸c˜ao e substitui¸c˜ao retrocedida, etapas j´a existentes na implementa¸c˜aooriginal que possu´ıa apenas o solver baseado em elimina¸c˜ao de Gauss. Veremos aseguir que o comportamento do m´etodo ´e diferente na outra subclasse.
68Listagem 3.11: Polimorﬁsmo: A implementa¸c˜ao do m´etodo solver na classeSistemaGauss.
1 MODULE mSistemaGauss(...)
2SOUBROUTINE solverM(this, p_solucao, p_label)3implicit none4class(sistemaGauss) :: this5(...)
6CALL this%factorM()7CALL this%backM()8(...)
9CALL this%btodM(p_solucao,ndof,numnp)10END SOUBROUTINE solverM11(...)
1213 END MODULE mSistemaGaussComo adiantado, observa-se na listagem 3.12 o comportamento polim´orﬁcodo m´etodo solver, cuja implementa¸c˜ao interna ´e completamente diferente nasubclasse SistemaPardiso, chamando a rotina solverPardisoPPD_Nodal,que realiza opera¸c˜oes espec´ıﬁcas do solver Pardiso.
Listagem 3.12: Polimorﬁsmo: A implementa¸c˜ao do m´etodo solver na classeSistemaPardiso.
1 MODULE msistemaPardiso(...)
2SUBROUTINE solverM(this, p_solucao, p_label)3implicit none4class(sistemaPardiso) :: this5(...)
6CALL solverPardisoPPD_Nodal(this, simetria, p_label, etapa);7(...)
8CALL this%btodM(p_solucao,ndof,numnp)9END SUBROUTINE solverM1069(...)
1112 END MODULE msistemaPardiso3.3.5
A nova organiza¸c˜ao do simulador com os novos m´oduloscontendo classesComo visto ao longo da se¸c˜ao 3.3, o m´odulo original algMatricial.F90
deu lugar a outros seis m´odulos com classes, mostrados do n´ıvel 3 da ﬁgura 3.7.
Nesta se¸c˜ao, abordamos a forma como os seis m´odulos integram-se ao restante dosimulador e como s˜ao feitas as instˆancias dos objetos das classes citadas nas se¸c˜oesanteriores em c´odigo.
Figura 3.7: Organiza¸c˜ao do simulador com os novos m´odulos fonte.
Lembramos que, como visto na se¸c˜ao 3.2, os m´odulos fratura.F90 ebloco.F90 englobam aspectos relacionados aos problemas f´ısicos de escoamentona fratura hidr´aulica e no bloco matriz. Por essa raz˜ao, decidiu-se que os objetosdas classes de sistemas de equa¸c˜oes e de estruturas de dados devem existir dentro70desses m´odulos. Faz sentido pensar que fratura e bloco “possuem”sistemas deequa¸c˜oes e estruturas de dados para tais sistemas. Haveria, portanto, uma instˆanciade sistemaEquacoes para a fratura hidr´aulica e outra para o bloco. O mesmosendo v´alido para as estruturas de dados.
As listagens 3.13 e 3.14 mostram trechos dos m´odulos fratura.F90 ebloco.F90 onde s˜ao declaradas vari´aveis que na verdade s˜ao ponteiros, os quais,no momento apropriado, far˜ao referˆencia `as regi˜oes de mem´oria em que ser˜aoalocados os objetos das classes criadas. ´E interessante observar que os ponteiross˜ao para objetos do tipos SistemaEquacoes e EstruturaDados, que s˜ao assuperclasses mostradas nas se¸c˜oes anteriores. Ponteiros para um classe m˜ae podemapontar para objetos de suas classes ﬁlhas e isso ser´a feito em momento oportunoe de acordo com a escolha do usu´ario.
Listagem 3.13: Objetos das classes SistemaEquacoes e EstruturaDados nom´odulo mFratura1 MODULE mFratura(...)
2class(SistemaEquacoes), pointer :: umSistEqFratura3class(estruturaDados), pointer :: umaEstDadosFratura4(...)
56 END MODULE mFraturaListagem 3.14: Objetos das classes SistemaEquacoes e EstruturaDados nom´odulo mBloco1 MODULE mBloco(...)
2class(SistemaEquacoes), pointer :: umSistEqBloco3class(estruturaDados), pointer :: umaEstDadosBloco4(...)
56 END MODULE mBloco71No caso do bloco, ´e interessante lembrar que os dados referentes ao sistemaseriam sobrescritos a cada passo de um processo iterativo que resolve m´ultiplosproblemas unidimensionais de elementos ﬁnitos, como descrito no cap´ıtulo 1 emostrado na ﬁgura 1.3. No caso da fratura, existe apenas uma malha e, portanto,o sistema n˜ao ´e sobrescrito em momento algum.
No programa principal, reservoirSimulator,localizado no arquivodriver2Escalas.F90, ´e feita a decis˜ao sobre os tipos de sistema e de estruturasde dados a serem utilizados. A seguir ser˜ao mostrados alguns trechos deste arquivofonte e destacados alguns pontos relevantes.
Primeiramente destacamos que o programa principal faz uso dos ponteirospresentes em fratura.F90 e bloco.F90, mostrados anteriormente naslistagens 3.13 e 3.14. Isso pode ser visto na listagem 3.15, nas declara¸c˜oes USEdas linhas 4, 5, 7 e 8.
Listagem 3.15: Programa principal fazendo uso dos ponteiros declarados nosm´odulos fratura.F90 e bloco.F90
1 PROGRAM reservoirSimulator(...)
2!Sistemas de Equações presentes em mFratura e mBloco:3USE mFratura,only : umSistEqFratura4USE mBloco,only : umSistEqBloco,5!Estruturas de dados presentes em mFratura e mBloco:6USE mFratura,only : umaEstDadosFratura7USE mBloco,only : umaEstDadosBloco8(...)
910 END PROGRAM reservoirSimulatorEm seguida, ´e feita a decis˜ao sobre os tipos de sistemas estruturas de dadosutilizados. Isso ´e feito por meio das diretivas de compila¸c˜ao encontradas nas linhas4 e 12 da listagem 3.16. Se a ﬂag withPardiso n˜ao for deﬁnida devemos tersistemas do tipo Gauss e estruturas Skyline. Caso a ﬂag esteja deﬁnida, issosigniﬁca que a op¸c˜ao do usu´ario ´e pelo solver Pardiso e, ent˜ao, devemos ter sistemas72desse tipo e estruturas do tipo CRS.
O conceito utilizado aqui ´e o de Typed Allocation, aloca¸c˜ao tipada. Assim,podemos alocar os objetos das classes SistemaEquacoes e EstruturaDadosj´a deﬁnindo neste momento que desejamos alocar objetos de uma subclasseespec´ıﬁca. Isso ´e feito para sistemas do tipo Gauss e estruturas Skyline nas linhas6, 7, 9 e 10. Para os sistemas do tipo Pardiso e estruturas CRS isso ´e feito naslinhas 14, 15, 17 e 18.
Listagem 3.16: Aloca¸c˜ao dos objetos das classes de sistemas de equa¸c˜oes eestruturas de dados.
1 PROGRAM reservoirSimulator(...)
2implicit none34 #ifndef withPardiso !SOLVER GAUSS:!Fratura:5ALLOCATE (sistemaGauss :: umSistEqFratura)6ALLOCATE (estruturaSkyline :: umaEstDadosFratura)7!Bloco:8ALLOCATE (sistemaGauss :: umSistEqBloco)9ALLOCATE (estruturaSkyline :: umaEstDadosBloco)1011 #endif12 #ifdef withPardiso !SOLVER PARDISO:!Fratura:13ALLOCATE (sistemaPardiso :: umSistEqFratura)14ALLOCATE ( estruturaCRS :: umaEstDadosFratura)15!Bloco:16ALLOCATE (sistemaPardiso :: umSistEqBloco)17ALLOCATE (estruturaCRS::umaEstDadosBloco)1819 #endif!Ligando os ponteiros:20umSistEqFratura%estDados => umaEstDadosFratura21umSistEqBloco%estDados=> umaEstDadosBloco22(...)
2373CALL preprocessadorFratura()24CALL preprocessadorBloco()25(...)
2627 END PROGRAM reservoirSimulatorChamamos aten¸c˜ao para as opera¸c˜oes feitas nas linhas 21 e 22, tamb´em nalistagem 3.16, depois da aloca¸c˜ao dos objetos, onde estabelecemos a liga¸c˜ao entre oatributo estDados dos objetos das classes de sistema com as estruturas de dadosrec´em alocadas. ´E conveniente atentar para o diagrama da ﬁgura 3.5, onde vemosque todo sistema tem um atributo que ´e a sua estrutura de dados.
Ap´os esta etapa da cria¸c˜ao dos sistemas, aparecem, ainda na listagem3.16, nas linhas 24 e 25, chamadas `as rotinas preprocessadorFraturapreprocessadorBloco, repons´aveis por m´ultiplas tarefas de inicializa¸c˜aoreferentes aos modelos do bloco e da fratura. A listagem 3.17 mostra a rotinapreprocessadorFratura. A rotina preprocessadorBloco ´e similar e fazopera¸c˜oes an´alogas para o caso do bloco.
Listagem 3.17: A rotina preprocessadorFratura.
1 MODULE mFratura(...)
2SUBROUTINE preprocessadorFratura()3(...)
4ALLOCATE(umSistEqFratura%estDados%id(ndof_F,numnp_F))5umSistEqFratura%estDados%id = 06call leituraCodigosCondContorno(umSistEqFratura%estDados%id,7ndof_F,numnp_F,n,iin,iecho,iprtin)umSistEqFratura%estDados%NEQ = n8ALLOCATE(umsistEqFratura%estDados%idiag(umSistEqFratura%estDados%9neq))umSistEqFratura%estDados%idiag=010ALLOCATE(umSistEqFratura%estDados%lm(ndof_F,nen_F,numel_F))11(...)
12SELECT TYPE (umSistEqFratura)1374type is (sistemaGauss)14optSolver_F=’Gauss’15call umSistEqFratura%construtorSistemaGauss16type is (sistemaPardiso)17optSolver_F=’PardisoEsparso’18call umSistEqFratura%construtorSistemaPardiso(nsd_F,nen_F,19numConexoesPorElem)END SELECT20(...)
21END SUBROUTINE preprocessadorFratura()2223 END MODULE mFraturaNas linhas 5, 9 e 11 vemos, respectivamente a aloca¸c˜ao dinˆamica dos vetoresid, idiag e lm, pertencentes `as estruturas de dados para armazenamento dematrizes esparsas e mostrados no diagrama da ﬁgura 3.6. ´E interessante lembrarque estes eram alguns dos vetores da ﬁgura 3.1, os quais, na implementa¸c˜ao originalde Hughes (1987), estavam contidos dentro do grande vetor est´atico A.
Dentre as tarefas realizadas pelas rotinas preprocessadorFraturapreprocessadorBloco,edestacamos,ainda,aschamadasaconstrutorSistemaGaussduasnovasrotinasimportantes:ouconstrutorSistemaPardiso, de acordo com o tipo de sistemas escolhido.
As chamadas a tais rotinas, as quais s˜ao m´etodos das subclasses de sistemas,podem ser vistas nas linhas 16 e 19 da listagem 3.17. Estes m´etodos cumpremaproximadamente a fun¸c˜ao de m´etodos construtores, j´a que s˜ao respons´aveis poralgumas tarefas de inicializa¸c˜ao dos sistemas que devem ser feitas imediatamenteap´os a aloca¸c˜ao de um objeto.
A importˆancia de tais m´etodos est´a no fato de que neles ´e feita a aloca¸c˜aodinˆamica das matrizes e do vetor carga dos sistemas de equa¸c˜oes. Dessa forma,assim que um novo sistema ´e alocado, o m´etodo construtor correspondente ´echamado e faz a aloca¸c˜ao dinˆamica da matriz ALHS e do vetor BRHS, pertencentesaos sistemas de equa¸c˜oes. As listagens 3.18 e 3.19 mostram as rotinas em quest˜ao.
Destacamos a aloca¸c˜ao das vari´aveis ALHS e BRHS.
75Listagem 3.18: O m´etodo construtorSistemaGauss.
1 MODULE mSistemaGauss(...)
2SUBROUTINE construtorSistemaGauss(this)3implicit none4class(sistemaGauss) :: this5ALLOCATE(this%ALHS(this%estDados%nalhs))6ALLOCATE(this%BRHS(this%estDados%NEQ))7END SUBROUTINE construtorSistemaGauss89 END MODULE mSistemaGaussListagem 3.19: O m´etodo construtorSistemaPardiso.
1 MODULE mSistemaPardiso(...)
2SUBROUTINE construtorSistemaPardiso(this, p_nsd_F, p_nen_F,3p_numConexoesPorElem)use mMalha, only: numConexoesPorElem4implicit none5class(sistemaPardiso) :: this6integer, intent(in) :: p_nsd_F, p_nen_F7integer :: p_numConexoesPorElem8ALLOCATE(this%ALHS(this%estDados%nalhs))9ALLOCATE(this%BRHS(this%estDados%NEQ))10p_numConexoesPorElem=p_nen_F11END SUBROUTINE construtorSistemaPardiso12(...)
1314 END MODULE mSistemaPardisoFinalmente, ao ﬁm do programa principal, todos os sistemas e estrtuturas dedados s˜ao desalocados, como mostra a listagem 3.20.
76Listagem 3.20: Desaloca¸c˜ao dos sistemas e estruturas de dados1 PROGRAM reservoirSimulator(...)
2DEALLOCATE(umSistEqFratura)3DEALLOCATE(umaEstDadosFratura)4DEALLOCATE(umaEstDadosBloco)5DEALLOCATE(umSistEqBloco)67 END PROGRAM reservoirSimulatorNo pr´oximo cap´ıtulo, veremos que a reestrutura¸c˜ao com orienta¸c˜ao a objetosdesenvolvida nesse trabalho facilitou a implementa¸c˜ao de uma estrat´egia deparaleliza¸c˜ao para o simulador. O desenvolvimento da solu¸c˜ao paralela produziuuma altera¸c˜ao na aloca¸c˜ao do sistema de equa¸c˜oes do bloco, o qual deixa de ser´unico e passa a dar lugar a v´arios sistemas alocados dinamicamente convivendosimultaneamente em mem´oria, deixando de ser sobrescrito a cada itera¸c˜ao dola¸co que resolve os m´ultiplos problemas relativos ao bloco. Tal abordagem ser´adetalhada no cap´ıtulo 4.
77Cap´ıtulo 4Paraleliza¸c˜ao do simulador 2 escalas deShale GasNeste cap´ıtulo, abordamos o desenvolvimento de estrat´egias de paraleliza¸c˜aocom os padr˜oes OpenMP e MPI para o c´odigo do simulador de escoamentos emreservat´orios de g´as em folhelhos.
Inicialmente ´e feita uma an´alise do perﬁl dedesempenho serial da aplica¸c˜ao com uso de ferramenta especializada. Em seguida,s˜ao apresentadas evolu¸c˜oes no c´odigo necess´arias `a implementa¸c˜ao do paralelismo.
Por ﬁm s˜ao apresentados testes de desempenho e criticados os seus resultados.
4.1
An´alise inicial do perﬁl serial de desempenho da aplica¸c˜ao comintel VTUNEO primeiro passo para a formula¸c˜ao das estrat´egias de paraleliza¸c˜ao propostasneste trabalho envolveu uma fase de an´alise de desempenho para a identiﬁca¸c˜ao,no c´odigo do simulador, das regi˜oes que consomem mais tempo de execu¸c˜ao. A
avalia¸c˜ao correta do perﬁl de desempenho do c´odigo suporta o desenvolvimentode estrat´egias de paraleliza¸c˜ao, na medida em que os esfor¸cos de otimiza¸c˜aos˜ao direcionados `as regi˜oes mais demandantes do c´odigo, onde um aumento nodesempenho ter´a o maior impacto no desempenho geral da aplica¸c˜ao.
Para a obten¸c˜ao de um perﬁl de desempenho do c´odigo, foi utilizada aferramenta de perﬁlamento de c´odigo Intel VTune Ampliﬁer XE, dispon´ıvel nocluster Altix-xe do LNCC. De acordo com Jeﬀers e Reinders (2013), o VTune78´e uma ferramenta capaz de fornecer diversas m´etricas a respeito da execu¸c˜ao deum programa como, por exemplo, uso de mem´oria e de cache, al´em de ajudarna identiﬁca¸c˜ao das regi˜oes com maior custo de execu¸c˜ao, conhecidas como dehotspots.
O arcabou¸co de orienta¸c˜ao a objetos desenvolvido neste trabalho eincorporado ao simulador permite a utiliza¸c˜ao de dois diferentes solvers: o solverinterno, implementando elimina¸c˜ao de Gauss, al´em de um solver externo, intelPardiso, da biblioteca intel MKL.
Neste momento inicial, estamos interessados apenas em analisar o perﬁl dedesempenho da aplica¸c˜ao e confrontar dois solvers neste simulador. Para tanto,foram realizadas an´alises com Intel VTune, com execu¸c˜oes seriais do c´odigo dosimulador, com ambos os referidos solvers.
Nesta an´alise inicial comparativa de solvers, utilizamos, no caso da fratura,uma malha unidimensional de 400 elementos. No bloco, cada malha possui 135elementos e o tempo de simula¸c˜ao total foi de 20 meses. Apesar de tratar-se deum primeiro caso de teste experimental e ainda sem pretens˜oes de interpreta¸c˜ao deresultados f´ısicos, os tamanhos de malhas utilizados nesta etapa s˜ao compat´ıveisaos adotados em simula¸c˜oes semelhantes como em Costa (2015).
O tipo de an´alise feito com a ferramenta de perﬁlamento, denominado “BasicHotspot Analysis” ´e, segundo Jeﬀers e Reinders (2013), o mais recomendado parauma vis˜ao geral do perﬁl de desempenho, com identiﬁca¸c˜ao das subrotinas maiscustosas em tempo de execu¸c˜ao.
As ﬁguras 4.1 e 4.2 mostram, na aba “Caller/Callee”, a lista de todas asrotinas do c´odigo do simulador, ordenadas pelo seu tempo de execu¸c˜ao total,considerando a soma de todas as vezes em que foram chamadas e executadas.
Os n´umeros s˜ao percentuais em rela¸c˜ao ao tempo total de execu¸c˜ao da aplica¸c˜ao.
79Figura 4.1: Percentual do tempo total de execu¸c˜ao por rotina com solver GaussNa ﬁgura 4.1 ´e mostrada a execu¸c˜ao com o solver interno (Elimina¸c˜aode Gauss), ao passo que na ﬁgura 4.2 a execu¸c˜ao foifeita com o solverexerno, intel Pardiso. Em ambos os casos, nota-se uma semelhan¸ca: a rotinaprocessadorBloco, cuja linha est´a em destaque nas ﬁguras, corresponde a umgrande percentual do tempo de execu¸c˜ao total da aplica¸c˜ao (99,5% e 93,3%).
Figura 4.2: Percentual do tempo total de execu¸c˜ao por rotina com solver intelPardisoA rotina em destaque, processadorBloco, ´e respons´avel, em linhasgerais, por resolver um problema unidimensional dentre os v´arios relativos a umbloco, como exposto no cap´ıtulo 1. Tal rotina, cuja implementa¸c˜ao, antes dequalquer interven¸c˜ao para paraleliza¸c˜ao ´e mostrada na listagem 4.1, ´e respons´avelpor: (i) montar o problema matricial relacionado a um sistema de equa¸c˜oes linearescom a chamada `a rotina montarSistema_B e (ii) resolver o sistema com achamada ao m´etodo polimorfo solver, visto no cap´ıtulo 3, se¸c˜ao 3.3.
80A rotina processadorBloco do m´odulo principal,Listagem 4.1:
driver2Escalas.F90
1 SUBROUTINE processadorBloco(...)
(...)
2USE mBloco, only : umSistEqBloco3USE mBloco, only : umaEstDadosBloco4(...)
5umSistEqBloco%ALHS=0.d0
6umSistEqBloco%BRHS=0.d0
7(...)
8CALL montarSistema_B(umSistEqBloco, DT, solucaoTmpAnt_B_aux,9solucao_B_aux)CALL umSistEqBloco%solverM(solucao_B_aux, "Bloco")10(...)
1112 END SUBROUTINE processadorBlocoComo visto no cap´ıtulo 1, se¸c˜ao 1.2, para cada ponto da malha de elementosﬁnitos do problema da fratura, existe um problema relativo ao bloco. Dessa forma,a rotina processadorBloco ´e executada tantas vezes quantos forem os pontosna malha da fratura. O grande n´umero de chamadas a essa rotina, junto a seucusto por chamada, fazem com que ela corresponda a um alt´ıssimo percentual dotempo total de execu¸c˜ao da aplica¸c˜ao, como visto nas ﬁguras 4.1 e 4.2. O fato deque cada chamada a tal rotina resolve um sistema de equa¸c˜oes independente nospermite a considerar sua execu¸c˜ao em paralelo. Esta ´e a ideia b´asica da estrat´egiade paralelismo desenvolvida e que ser´a melhor detalhada em se¸c˜oes seguintes.
Voltemo-nos agora `as diferen¸cas entre os dois solvers. A experiˆencia anteriorde colegas dentro do LNCC em implementa¸c˜ao de simuladores similares ao destetrabalho mostra que, especiﬁcamente para o caso de problemas unidimensionaisde elementos ﬁnitos, a utiliza¸c˜ao do solver baseado em elimina¸c˜ao de Gauss ´emais vantajosa em tempo de execu¸c˜ao do que a utiliza¸c˜ao de alguns outros solversexternos, dentre eles o Pardiso.
A ﬁm de conﬁrmar tal hip´otese neste simulador em espec´ıﬁco, apresentamosdados, tamb´em obtidos na mesma an´alise com a ferramenta Intel VTune Ampliﬁer81XE, capazes de clariﬁcar a diferen¸ca pr´atica entre os dois solvers dispon´ıveis,especiﬁcamente nesta aplica¸c˜ao, que lida unicamente com malhas unidimensionais,de acordo com o modelo apresentado na se¸c˜ao 1.2.
Na ﬁgura 4.3, pode-se observar a aba “Summary” do VTune que mostrao tempo total de execu¸c˜ao da aplica¸c˜ao. Com a utiliza¸c˜ao do solver interno(elimina¸c˜ao de Gauss), o tempo total de execu¸c˜ao do simulador para o caso deteste foi de pouco mais de 30 segundos.
Figura 4.3: Tempo total de execu¸c˜ao do caso experimental com solver GaussCom o uso do solver Pardiso, entretanto, o tempo total se aproximou de 1minuto e 24 segundos segundos, o que refor¸ca a hip´otese de que a utiliza¸c˜ao dosolver Gauss, para problemas com malhas unidimensionais, ou seja, aqueles queestamos interessados em resolver neste momento com a vers˜ao atual do simulador,´e mais vantajosa em termos de dempo de execu¸c˜ao.
Figura 4.4: Tempo total de execu¸c˜ao do caso experimental com solver intel PardisoExaminando os resultados das ﬁguras 4.1 e 4.2 um pouco mais a fundo, nosconcentraremos na rotina processadorBloco, que aparece em destaque em nasﬁguras e ´e respons´avel por alt´ıssimo percentual do tempo de execu¸c˜ao da aplica¸c˜ao.
As ﬁguras 4.5 e 4.6 s˜ao detalhamentos das ﬁguras 4.1 e 4.2, respectivamente.
Analisam especiﬁcamente a rotina processadorBloco, mostrando quais s˜aosuas rotinas “ﬁlhas”, ou seja, chamadas em seu interior, desmembrando o tempo82de execu¸c˜ao gasto em cada uma delas. Nas duas ﬁguras, destacamos a linha darotina solver, pois estamos interessados em confrontar os dois solvers.
Na ﬁgura 4.5 obervam-se dados da execu¸c˜ao com o solver interno (Gauss).
Nota-se que, dos 29,85 segundos gastos na rotina processadorBloco, apenas3,571 segundos foram gastos na rotina do solver propriamente dito, na linhadestacada na ﬁgura.
Figura 4.5: An´alise da rotina processadorBloco com solver GaussEm contraste, na ﬁgura 4.6, onde s˜ao mostrados resultados da execu¸c˜aocom solver Pardiso, percebe-se que, do total de 82,012 segundos gastos na rotinaprocessadorBloco, mais de 50 segundos foram gastos na rotina referente aosolver, sendo esta, neste caso, mais impactante do que a montagem do sistema.
Figura 4.6: An´alise da rotina processadorBloco com solver PardisoEsta ´ultima an´alise, portanto, conﬁrma a hip´otese de a execu¸c˜ao tornou-semais lenta com o solver Pardiso, especiﬁcamente em raz˜ao do custo de execu¸c˜aorotina do solver propriamente dito, e n˜ao por qualquer outro tipo de processamentoa ele relacionado. Dessa forma, consideramos o solver interno mais adequado aomodelo f´ısico e matem´atico atual utilizado por este simulador. O provimento deum solver externo, entretanto, n˜ao deixa de ser justiﬁc´avel e de representar umavan¸co para o simulador.
83Embora atualmente o modelo desenvolvido em Costa (2015) e utilizado nosimulador fa¸ca uso apenas de malhas unidimensionais, qualquer itera¸c˜ao futura quecontemple a utiliza¸c˜ao de malhas bidimensionais ou tridimensionais poder´a fazercom que o usu´ario deste simulador necessite lan¸car m˜ao de um solver externo maisadequado a tais situa¸c˜oes. Seja este o intel Pardiso, j´a disponibilizado, ou mesmoum outro que decida implementar, o que seria facilitado pelo uso do arcabou¸co deorienta¸c˜ao a objetos desenvolvido neste trabalho. Implementar uma nova classe desistemas de equa¸c˜oes e integr´a-la ao simulador ´e uma tarefa mais convidativa doque integrar um novo solver ao antigo m´odulo mAlgMatricial, visto no cap´ıtulo3.
4.2
A estrat´egia de paraleliza¸c˜ao com OpenMPNeste momento, ´e conveniente retomar uma caracter´ıstica do modelo f´ısicoe matem´atico proposto em Costa (2015), adotado no simulador. Conforme vistono cap´ıtulo 1 e na ﬁgura 1.3, o modelo para a simula¸c˜ao de escoamento do g´as noreservat´orio n˜ao convencional (composto por bloco e fratura induzida) ´e baseadoem m´ultiplos problemas unidimensionais de elementos ﬁnitos referentes ao bloco,os quais est˜ao relacionados aos pontos da malha unidimensional do problema nafratura, fornecendo termo de fonte de massa a este ´ultimo.
O modelo confere ao c´odigo a caracter´ıstica de ser naturalmente paraleliz´avel,visto que as solu¸c˜oes dos m´ultiplos problemas do bloco, originalmente feitasde forma serial, n˜ao apesentam qualquer tipo de dependˆencia entre si. Estacaracter´ıstica ´e conhecida, em inglˆes, como embarassing parallelism, o que sugereser constrangedor que n˜ao se explore oportunidade t˜ao convidativa `a execu¸c˜aoparalela de tais atividades. A estrat´egia de paralelismo desenvolvida neste trabalhoexplora, portanto, a solu¸c˜ao em paralelo de m´ultiplos problemas unidimensionaisde elementos ﬁnitos referentes ao bloco.
N˜ao ´e proposta aqui a paraleliza¸c˜ao de um solver, mas sim o desenvolvimentode uma estrat´egia para tornar paralela a execu¸c˜ao de um modelo, o qual inclui84a solu¸c˜ao de m´ultiplos problemas independentes para o bloco. Trata-se de umaestrat´egia de paraleliza¸c˜ao em um n´ıvel mais alto de abstra¸c˜ao e com granularidadegrossa, no sentido de que cada uma das unidades de execu¸c˜ao do OpenMP, asthreads, resolvem problemas completos.
Considerando que o m´odulo refatorado neste trabalho visa disponibilizarsolvers diferentes e,inclusive,facilitar a inclus˜ao de outros, ele confere aoc´odigo certo grau de heterogeneidade no seu ﬂuxo de execu¸c˜ao. A estrat´egia deparaleliza¸c˜ao desenvolvida ´e adequada a essa caracter´ıstica, na medida em quepermite que o simulador se beneﬁcie do paralelismo e tenha escalabilidade deexecu¸c˜ao independente de qual seja o solver em uso.
A ideia ´e que cada thread do OpenMP resolva um subconjunto do n´umerototal de problemas unidimensionais do bloco.
Cada um destes problemascorresponde basicamente a uma chamada `a rotina processadorBloco, a qual,como visto na se¸c˜ao 4.1, monta o problema matricial relacionado a um sistema eo resolve.
No c´odigo do simulador,em sua vers˜ao serial,existe uma rotinarespons´avel porresolver, um a um,todos os problemas relacionados aobloco: resolverProbVariosBlocos, mostrada na listagem 4.2. Na linha6, ´e poss´ıvel observar o loop que resolve cada problema, um ap´os outro,chamando a rotina processadorBloco v´arias vezes, al´em de armazenar,em cada itera¸c˜ao, a contribui¸c˜ao de um problema em uma posi¸c˜ao do vetorfluxoMassicoDeBlocoParaFratura a ser utilizado no problema da fratura.
Listagem 4.2: Rotina serial que resolve os m´ultiplos problemas do Bloco.
1 SUBROUTINE resolverProbVariosBlocos(...)
(...)
2INTEGER :: numBlocos3REAL*8 :: fluxoMassicoDeBlocoParaFratura(numBlocos), fluxoMolM2SINTEGER :: iBlocos45DO iBlocos=1, numBlocos685CALL processadorBloco(...)
7fluxoMassicoDeBlocoParaFratura(iBlocos) = fluxoMolM2S;8END DO! fim do loop do problema micro (blocos)910 END SUBROUTINE resolverProbVariosBlocos´E nesta rotina, resolverProbVariosBlocos, que ser˜ao inseridas asdiretivas de compila¸c˜ao do padr˜ao OpenMP, para a pareliza¸c˜ao do loop que queresolve os v´arios sistemas de equa¸c˜oes. Entretanto, ´e muito importante observarque, na vers˜ao serial do c´odigo, o objeto da classe SistemaEqua¸c˜oes possui seusdados sobrescritos a cada itera¸c˜ao do loop mostrado na linha 6 da listagem 4.2.
A listagem 4.1 mostra que a rotina processadorBloco, a cada vez que ´eexecutada, reconstr´oi as matrizes dos sistemas que resolve. As linhas 6 e 7 mostramas vari´aveis ALHS e BRHS sendo reinicializadas com valor zero pela rotina.
Neste momento percebe-se uma grande utilidade para os novos m´odulos´E preciso que tenhamos v´ariosbaseados no paradigma orientado a objetos.
sistemas coexistindo simultaneamente em mem´oria para que a estrat´egia deparaleliza¸c˜ao funcione e cada thread OpenMP seja capaz de operar em um sistemadiferente. Com a classe SistemaEquacoes,isso pode ser alcan¸cado comnaturalidade, uma vez que podemos instanciar m´ultiplos objetos da classe. Um
novo objeto dever´a ser criado a cada chamada da rotina processadorBloco.
Uma reformula¸c˜ao da rotina processadorBloco foi feita para que osobjetos da classe SistemaEquacoes referentes ao bloco fossem criados em seuinterior. A listagem 4.3 mostra parte da nova vers˜ao da rotina. Na linha 6, vemoso ponteiro umSistEqBloco para a classe m˜ae SistemaEquacoes, enquantonas linhas 8 ou 11 o objeto propriamente dito ´e criado (alocado em mem´oria) erelacionado ao ponteiro da linha 6. Na linha 14, o atributo do estDados dosistema ´e ralacionado `a estrutura de dados presente no m´odulo mBloco.
Listagem 4.3: Reformula¸c˜ao da rotina processadorBloco1 SUBROUTINE processadorBloco(...)
86(...)
2use mBloco, only : umaEstDadosBloco3(...)
4!Ponteiro para sistema:5pointerclass(SistemaEquacoes),:: umSistEqBloco67 #ifndef withPardisoALLOCATE (sistemaGauss :: umSistEqBloco)89 #endif10 #ifdef withPardisoALLOCATE(sistemaPardiso::umSistEqBloco)1112 #endif!Ligando os ponteiros:13umSistEqBloco%estDados => umaEstDadosBloco14(...)
15SELECT TYPE (umSistEqBloco)16type is (sistemaGauss)17optSolver_B_aux=’Gauss’18call umSistEqBloco%construtorSistemaGauss19type is (sistemaPardiso)20optSolver_B_aux=’PardisoEsparso’21call umSistEqBloco%construtorSistemaPardiso(nsd_B,nen_B,22numConexoesPorElem_aux)END SELECT23(...)
24umSistEqBloco%ALHS=0.d0
25umSistEqBloco%BRHS=0.d0
26(...)
27CALL montarSistema_B(umSistEqBloco, DT, solucaoTmpAnt_B_aux,28solucao_B_aux)CALL umSistEqBloco%solverM(solucao_B_aux, "Bloco")29(...)
30DEALLOCATE(umSistEqBloco)3132 END SUBROUTINE processadorBloco87O processo descrito anteriormente ´e exatamente o mesmo que antes era feitono m´odulo principal driver2Escalas.F90 mas, naquela situa¸c˜ao, utilizandoo ponteiro umSistEqBloco presente no m´odulo mBloco. O ponteiro apontavapara o objeto do tipo sistema de equa¸c˜oes alocado no programa principal. Isso foimostrado em detalhes nos trechos de c´odigo exibidos cap´ıtulo 3, se¸c˜ao 3.3.5. Na
nova vers˜ao, tanto o ponteiro para sistema como a aloca¸c˜ao do objeto em mem´oriaest˜ao dentro da rotina processadorBloco.
Chamamos aten¸c˜ao para o fato de que, ap´os a aloca¸c˜ao do sistema,ainda dentro da rotina processadorBloco, aparece agora a chamada aosm´etodos construtorSistemaGauss ou construtorSistemaPardiso, osquais, conforme discutido no cap´ıtulo 3, se¸c˜ao 3.3.5, fazem a aloca¸c˜ao dinˆamicadas matrizes dos sistemas de equa¸c˜oes.
Finalmente, ao ﬁnal da rotinaprocessadorBloco, na linha 31, o sistema ´e desalocado.
A compara¸c˜ao entre as listagens 4.1 e 4.3 permite, portanto, a identiﬁca¸c˜aode evolu¸c˜oes feitas na rotina processadorBloco que ser˜ao necess´arias aodesenvolvimento da estrat´egia de paraleliza¸c˜ao desenvolvida. Resumidamente,duas diferen¸cas mais importantes s˜ao:(i) O ponteiro para objetos da classe SistemaEquacoes referentes ao blocodeixa de estar no m´odulo mBloco e, portanto, deixa de ser ´unico, passando aser uma vari´avel de fun¸c˜ao, interna `a rotina processadorBloco, residindona pilha (stack ). A cada vez que ´e chamada, essa essa rotina cria um novoponteiro para sistema de equa¸c˜oes.
(ii) A aloca¸c˜ao dinˆamica dos objetos a serem apontados por tais ponteirostamb´em ´e feita no interior da rotina.
Isso signiﬁca que, a cada chamada`a mesma, um novo objeto ´e alocado e referenciado pelo ponteiro local.
De (i) e (ii) conslui-se que, caso a rotina processadorBloco seja chamadav´arias vezes em paralelo, teremos m´ultiplos ponteiros para sistemas e m´ultiplosobjetos da classe SistemaEquacoes coexistindo em mem´oria e apontados por88tais ponteiros.
Isso nos pertimitir´a a paralelizar o loop que resolve os v´ariosproblemas do bloco.
As altera¸c˜oes reﬂetiram-se no programa principal, anteriormente mostradona listagem3.15, onde havia quatro decla¸c˜oes USE para ponteiros nos m´odulosmFratura e mBloco (linhas 4, 5, 7 e 8). A listagem 4.4 mostra altera¸c˜oesrelevantes no programa principal. Das referidas quatro declara¸c˜oes USE, restaramapenas trˆes, sendo duas delas para ponteiros no m´odulo mFratura (linhas 4 e5), referentes ao sistema e `a estrutura de dados da fratura; para o caso do blocorestou apenas uma, na linha 7, fazendo uso do ponteiro para estrutura de dadosdo m´odulo mBloco.
Listagem 4.4: Altera¸c˜oes no programa principal.
1 PROGRAM reservoirSimulator(...)
2!Sistema de Equações e Estrutura de dados em mFratura:3use mFratura,only : umSistEqFratura4use mFratura,only : umaEstDadosFratura5!Apenas Estrutura de dados presente em mBloco:6use mBloco,only : umaEstDadosBloco7(...)
89 END PROGRAM reservoirSimulatorComo visto, para o caso da fratura, n˜ao houve altera¸c˜ao, uma vez que oparalelismo tratar´a unicamente dos problemas do bloco. Continuaremos tendoapenas um sistema de equa¸c˜oes para a fratura, al´em de uma estrutura de dados.
No caso do bloco, teremos m´ultiplos sistemas, por´em apenas uma ´unica estruturade dados para todos eles. Esta ser´a apontada por um ´unico ponteiro em mBloco.
Lembramos que estruturas de dados tratam de deﬁnir a forma espec´ıﬁca comoos dados referentes `as matrizes dos sistemas ser˜ao armazenados, considerandosua esparsidade; por´em, as estruturas n˜ao contˆem as matrizes dos sistemaspropriamente ditas, as quais s˜ao atributos da classe sistemaEquacoes.
89As altera¸c˜oes descritas at´eeste ponto, nos permitem, ﬁnalmente,aplicarasdiretivasdecompila¸c˜aodopadr˜ao OpenMP `arotinaresolverProbVariosBlocos, cuja vers˜ao serial foi apresentada na listagem4.2. No trecho de c´odigo mostrado na listagem 4.5, pode-se ver uma nova vers˜aoda rotina resolverProbVariosBlocos com as diretivas OpenMP para aparaleliza¸c˜ao do loop da linha 9 que resolve os v´arios problemas do bloco.
Listagem 4.5: Vers˜ao da rotina resolverProbVariosBlocos paralelizada comOpenMP1 SUBROUTINE resolverProbVariosBlocos(...)
implicit none2INTEGER :: numBlocos, NUSTEP3REAL*8 :: fluxoMassicoDeBlocoParaFratura(numBlocos), fluxoMolM2S4, DTINTEGER :: iBlocos5integer :: omp_get_thread_num6!Loop paralelizado com OpenMP:7!$omp parallel do firstprivate(NUSTEP, TEMPO, fluxoMolM2S,8condContorno, DT)DO iBlocos=1, numBlocos9CALL processadorBloco(...)
10fluxoMassicoDeBlocoParaFratura(iBlocos) = fluxoMolM2S;11END DO! fim do loop do problema micro (blocos)12!$omp end parallel do1314 END SUBROUTINE resolverProbVariosBlocosNas linhas 8 e 13 ´e poss´ıvel observar as diretivas $omp parallel do e$omp end parallel do utilizadas para a divis˜ao das itera¸c˜oes do loop entreas threads. Tamb´em na linha 8, observa-se a cl´ausula firstprivate seguida deuma s´erie de vari´aveis.
Isto foi necess´ario para corrigir e erros de execu¸c˜ao emdecorrˆencia de condi¸c˜oes de corrida causadas pelo paralelismo. Alguns recursos(vari´aveis) eram compartilhados pelas threads quando n˜ao deveriam sˆe-lo. As
escritas simultˆaneas causavam erros nos resultados obtidos com a vers˜ao paralela.
90Os defeitos puderam ser corrigidos com a utiliza¸c˜ao de uma ferrmentaespecialida em thread debugging. Trata-se do Intel Inspector, dispon´ıvel nosrecursos computacionais do LNCC. A ferramenta ´e capaz de apontar vari´aveis queest˜ao causando condi¸c˜ao de corrida. Sua utiliza¸c˜ao guiou a remo¸c˜ao de erros nestaaplica¸c˜ao e a tela de uma das an´alises feitas com ferramenta ´e mostrada na ﬁgura4.7, a t´ıtulo de ilustra¸c˜ao. De posse das informa¸c˜oes obtidas com a ferramenta, foiposs´ıvel utilizar com assertividade a cl´ausula firstprivate, que faz com que asvari´aveis listadas possuam c´opias privadas em cada thread, evitando as condi¸c˜oesde corrida.
Figura 4.7: An´alise de condi¸c˜oes de corrida feita com a ferramente Intel Inspector.
Em linhas gerais, a ideia da solu¸c˜ao paralela ´e que cada thread do OpenMPinstancie um sistema de equa¸c˜oes para um dos problemas do bloco, o resolva eo desaloque ao ﬁnal de sua solu¸c˜ao. O processo segue se repetindo at´e que osproblemas se esgotem, uma vez que o n´umero de problemas ´e, invariavelmente,ordens de grandeza maior do que o n´umero de threads. As threads podeminstanciar novos sistemas de equa¸c˜oes simplesmente chamando a nova vers˜ao darotina processadorBloco, como feito na linha 10.
´E importante lembrar neste momento, que a rotina processadorBlocon˜ao corresponde apenas `a solu¸c˜ao dos sistemas lineares propriamente ditos. Inclui,al´em do solver, a chamada `a rotina montarSistema_B, como visto nas ﬁguras4.5 e 4.6. Isso signiﬁca que a estrat´egia de paraleliza¸c˜ao engloba tanto a montagemdas matrizes dos sistemas quanto a solu¸c˜ao dos mesmos e nos permite ter ganhosnas duas frentes, o que n˜ao ocorreria com a paraleliza¸c˜ao de um solver.
91A organiza¸c˜ao ﬁnal dos ponteiros e objetos de sistemas e estruturas ap´osa implementa¸c˜ao da estrat´egia de paraleliza¸c˜ao descrita funcionasse corretamentetem a forma como ilustrado na ﬁgura 4.8.
Figura 4.8: A organiza¸c˜ao de objetos de sistemas e estruturas de dados na vers˜aoparalelizada com OpenMPS˜ao mostrados na ﬁgura 4.8: (i) o m´odulo mFratura, com dois ponteirospara dois objetos referentes `a fratura: um sistema e uma estrutura de dados, (ii)o m´odulo mBloco, com apenas um ponteiro para uma estrutura de dados a serutilizada em todos os problemas do bloco e (iii) uma s´erie de ponteiros na pilha(stack ) referentes `as chamadas da fun¸c˜ao processadorBloco que ocorrem emparalelo.
4.3
Testes de desempenho I: Paraleliza¸c˜ao com OpenMPNesta se¸c˜ao ser˜ao abordados testes de desempenho realizados com a aplica¸c˜aoparalela. Nas simula¸c˜oes realizadas foram adotados dados f´ısicos realistas, baseados92em um campo real. A tabela 4.1, adaptada de (Costa, 2015), mostra os parˆametrosf´ısicos utilizados nas simula¸c˜oes realizadas.
Tabela 4.1: Parˆametros f´ısicos relativos ao campo realista utilizado nos testes.
Adaptado de [Costa (2015)]1 × 10−19/1000.06
26.2/38006.89/1000355/18070%4.48/35096/5.18
Permeabilidade (K∗)(m2/nD)Porosidade na matriz (φP )Press˜ao inicial no reserv. (M P a/psi)Press˜ao no po¸co (M P a/psi)Temperatura no reserv. (K/F )Satura¸c˜ao do g´asPL(M P a/psi)VL(scf /ton)/((kg/m3)Foram adotadas nos experimentos duas conﬁgura¸c˜oes de tamanhos de malhaspara fratura e bloco:• Experimento (A): Malha de 400 elementos para a fratura e 135 elementospara o bloco, algo compat´ıvel com os tamanhos utilizados em Costa (2015),ambas com reﬁnamento em sua por¸c˜ao inicial. No caso da fratura, naregi˜ao mais pr´oxima ao po¸co e, no caso do bloco, na regi˜ao mais pr´oxima`a fratura.
• Experimento (B): Neste experimento a malhas do bloco s˜ao idˆenticas aoanterior. A ﬁm de aumentar o n´umero de sistemas de equa¸c˜oes referentesao bloco para observar o comportamento da vers˜ao paralelizada e compararresultados f´ısicos e de desempenho computacional, foi adotada para afratura uma malha maior, desta vez uniforme. Apesar de tratar-se deuma malha uniforme, o espa¸camento entre os pontos da malha existenteno experimento (A) para a regi˜ao reﬁnada foi mantido, o que nos faz chegarao n´umero de 2200 elementos para uma malha uniforme a ser adotada nafratura. Este experimento nos permitir´a avaliar se a solu¸c˜ao paralela ´esens´ıvel ao reﬁnamento das malhas.
Para ambas as conﬁgura¸c˜oes de tamanhos de malha,foram realizadas93simula¸c˜oes com tempo total de 30 anos. No experimento (A), com 400 elementosna malha da fratura foi obtida a seguinte sa´ıda:--> Pressão no reservatório:--> Pressão no poço:--> Quantidade de gás total:--> Quantidade de gás recuperável:--> Quantidade de gás produzido:--> Quantidade de gás produzido:--> Valor da pressão no último nó:--> Tempo de simulação--> Fator de recuperação (sobre gás total):--> Fator de recuperação (sobre gás recuperável):2.62000E+07(Pa)6.89000E+06(Pa)6.43831E+03(kg)4.26160E+03(kg)3.53262E+03(kg)2.35508E+06(kg/m^2)6.91931E+06(Pa)3.00000E+01(anos)5.48688E-018.28942E-01resultado para todo reservatorio--> Quantidade de gás total:--> Quantidade de gás recuperável:--> Quantidade de gás produzido:2.71087E+01(MMscf)1.79436E+01(MMscf)1.48742E+01(MMscf)Para o experimento (B), com 2200 elementos na malha uniforme da fratura,foi obtida a sa´ıda a seguir, sem diferen¸cas relevantes nos resultados, como esperado:--> Pressão no reservatório:--> Pressão no poço:--> Quantidade de gás total:--> Quantidade de gás recuperável:--> Quantidade de gás produzido:--> Quantidade de gás produzido:--> Valor da pressão no último nó:--> Tempo de simulação--> Fator de recuperação (sobre gás total):--> Fator de recuperação (sobre gás recuperável):2.62000E+07(Pa)6.89000E+06(Pa)6.43831E+03(kg)4.26160E+03(kg)3.53270E+03(kg)2.35514E+06(kg/m^2)6.91931E+06(Pa)3.00000E+01(anos)5.48701E-018.28961E-01resultado para todo reservatorio--> Quantidade de gás total:--> Quantidade de gás recuperável:--> Quantidade de gás produzido:2.71087E+01(MMscf)1.79436E+01(MMscf)1.48745E+01(MMscf)A valida¸c˜ao dos resultados obtidos tamb´em foi feita por compara¸c˜ao com assa´ıdas da vers˜ao do simulador utilizada em Costa (2015). As ﬁguras 4.9 e 4.10
mostram gr´aﬁcos relativos ao exeperimento (A) com 400 elementos na malha dafratura. Tais gr´aﬁcos n˜ao apresentam diferen¸cas vis´ıveis em rela¸c˜ao aos obtidospara o experimento (B), dada a semelhan¸ca dos resultados. Na ﬁgura 4.9, vemosos perﬁs de press˜ao ao longo dos 30,5 metros de dimens˜ao da fratura em 7 temposespec´ıﬁcos: 1 mˆes, 6 meses, 1, 5, 10, 20 e 30 anos.
94Figura 4.9: Perﬁs de press˜ao ao longo da fratura (30,5 metros) para: 1 mˆes, 6meses, 1, 5, 10, 20 e 30 anos.
A ﬁgura 4.10 mostra a produ¸c˜ao acumulada em Kg para o reservat´orio.
Figura 4.10: Produ¸c˜ao acumulada em Kg4.3.1
Ambiente de Execu¸c˜ao e Metodologia dos testesOs testes da aplica¸c˜ao paralelizada com OpenMP foram realizados e umam´aquina com duas CPUs multi-core com as seguintes especiﬁca¸c˜oes:• 2 Processadores Quad-Core Intel(R) Xeon(R) CPU X5550 @ 2.67GHz(Total de 8 cores)95• 12GB de mem´oria RAM DDR3• Sistema Operacional Ubuntu 12.04.5 LTSO compilador utilizado foi o gfortran vers˜ao 4.6.3 e todos os experimentosparalelos para a tomada de tempo foram repetidos 6 vezes para cada conﬁgura¸c˜aode n´umero de unidades de execu¸c˜ao, ou threads. Ao ﬁm de cada experimento,foram consideradas as m´edias das 6 execu¸c˜oes de cada caso: 1, 2, 4, 6 e 8 threads.
Nas se¸c˜oes seguintes apresentamos os resultados das tomadas de tempo para aaplica¸c˜ao paralelizada com OpenMP.
4.3.2
Resultados do experimento (A) com OpenMPNesta se¸c˜ao apresentamos os resultados das tomadas de tempo com a vers˜aoparalelizada com OpenMP. A tabela 4.2 mostra os tempos totais de execu¸c˜ao daaplica¸c˜ao (em minutos) para 1, 3, 4, 6 e 8 threads. Para cada n´umero de threads aaplica¸c˜ao foi executada 6 vezes. Na linha em destaque na tabela s˜ao apresentadasas m´edias dos tempos de execu¸c˜ao. A ´ultima linha apresenta o speedup obtido emcada caso onde:T empo serialT empo paraleloSpeedU p =Tabela 4.2: Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP para oexperimento (A).
1 Thread 2 Threads4.48
4.48
4.48
4.5
4.58
4.57
4.52
1x4 Threads1.37
1.37
1.37
1.37
1.37
1.4
1.37
3.29x
6 Threads0.98
0.95
0.92
0.92
0.93
0.92
0.94
4.82x
8 Threads0.75
0.72
0.73
0.75
0.72
0.72
0.73
6.18x
Execu¸c˜ao #1Execu¸c˜ao #2Execu¸c˜ao #3Execu¸c˜ao #4Execu¸c˜ao #5Execu¸c˜ao #6M´edia (minutos)SpeedUp Obtido2.55
2.53
2.53
2.52
2.65
2.53
2.55
1.77x
Na ﬁgura 4.11 ´e mostrado o gr´aﬁco dos speedups obtidos com OpenMP (emverde) em compara¸c˜ao ao caso ideal, speedup linear (em vermelho).
96Figura 4.11: Speedups da vers˜ao com OpenMP para o experimento (A).
4.3.3
Resultados do experimento (B) com OpenMPOs testes realizados para os experimento (A) foram repetidos para oexperimento (B), com malha uniforme de 2200 elementos na fratura. A seguir s˜aoexibidos: a tabela de tempos obtidos e o gr´aﬁco de speedups, os mesmos exibidosanteriormente para o experimento (A).
Tabela 4.3: Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP para oexperimento (B).
1 Thread 2 Threads25.47
24.93
24.40
24.97
24.95
25.52
25.04
1x4 Threads7.22
7.35
7.32
7.23
7.18
7.20
7.25
3.45x
6 Threads5.27
5.30
5.53
5.27
5.25
5.32
5.32
4.70x
8 Threads4.12
4.37
3.95
4.33
4.15
4.07
4.16
6.01x
Execu¸c˜ao #1Execu¸c˜ao #2Execu¸c˜ao #3Execu¸c˜ao #4Execu¸c˜ao #5Execu¸c˜ao #6M´edia (minutos)SpeedUp Obtido14.33
14.52
14.32
14.32
14.33
14.30
14.35
1.74x
97Figura 4.12: Speedups da vers˜ao com OpenMP para o experimento (B).
4.3.4
Discuss˜ao dos resultados e otimiza¸c˜ao com OpenMPAo ﬁm dos testes anteriores, foi poss´ıvel observar que a paraleliza¸c˜ao comOpenMP apresentou signiﬁcativos ganhos de desempenho, atingindo, para 8threads, speedups de 6,18x para o experimento (A) e de 6,01x para o experimento(B).
Speedups s˜ao m´etricas afetadas pelo balanceamento de carga, ou seja,pela forma como ´e feita a distribui¸c˜ao da carga de processamento entre asdiferentes threads ou unidades de execu¸c˜ao. Se o balanceamento ´e insuﬁciente,algumas threads terminam seu trabalho muito antes das demais e precisam esperarociosamente pelas outras, quando poderiam estar realizando parte do trabalhoextra que est´a destinado `as demais. Isso impacta negativamente o speedup obtido.
Sabe-se que, em nosso modelo, os problemas relativos ao bloco em sua parteinferior (mais pr´oximos ao po¸co) s˜ao problemas mais demorados que os localizadosna parte superior. Se isso for um fato, signiﬁcaria que as threads respons´aveis pelosproblemas superiores terminariam seu trabalho primeiro e ter´ıamos uma situa¸c˜aodesbalanceamento, ainda n˜ao mensurada, que poderia estar afetando o speedupobtido.
A ﬁm de conﬁrmar a hip´otese de que os problemas inferiores s˜ao mais98custosos, avaliamos, separadamente, os tempos totais de execu¸c˜ao gastos em cadaum dos problemas do bloco, para que o desbalanceamento de carga pudesseser visualizado em termos pr´aticos. As ﬁgura 4.13 e 4.14 mostram, para osexperimentos (A) e (B), os tempos de execu¸c˜ao, acumulados em todos os passos detempo da simula¸c˜ao, de cada um dos problemas do bloco, sendo os valores mais `aesquerda aqueles relativos aos problemas superiores (afastados do po¸co) e os mais`a direita, relativos aos problemas mais pr´oximos do po¸co.
Figura 4.13: Tempos de execu¸c˜ao por cada problema do bloco para o experimento(A).
Figura 4.14: Tempos de execu¸c˜ao por cada problema do bloco para o experimento(B).
Ambos os resultados s˜ao parecidos. As ﬁguras 4.13 e 4.14. Mostram umaoscila¸c˜ao consider´avel dos custos dos problemas do bloco ao longo de toda aexterns˜ao da fratura, por´em ambos os casos apresentam uma linha de tendˆenciacom uma inclina¸c˜ao a qual, embora pequena, ´e capaz de demonstrar que, de fato,99os problemas mais pr´oximos ao po¸co tendem a ser mais lentos, gerando algumdesbalanceamento de carga.
O padr˜ao OpenMP oferece recursos para o melhor balanceamento da cargaentre as threads. A cl´ausula schedule, quando usada na paraleliza¸c˜ao de um loop,pode deﬁnir, de diversas formas, como as itera¸c˜oes do loop ser˜ao divididas entre asthreads para promover melhor balanceamento de carga. A forma padr˜ao utilizadacom a omiss˜ao da cl´ausula schedule ´e chamada de escalonamento est´atico edivide todo o espa¸co de itera¸c˜oes do loop em blocos de itera¸c˜oes de tamanhoaproximadamente igual ao quociente entre o n´umero total de itera¸c˜oes do loope o n´umero de threads. Tais blocos de itera¸c˜oes, ou chunks, s˜ao ent˜ao designadospara as threads, ainda em tempo de compila¸c˜ao.
Os resultados expostos at´e aqui utilizam o escalonamento est´atico. Os testesdas se¸c˜oes 4.3.2 e 4.3.3 foram repetidos com a cl´ausula schedule deﬁnindouma nova maneira de dividir o espa¸co de itera¸c˜oes entre as threads capaz dediminuir os efeitos do desbalanceamento: o escalonamento dinˆamico. No loopparalelizado em nosso simulador, mostrado na listagem 4.5,
foi adicionada acl´ausula schedule(dynamic).
Com a utiliza¸c˜ao do escalonamento dinˆamico, recomendado para situa¸c˜oesonde o custo das itera¸c˜oes do loop n˜ao ´e constante, todas as itera¸c˜oes s˜aoorganizadas em uma esp´ecie de ﬁla de trabalho interna, por meio da qual s˜aodistribu´ıdas para as threads `a medida em que estas terminam seu trabalho. Dessaforma, evita-se que tenhamos threads ociosas por muito tempo.
A ﬁguras 4.15 e 4.16 mostram os novos speedups obtidos para o experimento(A) e para o experimento (B), por´em utilizando a cl´ausula schedule(dynamic).
100Figura 4.15: Speedups com a cl´ausula schedule(dynamic) para o experimento(A).
Figura 4.16: Speedups com a cl´ausula schedule(dynamic) para o experimento(B).
Com essesresultados,´eposs´ıvelperceberqueacl´ausulaschedule(dynamic) elevou consideravelmente os speedups obtidos, apesar deas inclina¸c˜oes da linhas de tendˆencia das ﬁguras 4.13 e 4.14 serem pequenas.
Neste momento ´e interessante saber o que ocorreria em situa¸c˜oes onde asinclina¸c˜oes s˜ao mais pronunciadas. Para o mesmo n´umero de tarefas, mantendoa malha da fratura com 400 elementos, foram aumentadas as malhas do bloco de135 para 600 elementos. A ﬁgura 4.17 mostra os resultados das tomadas de tempo101similares `as da ﬁgura 4.13, por´em com 600 elementos nas malhas do bloco.
Figura 4.17: Tempos de execu¸c˜ao por cada problema do bloco (Fratura com 400elementos e malhas de 600 elementos no bloco)Pode-se observar que as varia¸c˜oes diminu´ıram consideralvemnte. A linha detendˆencia continua apontando um maior custo nos problemas pr´oximos ao po¸co e,dessa vez com uma inclina¸c˜ao maior. A diferen¸ca percebida nas inclina¸c˜oes indicaque no caso com 600 elementos nas malhas do bloco, h´a uma maior diferen¸ca entreos custos dos problemas pr´oximos ao po¸co e aqueles mais distantes. Os valores detais inclina¸c˜oes s˜ao mostrados na ﬁgura 4.18 como fun¸c˜ao do n´umero de elementosnas malhas do bloco. Foi inclu´ıdo um experimento adicional e intermedi´ario com300 elementos nas malhas do bloco.
Figura 4.18: Inclina¸c˜oes das linhas de tendˆencia das ﬁguras 4.13 e 4.17 em fun¸c˜aodo tamanho das malhas do bloco.
Esses resultados indicam que, com malhas maiores no bloco, maiores ser˜ao102os problemas de desbalanceamento caso seja omitida a cl´ausula schedule e,portanto, utilizado o escalonamento est´atico. Nesses casos, espera-se que aeﬁc´acia da cl´ausula schedule(dynamic) seja maior, sendo maiores tamb´emos speedups com sua utiliza¸c˜ao. Apresentamos a seguir os resultados de speedupdos experimentos (A) e (B) por´em com as malhas do bloco aumentadas para 600elementos e uso da cl´ausula schedule(dynamic).
Figura 4.19: Speedups com a cl´ausula schedule(dynamic) para o experimento(A) com malhas do bloco aumentadas para 600 elementos..
Figura 4.20: Speedups com a cl´ausula schedule(dynamic) para o experimento(B) com malhas do bloco aumentadas para 600 elementos.
Osresultados mostram que, na verdade, os benef´ıcios da cl´ausula103schedule(dynamic) tiveram menor impacto nesses casos. Mesmo com umamaior inclina¸c˜ao na linha de tendˆencia da ﬁgura 4.17, que indica maior diferen¸caentre os custos dos problemas da parte inferior do bloco e os da parte superior,os ganhos em speedup atribu´ıdos ao uso do escalonamento dinˆamico foram menosimportantes do que nos casos dos experimentos (A) e (B), mostrados nas ﬁguras4.15 e 4.16, onde nota-se uma maior distˆancia entre static e dynamic.
Estas observa¸c˜oes nos permitem concluir que a eﬁc´acia da cl´ausulaschedule(dynamic) esteve muito mais relacionada com uma grande oscila¸c˜aonos custos de cada problema do que com a conhecida tendˆencia de que eles sejammais custosos pr´oximo ao po¸co.
Testes adicionais com todos os outros tipos de escalonamento oferecidos pelopadr˜ao OpenMP foram realizados para os experimentos padr˜ao (A) e (B), sendo osmelhores resultados obtidos com a cl´ausula schedule(dynamic). Levantamosa hip´otese de que, nos casos com malhas maiores no bloco, como os ´ultimoscasos testados, outros tipos de scheduling possam levar a melhores resultados.
Em raz˜ao da menor oscila¸c˜ao dos tempos de cada problema, nesses casos, oscustos inerentes ao dynamic scheduling, relacionados `a constru¸c˜ao da ﬁla quecontrola a distribui¸c˜ao da itera¸c˜oes para as threads, provavelmente n˜ao est˜ao sendosuﬁcientemente sobrepujados pela pouca melhoria de balanceamento oferecida.
4.4
A estrat´egia de paraleliza¸c˜ao com MPINas se¸c˜oes anteriores j´a foi poss´ıvel observar ganhos signiﬁcativos nodesempenho do simulador com a estret´egia de paraleliza¸c˜ao desenvolvida comuso do padr˜ao OpenMP. Como visto no cap´ıtulo 2, o padr˜ao OpenMP ´evoltado aos sistemas de mem´oria compartilhada, sendo aplicado frequentemente naparaleliza¸c˜ao de aplica¸c˜oes executadas em ambientes com CPUs multicore como osexistentes em cada um dos n´os do cluster Altix-xe, descrito mais adiante e utilizadoem testes com MPI neste trabalho.
A aplica¸c˜ao de uma estrat´egia utilizando a padr˜ao MPI, permitiria a104utiliza¸c˜ao de v´arios n´os do cluster, uma vez que tal padr˜ao ´e destinado a sistemasde mem´oria distribu´ıda. Com objetivo de expandir os resultados obtidos comOpenMP em um ´unica m´aquina, ou n´o, foi desenvolvida, com uso do MPI, umasegunda estrat´egia de paraleliza¸c˜ao para funcionar em conjunto com a primeira.
Para a implementa¸c˜ao da estrat´egia com MPI, nos concentramos novamentena rotina resolverProbVariosBlocos, j´a mostrada na se¸c˜ao 4.2 em suasvers˜oes serial (listagem 4.2) e com OpenMP (listagem 4.5) A seguir apresentaremospor partes, em trˆes trechos de c´odigo as altera¸c˜oes feitas na rotina para a inclus˜aoda paraleliza¸c˜ao com MPI.
Primeiramente, na listagem 4.6 observamos uma s´erie novas vari´aveis, apartir da linha 7, a serem usadas neste e nos pr´oximos dois trechos mostrados.
Destacamos as vari´aveis numProcs e meuId, na linha 8, que servir˜ao paraarmazenar, respectivamente, o tamanho do comunicador MPI (quantos processosestar˜ao executando em paralelo) e a identiﬁca¸c˜ao de cada processo. A essas duasvari´aveis s˜ao atribu´ıdos valores com uso de duas rotinas do MPI: MPI_Comm_sizee MPI_Comm_rank, cujas chamadas podem ser vistas nas linhas 13 e 14.
Listagem 4.6: Vers˜ao da rotina resolverProbVariosBlocos paralelizada comOpenMP+MPI.
1 SUBROUTINE resolverProbVariosBlocos(...)
USE mpi2implicit none3INTEGER :: numBlocos, NUSTEP4REAL*8 :: fluxoMassicoDeBlocoParaFratura(numBlocos), fluxoMolM2S5, DTINTEGER :: iBlocos6INTEGER :: error7INTEGER :: numProcs, meuId8INTEGER :: meuComeco, meuFim, meuTamanho, resto, parteInteira9INTEGER :: tamanho, cont !Tamanho do comunicador MPI10REAL*8 :: receiveBuffer(numBlocos)ALLOCATABLE :: sendArray(:)REAL*8,1112105call MPI_Comm_size (mpi_comm_world, numProcs, error )13call MPI_Comm_rank (mpi_comm_world, meuId, error )14(...)
1516 END SUBROUTINE resolverProbVariosBlocosA id´eia b´asica da paraleliza¸c˜ao com MPI, que ir´a conviver com aquilo quefoi feito com OpenMP, ´e ilustrada na ﬁgura 4.21 e consiste em dividir inicialmentea fratura em um n´umero N de partes de tamanho igual e destinar, a cada n´o deexecu¸c˜ao, todos os problemas do bloco relacionados a uma por¸c˜ao da fratura.
Cada processo MPI, tratar´a, portanto, de resolver um n´umero predeﬁnido deproblemas do bloco, relativos `a sua parcela da fratura.
Isso assemelha-se aoque era feito automaticamente pelo padr˜ao OpenMP na paraleliza¸c˜ao no loopem quest˜ao com escalonamento est´atico. Internamente, cada processo continuar´autilizando o paralelismo multithread com OpenMP para resolver o seu subconjuntode problemas, visto que cada n´o ´e dotado de CPUs multicore.
Figura 4.21: A estrat´egia de paraleliza¸c˜ao em processos com MPI.
Mais adiante no c´odigo da fun¸c˜ao resolverProbVariosBlocos, ap´oso trecho exibido na listagem 4.6, existe o loop que resolve os v´arios problemas106do bloco. Esta parte ´e mostrada na listagem 4.7. Chamamos aten¸c˜ao paraa linha 14, onde percebe-se que cada processo s´o realizar´a uma parte do looporiginal, resolvendo apenas uma parcela dos problemas do bloco, como ilustradona ﬁgura 4.21 e portanto, atribuindo valores a apenas uma parte do vetorfluxoMassicoDeBlocoParaFratura na linha 16.
Listagem 4.7: Vers˜ao da rotina resolverProbVariosBlocos paralelizada comOpenMP+MPI.
1 SUBROUTINE resolverProbVariosBlocos(..)
(...)
2resto = MOD(numBlocos, numProcs)3parteInteira=(numBlocos / numProcs)4meuComeco = parteInteira * meuId + 1;5if (resto .gt. meuId) then6meuComeco = meuComeco + meuId7meuFim = meuComeco + parteInteira8else9meuComeco = meuComeco + resto10meuFim = meuComeco + parteInteira - 111endif12!$omp parallel do firstprivate(NUSTEP, TEMPO, fluxoMolM2S,13condContorno, DT)DO iBlocos=meuComeco, meuFim14CALL processadorBloco(iBlocos, NUSTEP, TEMPO, fluxoMolM2S15, condContorno(iBlocos), DT)fluxoMassicoDeBlocoParaFratura(iBlocos) = fluxoMolM2S;16END DO! fim do loop do problema micro (blocos)17!$omp end parallel do18(...)
1920 END SUBROUTINE resolverProbVariosBlocosFinalmente, ap´os o trecho apresentado na listagem 4.7 cada processo possuiapenas uma parte do vetor fluxoMassicoDeBlocoParaFratura devidamentecalculada. ´E necess´ario que, nesse momento, exista uma comunica¸c˜ao entre osprocessos para que cada um possa enviar aos demais a sua parcela do vetor. Para107isso, ´e feito uso de mais uma rotina do MPI: MPI_AllGather, cuja chamada podeser vista na listagem 4.8, linha 9. Ao ﬁm da rotina, todos os processos possuem ovetor fluxoMassicoDeBlocoParaFratura completo, com a contribui¸c˜ao dosdemais.
Listagem 4.8: Vers˜ao da rotina resolverProbVariosBlocos paralelizada comOpenMP+MPI1 SUBROUTINE resolverProbVariosBlocos (...)
(...)
2!Comunicação entre os processos:3meuTamanho = (meuFim - meuComeco) + 14if (.not. ALLOCATED(sendArray)) then5allocate(sendArray(meuTamanho))6endif7sendArray(1:meuTamanho) = fluxoMassicoDeBlocoParaFratura(8meuComeco:meufim)call MPI_AllGather(sendArray, meuTamanho, MPI_REAL8,9receiveBuffer,meuTamanho, MPI_REAL8, MPI_COMM_WORLD, error)fluxoMassicoDeBlocoParaFratura(1:numBlocos) = receiveBuffer(1:10numBlocos)11 END SUBROUTINE resolverProbVariosBlocos4.5
Testes de desempenho II: Paraleliza¸c˜ao com OpenMP + MPINesta se¸c˜ao abordamos os testes de desempenho feitos com a segundaestrat´egia de paraleliza¸c˜ao desenvolvida, utilizando OpenMP e MPI em conjunto.
Os casos de teste s˜ao os mesmos experimentos (A) e (B) utilizados para os testescom OpenMP e descritos na se¸c˜ao 4.3.
4.5.1
Ambiente de Execu¸c˜ao e Metodologia dos testesTodos os testes realizados para a paraleliza¸c˜ao com OpenMP+MPI foramexecutados no cluster Altix-xe, do LNCC. O cluster ´e composto por 30 n´os de108execu¸c˜ao, cada um com a seguinte especiﬁca¸c˜ao:• Modelo Altix-XE 340• 2 Processadores Quad Core Intel(R) Xeon(R) CPU E5520 @ 2.27GHz(Total de 8 cores)• 24GB de mem´oria DDR3O compilador utilizado foi o gfortran vers˜ao 4.7.2. A implementa¸c˜ao do MPIutilizada foi o OpenMPI 1.8.5 e a metodologia de testes utilizada foi a mesma dase¸c˜ao 4.3.
Para os testes com MPI, foram submetidos jobs ao gerenciador de ﬁlas SunGrid Engine (SGE) e a aplica¸c˜ao foi testada em uma ﬁla que d´a acesso a 8 n´os comconﬁgura¸c˜ao descrita anteriormente. Por esta raz˜ao, os testes foram feitos com om´aximo de 8 processos, cada um utilizando 8 threads OpenMP internamente aon´o.
4.5.2
Resultados do experimento (A) com OpenMP+MPINesta se¸c˜ao apresentamos os resultados das tomadas de tempo com a vers˜aoparalelizada via OpenMP e MPI, para o experimento (A). A tabela 4.4 exibe, naparte esquerda, os tempos totais de execu¸c˜ao da aplica¸c˜ao (em minutos) para1, 3, 4, 6 e 8 threads (somente OpenMP) e, na parte direita, os tempos deexecu¸c˜ao utilizando a vers˜ao h´ıbrida (OpenMP e MPI), sempre com 8 threads,por´em variando o n´umero de processos. Para cada caso, a aplica¸c˜ao foi executada6 vezes. Na linha em destaque na tabelaa s˜ao apresentadas as m´edias dos temposde execu¸c˜ao. A ´ultima linha apresenta o speedup obtido em cada caso.
109Tabela 4.4: Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP+MPI parao experimento (A).
(P) Processos MPI(T) Threads OpenMP(T) Threads OpenMP2T3.50
3.47
3.37
3.52
3.43
3.43
3.45
1T6.40
6.42
6.43
6.28
6.28
6.03
6.31
1.00x 1.83x 3.38x 4.87x 6.07x 6.04x
1P 8T 2P 8T 4P 8T 8P 8T1.03
1.05
1.05
1.03
1.05
1.05
1.04
4T1.85
1.88
1.88
1.88
1.83
1.87
1.87
6T1.32
1.30
1.28
1.32
1.28
1.27
1.29
8T1.02
1.05
1.03
1.05
1.05
1.03
1.04
Execu¸c˜ao #1Execu¸c˜ao #2Execu¸c˜ao #3Execu¸c˜ao #4Execu¸c˜ao #5Execu¸c˜ao #6M´edia (minutos)SpeedUp Obtido0.30
0.30
0.30
0.30
0.30
0.30
0.30
21.03x 30.69x
0.62
0.65
0.65
0.65
0.65
0.63
0.64
9.83x
0.20
0.23
0.20
0.20
0.20
0.20
0.21
O gr´aﬁco da ﬁgura 4.22 mostra as m´edias dos tempos de execu¸c˜ao destacadasna tabela 4.4.
Figura 4.22: M´edias dos tempos de execu¸c˜ao (em minutos) da vers˜ao comOpenMP+MPI para o experimento (A).
Na ﬁgura 4.23 ´e mostrado o gr´aﬁco de speedups.
S˜ao exibidos, paravisualiza¸c˜ao comparativa, os speedups obtidos com a vers˜ao que inclui somenteOpenMP (em verde), aos quais juntam-se os speedups da vers˜ao h´ıbrida (em azul),ambos em compara¸c˜ao ao caso ideal, speedup linear, (em vermelho).
110Figura 4.23: Speedups da vers˜ao com OpenMP+MPI para o experimento (A).
4.5.3
Resultados do experimento (B) com OpenMP+MPIOs testes realizados para os experimento (A) foram repetidos para oexperimento (B), com malha uniforme de 2200 elementos na fratura. A seguirs˜ao exibidos: a tabela de tempos obtidos, o gr´aﬁco com as m´edias de tempo e ogr´aﬁco de speedup, os mesmos exibidos anteriormente para o experimento (A).
Tabela 4.5: Tempos de execu¸c˜ao (em minutos) da vers˜ao com OpenMP+MPI parao experimento (B).
(P) Processos MPI(T) Threads OpenMP(T) Threads OpenMP1T2T4T1P 8T 2P 8T 4P 8T 8P 8T5.77
5.77
5.68
5.78
5.75
5.75
5.75
6T7.10
7.43
7.27
7.23
7.02
7.25
7.22
8T5.68
5.68
5.77
5.80
5.75
5.70
5.73
Execu¸c˜ao #1Execu¸c˜ao #2Execu¸c˜ao #3Execu¸c˜ao #4Execu¸c˜ao #5Execu¸c˜ao #6M´edia (minutos)SpeedUp Obtido19.28
19.65
19.62
19.68
19.25
19.10
19.43
37.67
36.93
36.48
37.22
37.70
37.18
37.20
1.00x 1.91x 3.74x 5.15x 6.49x 6.47x
10.07
9.92
9.95
9.75
10.20
9.87
9.96
2.95
2.95
2.93
2.93
2.95
2.97
2.95
12.62x 20.20x 37.62x
1.90
1.75
1.82
1.87
1.85
1.87
1.84
1.00
1.02
1.00
1.02
0.98
0.92
0.99
111Figura 4.24: M´edias dos tempos de execu¸c˜ao (em minutos) da vers˜ao comOpenMP+MPI para o experimento (B).
Figura 4.25: Speedups da vers˜ao com OpenMP+MPI para o experimento (B).
4.5.4
Discuss˜ao dos resultados com MPIQuanto `a estrat´egia de paraleliza¸c˜ao h´ıbrida com OpenMP e MPI, obtivemosresultados de speedup de at´e 30,69x para o experimento (A) e 37,62x para oexperimento (B). Embora tais n´umeros estejam mais distantes do speedup linear,consideramos esta uma boa aproxima¸c˜ao inicial para uma paraleliza¸c˜ao do modeloem m´aquinas de mem´oria distribu´ıda que ainda pode ser aperfei¸coada. Sem aparaleliza¸c˜ao com MPI, estar´ıamos limitados a apenas um n´o de execu¸c˜ao.
112Os problemas quanto ao balanceamento de carga vistos para o OpenMPtamb´em ocorrem na paraleliza¸c˜ao com MPI, neste caso com um agravante: adivis˜ao inicial da fratura em por¸c˜oes de tamanho pr´e-deﬁnido foi a ideia centralda estrat´egia de paraleliza¸c˜ao para a divis˜ao de trabalho, o que se assemelha aoescalonamento est´atico do OpenMP. Espera-se que o desbalanceamento n˜ao possaser corrigido com a mesma facilidade encontrada no caso do OpenMP, que oferecemais ﬂexibilidade nesse sentido, com pouca altera¸c˜ao de c´odigo, por meio do usoda cl´ausula schedule.
O balanceamento de carga com MPI dever´a envolver t´ecnicas desenvolvidaspelo programador a ﬁm de que se divida os problemas do bloco entre os processosde forma mais adequada. Uma solu¸c˜ao paralela mais avan¸cada com MPI dever´adividir o espa¸co de itera¸c˜oes do loop mostrado na listagem 4.7 entre os processosde forma mais elaborada do que aquela mostrada na ﬁgura 4.21.
Um ponto de melhoria aqui identiﬁcado ´e a utiliza¸c˜ao de uma alternativa`a rotina MPI_AllGather,cuja chamada foi mostrada na listagem 4.8.
A rotina promovecomunica¸c˜oes desnecess´ariasentretodos os processospara que cada um envie a todos os demais a sua parcela do vetorfluxoMassicoDeBlocoParaFratura. ´E necess´ario que apenas um processocontenha o vetor completo para que prossiga com a execu¸c˜ao do programa. A
economia de comunica¸c˜oes entre os processos poder´a beneﬁciar consider´avelmenteo desempenho geral da aplica¸c˜ao.
113Cap´ıtulo 5Conclus˜oes e perspectivasNesta disserta¸c˜ao descrevemos um trabalho centrado em aspectoscomputacionais, realizado com um simulador relacionado `a ciˆencia de escoamentosem meios porosos. Baseado em uma implementa¸c˜ao original da d´ecada de 1980que se destacou em sua ´epoca como um poderoso programa de elementos ﬁnitos,o simulador pode, atualmente, beneﬁciar-se de algumas t´ecnicas de programa¸c˜aomais modernas. Este trabalho representou um passo evolutivo deste simulador quese manifestou de duas formas: (i) o emprego da programa¸c˜ao orientada a objetosem um de seus m´odulos e (ii) o desenvolvimento de estrat´egias de computa¸c˜aoparalela para reduzir o seu tempo de execu¸c˜ao.
Quanto ao primeiro aspecto, desenvolvemos uma reformula¸c˜ao do m´odulode sistemas de equa¸c˜oes deste simulador, conferindo ao mesmo caracter´ısticas maismodernas com a inclus˜ao do paradigma de orienta¸c˜ao a objetos, visando contribuirpara sua melhor organiza¸c˜ao, entendimento humano e capacidade de evolu¸c˜ao. Os
novos m´odulos com classes facilitam e encorajam a troca ou incorpora¸c˜ao de novossolvers neste ou em outros simuladores semelhantes. Al´em disso, a reformula¸c˜aofuncionou como facilitadora para o desenvolvimento de estrat´egias de paraleliza¸c˜aopara este simulador.
Quanto ao desempenho de execu¸c˜ao, desenvolvemos estrat´egias com ospadr˜oes OpenMP e MPI para a solu¸c˜ao em paralelo de m´ultiplos problemas deelementos ﬁnitos. A refatora¸c˜ao do m´odulo referente aos sistemas de equa¸c˜oes,114descrita no cap´ıtulo 3, facilitou essa tarefa. A inclus˜ao do paradigma de orienta¸c˜aoa objetos tornou mais natural a tarefa de criar m´ultiplas instˆancias em mem´oriade uma mesma entidade denominada sistema de equa¸c˜oes, para sua solu¸c˜ao emparalelo.
Nesse momento foi poss´ıvel observar como a escalabilidade do designpˆode contribuir para a escalabilidade de execu¸c˜ao. A organiza¸c˜ao est´atica doc´odigo-fonte de forma modular, a qual promoveu o agrupamento de elementosrelacionados, o encapsulamento e as abstra¸c˜oes, acabou, tamb´em, por contribuirpara a facilita¸c˜ao do desenvolvimento de solu¸c˜oes paralelas, que melhoraram odesempenho do simulador.
Beneﬁciando-se dos resultados obtidos neste trabalho, s˜ao algumas asperspectivas de trabalhos futuros.
Em primeiro lugar, ´e importante reconhecer que, embora os novos m´oduloscom orienta¸c˜ao objetos tenham trazido benef´ıcios ao simulador, contribuindopara sua melhor organiza¸c˜ao e capacidade de evolu¸c˜ao, estes s˜ao resultado deuma interven¸c˜ao localizada, restrita ao m´odulo de sistemas de equa¸c˜oes. Assim,ressaltamos que o simulador n˜ao apresenta, neste momento, caracter´ısticas deum produto ﬁnal desenvolvido com orienta¸c˜ao a objetos e n˜ao explora todos osrecursos deste paradigma, como, por exemplo, a prote¸c˜ao de dados. Dessa forma, aexpans˜ao do emprego da orienta¸c˜ao a objetos para outros m´odulos deste simulador,bem como a maior e mais profunda explora¸c˜ao dos recursos oferecidos por talparadigma, surgem como perspectivas para a continua¸c˜ao dos trabalhos.
Quanto `as estrat´egias de paraleliza¸c˜ao, especialmente `aquela desenvolvidacom o padr˜ao MPI, pode-se dizer que a continua¸c˜ao dos trabalhos envolve ciclosde otimiza¸c˜ao que podem melhorar o desempenho obtido at´e o presente momento.
Ainda que os testes de desempenho aqui realizados tenham utilizado o solverbaseado em elimina¸c˜ao de Gauss, mais adequado ao nosso modelo em espec´ıﬁco,a solu¸c˜ao paralela desenvolvida ´e independente de solver. Isso signiﬁca que, emoutras situa¸c˜oes, nas quais o uso de um solver mais robusto como o Intel Pardiso115se fa¸ca necess´ario, como, por exemplo, simula¸c˜oes com malhas bidimensionais outridimensionais, a mesma estrat´egia de paraleliza¸c˜ao poder´a ser utilizada, aindaque sejam demandados, provavelmente, esfor¸cos de otimiza¸c˜ao.
Tamb´em merece lembran¸ca o fato de que a refatora¸c˜ao do m´odulo de sistemasde equa¸c˜oes com inclus˜ao de orienta¸c˜ao a objetos possui potencial de re´uso emoutros simuladores similares que utilizam a mesma implementa¸c˜ao base do MEF.
Portanto, estender os benef´ıcios das classes a outros programas tamb´em ´e umaperspectiva de trabalho e pode representar novas possibilidades para os mesmos.
Alguns simuladores utilizados no LNCC contam apenas com uma op¸c˜ao de solver.
A inclus˜ao dos novos m´odulos com classes poder´a oferecer, com certa facilidade,nova op¸c˜oes em tal quesito.
116Referˆencias Bibliogr´aﬁcasK.J. Bathe. Finite Element Procedures in Engineering Analysis. Prentice-Hall, 1982.
Stephen J. Chapman. Fortran 95/2003 for Scientists and Engineers.
McGraw-Hill, 3 edi¸c˜ao, 2004.
Patr´ıcia A. Pereira Costa. Modelagem Computacional Multiescala deReservat´orios n˜ao Convencionais de G´as em Folhelhos. Tese deDoutorado, LNCC, 2015.
Thomas J. R. Hughes. The ﬁnite element method :linear static anddynamic ﬁnite element analysis. Englewood Cliﬀs, N.J. Prentice-HallInternational, 1 edi¸c˜ao, 1987.
James Jeﬀers e James Reinders.
Intel Xeon Phi Coprocessor High-Performance Programming. Morgan Kaufmann, 1 edi¸c˜ao, 2013.
ISBN9780124104143.
David Kirk e Wen-Mei. Hwu. Programming Massively Parallel Processors:A Hands-on Approach. Morgan-Kaufmann, 2013.
T. G. Mattson, B. A. SANDERS, e B. L. MASSINGILL. Patterns for ParallelProgramming. Addison Wesley, 2004. ISBN 0321228111.
Peter S. Pacheco. An Introduction to Parallel Programming. MorganKaumann, 2011.
117