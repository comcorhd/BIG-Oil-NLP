Felipe Codevilla MoraesVisão computacional em meio subaquático:Um estudo sobre detecção de pontos de interessee classificação utilizando contexto.
Universidade Federal de Rio GrandePrograma de Pós graduação em ComputaçãoMestrado em Engenharia de ComputaçãoOrientador: Nelson Duarte Lopez FilhoCoorientador: Silvia Silva da Costa BotelhoBrasil5 de março, 2015Um estudo sobre detecção de pontos de interessee classificação utilizando contexto./ Felipe Codevilla Moraes. – Brasil, 5 de março,2015-Orientador: Nelson Duarte Lopez FilhoFelipe Codevilla MoraesVisão computacional em meio subaquático:Dissertação de Mestrado – Universidade Federal de Rio GrandePrograma de Pós graduação em ComputaçãoMestrado em Engenharia de Computação, 5 de março, 2015.
1. Visão Computacional; 2. Visão Subaquática.
CDU 02:141:005.7
Felipe Codevilla MoraesVisão computacional em meio subaquático:Um estudo sobre detecção de pontos de interessee classificação utilizando contexto.
Nelson Duarte Lopez FilhoOrientadorSilvia Silva da Costa BotelhoCo-orientadoraNuno Estrela GraciasConvidadoGlauber Acunha GonçalvezConvidadoRafael GarciaConvidadoBrasil5 de março, 2015AgradecimentosEntre tantas dúvidas , resolvi apostar permanecer onde estava e, ao contrário doque se espera, não poderia ter acertado mais.
Primeiramente gostaria de agradecer a minha orientadora Silvia Botelho por todasas brilhantes ideias e oportunidades oferecidas, obviamente nada disso seria possível semela.
Agradeço a todos os colegas e amigos onde destaco Luan Silveira, Joel Gaya, FelipeGuth e, em especial, a ajuda fornecida pelo Pedro Ballester na última hora.
Agradeço a banca por comparecer e avaliar este trabalho.
I want to thank all the people from the ViCOROB Lab in Girona for receiving meso well during the 10 months I spent in Catalonia. Without this experience, the majorityof this thesis would not be possible.
I also want to thank all my classmates and friends from Vibot (and Patryk) for allthe fun and professional adventures we had toguether.
Agradeço o apoio financeiro da Agência Nacional do Petróleo, Gás Natural e Bio-combustíveis – ANP – , da Financiadora de Estudos e Projetos – FINEP – e do Ministérioda Ciência e Tecnologia – MCT por meio do Programa de Recursos Humanos da ANP parao Setor Petróleo e Gás – PRH-ANP/MCT. Um agradecimento especial aos professoresresponsáveis pelo PRH - 27, Maria Isabel e Gilberto Griep.
Por fim, agradeço a minha família pelo apoio e carinho que sempre me deram, emespecial ao meu pai, por sempre servir como um formidável exemplo ético em minha vida.
ResumoA exploração e o monitoramento do bentos no ambiente marinho possuemimportância econômica e ambiental crescente na sociedade atual. A qualidade datecnologia de obtenção de imagens óticas subaquáticas tem melhorado consideravel-mente devido ao advento dos Remotely Operated Vehicles (ROV) e dos AutonomousUnderwater Vehicles (AUVs), o que tem possibilitado a coleta de milhares de dadosvisuais do fundo do oceano.
Técnicas de visão computacional, atualmente em franca utilização em am-bientes terrestres, podem auxiliar a interpretação automática destas imagens, sejapara minimizar o trabalho de identificação e monitoramento de feições e espécies,seja para fornecer subsídios a realização autônoma de missões.
Porém devido a presença do meio líquido, a propagação da luz no meio su-baquático apresenta efeitos fotométricos que causam degradação na imagem, emer-gindo diversas questões a serem tratadas na classificação de imagens subaquáticas,as quais não estão presentes em outros ambientes.
Assim, o objetivo geral deste trabalho é estudar técnicas de visão computa-cional, e sua sensibilidade a presença do meio líquido. De forma mais precisa, duastécnicas de visão computacional são principalmente tratadas: a detecção de pontosde interesse e a adição das informações de contexto para classificação de objetos emambientes subsea.
São aplicados e analisados diferentes algoritmos de detecção de pontos deinteresse frente a imagens com diferentes níveis de turbidez. Um novo dataset foiproposto capaz de fornecer cenários com diferentes níveis de turbidez e objetos emcena, permitindo o testes múltiplos dos detectores mais usados na literatura e seucomportamento frente os fenômenos de degradação causados na imagem no meiosubaquático. Foi encontrado que o algoritmo DoG se mostrou como uma melhoralternativa para resolver tal problema de forma invariante a escala.
Também foi estudada a questão da adição de contexto como forma de me-lhorar a taxa de acerto da classificação de imagens subaquáticas. Foi proposto umnovo método para incluir contexto na classificação baseado em Geoestatística ecomparou-se com outras formas tradicionais de adição de contexto como os Condi-tional Random Fields (CRF).
Palavras-chaves: Visão Computacional, Geostatística, Visão Subaquática.
AbstractThe exploration and monitoring of the benthic sea zone has an importanteconomic and environmental role in the nowadays society. The quality of the opticalimage acquiring technologies has become considerably better. This happened mainlydue to the advent of the Remotely Operated Vehicles (ROV) and the AutonomousUnderwater Vehicles (AUVs) and has opened the possibility to collect thousands ofvisual data from the seabed environment.
Computer vision techniques are today being largely used in over-land envi-ronments and can help the autonomous interpretation of images. These techniquescan help to minimize the work of identifying and monitoring species and objects.
Either having vision as a data acquiring source or to assist the automation of theoperations.
However, due to the presence of the liquid media, the light propagationin underwater environments has photometric effects that cause degradation of theimage. This degradation develops a lot of issues to be treated on underwater imagesthat do not exist in other environments.
Thus, the objective of this work is to study computer vision tecniques consid-ering their sensibility to phenomenas of the underwater environments media. Moreprecisely, mainly two computer vision techniques are considered: feature point detec-tion and the adition context information for image classification, both on underwaterimages.
Different algorithms for feature point detection are applied for feature pointdetection under different turbidity levels. We provide a new dataset capable ofproviding different scenarios with different levels of turbidity. This dataset allowedthe test of multiple feature detectors regarding their behavior with respect to thedegradation effects of water turbidity. We found that, in this scenario, the DoGalgorithm is the best alternative to solve scale invariant feature detection problems.
Finally, we studied the issue concerning the addition of context as a way toimprove the accuracy of underwater image classification. We proposed a new methodto include the context information on classification that is based on Geostatistics.
This method was compared with an other traditional form of context addition thatis the Conditional Random Fields (CRF).
Key-words: Computer Vision, Geostatistics, Underwater Vision.
Lista de ilustraçõesFigura 1 – Comportamento da aplicação dos kernels Hessian e Harris para umaimagem teste (1a). (1b) mostra a saída da medida de Harris (Eq. 1.4).
(1c) mostra a saída do determinante da matriz Hessian ( Eq. 1.5 )
para a imagem teste. Tanto o Hessian como o Harris tem como saídaas regiões de alta curvatura ( Figura por Sojka (2003)). . . . . . . . . . 31
Figura 2 – O processo para geração do espaço de escala pelo DoG. Ao invés decomputar o Laplacian para cada escala, o mesmo é estimado pela dife-rença entre escalas consecutivas. Figura adaptada de (LOWE, 2004).
. 34
Figura 3 – Exemplo de um filtro caixa de tamanho 9x9 aplicado para geração deum espaço de escala equivalente a 𝜎 = 1.2. Outros espaços podem sergerados usando caixas maiores.
. . . . . . . . . . . . . . . . . . . . . . 34
Figura 4 – Alguns tipos de filtros utilizados para geração do espaço de escala peloCenSurE. O filtro estrela, o filtro hexagonal e o filtro por diferença decaixas. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
Figura 5 – Espaços de escala gerados. Primeira coluna mostra o espaço Gaussiano.
Segunda coluna mostra o filtro média de caixas usado pelo FastHes-sian. Terceira coluna mostra um filtro poligonal estrelar de seis lados.
A quarta Coluna mostra o espaço de escala anisotrópico usado peloKAZE.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
Figura 6 – Janela considerada para a classificação usando contexto. No caso daintegração de contexto diretamente nos classificadores (Fig. 6a), nãosão considerada as relações entre a vizinhança com si própria (Fig. 6b).
Ou seja, se existem propriedades correlacionadas na vizinhança.
. . . . 42
Figura 7 – A representação gráfica de um modelo CRF. Os quadrados em verme-lho (𝜙𝑢𝑖 (𝑥𝑖, 𝜃𝑢)) são os fatores unitários calculados com o resultado dadopelo classificador. Os quadrados em azul são os fatores locais computa-dos em cada aresta e utilizados para introduzir informação contextual.
Os circulos verdes representam os superpixeis sendo classificados.
. . . 44
Figura 8 – Tendências que existem para as classes estarem próximas umas dasoutras, quanto mais claro, maior é a tendência existente. Por exemplo,é possível perceber que a classe B é provável de aparecer perto de umaclasse C mas não próxima de uma classe E.
. . . . . . . . . . . . . . . 46
Figura 9 – Divisão especificada em dois níveis de classificação. O nível unário𝑃𝑢(𝐿|𝜃𝑢) onde somente a informação do superpixel segmentado é uti-lizada, apresentado em verde. E o nível local 𝑃𝑙(𝐿|𝑊), onde um de-terminado contexto local é incluído na classificação, representado pelocirculo azul. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
Figura 10 –Figura do separador linear obtido pelo treinamento do SVM. Dado osconjuntos de dados já rotulados ( Azuis e Vermelhos), o SVM determinao separador de máxima margem. A saído numérica do SVM já é própriapara se ter um certo grau de confiança do classificador.
. . . . . . . . 51
Figura 11 –Gráfico mostrando a probabilidade de acerto em função da máximaconfiança retornada pelo classificador para um conjunto de dados. Em
vermelho tem-se a função 𝐶𝑙𝑖 treinada a partir do conjunto de dadosem azul. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
Figura 12 –Histograma mostrando a distribuição de probabilidades de saída deum classificador. Para o caso, a segunda classe, é a que obteve maiorprobabilidade, porém existe uma certa incerteza com relação a primeiraclasse.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
Figura 13 –Diagrama geral da adição de contexto local utilizando Geoestatística.
Primeiramente é medida a variabilidade entre as classes no contextoespacial. Tanto diretamente através das frequências de transição naimagem (taxa de transição medida), quanto através da inferência depropriedades estatísticas vindas da imagem (taxa de transição mode-lada). Em seguida são calculados os vetores de transição. Na segundaparte os vetores são utilizados para gerar pesos para imagem. Com isso,utilizando os pesos, o sistema SIS computa a adição de contexto localpara cada superpixel.
. . . . . . . . . . . . . . . . . . . . . . . . . . . 54
Figura 14 –Medida feita do número de transições que uma classe faz para cadaoutra para múltiplas distâncias. Foi utilizada um kernel móvel e foramcontadas as transições desde o centro (ponto vermelho) para todas asdireções (representado pelos quadrados). . . . . . . . . . . . . . . . . 56
Figura 15 –A transição de probabilidade modelada para um determinado dataset.
O eixo y apresenta a distância em pixeis. As linhas verdes mostramas proporções para cada classe. Pode-se observar uma certa tendênciana classe Urchin em transitar para categoria de background. Ainda,percebe-se que a classe de background tem um grande comprimentomédio, dado que sua taxa de decaimento é bastante alta.
. . . . . . . . 58
Figura 16 –Exemplo de uma vizinhança sendo considerada para um superpixel (apontado em vermelho). Um raio 𝑟 é considerado e 𝑁 pontos são amos-trados nessa vizinhança ( em azul). Cada um dos pontos amostradosirá influenciar no potencial do superpixel apontado em vermelho. . . . . 60
Figura 17 –Representação gráfica do modelo de Geoestatística (GS). Os fatoreslocais são representados em azul e usam a estatística de probabilidadede transição computada pela Eq. 3.3. Diferentemente do que no modeloda Fig. 7, vizinhos de diferentes distâncias também contribuem paracalcular a distribuição de cada posição.
. . . . . . . . . . . . . . . . . 61
Figura 18 –Três trajetórias da luz até o plano da imagem. O componente direto,contendo a informação direta da cena. O forward-scattering, contendoinformação da cena espalhada. Por fim, o backscattering contendo in-formações de fora da cena. . . . . . . . . . . . . . . . . . . . . . . . . . 64
Figura 19 –Imagem de exemplo para as degradações do ambiente subaquático. É
possível ver que existe uma variação conforme a distância e uma perdasignificativa da informação de cor. . . . . . . . . . . . . . . . . . . . . . 65
Figura 20 –A sequência utilizada para classificação de imagens em meio subaquático. 66
Figura 21 –A cena criada para avaliar os algoritmos de avaliação de features. Ela écomposta por lampadas fluorescentes e uma camera fotografando fotosimpressas do assoalho do oceano.
. . . . . . . . . . . . . . . . . . . . . 72
Figura 22 –As imagens utilizadas no teste. As três imagens foram capturadas nasBahamas em condições de turbidez próximas do ideal em uma resoluçãode 4928x3264 pixeis. . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
Figura 23 –As imagens capturadas sob diferentes níveis de degradação devido aturbidez, controlado pela adição de leite. Foram fotografadas três fotosimpressas diferentes, 𝑃1 (primeira coluna), 𝑃2 (segunda coluna) e 𝑃3(terceira coluna). Na primeira linha foi mostrada a imagem limpa (semleite) para cada foto capturada. A segunda linha apresenta o intervalode Baixa Turbidez com por volta de 15ml de leite (𝑇4). O intervalo deMédia Turbidez é mostrado na segunda linha e contém por volta de 50ml de leite (𝑇10). Finalmente, na ultima (quarta) linha é mostrado ointervalo com Alta turbidez tendo por volta de 100 ml de leite (𝑇16).
Quantidade de leite setada para uma caixa com 1000 litros de água. . . 76
Figura 24 –Repetibilidade ( Taxa de Acerto) contra o indice de degradação estru-tural normalizado (NSDI). As linhas em laranja indicam os intervalosde degradação. Baixa Turbidez 0 até 0.25; Média Turbidez, 0.25 até0.75, e Alta Turbidez de 0.75 até 1.
. . . . . . . . . . . . . . . . . . . . 79
Figura 25 –Comparação entre a geração de um nível do kernel do espaço de escalausado por quatro detectores diferentes. O kernel foi aplicado em níveisde turbidez diferentes para a imagem 𝑃1. Sendo que a primeira linha éa imagem limpa (𝑇0), a segunda linha é uma imagem com baixo nívelde degradação (𝑇4), a terceira linha apresenta uma imagem com médionível de degradação (𝑇10), a quarta linha apresenta imagens do nível dedegradação alto (𝑇16). Para cada caso é mostrado o resultado de filtroequivalente a a aproximadamente um kernel gaussiano de 𝜎 = 59.0.
Primeira Coluna: Gaussiano puro. Segunda Coluna: Borramento apro-ximado em caixas . Terceira Coluna: Difusão utilizando um polígono es-trelar de seis pontas. Quarta Coluna: kernel anisotrópico g2 do KAZE.
É possível ver de certa forma estruturas mais definidas para o esquemade difusão usado pelo CenSurE (AGRAWAL; KONOLIGE; BLAS, 2008). 81
Figura 26 –Partes manualmente segmentadas utilizadas para treinamento do clas-sificador. A esquerda são mostrados exemplos de nove amostras usadaspara treinar o dataset Redsea. A direita são apresentadas nove amostrasdo dataset Marker.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
Figura 27 –Curvas de confiança geradas no treinamento unário de cada classe parao dataset Redsea. A curva de confiança 𝐶𝑙𝑖 treinada para cada uma dasclasses é mostrada, se bem como o grau de confiança obtido.
. . . . . . 86
Figura 28 –Curvas de confiança geradas no treinamento unário de cada classe parao dataset Marker. A curva de confiança 𝐶𝑙𝑖 treinada para cada uma dasclasses é apresentada, bem como o grau de confiança obtido.
. . . . . . 87
Figura 29 –Vetores de transição obtidos na etapa de treinamento para o métodode Geoestatística do Capítulo 3. Os vetores indicam a probabilidade deuma classe transitar para outra a uma determinada distância. O eixox apresenta a distância em pixeis. O eixo 𝑦 dos gráficos apresenta asprobabilidades de transição. Pode-se observar, por exemplo, uma certatendência na classe Urchin em transitar para categoria de background.
88Figura 30 –Mapa temático dos Mosaicos para o dataset Redsea. As figuras mostrama porcentagem de acerto relativa ao GroundTruth. As classes são repre-sentadas pelas seguintes cores: Verde Brain Coral; Amarelo BranchinCoral; Azul Faviid Coral; Magenta Urchin e sem cor é o background.
Os seguintes resultados são mostrados.(30a) classificação Unária. (30b)mostra a classificação Unária baseada nas curvas de confiança. (30c)classificação com adição de contexto baseada em Geoestatística. (30d)classificação com adição de contexto utilizando CRF.
. . . . . . . . . . 92
Figura 31 –Mapa temático dos Mosaicos para o dataset Marker. As figuras mos-tram a porcentagem de acerto relativa ao GroundTruth. As classes sãorepresentadas pelas seguintes cores: Verde Sand; Amarelo Sea Gorgon;Azul Corals e sem cor é o background. Os seguintes resultados sãomostrados.(31a) classificação Unária. (31b) mostra a classificação Uná-ria baseada nas curvas de confiança. (31c) classificação com adição decontexto baseada em Geoestatística. (31d) classificação com adição decontexto utilizando CRF.
. . . . . . . . . . . . . . . . . . . . . . . . . 93
Figura 32 –Resultados de classificação para os datasets Marker e os datasets Red-sea. A primeira coluna apresenta a classificação unitária. A segundacoluna apresenta os resultados de Geoestatística. A terceira colunaapresenta os resultados para o CRF. Por fim, a ultima coluna apre-senta o GroundTruth. Foi utilizada como peso para o potencial local𝑤𝑙 como sendo 0.4 para ambas as abordagens. Na primeira coluna foipossível perceber um resultado melhor para o CRF devido a uma maiorsuavização local. Na segunda linha, o método de Geoestatística obtevemelhores resultados devido a suas medidas estatísticas de longa distân-cia. Na última linha é mostrado os resultados para o dataset Marker,onde ambas as abordagens tiveram melhores resultados para esse caso.
94Lista de tabelasTabela 1 – A quantidade de leite adicionada para cada nível de turbidez simulado. 75
Tabela 2 – Matriz de covariância que mostra as relações de proximidade entre asclasses. Tais medidas são fatores que indicam correlação e não distri-buições de probabilidade. Este resultado é normalizado ao final.
. . . . 86
Tabela 3 – Matriz de covariância que mostra as relações de proximidade entre asclasses. Tais medidas são fatores que indicam correlação e não distri-buições de probabilidade. Este resultado é normalizado ao final.
. . . . 87
Tabela 4 – Resultados para a taxa de acerto de diferentes segmentos para o data-set Redsea. Foram testados diversos segmentos quadrados amostradosaleatoreamente nos mosaicos. O tamanho do segmento é especificadopelo lado do quadrado . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
SumárioIntrodução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
0.1 Motivação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
0.2 Detectores de Pontos de Interesse . . . . . . . . . . . . . . . . . . . . . . . 24
0.3 Classificação de Imagens do Assoalho Oceânico . . . . . . . . . . . . . . . . 24
0.4 Sumário desta Dissertação . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
1Fundamentação Teórica 1: Detectores de Pontos de Interesse . . . . . . . 27
1.1 Detectores de Única Escala . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.1.1 Harris . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.1.2 Hessian e Laplacian . . . . . . . . . . . . . . . . . . . . . . . . . . 30
1.1.3 Comparação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
1.2 Detectores Invariantes a Escala . . . . . . . . . . . . . . . . . . . . . . . . 31
. . . . . . . . . . . . . . . . . . 32
1.2.1 Hessian-Laplace e Hessian-Laplace1.2.2 Diference-of-Gaussians(DoG). . . . . . . . . . . . . . . . . . . . . 33
1.2.3 Fast Hessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
1.2.4 Center Surround Extrema Filters(CenSurE) . . . . . . . . . . . . . 35
1.2.5 KAZE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
1.2.6 Comparação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2 Fundamentação Teórica 2: Classificação de Imagens Utilizando Contexto . 39
2.1 Utilização do Contexto em Visão Computacional . . . . . . . . . . . . . . . 39
2.1.1 Níveis de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
2.1.2
Interações de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . 40
Integração de Contexto Na Classificação . . . . . . . . . . . . . . . . . . . 41
Integrando contexto com base em Classificadores . . . . . . . . . . 42
2.2.1
Integrando contexto com base em Modelos Probabilísticos Gráficos2.2.2
422.2.2.1 O Problema da Inferência Estatística . . . . . . . . . . . . 44
2.2.2.2 Aprendizado de parâmetros . . . . . . . . . . . . . . . . . 45
2.3 Trabalhos utilizando Modelos Probabilísticos Gráficos. . . . . . . . . . . 45
2.4 Sumário . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
2.2
3 Classificação Baseada em Contexto utilizando Geoestatística. . . . . . . 49
3.1 Visão Geral da Proposta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.2 Nível Unário 𝑃𝑢(𝐿|𝜃𝑢). . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
Classificador. . . . . . . . . . . . . . . . . . . 51
Treinando Curvas de Confiança3.2.1
3.2.2
3.3 Distribuição de Probabilidades . . . . . . . . . . . . . . . . . . . . . . . . . 53
3.4 Nível Local 𝑃𝑙(𝐿|𝑊). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
. . . . . . . . . . . . . . . . 54
Taxa de Transição Medida 𝑅𝑚𝑒𝑠. . . . . . . . . . . . . . 55
3.4.1.1
3.4.1.2
Calculo da Matriz 𝑅𝑚𝑜𝑑 . . . . . . . . . . . . . . . . . . . 57
Sequential Indicator Simulation . . . . . . . . . . . . . . . . . . . . 58
. . . . . . . . . . . . . . . . . 59
3.5 Geoestatística e CRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.6 Sumário . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
3.4.1 Medindo Transições de Probabilidades3.4.2
3.4.3 Computando o Potencial Final 𝑃(𝐿)4 Classificação de Imagens do Assoalho Oceânico. . . . . . . . . . . . . . . 63
4.1 Propriedades de Imagens Subaquáticas . . . . . . . . . . . . . . . . . . . . 63
4.2 Classificação Autônoma de Imagens do fundo Oceânico . . . . . . . . . . . 66
4.2.1 Pré-Processamento . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
4.2.1.1 Contraste . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
4.2.1.2 Correção de Cor. . . . . . . . . . . . . . . . . . . . . . . 68
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
Segmentação4.2.2
4.2.3 Descritores. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
4.2.4 Treinamento e Classificação . . . . . . . . . . . . . . . . . . . . . . 70
4.3 Conclusões . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
5 Testes e Resultados 1: Detecção de Pontos de Interesse em AmbienteSubaquático . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
5.1 Descrição do experimento . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
5.1.1 Cena Montada5.1.2 Procedimento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
5.2 Avaliando a degradação causada pela turbidez . . . . . . . . . . . . . . . . 75
5.3 Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
5.3.1 Procedimento de Avaliação . . . . . . . . . . . . . . . . . . . . . . . 77
5.3.2 Comparação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
5.4 Conclusões finais6 Testes e Resultados 2: Contexto em Classificação Subaquática . . . . . . . 83
6.1 Datasets Utilizados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
6.2 Descrição do Geral do Sistema . . . . . . . . . . . . . . . . . . . . . . . . 83
6.2.1 Pré-Processamento . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.2.2
. . . . . . . . . . . . . . . . . . . . . . . 84
6.2.3 Classificação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.2.4 Adição de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.3 Treinamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
Segmentação e Descrição. . . . . . . . . . . . . . . . . . . . . 84
6.3.1 Treinamento do Classificador6.3.2 Treinamento Unário. . . . . . . . . . . . . . . . . . . . . . . . . . 85
6.3.3 Treinamento Potenciais Locais . . . . . . . . . . . . . . . . . . . . . 86
6.4
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Sistemas Testados6.5 Computação do Mapa Temático . . . . . . . . . . . . . . . . . . . . . . . . 90
6.6 Conclusões . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
7 Conclusões Finais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
7.1 Detectores de Pontos de Interesse em Imagens Subaquáticas Turvas . . . . 95
7.1.1 Contribuições Obtidas. . . . . . . . . . . . . . . . . . . . . . . . . 95
7.1.2 Limitações e Trabalhos Futuros . . . . . . . . . . . . . . . . . . . . 95
7.2 Adição de Contexto Baseado em Geoestatística . . . . . . . . . . . . . . . 96
7.2.1 Contribuições Obtidas. . . . . . . . . . . . . . . . . . . . . . . . . 96
7.2.2 Limitações e Trabalhos Futuros . . . . . . . . . . . . . . . . . . . . 96
Referências . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
23IntroduçãoEste trabalho apresenta um estudo sobre técnicas de visão computacional consi-derando os aspectos fotométricos do meio subaquático. Dois pontos chaves no processosão analisados: A extração autônoma de pontos de interesse; e a utilização do contextoespacial para a classificação.
0.1 MotivaçãoVisão computacional é a ciência que visa possibilitar às máquinas a capacidade deinterpretação e representação de informações visuais.
Com tal capacidade, diversas aplicações podem ser então desenvolvidas, como: ainspeção industrial autônoma , a reconstrução de cenas em três dimensões, a localizaçãode robôs, a rotulação ou classificação de objetos em imagens, entre outras. Tais aplicaçõespodem ser implementadas nos mais diversos ambientes, desde o domínio industrial oudoméstico, em ambientes fechados ou abertos, em localidades sobre a terra ou no fundodo mar, etc.
Neste trabalho se dá atenção especial ao ambiente marinho, o qual, cobrindo emtorno de 70% da terra, e contendo cerca de 90% de sua biodiversidade, é de evidenteimportância. O advento dos Remotely Operated Vehicles(ROV ) e dos Autonomous Un-derwater Vehicles (AUVs), tem possibilitado a coleta de milhares de imagens para moni-toramento do oceano, ampliando as possibilidades de aplicações em visão computacionalem ambientes subseaDiversas das aplicações para visão computacional em terra podem ser facilmenteextrapoladas para utilização no meio subaquático. Como exemplo, tem-se o caso da clas-sificação autônoma de imagens do assoalho oceânico. Para tal aplicação, tem-se o caso dosrecifes de corais, os quais desde 1980 sofrem de massivas perdas devido a poluição, pescaexcessiva e espécies invasivas (NEMETH et al., 2008). Uma classificação autônoma é fun-damental, dada a grande área monitorada e a necessidade de reduzir o tempo necessáriode especialistas para se classificar as espécies.
O monitoramento é também uma realidade que gera demanda para sistemas robó-ticos autônomos. Isso gera margem para utilização de sistemas visuais nas mais diversasaplicações como: a localização de robôs subaquáticos, a inspeção e rastreio de risers eflows na indústria de óleo e gás, entre outras.
Devido a dificuldade de desenvolvimento e instrumentação subsea, o uso de ROVse AUVs é recente, implicando em uma limitada quantidade de estudos relacionados ao24Introduçãodomínio da visão computacional para o ambiente subaquático. Nesse ambiente existemdesafios específicos que não necessitam ser tratados em outros ambientes. A propagação daluz em meio subaquático apresenta efeitos fotométricos associados o que causa degradaçãona formação da imagem. Efeitos como borramento, espalhamento da informação luminosae atenuação de cor na imagem, são alguns exemplos que precisam ser considerados emaplicações subaquáticasAlém disso, quando se trata das cenas capturadas em tais ambientes, a monotoni-cidade do ambiente, dada pela falta de diversificação dos objetos e a falta de estruturasgeométricas bem definidas, muito causada pela erosão, dificulta a interpretação visual, oque por sua vez, acarreta no aumento da complexidade das aplicações em visão compu-tacional.
Neste contexto, o objetivo deste trabalho é analisar duas aplicações fundamentaispara visão computacional em meio subaquático: a detecção de pontos de interesse e aconsideração de contexto para classificação de grande extensões de mosaicos de imagensdo assoalho oceânico.
0.2 Detectores de Pontos de InteresseA detecção de pontos de interesse é de fundamental importância para diversasáreas fundamentais de uso no meio subaquático, como a classificação de imagens (PAD-MAVATHI; MUTHUKUMAR; THAKUR, 2010), reconstrução 3D (BEALL et al., 2010)(NICOSEVICI et al., 2009), localização de robôs (AULINAS et al., 2011) , etc.
Este trabalho propõe um novo dataset de imagens subaquáticas, o qual é usadopara apontar os detectores de pontos de interesse mais adaptados ao meio subaquático. Taldataset deve ser capaz de isolar a degradação causada pelo comportamento da propagaçãoda luz em meio subaquáticos como a principal fonte de degradação.
Serão testados detectores, considerando diversos paradigmas para detecção, comrespeito a sua robustez a degradação das imagens subaquáticas. Um especial tratamentoserá dado aos detectores invariantes a escala por sua comprovada baixa performance nestemeio (GARCIA; GRACIAS, 2011).
0.3 Classificação de Imagens do Assoalho OceânicoA outra aplicação analisada diz respeito ao uso do contexto espacial, muito poucoutilizado para classificação de imagens subaquáticas e, de fundamental importância, amedida que grandes extensões passam a ser monitoradas.
Na classificação de grandes extensões de recifes de corais, por exemplo, é natural250.4. Sumário desta Dissertaçãoque as diferentes espécies possam estar inseridas dentro de um contexto. A utilização dainformação de contexto pode auxiliar a interpretação da cena (BAR, 2004). Assim, analisa-se diversos algoritmos para a utilização de contexto em situações e cenários genéricos.
Com isso, este trabalho tem como objetivo também propor um novo algoritmopara adição de contexto inspirado em Geoestatística, área que modela a variabilidade degrandezas no espaço geométrico, de tal forma o método proposto seja capaz de mitigar afalta de informação anotada no meio subaquático.
0.4 Sumário desta DissertaçãoO Capítulo 1 apresenta a fundamentação teórica sobre a detecção de pontos deinteresse. Primeiramente, uma definição formal de pontos de interesse é realizada e suasprincipais características desejadas são apontadas. São apresentadas as definições dosdetectores Harris e Hessian, Harris-Laplace, Hessian-Laplace, Difference of Gaussians(DoG), FastHessian, CenSurE e KAZE.
O Capítulo 2 apresenta o problema de classificação de imagens usando o contexto.
Uma definição de como representar as relações de contexto em uma imagem é apresentado.
Em seguida é feita uma revisão dos métodos de visão computacional os quais incorporamesses conceitos. Um destaque é dado aos métodos que utilizam os Conditional RandomField (CRF) para incorporar o contexto.
No Capítulo 3 é apresentado um sistema de classificação de imagens baseado emGeoestatística, a qual é uma área da estatística que busca modelar a variabilidade espacialde uma determinada grandeza. Nesse capítulo é proposta uma extensão deste conceitopara adição de informação de contexto na classificação de imagens.
O Capítulo 4 apresenta os problemas existentes na classificação de imagens su-baquáticas e também, os aspectos especiais que existem para aplicações em visão su-baquática. Também se apresenta uma breve revisão dos resultados já obtidos na classifi-cação de mosaicos do bentos sem utilização do contexto e, também, uma visão geral dosistema proposto por Shihavuddin et al. (2013) o qual foi usado como base para os testese resultados.
O Capítulo 5 apresenta um estudo sobre o comportamento dos detectores apresen-tados no Capítulo 1 quanto a sua robustez à degradação causada em imagens subaquáticas.
É especificado um experimento realizado para geração de diferentes níveis de degradaçãonas imagens. Por fim, são apresentados os detectores mais adaptados ao meio.
O Capítulo 6 apresenta um estudo de caso da aplicação de contexto para classifi-cação no meio subaquático. Os resultados gerados para o novo método proposto baseadoem Geoestatística são mostrados, e também a sua comparação com os demais métodos26Introduçãodo estado da arte em adição de contexto.
Por fim, no Capítulo 7 as conclusões deste trabalho são apresentadas.
271 Fundamentação Teórica 1: Detectores dePontos de InteresseEste capítulo apresenta a fundamentação teórica sobre detectores de pontos deinteresse. Formalmente pontos de interesse são definidos como um padrão de uma ima-gem que difere de sua vizinhança imediata (TUYTELAARS; MIKOLAJCZYK, 2008).
Normalmente são pontos com particularidades de uma imagem as quais possuem algumacaracterística visual relevante. Vale notar que, apesar do termo utilizado ser "pontos deinteresse", não é utilizada a definição matemática de um ponto infinitesimal sendo de-finidos como pequenas regiões. Pontos de interesse servem como âncoras de regiões daimagem, determinando quais posições podem ser descritas para se ter uma representaçãoconfiável da mesma. Distintas aplicações fazem uso dos pontos de interesse como: a clas-sificação de imagens (PADMAVATHI; MUTHUKUMAR; THAKUR, 2010), reconstrução3D (BEALL et al., 2010) (NICOSEVICI et al., 2009), mapeamento e localização (GIL etal., 2010) , rastreio (CORKE et al., 2007), etc.
Um exemplo de pontos de interesse seriam as quinas, as quais são responsáveispor boa parte do processo de interpretação visual de um objeto (TUYTELAARS; MIKO-LAJCZYK, 2008). Muitas vezes, os pontos de interesse apresentam uma relação semânticamais estreita com a aplicação. Por exemplo, ao classificar faces, as regiões do olho ou daboca são de grande interesse para a classificação.
A utilização de pontos de interesse locais traz as seguintes vantagens, em contrastecom o uso do contexto geral da imagem:∙ Redução significativa do custo computacional;∙ Descarte de parte do ruído presente na imagem pois somente os pontos relevantessão utilizados;∙ Obtenção e uso de apenas características mais distintas da imagem;∙ Possibilidade de reconhecimento de cenas sem a necessidade de segmentação.
Porém, para um ponto de interesse ser eficaz, a presença de algumas propriedadessão de fundamental importância (TUYTELAARS; MIKOLAJCZYK, 2008). Entre as maisimportantes tem-se:∙ Repetibilidade: Um ponto de interesse deve representar características que possamser encontradas em determinados objetos, independente da configuração em que tal28Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de Interesseobjecto foi fotografado. Dado duas imagens de um mesmo objeto ou cena, o que foivisto em ambas as cenas deve ser detectado como ponto de interesse em ambas ascenas.
∙ Distintividade: Um ponto de interesse deve representar características que sejamdistintas, com destaque sobre as demais características e que sejam especificas deum determinado objeto. Só assim este objeto pode ser descriminado com relaçãoaos demais.
A repetibilidade, de fato a propriedade mais importante (TUYTELAARS; MI-KOLAJCZYK, 2008), pode ser atingida tendo os pontos de interesse sendo invariantes adeterminadas transformações que uma imagem pode sofrer, tais como:∙ Rotação: Um ponto que pertence a uma cena, deve ser encontrado independente daorientação que a cena foi capturada.
∙ Translação: Se o ponto representa o mesma objeto, o mesmo deve ser encontradoindependente da posição na imagem onde ele foi capturado.
∙ Escala: Independente da distância em que a cena foi capturada, o mesmo pontodeverá ser encontrado.
Para outras transformações que a imagem possa sofrer, muitas vezes é interessanteque um ponto seja somente robusto. Ou seja, capaz de ser encontrado somente até umdeterminado nível da transformação. Alguns efeitos, ou transformações, a se ter robustezsão: efeitos de discretização, artefatos causados por compressão, borramento devido amovimento, ruído branco, distorção de perspectiva, etc.
Diversos algoritmos são desenvolvidos para encontrar pontos os quais apresentamas propriedades acima descritas. São eles chamados os Detectores de Pontos de Interesse.
Os Detectores são desenvolvidos de forma a terem um valor de retorno alto em relação acertas estruturas presentes na imagens. Define-se estrutura como um determinado padrãocom respeito a variação de intensidade luminosa em uma região da imagem.
Divide-se os Detectores de Pontos de Interesse com respeito as determinadas pro-priedades as quais os mesmos possuem invariância.
Neste trabalho, selecionou-se nove detectores principais encontrados na bibliografiaa serem fundamentados. Primeiramente, na seção 1.1, são expostos os detectores capazesde responder a estruturas possuindo invariância a rotação e translação. Tais detectoressão chamados também de detectores de única escala pois, não possuindo invariância aescala, somente analisam a imagem em uma única escala.
291.1. Detectores de Única EscalaPor fim, na seção 1.2, são apresentados detectores que convivem também com ainvariância a escala. Estes simulam múltiplas escalas de forma a encontrar pontos invari-antes a escala. Tais detectores são chamados de detectores de múltipla escala.
1.1 Detectores de Única EscalaOs detectores apresentados nessa seção possuem invariância a translação ou rota-ção, podendo possuir em algum nível, também invariância a escala. Os detectores apre-sentados podem também ter robustez a diversos tipos de ruído.
Normalmente um detector é implementado como uma função, ou kernel, o qual éconvoluida com a imagem e produz uma imagem de saída a qual apresenta o resultadoda aplicação deste kernel.
Como já explicado, existem diversas características em uma imagem a serem bus-cadas como pontos de interesse. Neste trabalho, tanto para o caso de única, como demúltipla escala, seleciona-se características baseadas na alta curvatura de uma região,calculada através do gradiente da imagem. Duas estruturas são escolhidas, quinas e blobs.
Ambas são bastante utilizadas como pontos de interesse pelos detectores mais populares.
As quinas, são estruturas que não necessariamente representam uma quina defato. São estruturas as quais possuem gradientes de alta intensidade em pelo menos duasdireções distintas.
Blobs são definidos como regiões que são diferentes em intensidade da região ao re-dor. Normalmente são associados com algum ponto de extremo na intensidade da imagem(LINDEBERG; EKLUNDH, 1991).
1.1.1 HarrisO detector Harris (HARRIS; STEPHENS, 1988) é um dos mais populares detec-tores de quinas encontrados na literatura. Uma quina é detectada quando existir variaçãoem duas direções principais de uma função analítica de auto-correlação na imagem. Talfunção indica a variação de intensidade em todas as direções para uma imagem 𝐼(𝑥, 𝑦) epode ser definida pela equação 1.1.
⎡⎣⎤⎦𝑥(𝑥, 𝑦, 𝜎𝐷)𝐼2𝐼𝑥(𝑥, 𝜎𝐷)𝐼𝑦(𝑥, 𝑦, 𝜎𝐷)𝐷𝑔(𝜎𝐼) *𝑀 = 𝜎2(1.1)
𝐼𝑥(𝑥, 𝑦, 𝜎𝐷)𝐼𝑦(𝑥, 𝑦, 𝜎𝐷)𝑦(𝑥, 𝑦, 𝜎𝐷)𝐼2onde:𝑔(𝜎𝐷) * 𝐼(𝑥, 𝑦)𝐼𝑥(𝑥, 𝑦, 𝜎𝐷) = 𝜕𝜕𝑥(1.2)
30Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de Interessee 𝑔 é uma função gaussiana definida por:𝑔(𝜎) = 1− 𝑥2+𝑦22𝜎2(1.3)
2𝜋𝜎2 𝑒A quina pode ser computada por uma análise dos autovalores da matriz 𝑀 .
Quando os dois autovalores tiverem valores altos, isso indica a existência de uma quina.
Uma maneira de medir a intensidade dos autovalores sem a necessidade de computar osautovalores de 𝑀 diretamente, é através da medida de Harris dada por:𝑐𝑖𝑛 = 𝑑𝑒𝑡(𝑀) − 𝑘 𝑡𝑟𝑎𝑐𝑜(𝑀),(1.4)
onde 𝑘 é uma constante normalmente setada entre 0.04 e 0.06. Quando a medida 𝑐𝑖𝑛 daEq. 1.4 for alta, a presença de quinas também o será (HARRIS; STEPHENS, 1988). Um
ponto da imagem é considerado uma quina, se a saída da aplicação da Eq. 1.4 for maiorque um limiar 𝑡.
Harris já foi avaliado como sendo o detector com melhor repetibilidade quandocomparado com outros detectores de única escala (SCHMID; MOHR; BAUCKHAGE,2000).
1.1.2 Hessian e LaplacianO detector Hessian, proposto inicialmente por (BEAUDET, 1978), é um métodobastante usado para detecção de blobs em imagens. Para uma imagem 𝐼(𝑥, 𝑦), os blobspodem ser calculado pelo determinante da matriz Hessiana:⎡⎣𝐼𝑥𝑥(𝑥, 𝑦, 𝜎𝐷) 𝐼𝑥𝑦(𝑥, 𝑦, 𝜎𝐷)⎤⎦𝐻 =(1.5)
𝐼𝑥𝑦(𝑥, 𝑦, 𝜎𝐷) 𝐼𝑦𝑦(𝑥, 𝑦, 𝜎𝐷)O determinante responde aos gradientes em múltiplas direções da imagem e tendea revelar blobs de alta curvatura, o que representa uma região distinta. O detector, deter-minante de Hessian, ou simplesmente detector Hessian é dado selecionando os pontos osquais tem uma saída com respeito a matriz H maior que um valor de limiar 𝑡.
Uma variação do Hessian é a aplicação de um kernel Laplacian o qual é computadopelo traço da matriz 𝐻 ( 𝐼𝑥𝑥+𝐼𝑦𝑦). Porém o Laplacian tende também a responder a bordas(TUYTELAARS; MIKOLAJCZYK, 2008). Bordas não são bons pontos de interesse pois,não possuem uma aceitável invariância a rotação (TUYTELAARS; MIKOLAJCZYK,2008).
311.2. Detectores Invariantes a Escala1.1.3 ComparaçãoA Figura 1 mostra um exemplo de aplicação do Hessian e Harris em uma imagem.
As blobs podem ser vistos como a área mais elevada em morros de intensidade. As quinaspodem ser juntas "T"ou "L", também podendo ter formato mais arredondado.
(a) Original(b) Harris(c) HessianFigura 1 – Comportamento da aplicação dos kernels Hessian e Harris para uma imagemteste (1a). (1b) mostra a saída da medida de Harris (Eq. 1.4). (1c) mostra a saída dodeterminante da matriz Hessian ( Eq. 1.5 ) para a imagem teste. Tanto o Hessian comoo Harris tem como saída as regiões de alta curvatura ( Figura por Sojka (2003)).
Percebe-se que há semelhança entre ambos, dado que ambos são associados aregiões de alto gradiente.
1.2 Detectores Invariantes a EscalaA noção de escala é crucial na interpretação de uma imagem (LINDEBERG, 1994).
Alguns objetos só são entidades visuais significativas em uma determinada escala. Sendoassim, uma modelagem explicita de cada nível de escala se torna necessário para o pro-32Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de Interessecessamento (LINDEBERG, 1998). Ou seja, uma imagem não mais pode ser representadacomo uma matriz 𝐼(𝑥, 𝑦) e passa a ter um terceiro componente de escala 𝑠, sendo assimdeterminada como a função 𝐿(𝑥, 𝑦, 𝑠).
Para gerar o conjunto espaços de escala 𝐿(𝑥, 𝑦, 𝑠), pode-se utilizar o princípio dadifusão (LINDEBERG, 1994). O qual determina que uma família de escalas 𝐿 pode serdeterminada através da equação da difusão:2 ▽2 𝐿 = 1𝜕𝜎𝐿 = 12(𝜕𝑥𝑥 + 𝜕𝑦𝑦)𝐿(1.6)
O que representa o fato de que, à medida que a escala se torna menos detalhada,a informação visual tende a se dispersar.
Portanto, para a geração do espaço de escala de uma imagem 𝐿(𝑥, 𝑦, 𝑠) deve serproposta uma equação que atenda a Equação 1.6. Inicialmente, foi adotado que a funçãogaussiana seria a única a ser uma solução da equação 1.6. Posteriormente, outras funçõesforam colocadas como possíveis para geração do espaço de escala (LINDEBERG, 1997).
Considerando determinada uma escala 𝑠, definida igual a um parâmetro de difusão 𝜎, ageração de um espaço de escala 𝜎 é dada por:𝐿(𝑥, 𝑦, 𝜎) = 𝑔(𝑥, 𝑦, 𝜎) * 𝐼(𝑥, 𝑦)(1.7)
sendo a função gaussiana 𝑔(𝑥, 𝑦, 𝜎) calculada como na Eq.1.3.
De forma a atingir a invariância a escala, os detectores passam a considerar essafunção 𝐿(𝑥, 𝑦, 𝜎) para se detectar os pontos de interesse. Porém, (LINDEBERG, 1994) de-terminou que é possível realizar a escolha de uma escala, e tal escala será sempre escolhidaindependente do ambiente e sem a necessidade de escolha de parâmetros. Caracterizandouma escala onde existe invariância.
Foi sugerido que os pontos de extremo de funções gradientes das estruturas en-tre as escalas tem propriedades invariantes. Isso representa a escala com o máximo desensibilidade a função. Tal escala é chamada de escala característica.
Nesta seção apresentam-se alguns detectores invariantes a escala. A ideia de má-ximo de uma determinada função gradiente entre escalas é usada por todos os métodosapresentados.
1.2.1 Hessian-Laplace e Hessian-LaplaceUmas primeiras extensões para detectores de múltipla escala foram feitas para asas funções Harris e Hessian (MIKOLAJCZYK; SCHMID, 2004) Nestes métodos, o espaço331.2. Detectores Invariantes a Escalade escala é gerado por uma equação gaussiana tal como na Eq. 1.7. Os pontos de extremoentre um conjunto de escalas 𝜎𝑛 são computados conforme a Eq. 1.8.
|𝐿𝑜𝐺(𝑥, 𝑦, 𝜎𝑛)| = 𝜎2|𝐿𝑥𝑥(𝑥, 𝑦, 𝜎𝑛) + 𝐿𝑦𝑦(𝑥, 𝑦, 𝜎𝑛)|(1.8)
sendo a Eq. 1.8 uma representação da função Laplacian em múltiplas escalas. Desta forma, são selecionados os pontos extremos que tem alta reposta a função Harris, para o casodo Harris-Laplace ou da função Hessian para o caso do Hessian-Laplace.
1.2.2 Diference-of-Gaussians(DoG)O detector DoG é uma otimização a aplicação do Hessian-Laplace. É o detectorproposto pelo método SIFT (LOWE, 2004).
Ao invés de computar o Laplacian para cada escala, neste aplica-se o Laplacianpela diferença, 𝐷(𝑥, 𝑦, 𝜎), entre múltiplos níveis do espaço gaussiano 𝐿(𝑥, 𝑦, 𝜎). Sendoassim:𝐷(𝑥, 𝑦, 𝜎) = 𝐿(𝑥, 𝑦, 𝑘𝜎) − 𝐿(𝑥, 𝑦, 𝜎)(1.9)
Diversos níveis de escala são gerados. A cada determinado número de imagens,chamado oitava, é feito um redimensionamento na imagem. Dentro de uma oitava, asimagens diferentes são criadas pela aplicação do filtro gaussiano. A função 𝐷 é gerada apartir da diferença entre níveis vizinhos. O processo utilizado pelo algoritmo é mostradona Figura 2.
Para se encontrar a escala característica, basta encontrar o máximo na função𝐷(𝑥, 𝑦, 𝜎) variando 𝜎. Ao final, os extremos do espaço, os quais tem baixa resposta àfunção Hessian são eliminados.
1.2.3 Fast HessianTrata-se de um método que busca fazer uma otimização ainda maior em relação aoDoG para geração do espaço de escala (BAY et al., 2008). Trata-se de um filtro que não usao filtro gaussiano para geração do espaço de escala . Os filtros gaussianos são aproximadospor filtros caixas. Um filtro caixa basicamente computa a média de uma imagem dadouma janela de convolução, podendo ser computado rapidamente pela utilização de ImagensIntegrais (DERPANIS; LEUNG; SIZINTSEV, 2007).
É possível neste caso fazer a abordagem de diferença de caixas, o que permitejuntar a aplicação do filtro Hessian com a geração do espaço de escala. Uma aproximaçãodo Hessian já é computada diretamente ao se aplicar as diferenças de caixas.
34Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de InteresseFigura 2 – O processo para geração do espaço de escala pelo DoG. Ao invés de computar oLaplacian para cada escala, o mesmo é estimado pela diferença entre escalas consecutivas.
Figura adaptada de (LOWE, 2004).
Para um determinado tamanho de caixa de aresta 𝑁, a resposta do Hessian é dadapor:𝑑𝑒𝑡(𝐻𝑎𝑝𝑝𝑟𝑜𝑥) = 𝐷𝑥𝑥𝐷𝑦𝑦 − (0.9𝐷𝑥𝑦)2(1.10)
A Figura 22 mostra um exemplo de filtros 𝐷𝑥𝑥 e 𝐷𝑥𝑦 que são aplicados. Enquantoaplicar a diferença entre caixas, produz o Hessian, a computação em blocos aplica adifusão na imagem.
(a) 𝐷𝑥𝑥(b) 𝐷𝑥𝑦Figura 3 – Exemplo de um filtro caixa de tamanho 9x9 aplicado para geração de umespaço de escala equivalente a 𝜎 = 1.2. Outros espaços podem ser gerados usando caixasmaiores.
Para relacionar com o espaço gaussiano, basta saber que uma imagem de filtrogaussiano 𝜎 = 1.2 é equivalente a utilização de um filtro caixa 9x9. Então, para geração351.2. Detectores Invariantes a Escalado espaço de escala basta gerar a resposta de vários tamanhos de caixa 𝑁 = 9, 11, 13..
etc.
Para encontrar os pontos característicos basta encontrar o máximo para todos osníveis de escala.
1.2.4 Center Surround Extrema Filters(CenSurE)O Filtro de centro e arredores (AGRAWAL; KONOLIGE; BLAS, 2008) tem umaabordagem similar a utilizada pelo detector Fast Hessian, porém realizando a diferençaentre múltiplos níveis como no caso do DoG. Este processo visa também uma aproximaçãodo Laplacian. Os espaços de escala são criados pela geração de polígonos de múltiplostamanhos. Tal como o filtro caixa, um filtro poligonal representa a media através de umajanela de convolução.
De maneira similar ao FastHessian, um filtro de polígono lado 𝑁 = 2 é equivalentea um espaço gaussiano de 𝜎 = 1.88 A Figura 4 mostra alguns tipos de polígonos usadospara gerar o espaço de escala. Os polígonos podem ter estruturas estreladas, poligonais,entre outras.
(a) Estrela(b) Hexágono(c) QuadradoFigura 4 – Alguns tipos de filtros utilizados para geração do espaço de escala pelo Cen-SurE. O filtro estrela, o filtro hexagonal e o filtro por diferença de caixas.
Para gerar o Laplacian uma imagem a qual teve aplicada um filtro maior é sub-traída de uma imagem com um polígono menor aplicado.
O máximo deste espaço gerado é encontrado como pontos de interesse.
Por fim uma função Harris é aplicada, eliminando os pontos que obtiveram baixaresposta. Isso segue, pelo fato do Harris ter sido determinado como uma função commelhor repetibilidade.
1.2.5 KAZEA ideia do KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) é gerar umespaço de escala suavizando de maneira diferente em locais com alta intensidade de bordas.
Tal abordagem trata-se de uma difusão não linear.
36Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de InteresseA geração do espaço de escala é dada pela solução para equação da difusão nãolinear:= 𝑑𝑖𝑣(𝑐(𝑥, 𝑦, 𝑡) ▽ 𝐿),𝜕𝐿𝜕𝑡(1.11)
Abordagens que aplicam uma difusão não linear podem obter resultados melhorespara o caso da segmentação de imagens e remoção de ruído (WEICKERT; ROMENY;VIERGEVER, 1998).
A ideia principal é que, durante a formação da escala, as bordas das estruturasdevem se manter mais do que de fato acontece com o filtro gaussiano. Desta forma,primeiramente uma função ▽𝐼 que responde as bordas é aplicada. Sendo ▽𝐼 basicamenteum gradiente da imagem. Com base nessa saída, uma definição alternativa da funçãogaussiana é aplicada para geração do espaço de escala . Perona e Malik (1990), descreveramalgumas possíveis formulações de funções:𝑐1 = 𝑒𝑥𝑝(| ▽ 𝐼𝜎|2𝑘21), 𝑐2 = 𝑒𝑥𝑝((1.12)
)1 + |▽𝐼𝜎|2𝑘2sendo k um parâmetro que controla o nível de difusão. Alcantarilla, Bartoli e Davison(2012) propôs uma terceira formulação de kernel:⎧⎨⎩,| ▽ 𝐼𝜎|2 = 0,| ▽ 𝐼𝜎|2 > 011 − 𝑒𝑥𝑝((|▽𝐼𝜎|/𝑘)8 )𝑐3 =(1.13)
3.315
Levando em conta os kernels definidos, cada nível do espaço de escala 𝐿𝑘(𝑥, 𝑦, 𝑡)é gerado pela aplicação da seguinte função recursiva:𝐿𝑘(𝑥, 𝑦, 𝑡 + 1) = (𝐼 − (𝑡𝑖 + 1 − 𝑡𝑖).𝑐(𝑥, 𝑦, 𝑡) * 𝐿𝑘(𝑥, 𝑦, 𝑡))−1𝐿𝑘(𝑥, 𝑦, 𝑡)(1.14)
onde 𝑡 é um parâmetro de escala temporal facilmente relacionado a 𝜎. Ao final, tambémsão desconsideradas as regiões que tem baixa resposta a aplicação de uma matriz Hessian.
1.2.6 ComparaçãoA Figura 5 apresenta exemplos de geração do espaço de escala baseado em 4funções diferentes. O gaussiano, utilizado pelo DoG, Harris-Laplace e Hessian-Laplace, afunção de caixas utilizada pelo FastHessian, uma função poligonal estrelar de seis lados,utilizadas pelo CenSurE e a função de difusão anisotrópica utilizado pelo KAZE.
Pode-se perceber que determinadas estruturas se mantem mais que outras paraespaços diferentes. Claramente algumas aplicações se beneficiariam do uso de um espaçode escala diferente. No Capítulo 5 se estudam os melhores detectores para o campo deestudo de imagens subaquáticas com presença de turbidez.
371.2. Detectores Invariantes a Escala𝜎 = 3.6
𝜎 = 3.6
𝜎 = 3.6
𝜎 = 3.6
𝜎 = 11.6
𝜎 = 11.6
𝜎 = 11.6
𝜎 = 11.6
𝜎 = 27.6
𝜎 = 27.6
𝜎 = 27.6
𝜎 = 28.7
𝜎 = 59.6
𝜎 = 59.6
𝜎 = 59.6
𝜎 = 57.6
Figura 5 – Espaços de escala gerados. Primeira coluna mostra o espaço Gaussiano. Se-gunda coluna mostra o filtro média de caixas usado pelo FastHessian. Terceira colunamostra um filtro poligonal estrelar de seis lados. A quarta Coluna mostra o espaço deescala anisotrópico usado pelo KAZE.
392 Fundamentação Teórica 2: Classificação deImagens Utilizando ContextoEste capítulo apresenta a fundamentação teórica utilizada neste trabalho associadaa utilização de contexto para a classificação de imagens. Inicialmente são postuladas asdefinições de como representar as relações de contexto em uma imagem. Também é feitaa definição de classificação de imagens incorporando o conceito de contexto, bem comouma revisão dos métodos de visão computacional que os tratam são apresentados. Um
destaque é dado aos métodos que utilizam os Conditional Random Field (CRF).
2.1 Utilização do Contexto em Visão ComputacionalExistem diversos descritores capazes de discriminar os objetos com base em suascaracterísticas visuais, como textura, cor e forma. Tais características buscam capturar avariabilidade dos objetos para sua classificação (GALLEGUILLOS; BELONGIE, 2010).
Porém, estudos envolvendo o sistema perceptivo visual humano trazem novas perspectivasno que tange a como as típicas configurações dos objetos em uma cena podem contribuirpara a percepção, de tal forma que o reconhecimento de objetos no sistema visual humanoconsidera não somente os aspectos locais referentes a interpretação da cena, mas tambéma situação geral onde um objeto foi encontrado.
Biederman (BIEDERMAN; MEZZANOTTE; RABINOWITZ, 1982) estabelece al-guns tipos de relações contextuais importantes que são fundamentais para o reconheci-mento de objetos no sistema visual humano. Estas relações estabelecem níveis semânticostais como: i suporte (onde os objetos tendem a sustentar ou ser sustentados por outros),interposição (relativo a relações de oclusão), ii probabilidade (objetos tendem a aparecerna mesma situação), iii posição (objetos tendem a ficar em determinada posição relativacom outros) e iv tamanho (objetos tendem a ter certo tamanho se comparado com outrosem uma dada escala).
Vários modelos computacionais já fizeram uso destas relações semânticas as quaispodem ser usadas para classificar objetos. Essas relações normalmente são resumidas emtrês tipos de contexto principais: semântico, posição e escala.
O contexto semântico, tende a incluir as relações de ocorrência entre objetos. Ao
encontrar um determinado objeto em uma cena, o qual se possui certeza de sua pre-sença, considera-se uma maior probabilidade de presença de outros objetos. Por exemplo,a existência de um bule de chá implica em uma maior probabilidade de existência de40Capítulo 2. Fundamentação Teórica 2: Classificação de Imagens Utilizando Contextooutros utensílios de cozinha como talheres ou um fogão (FISCHLER; ELSCHLAGER,1973) (HANSON; RISEMAN, 1978). Como exemplo, Rabinovich et al. (2007), incorpo-rou a informação anotada pelos Google Sets indicando objetos que tendem a aparecer emsituações semelhantes de forma a melhorar a classificação.
O contexto de posição indica que os objetos tendem a ter uma relação espacialna imagem. Como por exemplo, o céu em uma imagem tende a estar acima do chão.
Já o contexto de escala esta associado as relações de tamanho entre objetos na cena(TORRALBA, 2003) (KUMAR; HEBERT, 2005) (TORRALBA; MURPHY; FREEMAN,2004). Pois, existe já, uma relação de tamanho típica que os objetos possuem entre eles(GALLEGUILLOS; BELONGIE, 2010).
Para incluir tais tipos de contexto na classificação de imagens, alguns aspectosfundamentais devem ser considerados. Primeiramente, qual nível de contexto será clas-sificado. Se as relações a serem consideradas serão apenas entre objetos próximos, ouno domínio geral de uma imagem. Ou ainda, por meio de que tipo de estrutura visualencontrada na imagem, a interação de contexto ocorre.
2.1.1 Níveis de ContextoOs sistemas que adicionam contexto na classificação normalmente dividem o con-texto em dois níveis (GALLEGUILLOS; BELONGIE, 2010): local e global.
O contexto local é onde somente as interações de vizinhança são utilizadas paraadicionar o contexto a um determinado objeto. O contexto local está relacionado aosobjetos que cercam outros objetos. Vale notar que a aplicação de contexto é recursiva, ouseja, a própria vizinhança possuí também suas próprias relações de contexto. Isso faz quenão somente as relações estritamente próximas façam parte do contexto local.
O contexto global está relacionado as interações de contexto presentes ao longode toda a imagem utilizada. O contexto global normalmente está associado ao ambienteonde os objetos estão posicionados. Por exemplo, se as relações contextuais indicam que osobjetos estão em uma cozinha, isso implica em uma alta probabilidade de um dos objetosser uma panela.
2.1.2 Interações de ContextoNão necessariamente cada componente da imagem deve ser um objeto com umconceito semântico relacionado. Na literatura se estabelecem três níveis básicos de inte-ração nos quais o contexto pode ser integrado (GALLEGUILLOS; BELONGIE, 2010).
Além de objetos, as interações também se dão entre pixeis ou regiões.
A interação em nível de pixel estabelece que pixeis vizinhos tendem a ter a mesmaclasse. Tais interações ajudam a inferir as bordas existentes na imagem. Vale notar a412.2.
Integração de Contexto Na Classificaçãoutilização de tais interações são mais computacionalmente intensas, dado que existemdiversas combinações entre pixeis da imagem. Ressalta-se que o uso de níveis mais baixosde contexto não necessariamente implica na perda da informação semântica. Ou seja,encontrar que pixeis de determinado objeto são próximos, é também identificar a altaprobabilidade de proximidade de tais objetos.
O conceito de pixel pode ser estendido para o nível de representação de regiões. Ao
utilizar regiões, tende-se a reduzir a complexidade levantada pelo grande número de pixeisexistentes na imagem. Uma estrutura de região bastante utilizada é a consideração de pe-quenas regiões adaptadas a estrutura local da imagem. Tais regiões chamadas, superpixeis,capturam a redundância dos dados, facilitando a utilização do contexto (FULKERSON;VEDALDI; SOATTO, 2009).
Já a interação em nível de objetos é a representação mais natural para reconhe-cimento de contexto humano (BAR, 2004). Sabendo-se já a classe do objeto é possíveltreinar as relações de contexto. No trabalho de (TORRALBA; MURPHY; FREEMAN,2004), os objetos mais fáceis de classificar ajudam, através do contexto, a obter a classe deobjetos mais difíceis. Se por um lado usar objetos tende a capturar melhor as interaçõesexistentes na cena, o uso do contexto em nível de objetos implica já o conhecimento pré-vio ( classificação) dos objetos existentes na imagem. A interação entre regiões, por outrolado, ajuda a reduzir a quantidade de combinações existentes na interação de pixeis, sem anecessidade de um conhecimento maior sobre a imagem (GALLEGUILLOS; BELONGIE,2010).
2.2 Integração de Contexto Na ClassificaçãoNesta seção são apresentadas algumas abordagens para integração do contexto naclassificação de imagens. São escolhidos métodos com integração baseada em superpixeis,com foco para integração local de contexto. Quanto aos tipos de contexto, por consideraro nível de interação como superpixeis, os principais tipos integrados são os de posição eescala.
Dado a representação da imagem como uma matriz 𝑆𝑃(𝑥, 𝑦) onde cada elemento𝑠𝑝 é um superpixel, a definição de classificação é dada pela determinação de um rótulo𝑙𝑖 dentre um conjunto possível de rótulos 𝐿 = 𝑙1, 𝑙2, ...𝑙𝑛 para cada 𝑠𝑝. Para classificaçõessem contexto, apenas o superpixel 𝑠𝑝 é considerado, já para o caso apresentado nestaseção, a vizinhança de 𝑠𝑝 é também importante para determinar um rótulo 𝑙𝑖.
Nesta seção são especificadas duas formas de incorporar o contexto. Utilizandoa vizinhança de um superpixel 𝑠𝑝 diretamente no classificador ou através de modelosprobabilísticos gráficos (MPGs).
42Capítulo 2. Fundamentação Teórica 2: Classificação de Imagens Utilizando Contexto2.2.1
Integrando contexto com base em ClassificadoresAs informações locais advindas de uma análise de contexto podem ser incorporadasdiretamente aos sistemas de classificação, considerando uma janela de contexto em tornoda região a ser classificada (Figura 6)Fink e Perona (2003) incorporou o contexto local usando a janela da região paratreinamento de classificador fracos em um esquema de boosting.
Kruppa e Schiele (2003), visando melhorar a classificação de rostos, incorporou adescrição dos descritores da vizinhança local da face em um sistema Naive BayesO principal problema é que tais aplicações não levam em conta as possíveis corre-lações entre os vizinhos. Este problema é demonstrado na Figura 6, a vizinhança só afetao que foi considerado no centro da imagem, sem afetar a si própria. Tais problemas sãoparcialmente resolvidos criando-se interações mais conectadas, como no caso dos modelosprobabilísticos gráficos a serem explicados na próxima seção.
(a)(b)Figura 6 – Janela considerada para a classificação usando contexto. No caso da integraçãode contexto diretamente nos classificadores (Fig. 6a), não são considerada as relações entrea vizinhança com si própria (Fig. 6b). Ou seja, se existem propriedades correlacionadasna vizinhança.
2.2.2
Integrando contexto com base em Modelos Probabilísticos GráficosNesta seção, serão apresentados os principais conceitos associados aos ModelosProbabilísticos Gráficos (MPGs) e seu uso na integração contextual em classificação deimagens.
Uma forma natural de representar a dependência entre variáveis é utilizando osModelos Probabilisticos Gráficos (MPGs)(SUTTON; MCCALLUM, 2006). Estes mode-los representam algumas fatorizações de uma função de probabilidades como o MarkovRandom Fields MRF ou Conditional Random Fields CRF.
432.2.
Integração de Contexto Na ClassificaçãoUm MPG é usado para capturar a correlações existentes dentro de um conjunto dedados. Baseado neste modelo, é possível calcular uma função potencial. Esta abordagem,quando baseada em modelos probabilísticos não direcionadas, é usada no MRF e no CRF(SUTTON; MCCALLUM, 2006).
O MRF modela a função de probabilidade 𝑝(𝑦, 𝑥) de um dado conjunto de rótulos𝑦 e os conjunto de descritores de entrada 𝑥. Esse modelo necessita um alto custo compu-tacional para classificação de imagens (CARBONETTO; FREITAS; BARNARD, 2004).
Ainda, dado que deve seguir a premissa de Markov, nenhuma característica global deveser adicionada. Paro caso de Markov, a computação de 𝑝(𝑦, 𝑥) necessita a computaçãode 𝑝(𝑦) e também 𝑝(𝑥), o qual não se tem conhecimento sobre, pois está relacionado aprobabilidade das descrições de entrada aparecerem.
Uma abordagem mais comumente utilizada para classificação de imagens é o mo-delo CRF. Neste modelo, somente a distribuição condicional, 𝑝(𝑦|𝑥) , é computada. Nor-malmente o CRF tem uma melhor associação aos dados, dado que não é necessário com-putar a probabilidade a priori para os dados de entrada (𝑝(𝑥)) (SUTTON; MCCALLUM,2006).
Considerando um dado modelo, é definida a probabilidade para um conjunto derótulos serem atribuídos . Esta probabilidade é estabelecida como uma função de um fatorunitário e um fator local. Deste modo, define-se a probabilidade de uma imagem possuirum certo conjunto de rótulos 𝐿 = 𝑙1, 𝑙2, ...𝑙𝑛 dado um grafo de um modelo 𝐺 e um conjuntode parâmetros 𝜃𝑢 e 𝜃𝑙 como a Eq. 2.1.
𝑢∑︁𝜖∑︁𝑙𝑜𝑔𝑃(𝐿|𝐺, 𝜃) = 𝑤𝑢𝑖 (𝑥𝑖, 𝜃𝑢) + 𝑤𝑙𝜙𝑢𝑖𝑗(𝑥𝑖, 𝑥𝑗, 𝜃𝑙)𝜙𝐿(2.1)
(𝑥𝑖,𝑥𝑗)𝜖𝜀𝑥𝑖𝜖𝑋onde 𝑋 é um conjunto de vértices no modelo probabilístico gráfico, cada um relacionadoa um superpixel da imagem e 𝜀 é o conjunto de arestas no grafo de adjacência 𝐺(𝑋, 𝜀).
𝑖 (𝑥𝑖, 𝜃𝑢) é a distribuição de probabilidades a priori de um rótulo, para este caso, o con-𝜙𝑢junto de parâmetros 𝜃𝑢 esta associado com o treinamento da geração da distribuição apriori . 𝜙𝐿
𝑖 (𝑥𝑖, 𝜃𝑙) é o fator local associado com a probabilidade de duas classes seremvizinhas uma da outra. Neste caso, o parâmetro 𝜃𝑙 está associado as matrizes de covari-ância, treinadas para indicar a probabilidades proximidade entre os rótulos do conjuntos𝐿 = 𝑙1, 𝑙2, ...𝑙𝑛 considerando sua conexão 𝐺.
Os pesos 𝑤𝑢 e 𝑤𝑙 facilitam a calibração empírica do modelo, determinando a im-portância de cada termo na Eq. 2.1. A Figura 7, mostra uma representação visual departe da modelagem usando CRF para a aplicação de interesse que é a classificação esegmentação de imagens.
No modelo CRF também é possível incluir diferentes aspectos baseado em proprie-44Capítulo 2. Fundamentação Teórica 2: Classificação de Imagens Utilizando ContextoFigura 7 – A representação gráfica de um modelo CRF. Os quadrados em vermelho(𝜙𝑢𝑖 (𝑥𝑖, 𝜃𝑢)) são os fatores unitários calculados com o resultado dado pelo classificador.
Os quadrados em azul são os fatores locais computados em cada aresta e utilizados paraintroduzir informação contextual. Os circulos verdes representam os superpixeis sendoclassificados.
dades da imagem. A função de bordas de Potts (SHOTTON et al., 2009) (FULKERSON;VEDALDI; SOATTO, 2009) reforça nodos que não são separados por bordas a perten-cerem a mesma classe. Isto é implementado incluindo o atributo 𝑔𝑖𝑗 em 𝜙𝐿𝑖 . Onde 𝑔𝑖𝑗 édefinido pela Eq. 2.2.
⎡⎣𝑒𝑥𝑝(−𝛽||𝑥𝑖 − 𝑥𝑗||2)⎤⎦𝑔𝑖𝑗 =(2.2)
1Onde 𝛽 é uma função de contraste dependente da imagem que pode ser facilmente esti-mada como explicado em (SHOTTON et al., 2009).
2.2.2.1 O Problema da Inferência EstatísticaDado um modelo probabilístico gráfico e uma função de probabilidades, uma dasprincipais dificuldades é encontrar um conjunto de rótulos 𝐿′ que maximize uma funçãode probabilidades como a função da Eq. 2.1. Em outras palavras, seria encontrar a con-figuração de classificação na imagem mais provável, dado um modelo probabilístico. Esteproblema é considerado NP-Hard, dado que existe uma combinação de rótulos exponen-cialmente grande. O problema de inferência é especialmente difícil quando se utiliza aabordagem MRF, dado que existem muito mais casos para computar a distribuição deprobabilidades conjunta.
Algumas aproximações são introduzidas de forma reduzir o custo computacional.
452.3. Trabalhos utilizando Modelos Probabilísticos GráficosPor exemplo, a abordagem loopy belief propagation (LBP) propaga as informações de dis-tribuição de probabilidades dos vértices ao longo do grafo através de mensagens e obtemboa performance (WEISS, 2000), entretanto, a convergência não pode ser garantida. Ou-tra estratégia é o corte de grafos baseado no alpha-cut (BOYKOV; JOLLY, 2001). Estealgoritmo produz melhores resultados apesar de possuir maior complexidade.
2.2.2.2 Aprendizado de parâmetrosÉ necessário estimar os parâmetros 𝜃𝑢 and 𝜃𝑙. Estes parâmetros são a matriz decovariância que representa as tendências das classes serem vizinhas (𝜃𝑙), a matriz 𝜃𝑙 estaassociada às relações espaciais entre as classes.
Os parâmetros podem ser estimados utilizando a técnica de máximo a-posteriori(MAP). Esta técnica seleciona os parâmetros que maximizam os resultados para a Eq.
2.1. Isto é custoso, dado que existe a necessidade de computar a inferência diversas vezes.
Porém, é possível realizar a estimativa, parte a parte, dividindo os parâmetros os quaismaximizar (SHOTTON et al., 2009), então reduzindo o custo computacional.
A Figura 10 mostra um exemplo de uma matriz de covariância estimada, sendoquanto mais claro for o quadrado mais relacionadas espacialmente as classes estão. É
possível perceber que a classe B tem uma probabilidade muito maior de ficar próxima aoC mas não necessariamente a classe E.
2.3 Trabalhos utilizando Modelos Probabilísticos GráficosDiversos trabalhos já utilizaram os modelos probablístico gráficos (MPGs) paraadição de contexto. Apresenta-se aqui alguns relevantes para elaboração deste trabalho.
Carbonetto, Freitas e Barnard (2004) foi um dos primeiros trabalhos a usar MPGspara classificação de imagens . O autor utilizou uma versão usando um modelo MRF como contexto local e propôs uma forma de reduzir o tempo de inferência usando uma técnicade expectation maximization (EM) (DEMPSTER; LAIRD; RUBIN, 1977).
Shotton et al. (2009) utilizou uma combinação de descritores diretamente dosdescritores de textura, cor e localização como fatores unários e adicionou a informaçãode contexto local usando a medida de potts. O nível de interação foi baseado em regiõesutilizando um novo esquema de representação de imagens através "canais de textura". A
inferência foi feita utilizando o algoritmo de alpha-cut (BOYKOV; JOLLY, 2001).
Fulkerson, Vedaldi e Soatto (2009), utiliza uma representação usando SIFT (LOWE,2004) para bag-of-words (SIVIC; ZISSERMAN, 2006) para o fator unário. Como nível deinteração, foram utilizadas regiões baseadas em superpixeis. Em seguida, aplica-se umsistema CRF similar ao proposto por (SHOTTON et al., 2009).
46Capítulo 2. Fundamentação Teórica 2: Classificação de Imagens Utilizando ContextoFigura 8 – Tendências que existem para as classes estarem próximas umas das outras,quanto mais claro, maior é a tendência existente. Por exemplo, é possível perceber que aclasse B é provável de aparecer perto de uma classe C mas não próxima de uma classe E.
Koltun e Vladlen (2011), utiliza um CRF com uma maior conectividade entre osvértices e utiliza um nível de interação por pixel. Neste caso, dado o conjunto de pixeis,cada par possível de pixeis é conectado. O aumento da complexidade de inferência éresolvido com um sistema aproximado baseado em médias.
Boix et al. (2012) propõem adicionar o contexto global ao CRF. Para isso, aEquação 2.1 pode ser extendida para a Eq. 2.3.
𝜖∑︁𝑢∑︁𝜖∑︁𝑙𝑜𝑔𝑃(𝐿|𝐺, 𝜃) = 𝑤𝑢𝑖𝑔(𝑥𝑖, 𝑥𝑔, 𝜃𝑔)𝜙𝐺𝑖𝑗(𝑥𝑖, 𝑥𝑗, 𝜃𝑙) + 𝑤𝑔𝜙𝐿𝑖 (𝑥𝑖, 𝜃𝑢) + 𝑤𝑙𝜙𝑢(𝑥𝑖,𝑥𝑔) 𝜀𝑔(𝑥𝑖,𝑥𝑗)𝜖𝜀𝑥𝑖𝜖𝑋(2.3)
𝑖𝑔(𝑥𝑖, 𝑥𝑔, 𝜃𝑔) representa as conexões com um nodo global que, tendo esti-onde a porção 𝜙𝐺472.4. Sumáriomado seu conjunto de parâmetros 𝜃𝑔, indica as configurações mais prováveis entre todasas porções da imagem. Com tal modelo, as relações de contexto global, como o conjuntotípico de objetos possíveis em cena, podem ser incorporadas.
Por fim, Lucchi et al. (2011) critica o funcionamento do CRF, comparando autilização do CRF com pontos de interesse globais (BOIX et al., 2012), concluindo quenão há ganho significativo. Além disso, o contexto local adicionado pelo CRF a tendeapenas melhorar a suavização da classificação local. Ou seja, dado uma pequena regiãoda imagem, as variabilidade de classes é reduzida.
2.4 SumárioEste capítulo apresentou os conceitos de utilização de contexto para visão compu-tacional. Apresentou-se em quais níveis o contexto pode ser utilizado, sendo eles globaisou locais. Também foi apresentado quais níveis de interação o contexto podem se dar,sendo eles no nível de pixeis, regiões ou objetos.
Nesse âmbito, formalizou-se a classificação utilizando contexto, considerando onível de interação baseado em regiões, no caso, superpixeis. Em seguida, foram apresen-tadas formas de utilizar o contexto. Primeiramente foram apresentadas formas de aplicaro contexto diretamente no classificador. Em seguida, foi apresentado o uso de modelosprobabilísticos gráficos para a aplicação de contexto.
Por fim, alguns dos principais trabalhos em modelos probabilísticos gráficos foramapresentados.
493 Classificação Baseada em Contexto utili-zando GeoestatísticaTendo em vista as limitações existentes no CRF (LUCCHI et al., 2011) e o conhe-cimento obtido através de estudos em Geoestatística, neste capítulo, busca-se propor umnovo método para adição de contexto baseado em Geoestatística.
Tal abordagem agrega duas áreas com aplicações distintas mas conceitos seme-lhantes. No campo da modelagem geológica, uma abordagem baseada em geostatísticaprimeiramente busca modelar a variabilidade espacial de uma determinada medida como objetivo de interpolar este comportamento para áreas desconhecidas (CARLE; FOGG,1996). Esta estratégia é bastante utilizada para aplicações como modelagem de reservató-rios em campos de de extração óleo (BEATTIE; MILLS; MAYO, 1998) ou mapeamentogeológico (PURKIS; VLASWINKEL; GRACIAS, 2012).
Porém, neste trabalho busca-se também mostrar que este conceito se aplica parao caso de adição de contexto classificação de imagens. A abordagem apresentada é capazde assegurar a suavização de estruturas espaciais de maneira similar que o CRF, porém,o método proposto, também considera correlações em longa distância entre rótulos.
3.1
Visão Geral da PropostaA Equação 3.1 apresenta a adição do contexto espacial utilizando Geoestatística:𝑃(𝐿) = 𝑤𝑢𝑃𝑢(𝐿|𝜃𝑢) + 𝑤𝑙𝑃𝑙(𝐿|𝑊),(3.1)
sabe-se que a probabilidade, 𝑃 de um dado conjunto de rótulos 𝐿, é dada pela somaponderada, pelos pesos 𝑤𝑢 e 𝑤𝑙, das probabilidades unária 𝑃𝑢(𝐿|𝜃𝑢), da parte segmentada,e a probabilidade do contexto local 𝑃𝑙(𝐿|𝑊). A matriz W está associada ao peso atribuídoaos superpixeis da vizinhança. 𝜃𝑢 está associado aos parâmetros de usados para obtençãoda distribuição unária.
Como nível de interação, parte-se de uma segmentação baseada em superpixeisem um grid retangular e uniforme onde cada superpixel tem aproximadamente o mesmotamanho. O sistema de classificação proposto neste capítulo, é mostrado na Figura 10.
Nesta proposta, o nível de interação, em uma imagem segmentada ocorre através deTurbopixels (LEVINSHTEIN et al., 2009).
No nível unário 𝑃𝑢(𝐿|𝜃𝑢), somente as informações visuais descritas de um único50Capítulo 3. Classificação Baseada em Contexto utilizando GeoestatísticaFigura 9 – Divisão especificada em dois níveis de classificação. O nível unário 𝑃𝑢(𝐿|𝜃𝑢)onde somente a informação do superpixel segmentado é utilizada, apresentado em verde.
E o nível local 𝑃𝑙(𝐿|𝑊), onde um determinado contexto local é incluído na classificação,representado pelo circulo azul.
superpixel são relevantes para a classificação do mesmo. Na seção 3.2, mostra-se a compu-tação do nível unário e a necessidade do mesmo de produzir uma distribuição confiável.
No nível local 𝑃𝑙(𝐿|𝑊), se considera as conexões de uma determinada área ondemedidas estatísticas são utilizadas (Circulo Azul Fig. 10). O nível 𝑃𝑙(𝐿|𝑊) é apresentadona seção 3.4.
3.2 Nível Unário 𝑃𝑢(𝐿|𝜃𝑢)Para o sistema proposto, o foco da classificação unária é obter uma distribuiçãode probabilidades previa para cada superpixel. Essa probabilidade a priori vai ser usadapara inferir a vizinhança.
Em um dado superpixel o qual pode ser classificado como um dentre um conjuntoonde ∑︀ 𝑃𝑢(𝐿|𝜃𝑢) = 1. Onde 𝜃𝑢 é conjunto de parâmetros usados para se ter essa saída.
de rótulos 𝐿 = 𝑙1, 𝑙2..𝑙𝑛 busca-se obter uma saída 𝑃𝑢(𝐿|𝜃𝑢) = 𝑃𝑢(𝑙1|𝜃𝑢), 𝑃𝑢(𝑙2|𝜃𝑢)...𝑃𝑢(𝑙𝑛|𝜃𝑢)Para se chegar em tal resultado, a geração do nível unário é dividida em duasetapas. A primeira corresponde ao treinamento da função de discriminação 𝑓(𝑥), do clas-sificador. No caso, é feito o treinamento de um kernel linear para uma Support VectorMachine (SVM). A segunda etapa é a determinação das curvas de confiança, que corres-ponde ao grau de certeza da classificação. Ou seja, o grau de certeza 𝐶𝑙𝑖 é dado como uma3.2. Nível Unário 𝑃𝑢(𝐿|𝜃𝑢)51função treinada, e é usado para gerar 𝑃𝑢(𝐿|𝜃𝑢) (ABFALG et al., 2007).
3.2.1
ClassificadorComo classificador, foi utilizado uma Support Vector Machine(SVM) com um ker-nel linear. A ideia do algoritmo é encontrar uma função de hiperplano 𝑓𝑙𝑖(𝑥), para cadaclasse 𝑙𝑖 que separa linearmente um conjunto de dados previamente rotulados, porémmaximizando uma determinada margem. Trata-se de uma abordagem de classificaçãosupervisionada.
Para dada aplicação é necessário que o classificador produza uma distância de umobjeto à borda de classe mais próxima a borda entre classes (ABFALG et al., 2007). Talresultado é obtido diretamente pelo SVM dado que sua função de hiperplano já maximizaa margem entre classes. A saído numérica do SVM já é própria para se ter um certo graude confiança do classificador.
Figura 10 – Figura do separador linear obtido pelo treinamento do SVM. Dado os conjun-tos de dados já rotulados ( Azuis e Vermelhos), o SVM determina o separador de máximamargem. A saído numérica do SVM já é própria para se ter um certo grau de confiançado classificador.
3.2.2 Treinando Curvas de ConfiançaSomente as distâncias de saída do SVM (CRISTIANINI; SHAWE-TAYLOR, 2000),não estabelecem diretamente o grau de confiança de uma classificação (ABFALG et al.,
2007) . Ou seja, uma distância de valor número 5 para o SVM pode ser para alguns casosuma saída confiável, para outros não. É necessário treinar para quais distâncias existe uma52Capítulo 3. Classificação Baseada em Contexto utilizando Geoestatísticagrande probabilidade da predição ser correta. Isso depende do dataset que foi utilizado,da classe (rótulo) e também do classificador.
O estudo apresentado por Platt (PLATT, 1999) demonstra que comportamentosigmoidal pode modelar a distribuição de probabilidade do SVM.
Sendo assim, para cada classe 𝑙𝑖 é feito um ajuste de uma função sigmoidal 𝐶𝑙𝑖. Estafunção 𝐶𝑙𝑖 não mais retorna uma distância e sim uma probabilidade de uma determinadaentrada na função 𝑓𝑙𝑖(𝑥) ser correta.
A Figura 11 apresenta a saída esperada para a curva de confiança treinada 𝐶𝑙𝑖,para um dado rótulo 𝑙𝑖. Dado um conjunto de validação em que já se possui os retornos𝑓𝑙𝑖(𝑥), o treinamento é feito da seguinte forma: Obtém-se os pontos em azul os quaisindicam a porcentagem de acertos que se tem utilizando apenas as parcelas de dadosas quais seu retorno vindo do classificador (𝑓𝑙𝑖(𝑥)) é de no máximo o que é mostradono eixo 𝑥. Por exemplo, na Figura 11, para um conjunto de dados com uma distânciado classificador(𝑓𝑙𝑖(𝑥)) de até dois, tem-se uma porcentagem de acerto de 70%. Dadoesse conjunto de pontos, o algoritmo de Levenberg-Marquardt (MARQUARDT, 1963) deotimização é utilizado para encontrar os coeficientes, 𝛼𝑘 e 𝛽𝑘 da função sigmoidal:0.5
1 + 𝑒𝑥𝑝(𝛼𝑙𝑖 * 𝑓𝑙𝑖(𝑥) + 𝛽𝑙𝑖) + 0.5
(3.2)
𝐶𝑙𝑖 = 𝑁𝑙𝑖onde 𝑁𝑙𝑖 é uma constante de normalização para a classe 𝑙𝑖. A função inicia de 0.5 pois éa probabilidade inicial de uma classe ser acertada aleatoriamente. A abordagem propostacontrasta com a proposta apresentada por ABfalg et al. (2007) por propor uma curva deconfiança para cada classe. Isso também leva em conta as diferenças existentes em cadaclasse. 𝜃𝑢 está relacionado aos parâmetros 𝛼𝑘 e 𝛽𝑘 de 𝑃𝑢(𝐿|𝜃𝑢).
Figura 11 – Gráfico mostrando a probabilidade de acerto em função da máxima confiançaretornada pelo classificador para um conjunto de dados. Em vermelho tem-se a função𝐶𝑙𝑖 treinada a partir do conjunto de dados em azul.
533.3. Distribuição de Probabilidades3.3 Distribuição de ProbabilidadesNormalizando o grau de confiança para a distância com relação a todas as classes,se obtém a distribuição de probabilidades para um determinado objeto. Sendo assim, umclassificador não mais produz somente uma saída, mas também uma chance de cada itemde um conjunto de dados a pertencer a cada uma das classes. A Figura 12 mostra a saídada classificação de um exemplo calculado. Sendo que cada barra representa a chance doobjeto pertencer a tal classe.
Figura 12 – Histograma mostrando a distribuição de probabilidades de saída de um clas-sificador. Para o caso, a segunda classe, é a que obteve maior probabilidade, porém existeuma certa incerteza com relação a primeira classe.
Observa-se na Figura 12 que a saída do classificador mostra a classe mais provávelmas existe uma incerteza significativa para uma segunda classe ser a correta.
3.4 Nível Local 𝑃𝑙(𝐿|𝑊)A Figura 13 mostra o conjunto de passos para calcular os parcelas locais utilizandoo contexto baseado em Geoestatística.
A primeira parte do método (lado direito da Figura 13) é estimar e modelar aincerteza existente nos conjunto de dados os quais se quer adicionar o contexto. Essa mo-delagem se da através da estimativa da matriz de probabilidade de transição (𝑇) entre ospossíveis rótulos presentes no conjunto de dados. Isso é feito em uma etapa de treinamentooffline do método A estimativa é feita em duas partes que são combinadas: analisandoas frequências de transições entre as classes de um conjunto de imagens (CARLE et al.,
1998) e medindo propriedades estatísticas nos dados como proporções e espessuras.
54Capítulo 3. Classificação Baseada em Contexto utilizando GeoestatísticaFigura 13 – Diagrama geral da adição de contexto local utilizando Geoestatística. Primei-ramente é medida a variabilidade entre as classes no contexto espacial. Tanto diretamenteatravés das frequências de transição na imagem (taxa de transição medida), quanto atravésda inferência de propriedades estatísticas vindas da imagem (taxa de transição modelada).
Em seguida são calculados os vetores de transição. Na segunda parte os vetores são utiliza-dos para gerar pesos para imagem. Com isso, utilizando os pesos, o sistema SIS computaa adição de contexto local para cada superpixel.
A segunda parte do método é a geração do contexto local 𝑃𝑙(𝐿|𝑊). Deste modo,para cada superpixel que se deseja computar, a matriz de probabilidades de transiçãoé usada para computar os pesos 𝑊, para servir como entrada em um sistema de SIS,Sequential Indicator Simulation (Indicador de simulação sequencial) (EMERY, 2004) oqual computa 𝑃𝑙(𝐿|𝑊). Cada um dos processos apontados na Figura 13 são detalhadosno restante desta seção.
3.4.1 Medindo Transições de ProbabilidadesPrimeiramente, um sistema de transição de probabilidades baseado em cadeias deMarkov é medido. Este modelo representa a variabilidade espacial existente juntamentecom os dados da imagem.
A estrategia proposta é calcular uma matriz 𝑇, onde cada componente é a função𝑡𝑖𝑗(ℎ𝜑) a qual modela a probabilidade de uma classe 𝑖 de transitar para a classe 𝑗 emuma distância ℎ considerando a direção 𝜑. É necessário obter tal medida para cada parde classes 𝑖 e 𝑗 presente no conjunto de dados.
Neste método, assume-se que os dados são isomórficos. Portanto, para uma dadatransição, todas as direções são consideradas como idênticas. Não obstante, a abordagempode ser utilizada em casos não isomórficos, considerando duas ou mais direções, cadauma com sua própria matriz de probabilidade de transições.
Foi assumido que a transição de probabilidades tem um comportamento exponen-3.4. Nível Local 𝑃𝑙(𝐿|𝑊)55cial, como proposto por (CARLE et al., 1998). As equação 3.3 mostra como calcular atransição de probabilidades entre classes diferentes e também para a mesma classe ( autotransição).
⎧⎪⎨⎪⎩𝑡𝑖𝑗 = 𝑒𝑟𝑖𝑗 ℎ𝜑 + 𝑝𝑖 [𝑖 = 𝑗]⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣se [𝑖 = 𝑗]se [𝑖 ̸= 𝑗]𝑡𝑖𝑗 =(3.3)
𝑡𝑖𝑗 = 𝑝𝑗 − 𝑒−𝑟𝑖𝑗 ℎ𝜑 [𝑖 ̸= 𝑗]A função de transição na Equação 3.3 também depende da distância ℎ e da probabilidadea priori da classe 𝑝𝑗. Cada fator 𝑟𝑖𝑗 é um componente da matriz 𝑅 Essa matriz é a taxade transição entre as classes, para 𝑘 classes, 𝑅 pode ser calculada como:⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦... 𝑟1𝑖.
.
.
𝑟𝑗𝑖.
.
... 𝑟𝑘𝑖𝑟11.
𝑟𝑗1.
𝑟𝑘1... 𝑟1𝑘.
.
.
𝑟𝑗𝑘.
.
... 𝑟𝑘𝑘(3.4)
𝑅 =Cada elemento da matriz representa a taxa na qual ocorre a transição, sendo assim:𝑟𝑖𝑗 = 𝜕𝑡𝑖𝑖(0))(3.5)
𝜕ℎA matriz 𝑇 não pode ser diretamente calculada a partir dos dados (AGTERBERG,1988). Para tal, primeiramente, é necessario estimar a matriz 𝑅. Carle et al. (1998),propõem obter o calculo de 𝑅 através da multiplicação elemento a elemento das medidasda correlação entre as configurações espaciais diretas (𝑅𝑚𝑒𝑠) e da medida de conceitosestatísticos (𝑅𝑚𝑜𝑑) extraídos das imagens:𝑅 = 𝑅𝑚𝑒𝑠 * 𝑅𝑚𝑜𝑑.
(3.6)
Esta foi a técnica adotada neste trabalho para calcular 𝑅, porém com algumasmodificações. Na seção a seguir, mostra-se o processo para calcular as matrizes 𝑅𝑚𝑒𝑠 e𝑅𝑚𝑜𝑑.
3.4.1.1 Taxa de Transição Medida 𝑅𝑚𝑒𝑠𝑅𝑚𝑒𝑠 é calculado medindo a frequência de transição cumulativa da matriz 𝐹. Paracomputar 𝐹, foi somado o número de vezes que cada classe transita para cada outra classe.
Foi considerado um conjunto de direções e um conjunto de distâncias ℎ. Tal treinamento éfeito em um conjunto de imagens já previamente classificadas. Este processo é apresentadona Figura 14. Foi utilizado um kernel de janela deslizante que iterativamente se deslocaao longo de toda a imagem.
56Capítulo 3. Classificação Baseada em Contexto utilizando GeoestatísticaPara cada posição do kernel, foram contadas todas as transições que o rótulo doponto central do kernel faz. Isto é feito para diversas distâncias, o qual é representadopelos quadrados coloridos da Fig. 14. Ao final, cada linha de 𝐹 é normalizada.
Figura 14 – Medida feita do número de transições que uma classe faz para cada outrapara múltiplas distâncias. Foi utilizada um kernel móvel e foram contadas as transiçõesdesde o centro (ponto vermelho) para todas as direções (representado pelos quadrados)A equação 3.7 mostra um exemplo da matriz 𝐹 feitas para um "dataset” exemplo.
⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦0.762 0.007 0.037 0.060 0.132
0.639 0.066 0.048 0.061 0.184
0.607 0.010 0.214 0.052 0.115
0.594 0.006 0.032 0.261 0.104
0.642 0.010 0.036 0.054 0.255
𝐹 =(3.7)
A matriz estimada 𝐹 é afetada pelas incertezas nas premissas de probabilidadeassumidas. Por exemplo, a premissa do isomorfismo assumida não é perfeitamente verda-deira. Para reduzir o efeito das incertezas e encontrar um padrão na representação, umaanálise de autovetores e autovalores é aplicada na Eq. 3.7 (CARLE; FOGG, 1996).
A partir disso, é possível computar 𝑅𝑚𝑒𝑠 aplicando a equação 3.8.
𝐿∑︁𝑅𝑚𝑒𝑠 =(3.8)
𝜃𝑘𝑍𝑘𝑘=1onde o termo 𝜃𝑘 de 𝑘 = 1, ..., 𝐿 denota os autovalores de F e 𝑍𝑘 denota os componentesespectrais das matrizes desde a analise de auto-vetores. Foi calculado 𝑍𝑘 como mostradona Eq. 3.9.
∏︀∏︀𝑚̸=𝑘(𝜃𝑘𝐼 − 𝐹)𝑚̸=𝑘(𝜃𝑚 − 𝜃𝑘) 𝑘 = 1, ..., 𝐿
(3.9)
𝑍𝑘 =Esta computação consiste em uma medida inicial que congrega as tendências deverossimilhança espacial entre as classes. Contudo, esta medida ainda contém muita im-3.4. Nível Local 𝑃𝑙(𝐿|𝑊)57precisão para ser usada como entrada para a simulação. A medida pode ser ainda maisestabilizada adicionando a computação de 𝑅𝑚𝑜𝑑 assim como mostrado na Eq. 3.6.
3.4.1.2
Calculo da Matriz 𝑅𝑚𝑜𝑑Computa-se 𝑅𝑚𝑜𝑑 utilizando estatísticas extraída dos dados, como: proporções dasclasses, comprimentos médios das classes e as tendências de justaposição.
A proporção de uma classe 𝑙𝑖 é a probabilidade a priori desta classe aparecer. Em
outras palavras, a proporção é a chance de selecionar uma parcela da classe 𝑙𝑖 aleatoria-mente da imagem classificada (CARLE; FOGG, 1996).
O comprimento médio é calculado pela quantidade média de pixeis contínuos deuma certa classe ao longo de uma determinada direção. Como assume-se isomorfismo nosdados, esta direção é arbitraria. Considerando em termos de transição de probabilidades,o comprimento médio 𝐿ℎ𝜑 é a taxa de decaimento da curva de transição da função 𝑡𝑖𝑖(ℎ𝜑)na direção 𝜑 . O comprimento médio é mostrado na equação 3.10.
= 1𝐿ℎ,𝜑−𝜕𝑡𝑖𝑖(0))(3.10)
𝜕ℎIsso é análogo a taxa de uma classe transitar para si mesma, como mostrado naEq. 3.11 (CARLE; FOGG, 1996).
˜𝑟𝑖𝑖 = − 1𝐿ℎ,𝜑(3.11)
O conceito de tendência de justaposição modela as probabilidades de uma classetransitar fora de si mesmo e depois em outra dado uma distância. Considerando 𝑟𝑖𝑖 comoa taxa que a uma certa classe transita para si mesma, 𝑟𝑖𝑗 depende das proporções de 𝑗como mostrado na Eq. 3.12.
𝑝𝑘˜𝑟𝑗,𝑘(ℎ𝜑) =(3.12)
𝐿𝑗𝜑(1 − 𝑝𝑗)Para o caso de um dataset de cinco classes, a matrix 𝑅𝑚𝑜𝑑 tem a seguinte estrutura:⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦˜𝑟111𝐿22˜𝑟32˜𝑟42˜𝑟52˜𝑟13˜𝑟231𝐿33˜𝑟43˜𝑟53˜𝑟14˜𝑟24˜𝑟341𝐿44˜𝑟54˜𝑟15˜𝑟25˜𝑟35˜𝑟451𝐿551𝐿11˜𝑟21˜𝑟31˜𝑟41˜𝑟51𝑅𝑚𝑜𝑑 =(3.13)
Finalmente, usando 𝑅𝑚𝑒𝑠 e 𝑅𝑚𝑜𝑑 é possível computar a Eq 3.6. Na Figura 15são mostradas as transições de probabilidades calculadas para um dataset. Os gráficos58Capítulo 3. Classificação Baseada em Contexto utilizando Geoestatísticada Figura 15 foram computados aplicando a Eq. 3.3 variando a distância ℎ. Como umexemplo, pode-se perceber que o comprimento médio da classe background é bem alto.
Isso acontece por que o seu decaimento exponencial é muito baixo.
Figura 15 – A transição de probabilidade modelada para um determinado dataset. O
eixo y apresenta a distância em pixeis. As linhas verdes mostram as proporções para cadaclasse. Pode-se observar uma certa tendência na classe Urchin em transitar para categoriade background. Ainda, percebe-se que a classe de background tem um grande comprimentomédio, dado que sua taxa de decaimento é bastante alta.
3.4.2 Sequential Indicator SimulationDado que a matriz de transição 𝑇 já foi calculada para um dataset, o algoritmoSequential Indicator Simulation (SIS) tenta simular o 𝑃𝑙(𝐿|𝑊) de um superpixel com baseem sua vizinhança espacial. Para simular os fatores locais de um certo superpixel 𝑥0, umcerto número 𝑁 de posições aleatórias amostradas 𝑥𝛼 são computados em torno da regiãoem um raio 𝑟. Cada uma das posições amostradas vai contribuir para o computar o fatorlocal, sendo que a contribuição é feita de forma a minimizar a variança desta vizinhançacom respeito ao modelo.
Com isso, a probabilidade relacionada com o contexto espacial para cada classe 𝑘3.4. Nível Local 𝑃𝑙(𝐿|𝑊)59em uma certa parcela 𝑥0 é computada como:𝑁∑︁𝐾∑︁𝑃𝑙(𝑥0 = 𝑘|𝑃𝑢(𝑋𝛼)) = 𝑃𝑢(𝑥0 = 𝑘)𝑃𝑢(𝑋𝛼 = 𝑗)𝑤𝑗𝑘,𝛼(3.14)
𝛼=1𝑗=1onde 𝑃𝑢 é a probabilidade a priori (unário) de uma região, sendo 𝑃𝑢(𝑋0 = 𝑘) o superpixelem questão e 𝑃𝑢(𝑋𝛼 = 𝑗), os amostrados. 𝑤𝑗𝑘,𝛼 é o peso da posição 𝛼 para a classe 𝑗transitar para a classe 𝑘. Ou seja a probabilidade local de um superpixel é função dadistribuição do mesmo (𝑃𝑢(𝑋0 = 𝑘)) e o quanto cada posição amostrada contribui para∑︀𝐿𝑗=1 𝑃𝑢(𝑋𝛼 = 𝑗)). O fator é controlado pelo peso 𝑤𝑗𝑘,𝛼.
este superpixel (∑︀𝑁𝛼=1Os pesos para cada posição amostrada formam o conjunto de matrizes 𝑊𝑁 e sãocalculados resolvendo o sistema linear da Eq. 3.15 :⎡⎢⎢⎢⎣ 𝑇(𝑥1 − 𝑥1)⎤⎥⎥⎥⎦⎡⎢⎢⎢⎣ 𝑊1⎤⎥⎥⎥⎦⎡⎢⎢⎢⎣𝑤11,𝛼⎡⎢⎢⎢⎣ 𝑇(𝑥0 − 𝑋1)⎤⎥⎥⎥⎦ (3.15)
... 𝑇(𝑥𝑁 − 𝑥1).
... 𝑇(𝑥𝑁 − 𝑥𝑁)=.
.
.
.
𝑇(𝑥1 − 𝑥𝑁)𝑇(𝑥0 − 𝑋𝑁)𝑊𝑁⎤⎥⎥⎥⎦onde:... 𝑤1𝐿,𝛼.
𝑊𝑖 =(3.16)
.
.
𝑤𝐿1,𝛼 ... 𝑤𝐿𝐿,𝛼A Figura 16 mostra o exemplo de um superpixel arbitrário e sua respectiva regiãoamostrada, para a computação do potencial local. Para tal região a Eq. 3.15 será aplicadade forma a encontrar o peso para cada uma das posições. O peso encontrado é o quetornaria a região o mais homogênea possível.
3.4.3 Computando o Potencial Final 𝑃(𝐿)Depois de obter uma saída da curva de confiança para cada superpixel, primeira-mente se busca os superpixeis com uma saída bem alta de confiança. Foi decido computaro potencial local apenas para superpixeis onde a confiança está abaixo de um limiar 𝑡. O
limiar é selecionado como a confiança máxima, dado pelo conjunto de validação.
O processo do SIS é repetido para cada superpixel presente na imagem em ordemaleatória e os pesos já são atualizados. Isso garante que a correlação entre a própriavizinhança seja considerada.
Os pesos são obtidos diretamente pela Eq. 3.15. Dois parâmetros devem ser escolhi-dos para este método, o número de amostras 𝑁 e o raio 𝑟 onde vai ser feita a amostragem.
Experimentos preliminares mostraram que não existe vantagem pratica em usar mais de60Capítulo 3. Classificação Baseada em Contexto utilizando GeoestatísticaFigura 16 – Exemplo de uma vizinhança sendo considerada para um superpixel ( apontadoem vermelho). Um raio 𝑟 é considerado e 𝑁 pontos são amostrados nessa vizinhança ( emazul). Cada um dos pontos amostrados irá influenciar no potencial do superpixel apontadoem vermelho.
25 amostras. Também, o raio 𝑟 passa e se tornar irrelevante a partir de uma certa dis-tância, dado que às transições de probabilidade tendem a ser iguais as proporções nolimite.
3.5 Geoestatística e CRFTanto as abordagem de CRF, quanto de Geoestatística (GS) tentam minimizaruma função que tenta impor uma certa homogeneidade espacial. Ou seja, superpixeispróximos tendem a ser da mesma classe. A diferença é que o modelo de Geoestatística ébaseado em uma amostragem o que torna o problema da inferência mais simples. O modelode GS é também análogo a um CRF densamente conectado (KOLTUN; VLADLEN, 2011),mas com amostragens mais esparsas.
A abordagem de GS pode ser vista como uma representação mais esparsa do CRFporém, com medidas estatísticas mais ricas. Não obstante, a computação da matriz depesos 𝑊 para a Eq. 3.14 pode ser considerado como a minimização de uma função deenergia, usando uma soma ponderada.
Como uma forma de comparar ambos os métodos, a Figura 17 mostra o modeloGS como um modelo gráfico probabilístico. O vértice central, em verde claro, é o casoatual sendo calculado. Os vértices em verde escuro são aqueles amostrados. Cada verticeem verde escuro contribui para a distribuição do vertice central dependendo das proba-bilidades de transição estimadas da Fig. 15. Em vermelho são representados os fatores613.6. Sumáriounários de cada quadrado em azul é a contribuição desses mesmos ( fatores locais).
Figura 17 – Representação gráfica do modelo de Geoestatística (GS). Os fatores locaissão representados em azul e usam a estatística de probabilidade de transição computadapela Eq. 3.3. Diferentemente do que no modelo da Fig. 7, vizinhos de diferentes distânciastambém contribuem para calcular a distribuição de cada posição.
3.6 SumárioNeste Capítulo apresentou-se um novo método para adição de contexto na classifi-cação. O método foi inspirado nas técnicas de modelagem da variabilidade espacial usadaem Geoestatística.
Foi feita, por fim, uma comparação do método proposto com o CRF. Acredita-se que o método apresentado neste capítulo tende a se comportar melhor que o CRFquando existem menos dados de treinamento, e os mesmos dados não possuem padrõesbem definidos, como no caso do ambiente subaquático. Isso pode ser atingido visto queo método proposto estima padrões de forma para as classes. Sendo assim as relações decorrelação espacial, são também estimadas com base em um modelo para as classes. O
método proposto será testado e avaliado no Capítulo 6.
634 Classificação de Imagens do AssoalhoOceânicoNeste Capítulo é apresentado o domínio de aplicação no qual será aplicado ométodo de adição de contexto proposto no Capítulo 3.
Como apresentado na introdução, o conhecimento sobre as espécies presentes nofundo do mar, especialmente os recifes de corais, é de fundamental importância para osespecialistas na área.
Ao se fazer monitoramento do assoalho oceânico, assim como para o caso do sen-soriamento remoto, é interessante ser capaz de rotular automáticamente cada pixel dasimagens e assim ser capaz de medir propriedades relevantes. O objetivo desta classifica-ção é fazer os chamados mapas temáticos. Tais mapas são a representação final de ummapa classificado de uma imagem, feito de forma visualmente interpretável. Mapas temá-ticos agregam grandes conjuntos de imagens em mosaicos representando áreas de grandeextensão.
Considerando o ambiente subaquático, suas propriedades fotométricas demandamum tratamento especial para contornar a degradação da imagem. Esses desafios própriosdo meio não são comumente endereçados na literatura. Tais propriedades causam proble-mas como bordas confusas entre objetos, variação na qualidade da imagem, etc.
Neste capítulo primeiramente é formalizada as propriedades do meio subaquático,o que sera útil também para capítulos posteriores. Depois, é apresentada uma visão geraldos principais sistemas utilizados para classificação de mosaicos do assoalho oceânico.
Entre os sistemas apresentados, um em especial será detalhado, o qual será utilizadocomo um estudo de caso para adição de contexto.
4.1
Propriedades de Imagens SubaquáticasDe forma a obter imagens capturadas em ambiente subaquático com uma melhorqualidade visual, é fundamental o entendimento de sua formação, levando em conta osaspectos específicos que ocorrem no meio subaquático.
Um modelo de formação de imagens busca descrever os caminhos pelos quais a luzpassa, desde a fonte até a sua captura, onde é formada a imagem. A Figura 18 ilustraeste processo de propagação. Em meios participativos, a irradiação, ou seja, a quantidadede energia luminosa em um pixel, pode ser obtida pelo somatório de três componentes asquais chegam por caminhos distintos. A componente direta, a qual contém a luz sem es-64Capítulo 4. Classificação de Imagens do Assoalho Oceânicopalhamento que veio diretamente do objeto. Muitas vezes, informações que vinham de umúnico ponto são espalhadas entre seus pontos vizinhos causando um efeito de borramentona imagem. Este fenômeno é chamado espalhamento dianteiro (forward scattering),representado pela componente forward scattering. O forward-scattering faz com que asinformações visuais da cena fiquem espalhadas, causando um efeito de borramento.
Figura 18 – Três trajetórias da luz até o plano da imagem. O componente direto, con-tendo a informação direta da cena. O forward-scattering, contendo informação da cenaespalhada. Por fim, o backscattering contendo informações de fora da cena.
Por último, tem-se a componente de backscattering, a qual luz chega no plano daimagem a partir de um ponto que não faz parte da cena observada. Isso acontece devidoà alguma partícula flutuante que desvia a trajetória da luz para o plano da imagem. O
backscattering se comporta tal como um ruído aditivo.
Para calcular cada uma das componentes, algumas simplificações devem ser con-sideradas. Tais simplificações visam tornar o modelo mais simples e tratável computacio-nalmente, ressaltando somente alguns aspectos principais na formação da imagem.
Primeiramente, se assume o objeto como tendo sua reflectividade uniforme. Assume-se uma iluminação completa e uniforme da cena. Por fim, pode-se descartar os parâmetrosda câmera e considerar a captura da luz como sendo também uniforme.
Normalmente o efeito causado pelo forward-scattering tende ser desprezado, porcontribuir com uma participação menor que o backscattering na formação da imagem(TREIBITZ; SCHECHNER, 2006).
A descrição final do modelo é dada pela equação de Koschmieder (KOSCHMI-EDER, 1924), bastante utilizada para a propagação da luz na névoa. Sendo assim, a654.1. Propriedades de Imagens Subaquáticasformação de um ponto (𝑥, 𝑦) na imagem é dado por:𝐼(𝑥, 𝑦) = 𝐽(𝑥, 𝑦) 𝑒−𝑐𝑧(𝑥,𝑦) + 𝐵∞(1 − 𝑒−𝑐𝑧(𝑥,𝑦)),(4.1)
Sendo 𝐽(𝑥, 𝑦) a imagem sem degradação e 𝑧(𝑥, 𝑦) uma função da distância paracada ponto na imagem. Essa equação pode ser interpretada da seguinte forma: quantomais distante estiver o objeto maior será o componente backscattering, menos da cena realirá existir na imagem.
Sabe-se que, devido as propriedades do meio subaquático, existe uma diferença sig-nificativa entre a absorção e espalhamento dos comprimentos de onda (DUNTLEY, 1963)Desta forma, o modelo pode ser estendido de forma incorporar diferentes comprimentosde onda. A equação 4.1 modela a quantidade de luminosidade capturada relativa a umdeterminado pixel. Porém é possível adequá-la para diferentes comprimentos de onda, ouno caso do padrão RGB de representação, dividi-la em três canais conforme a equação4.2,
𝐼 𝜆(𝑥, 𝑦) = 𝐽 𝜆(𝑥, 𝑦) 𝑒−𝑐𝜆𝑧(𝑥,𝑦) + 𝐵𝜆∞(1 − 𝑒−𝑐𝜆𝑧(𝑥,𝑦)), 𝜆 𝜖 {𝑅, 𝐺, 𝐵}(4.2)
A Figura 19 apresenta uma típica imagem com alto nível de turbidez. Turbidez éuma propriedade comum no meio aquático que esta relacionada com a quantidade de luzque é absorvida ou espalhada ao invés de ser transmitida em uma linha reta (OMAR;MATJAFRI, 2009).
Figura 19 – Imagem de exemplo para as degradações do ambiente subaquático. É possívelver que existe uma variação conforme a distância e uma perda significativa da informaçãode cor.
66Capítulo 4. Classificação de Imagens do Assoalho OceânicoÉ interessante observar que a degradação não afeta uniformemente a imagem.
Existem níveis de degradação mais altos de acordo com a distância. Além disso, o com-primento de onda vermelho tende a se perder rapidamente, tendo a cor verde nesse casocomo predominante.
Por fim, vale notar que, fenômenos adicionais também acontecem. Um exemplo éo efeito da "neve submarina", a qual causa aparecimento de pequenos pontos brancos naimagem. Por estes e outros fatos é relevante constatar que o meio subaquático já tem umaalta presença de ruído (BAZEILLE et al., 2006).
4.2 Classificação Autônoma de Imagens do fundo OceânicoA Figura 20 mostra uma adaptação do que é usado pela maioria dos frameworksem visão computacional para criação de mapas temáticos de mosaicos em ambientessubaquáticos (SHIHAVUDDIN et al., 2013).
Figura 20 – A sequência utilizada para classificação de imagens em meio subaquático.
Para classificar os objetos de uma imagem é necessário passar por diversas etapas.
A seguir são listadas as etapas apresentando algumas das técnicas usadas na literatura:∙ Pré-processamento: etapa fundamental em ambientes subaquáticos. Normalmente éonde correções de cor (PIZARRO et al., 2008) e contraste (JOHNSON-ROBERSON;KUMAR; WILLAMS, 2007) são aplicadas para atenuar a degradação e ressaltaraspectos importantes das imagens subaquáticas.
∙ Segmentação: Nesta etapa a imagem é super-segmentada em regiões com proprie-dades similares. Tal etapa pode ser evitada, para o caso onde ocorre uma seleçãomanual do que ser classificado.
∙ Extração de Descritores: é onde as características relevantes para cada segmentosão extraídas e representadas. Diversas abordagens são utilizadas, um exemplo seriao uso de descritores locais e bag-of-words por Pizarro, Eustice e Singh (2004). Os
674.2. Classificação Autônoma de Imagens do fundo Oceânicodescritores de textura e cor são bastante utilizados no meio subaquático (BEIJBOMet al., 2012) (STOKES; DEANE, 2009), (MARCOS; SORIANO; SALOMA, 2005).
∙ Classificação: é onde se realiza o treinamento do classificador e classificação para ostestes. Diversos classificadores são utilizados como o SVM (PIZARRO; EUSTICE;SINGH, 2004) ou o LDA (MARCOS; SORIANO; SALOMA, 2005).
∙ Pós-processamento: é onde informações adicionais são utilizadas para refinar o resul-tado da classificação. Em (SHIHAVUDDIN et al., 2013) é feito um simples sistemade votação para verificar a consistência da vizinhança No caso, até onde se sabe, nãoocorreram outras aplicações de técnicas mais elaboradas para adição de contexto.
Nesta seção é especificado em detalhe cada etapa apresentada elucidando o quefoi utilizado por Shihavuddin et al. (2013) para geração de mapas temáticos. Tal métodofoi escolhido como base para aplicação de técnicas para adição de contexto. O mesmo foiescolhido devido a alta taxa de acerto na classificação quando comparados com diversosmétodos do estado da arte (SHIHAVUDDIN et al., 2013). Os algoritmos usados em cadauma das etapas da Figura 20 são elucidados a seguir.
4.2.1 Pré-ProcessamentoO processo de pré-processamento almeja deixar a imagem o mais próxima possívelda cena em qual a mesma foi capturada. Isso é feito tanto no escopo radiométrico quantogeométrico. Ou seja, o objectivo é tornar, as estruturas geométricas , seu brilho e cor omais próximos possível da cena (GONZALEZ; WOODS, 2006).
Para lidar com o processamento embaixo d’água, primeiramente, precisa-se consi-derar todos os princípios básicos de propagação da luz nesse meio os quais foram colocadosna Seção 4.1. (SCHETTINI; CORCHS, 2010)Seguindo a ideia de que a qualidade visual subjetiva é importante, pode-se melhor aqualidade de imagens subaquáticas utilizando técnicas que abordam diretamente os efeitosdegradantes apontados. Esta seção apresenta as alternativas existentes para corrigir cadaum dos tipos de degradação.
4.2.1.1 ContrasteObserva-se pela Equação 4.1 que o processo de degradação da imagem em ambientesubaquático não é uniforme ao longo da imagem. O mesmo depende da distância de cadaponto a câmera.
Nesse contexto, o Shihavuddin et al. (2013) faz o uso do CLAHE (Contrast LimitedAdaptative Histogram Equalization) (ZUIDERVELD, 1994) para correção de contraste.
68Capítulo 4. Classificação de Imagens do Assoalho OceânicoTal método faz uma construção de histograma diferente para cada segmento da imageme aplica uma equalização de histograma somente nesse segmento. Além disso, o métodocoloca um limite de intensidade maxima, redistribuindo todos as intensidades que ficamacima deste limite.
4.2.1.2 Correção de CorComo mostrado na seção 4.1, existe uma não uniformidade na absorção de cadacomprimento de onda no ambiente subaquático. Isso causa que boa parte da informaçãocromática da cena seja perdida.
De forma a obter cores mais próximas de realidade existe a necessidade de estimartais diferenças de absorção. Uma das formas de resolver isso é considerar que é possí-vel obter as diferenças de absorção considerando essas diferenças como uma questão deestimativa da fonte de luz. Colocado de tal forma, o problema, se torna basicamente aaplicação de algoritmos de balanceamento de branco, os quais podem ser uma simplesnormalização.
O método de (SHIHAVUDDIN et al., 2013) aplicou a premissa de que que oponto de maior intensidade da imagem foi causado por reflexão perfeita. Desta forma ailuminação pode ser estimada achando o ponto de maior intensidade da imagem. Sendoassim, para tornar a cor da imagem balanceada, o ganho para cada pixel pode ser dadocomo:𝑅𝑔𝑎𝑛ℎ𝑜 = 1/𝑅𝑚𝑎𝑥𝐺𝑔𝑎𝑛ℎ𝑜 = 1/𝐺𝑚𝑎𝑥𝐵𝑔𝑎𝑛ℎ𝑜 = 1/𝐵𝑚𝑎𝑥(4.3)
4.2.2 SegmentaçãoDiversos desafios em classificação de imagens colocam o desafio atual como classi-ficar os objetos pixel a pixel (FULKERSON; VEDALDI; SOATTO, 2009).
O caso da aplicação em sensoriamento remoto, claramente se beneficia deste fato,onde cada pixel da imagem é relevante. A questão é que, devido ao custo computacional,e ao fato que somente um pixel não possuir grande significado semântico para efetuara classificação e extrair os descritores, muitas vezes a abordagem de usar segmentos daimagem, ajuda a melhorar a consistência.
Existe e a tendência de muitos autores fazer uma pré-segmentação, a qual aparen-temente não esta relacionada com a classificação final. Porém, tal segmentação ajuda aa garantir que cada parte da imagem sendo classificada tenha uma homogeneidade local.
Tal segmentação é chamada de segmentação em superpixeis.
694.2. Classificação Autônoma de Imagens do fundo OceânicoPara o caso da abordagem de Shihavuddin et al. (2013), os superpixeis são utiliza-dos como estrutura de interação. A imagem é definida como um conjunto de superpixeisa serem classificados.
Diversos algoritmos existem para a criação de superpixeis. Porém, Shihavuddin etal. (2013) selecionou aquele que tende a manter uma estrutura o mais regular possível.
No caso foi utilizado os Turbopixels (LEVINSHTEIN et al., 2009) .
4.2.3 DescritoresPara descrever a imagem foi utilizado majoritariamente descritores de textura.
Textura pode ser definida como a variação dos dados visuais em escalas menores que aescala observada (PETROU; GARCÍA-SEVILLA, 2006).
O assoalho submarino é tipicamente texturizado. Observou-se diversos bancos dedados de corais, e outras estruturas encontradas no meio, e percebe-se que existem sem-pre oscilações na estrutura dos objetos em diferentes escalas. Tal fenômeno caracteriza aexistência da textura. Além da tendência existente na literatura em usar textura (SHIHA-VUDDIN et al., 2013).
Com isso em vista, (SHIHAVUDDIN et al., 2013) utiliza três descritores como des-critores de texturas: Gabor Filter, Grey Level Co-occurence Matrix (GLCM) e CompletedLocal Binary Pattern (CLBP).
Os Gabor Filters são um grupo de Wavelets 2D que tomam forma de uma gaussiana2D modulada no espaço 2D (PORTER; CANAGARAJAH, 1997). Basicamente são umarepresentação da variação de frequência em um segmento da imagem.
O GLCM (HARALICK; SHANMUGAM; DINSTEIN, 1973), utiliza a represen-tação de padrões de variações espaciais dos segmentos da imagem em uma matriz, querepresenta a variação de intensidade dos pixeis em diferentes ângulos e distâncias. Diver-sos indicadores são computados a partir dessas matrizes como a média de variações ou aentropia.
O CLBP (GUO; ZHANG, 2010), é um descritor de textura invariante a rotação oqual retrata, principalmente, a variação de sinais de um pixel central para com pixeis aoredor em uma determinada posição.
A utilização de cor é complexa dado a perda de cor não uniforme entre os compri-mentos de onda como mostrado na Seção 4.1. Porém ainda é possível utilizar um descritorde cor que possui propriedades importantes como robustez a variações fotométricas causa-das por sombras, sombreamento e também mudanças geométricas como escala e alteraçãode ponto de vista. (SHIHAVUDDIN et al., 2013) utiliza o trabalho de (WEIJER; SCH-MID, 2006) que aproximou tais propriedades.
70Capítulo 4. Classificação de Imagens do Assoalho OceânicoAo final, ao utilizar múltiplos descritores, se tem uma representação da imagemcom uma grande quantidade de dimensões e muitas vezes com um padrão pouco evidente.
Para resolver isso é aplicado normalizações e modificações nos descritores. Por exemplo,os descritores podem ser manipulados de forma que os mesmos sejam o mais próximos ase tornaram linearmente separáveis. Essa modificação é fundamental para se melhorar aqualidade da classificação. Por fim, os descritores são normalizados de forma a que todosos descritores estejam numa escala compatível.
4.2.4 Treinamento e ClassificaçãoO treinamento foi feito utilizando três classificadores distintos de forma mutu-almente exclusiva. Foram utilizados o Support Vector Machine (SVM), o K-nearest-neighbors e o PDWMD proposto por (STOKES; DEANE, 2009). Cada um destes classi-ficadores foi utilizado dependendo das características dos dados.
Dado que o aprendizado foi feito, novos dados podem ser classificados. É feitoum mapa temático baseado na segmentação em superpixeis. Sendo que cada superpixel éclassificado individualmente.
4.3 ConclusõesNeste capítulo apresentou-se o cenário onde vai ser feito o estudo desta dissertação.
Também se apresentou alguns métodos os quais já fizeram classificação de imagens dobentos.
No capítulo 6 serão apresentados os resultados de aplicação do método de (SHIHA-VUDDIN et al., 2013) e será feito o estudo sobre a incorporação de contexto para essemétodo.
715 Testes e Resultados 1: Detecção de Pontosde Interesse em Ambiente SubaquáticoUma das principais contribuições desta dissertação foi a criação de um experi-mento para analizar e compreender o comportamento dos detectores de pontos de interessequando utilizados em ambiente subaquático.
Como apresentado no Capítulo 1, diversos detectores foram desenvolvidos paraserem invariantes a uma serie de fenômenos. A ideia é que o mesmo ponto de interessepossa ser encontrado independentemente de diversas circunstâncias da cena.
Porém, existem fenômenos adicionais que atuam sobre a cena no ambiente su-baquatico os quais devem ser considerados. Quando a luz se propaga neste meio, ela éabsorvida e espalhada pelos diferentes coeficientes de refração encontrados nas particulaspresentes no meio. Isso espalha a informação capturada e cria o efeito de "enevoado"naimagem. Tais fenômenos foram descritos mais detalhadamente no Capítulo 4, Seção 4.1.
Um estudo feito por Garcia e Gracias (GARCIA; GRACIAS, 2011), comparouos detectores de pontos de interesse mais populares na literatura. Eles encontraram queestruturas do tipo blob, obtidos por métodos baseados em Hessian (BEAUDET, 1978),por exemplo, são melhores detectadas tanto para o caso de métodos invariantes a escalacomo os de única escala. A justificativa é que a turbidez da água tende a suavizar quinas eborrar regiões definidas, fazendo com que métodos como Harris (HARRIS; STEPHENS,1988) ou Harris-Laplace (MIKOLAJCZYK; SCHMID, 2004) sejam menos propícios parao ambiente. Entretanto, eles avaliaram somente algumas estruturas em uma única cena.
É do interesse desta dissertação melhorar este estudo. Neste contexto, alguns principaisobjetivos são buscados.
Foi proposto um novo dataset no qual é possível utilizar diferentes estruturassubmarinas obtidas através da impressão de fotos subaquáticas. Estas estruturas foramrefotografadas dentro de um tanque de água onde imagens com a degradação controladaforam produzidas. Isso é uma melhoria a tentativas anteriores em termos de diversidadede elementos visuais. Considerando que a degradação causada por imagens com baixa ealta turbidez não é linear, uma contribuição é dividir a análise em diferentes intervalosde turbidez.
Foram testados detectores de pontos de interesse, considerando diferentes aborda-gens, com respeito a sua robustez a degradação causada pela turbidez. Foi focado inves-tigar o problema de que detectores invariantes a escala tendem a ter baixa performance(GARCIA; GRACIAS, 2011). Isto é feito através da análise de diferentes espaços de es-72Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente Subaquáticocala. Finalmente, foi indicado o melhor detector invariante para imagens subaquáticascomo sendo o DoG (LOWE, 2004).
Este Capítulo está organizado da seguinte maneira. A seção 5.1 apresenta a des-crição completa do experimento a ser realizado. Tal seção mostra todos os detalhes daexperimentação necessários para que o mesmo seja bem sucedido. Também explica to-das as considerações feitas para se ter dados aceitaveis. Por fim, a Seção 5.3 mostra osresultados obtidos para tal experimento, e apresenta uma discussão sobre os resultadosencontrados.
5.1 Descrição do experimentoNa literatura, poucos são os trabalhos que analisam o comportamento dos detec-tores de pontos de interesse em ambiente subaquático. Nesta seção, descreve-se todo oprocesso de realização do experimento para que ele seja completamente reproduzível.
Neste experimento foram capturadas diversas imagens em uma cena onde a únicamodificação entra as cenas é a degradação causada pela turbidez. O objetivo fundamentaldo experimento é tentar obter o máximo de isolamento desta degradação possível. Paratal, a câmera utilizada deve estar estática e a iluminação deve ser controlada.
5.1.1 Cena MontadaConstruí-se uma cena onde as imagens foram colocadas. A Figura 21 mostra aespecificação da cena.
Figura 21 – A cena criada para avaliar os algoritmos de avaliação de features. Ela é com-posta por lampadas fluorescentes e uma camera fotografando fotos impressas do assoalhodo oceano.
Na cena montada existe uma fotografia a ser capturada por uma câmera posicio-nada a uma distância perpendicular de 0.58𝑐𝑚 . A fotografia esta posicionada em uma735.1. Descrição do experimentocaixa de água de mil litros. Duas luminárias usando lâmpadas fluorescentes brancas foramposicionadas perto do tanque.
Três fotografias diferentes foram utilizadas, representando o fundo do mar captu-rado nas Bahamas em condições próximas ao ideal de turbidez (ZVULONI et al., 2009). As
diferentes cenas contém os mais variados tipos de textura que podem ser encontradas noambiente subaquático e também objetos feitos pelo homem. As fotografias foram impres-sas usando um "ploter"a laser usando uma mídia de vinil adesivo fosco e a prova d’água.
Cada fotografia foi impressa num tamanho de 91cm X 60 cm e possuem 4928x3264 pixeisde resolução. O diferencial desta deste dataset é que ele contém verdadeiras estruturasdo assoalho oceano, e ainda algumas estruturas feitas pelo homem, sendo o seu princi-pal problema, a perda de resolução devido a impressão e a refotografia. Isso cria umaperda de resolução de 20 𝑝𝑖𝑥𝑒𝑙𝑠/𝑚𝑚2 para 4 𝑝𝑖𝑥𝑒𝑙𝑠/𝑚𝑚2 e adição de algumas pequenasimperfeições devido a erros de impressão.
A Figura mostra as imagens que foram impressas, nomea-se cada uma das imagenscomo 𝑃1, 𝑃2 e 𝑃3.
A câmera utilizada para a captura foi uma Gopro Hero 3 Black edition. Cadaimagem foi capturada em uma resolução de 12 mega pixels(3000x4000).
5.1.2 ProcedimentoFoi decidido simular principalmente o efeito do fenômeno de backscattering. Sabe-se que os motivos que levam a degradação de uma imagem capturada em meio subaquáticosão complexos (DUNTLEY, 1963). Porém, neste experimento tentou-se isolar o princi-pal fenômeno que causa a degradação na imagem. Um estudo feito por Narasimhan etal. (2006) mostra que uma solução de água e leite integral apresenta um alto grau debackscattering, apontado por alguns como a principal fonte de degradação da imagem(TREIBITZ; SCHECHNER, 2006). Isso é causado pelo maior tamanho das partículas doleite integral que fazem que o ângulo de refração seja maior, aumentando o backscattering.
Foi decidido dividir o experimento em 3 ensaios, cada um contendo uma imagemdiferente.
Cada ensaio foi capturado com 19 níveis de turbidez diferentes, cada um contendouma determinada quantidade de leite. Chamou-se cada nível de turbidez de 𝑇1...𝑇19.
Considera-se 𝑇0 como o nível de turbidez com a imagem limpa. A Tabela 1 mostra os níveisde turbidez e suas respectivas quantidades de leite (Em uma caixa com aproximadamente1000 litros de água).
Para capturar as imagens, a câmera foi setada para capturar uma foto a cada10 segundos. Para cada nível de turbidez foi escolhido um grupo de fotos com o menornível de perturbação. Como explicado no Capítulo 4, Seção 4.1, o meio subaquático é74Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente Subaquático(a) 𝑃1(b) 𝑃2(c) 𝑃3Figura 22 – As imagens utilizadas no teste. As três imagens foram capturadas nas Bahamasem condições de turbidez próximas do ideal em uma resolução de 4928x3264 pixeiscomposto por uma certa quantidade de ruído. Em um ambiente controlado, como o quefoi feito é possível, tendo uma seleção de fotos em um mesmo nível de turbidez 𝑇𝑖, reduziro ruído extraindo mediana entre as imagens iguais (GARCIA; GRACIAS, 2011). Destaforma busca-se reduzir a degradação na imagem por ruídos que podem ter diversas causas755.2. Avaliando a degradação causada pela turbidezImagem (𝑇𝑖) Quantidade de Leite Integral Leite AdicionadoT1T2T3T4T5T6T7T8T9T10T11T12T13T14T15T16T17T18T195 ml10 ml15 ml20 ml25 ml30 ml36 ml42 ml50 ml58 ml66 ml74 ml82 ml90 ml100 ml110 ml120 ml130 ml190 ml5 ml5 ml5 ml5 ml5 ml5 ml6 ml6 ml8 ml8 ml8 ml8 ml8 ml8 ml10 ml10 ml10 ml10 ml60 mlTabela 1 – A quantidade de leite adicionada para cada nível de turbidez simulado.
como erro no sensor da câmera, partículas bloqueando totalmente a passagem da luz, etc.
Tenta-se de certa forma isolar significativamente a degradação por turbidez (IDT), comoo principal fenômeno da cena.
A Figura 23 apresenta as imagens geradas pelo experimento. Neste caso fez-sea distinção entre diversos intervalos de turbidez. Na Figura 23 é mostrado um nível deturbidez por intervalo, para cada imagem.
5.2 Avaliando a degradação causada pela turbidezMedir a quantidade de degradação é fundamental neste experimento de forma acomparar os detectores somente relativo a este fenômeno. A degradação causada pela tur-bidez é dependende da quantidade de particulas em suspenção na água, e também os tiposde particulas em suspenção. Além disso, a quantidade de iluminação e a maneira como acena é iluminada é também fundamental para determinação da degradação causada pelaturbidez.
Este conceito difere do conceito de turbidez que esta relacionado somente com aquantidade de sedimentos flutuantes (SSC) na água os quais espalham a luz. A degradaçãocausada pela turbidez difere pois ela não esta relacionado somente as partículas presentesna água e sim a degradação que o SSC causa na cena, levando em conta os parâmetros76Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente SubaquáticoFigura 23 – As imagens capturadas sob diferentes níveis de degradação devido a turbi-dez, controlado pela adição de leite. Foram fotografadas três fotos impressas diferentes,𝑃1 (primeira coluna), 𝑃2 (segunda coluna) e 𝑃3 (terceira coluna). Na primeira linha foimostrada a imagem limpa (sem leite) para cada foto capturada. A segunda linha apre-senta o intervalo de Baixa Turbidez com por volta de 15ml de leite (𝑇4). O intervalo deMédia Turbidez é mostrado na segunda linha e contém por volta de 50 ml de leite (𝑇10).
Finalmente, na ultima (quarta) linha é mostrado o intervalo com Alta turbidez tendo porvolta de 100 ml de leite (𝑇16). Quantidade de leite setada para uma caixa com 1000 litrosde água.
da câmera e o volume de água iluminado.
Uma forma de medir a turbidez é usando um turbidímetro nefelômetro, o qualmede a turbidez pela quantidade de luz espalhada ao emitir um feixe de laser numaporção da água.
Esta alternativas não é capaz de estimar a degradação causada pela turbidez,que é também dependente da cena. Com essas considerações, Garcia e Gracias (2011)propuseram a utilização de uma variação Structural Similarity Index (WANG et al., 2004),para avaliar a degradação, chamado Structural Degradation Index (SDI). Essa abordagemavalia a degradação pela perda de informação estrutural, o que de fato esta relacionado775.3. Resultadoscom a turbidez. Porém, a mesma não tenta isolar a medição do fenômeno de absorção eespalhamento como principais causadores da degradação.
Neste trabalho utiliza-se a métrica proposta por (GARCIA; GRACIAS, 2011),porém normalizada em função da imagem completamente turva pelo leite. Tal métricaé capaz de medir a porcentagem de degradação em função da imagem onde teve suainformação visual inicial completamente eliminada. O método é explicado na secção 5.3.1
5.3 ResultadosNesta seção são mostradas a comparações entre os detectores. Foram comparadosos seguintes detectores, previamente definidos no Capítulo 1. Para única escala, Harris(HARRIS; STEPHENS, 1988), Hessian (BEAUDET, 1978) e Laplacian (TUYTELAARS;MIKOLAJCZYK, 2008). Com múltiplas escalas avaliou-se Fast Hessian do SURF (BAYet al., 2008) e Difference of Gaussians do SIFT (LOWE, 2004). Foram avaliados tambémoutros detectores com propriedades relevantes. Os três kernels baseados em difusão aniso-trópica do detector KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) e o geradopelo centro e arredores usando estruturas poligonais CenSurE (AGRAWAL; KONOLIGE;BLAS, 2008) usando tanto um polígono convexo de seis lados e um polígono estrelado detambém seis lados.
5.3.1 Procedimento de AvaliaçãoOs resultados são avaliados quanto ao critério de repetibilidade descrito em (SCH-MID; MOHR; BAUCKHAGE, 2000). Tal critério indica a porcentagem dos pontos deinteresse que se repetiram, ou seja, ainda foram encontrados após a aplicação da trans-formação.
Primeiramente computa-se 𝑁 = 1000 pontos de interesse para cada detector naimagem com a turbidez 𝑇0 e para todos os níveis 𝑇1...𝑇19. Os 𝑁 pontos de interesseselecionados são os N melhores pontos de interesse segundo o critério do detector, no casoHessian ou Harris. Na imagem com turbidez 𝑇0 é selecionada cada ponto-chave e é testadose esse ponto é resistente na presença de turbidez. Para esse ponto-chave ser resistente énecessário que o mesmo seja encontrado nas imagens turvas sem sofrer um deslocamentomaior que um fator de 𝑒 = 5 pixeis. Esse valor é determinado de forma a escolher somenteos melhores pontos de interesse. Subsequentemente, para determinar a repetibilidade deum certo detector, o número de pontos chaves encontrados em cada imagem túrbida sãocontados. Considerando essa questão, a repetibilidade quanto ao degradação por turbidez78Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente Subaquático(𝑅) é calculada como:𝑅 = 𝑁𝑖𝑁0(5.1)
Onde 𝑁0 é o número de pontos de interesse na imagem limpa (capturada em 𝑇0) e 𝑁𝑖 éa imagem com a degradação estimada.
Para medir a degradação causada pela turbidez, foi usado uma versão diferente doSDI (WANG et al., 2004) (GARCIA; GRACIAS, 2011). O índice SDI não responde comos mesmos valores para as mesmas quantidades de turbidez. Por esta razão, foi utilizadouma versão normalizada do SDI. Considerando a imagem 𝑇19 como sendo totalmentedegradada, pode-se medir o SDI como uma percentagem da degradação máxima, o quefacilita a comparação:𝑁 𝑆𝐷𝐼𝑖 = 𝑆𝐷𝐼𝑖/𝑆𝐷𝐼𝑁(5.2)
Onde 𝑆𝐷𝐼𝑁 é o índice de degradação da imagem 𝑇19.
5.3.2 ComparaçãoA Figura 24, mostra os gráficos com os valores de repetibilidade para as três fotosimpressas (𝑃1,𝑃2,𝑃3) testando multiplos detectores. No eixo 𝑥 é mostrado o indice 𝑁 𝑆𝐷𝐼e a quantidade de leite adicionada.
Da Figura 24, são mostrados as analises para três intervalos diferentes de degra-dação causada por turbidez baseado no NSDI . Desde 0 a 0.25 de 𝑁 𝑆𝐷𝐼 foi consideradocomo um ambiente de Baixa Turbidez(Fig. 23 segunda linha). Nestes casos a maioria dainformação estrutural é mantida e o backscattering é mínimo. No intervalo de 0.25 até0.75 foi considerado como imagens de parte de um intervalo de Média Turbidez( Fig. 23
terceira linha). Nestes níveis, a informação estrutural é parcialmente mantidas, mas asbordas passam a ser mal definidas. Ao final, desde 0.75 até 1, em Alta Turbidez(Fig. 23
quarta linha), quase nenhuma informação estrutural é mantida. Nestes níveis, os detec-tores podem somente fazer uso de algumas poucas pistas visuais que ainda resistiram aturbidez.
Para todos os intervalos de turbidez, é possível separar claramente os detectoresanalisados em quatro grupos.
Os detectores baseados em única escala (Azul Fig. 24) obtiveram os melhoresresultados em todos os intervalos de turbidez. Comparado com outras comparações dedetectores de pontos de interesse (GIL et al., 2010) (CRISTINACCE; COOTES, 2006),a superioridade dos detectores não invariantes a escala em comparação a aqueles que são795.3. ResultadosFigura 24 – Repetibilidade ( Taxa de Acerto) contra o indice de degradação estruturalnormalizado (NSDI). As linhas em laranja indicam os intervalos de degradação. BaixaTurbidez 0 até 0.25; Média Turbidez, 0.25 até 0.75, e Alta Turbidez de 0.75 até 1.
80Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente Subaquáticoinvariantes a escala, em situações onde a escala não varia, é mais expressiva. O detectorHarris foi melhor para o caso de 𝑃1 (Fig. 24a) até um nível médio de turbidez. Após issoo mesmo teve um decaimento maior, quando as estruturas começaram a se perder.
O detector baseado em espaços de escala com difusão anisotrópica, obteve os pioresresultados (Vermelho Fig. 24). Isso é o oposto do que é mostrado em cenas fora d’água(ALCANTARILLA; BARTOLI; DAVISON, 2012). O algoritmo KAZE necessita calcularas respostas das bordas antes de obter o espaço de escala. Isso é mais dificil em ambientessubaquáticos devido a suas propriedades naturais. Porém, no intervalo de Baixa Turbidez,KAZE foi capaz de obter uma repetibilidade maior que o FastHessian e o DoG, dado queas bordas ainda estão bem definidas. Para o caso de Média Turbidez, a taxa de acerto cairapidamente, chegando a zero em Alta Turbidez.
Os melhores resultados para níveis de media e alta turbidez, foram, de fato, obtidospelo detector DoG (LOWE, 2004). O detector Fast Hessian, possui uma aproximação maisbrusca do espaço de escala a qual tende a produzir artefatos. Por isso, tratou-se do piorresultado dentre os analisados.
CenSurPoly e o CenSurStar apresentaram resultados similares ao Kaze tendo pi-ores resultados para níveis mais altos de turbidez.
A Figura 25 mostra a comparação de um determinado nível de espaço de escalagerado por um kernel gaussiano , um kernel baseado em caixas (FastHessian), um kernelbaseado em polígonos estrelados (CenSurE) e um gerado pelo filtro anisotrópico (KAZE)𝑔2 da Eq. 1.12 . Tais kernels são aplicados em múltiplos níveis de turbidez, sendo quecada linha da figura apresenta um nível de turbidez diferente.
É possível perceber que a informação estrutural se mantém mais para o polígonoestrelado. O que justifica o seu estudo, principalmente para o caso de maior turbidez. Já
o KAZE também possui um comportamento interessante, porém muito da informaçãotende a se perder com a turbidez para um mesmo nível de escala.
Como mostrado no Capítulo 4, Seção 4.1 , existe um comportamento de borra-mento regido por um certo fenômeno. É possível que funções, como as utilizadas peloCenSurE e o KAZE, as quais tendem a não seguir o comportamento do borramento cau-sado pelas propriedades do meio subaquático, tendam a manter as estruturas geométricas, e , ao encontrar pontos que possuem máximo sobre escala, encontrem regiões em queainda existe informação visual provida pela imagem.
5.4 Conclusões finaisEste capítulo apresentou a avaliação a invariância a degradação em ambientessubaquáticos para detectores de pontos de interesse mais utilizados na literatura. Foi815.4. Conclusões finaisFigura 25 – Comparação entre a geração de um nível do kernel do espaço de escala usadopor quatro detectores diferentes. O kernel foi aplicado em níveis de turbidez diferentespara a imagem 𝑃1. Sendo que a primeira linha é a imagem limpa (𝑇0), a segunda linhaé uma imagem com baixo nível de degradação (𝑇4), a terceira linha apresenta uma ima-gem com médio nível de degradação (𝑇10), a quarta linha apresenta imagens do nível dedegradação alto (𝑇16). Para cada caso é mostrado o resultado de filtro equivalente a aaproximadamente um kernel gaussiano de 𝜎 = 59.0. Primeira Coluna: Gaussiano puro.
Segunda Coluna: Borramento aproximado em caixas . Terceira Coluna: Difusão utilizandoum polígono estrelar de seis pontas. Quarta Coluna: kernel anisotrópico g2 do KAZE. É
possível ver de certa forma estruturas mais definidas para o esquema de difusão usadopelo CenSurE (AGRAWAL; KONOLIGE; BLAS, 2008).
proposto um novo dataset, completamente aberto, usando fotos impressas reais as quaistinham uma quantidade controlada de turbidez.
Foi concluído que para, imagens subaquáticas, métodos de única escala tem umarepetibilidade consideravelmente melhor que abordagens de multipla escala. Entre Harris(HARRIS; STEPHENS, 1988) e Hessian (BEAUDET, 1978), Hessian obteve resultadosmelhores principalmente para níveis mais altos de turbidez e em imagens onde há poucainformação estrutural.
82Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente SubaquáticoConsiderando múltipla escala, foram avaliados novos detectores os quais não usamos espaços de escala Gaussianos. Foi proposto que nestes espaços diferentes, como os centersurround ou os baseados em difusão anisotrópica, a difusão não acontece com a mesmaestrutura que o fenômeno de degradação da turbidez, assim então produzindo melhoresresultados, em alguns níveis de turbidez.
Os melhores resultados para múltipla escala foram obtidos pelo DoG (LOWE,2004) Também mostrou-se que o KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012)apresenta resultados relevantes mas tende a perder precisão em níveis mais altos de tur-bidez.
Finalmente, a avaliação proposta mostra que um espaço de escala não Gaussianopode também produzir melhores resultados. Como trabalho futuro, buscar-se-á explorarque espaços de escala que consideram a degradação causada pela turbidez de forma aobter melhores resultados de repetibilidade.
836 Testes e Resultados 2: Contexto em Clas-sificação SubaquáticaAqui são apresentados os resultados de aplicação do método proposto baseado emGeoestatística (no Cap. 3), comparado com outros métodos, com e sem a incorporaçãodo contexto.
O método será aplicado em mosaicos de imagens do assoalho oceânico, para obten-ção de mapas temáticos. As imagens resultantes são a representação final de um mosaico,feito de forma visualmente interpretável, contendo a classificação realizada de forma pixel-a-pixel.
O capítulo apresenta os datasets, compostos por mosaicos, utilizados como caso deteste para a classificação e também as configurações utilizadas para os testes e, por fim,os resultados da classificação dos mosaicos são mostrados.
6.1 Datasets UtilizadosPara avaliação dos resultados obtidos foi proposto utilizar dois datasets distintosde mosaicos de recifes de corais. Cada dataset é composto por um mosaico obtido pelajunção de centenas de imagens coletadas por especialistas da Universidade de Miami.
O dataset Redsea contém imagens do Mar Vermelho, capturadas em águas bastanterasas perto da cidade de Eilat, como parte de uma pesquisa por ecologistas de recifesde corais (ZVULONI et al., 2009). Para a classificação, foram considerado cinco classes:Urchin, Branching Coral, Brain Coral, Favid Coral e o Background. Os mosaicos utilizadosforam capturados a uma resolução de 1.1 𝑝𝑖𝑥𝑒𝑖𝑠/𝑚𝑚2.
O segundo dataset chamado Marker, foi capturado nas Bahamas. Foi feita a divisãoem quatro classes para classificação. General Corals, Sea Gorgons, Sand e Background.
Os mosaicos utilizados foram capturado em uma resolução de 2.2 𝑝𝑖𝑥𝑒𝑖𝑠/𝑚𝑚2.
6.2 Descrição do Geral do SistemaNesta seção é descrito uma versão geral do sistema, tanto para a classificação emnível unário, quanto os tipos de classificação integrando contexto.
84Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática6.2.1 Pré-ProcessamentoTanto para os dados do dataset Redsea quanto para o caso do dataset Marker , aqualidade visual da imagem é bastante satisfatória, contendo baixa presença de degrada-ção devido a turbidez. O principal tipo de degradação encontrado é a variação de cor aolongo do datasets existentes durante a captura. Para resolver esta questão foi utilizadoCLAHE (ZUIDERVELD, 1994) e uma normalização de cor em ambos os datasets.
6.2.2 Segmentação e DescriçãoOs datasets foram segmentados como superpixeis baseados em TurboPixels (LE-VINSHTEIN et al., 2009). O tamanho do pixel foi escolhido como que para caber em umajanela de tamanho de aproximadamente 32x32 pixeis.
Para cada superpixel, a combinação entre três descritores de textura foi utilizada.
Filtros de Gabor, CLBP e GLCM. Um kernel mapping é feito depois para tornar osdescritores mais linearmente separáveis. O resultado é também por fim, normalizado.
6.2.3 ClassificaçãoNo caso, para todos os testes, foi utilizado um SVM configurado com um kernellinear.
6.2.4
Adição de ContextoA adição de contexto é apresentada feita de duas formas distintas: utilizando osConditional Random Fields (CRF) e utilizando o modelo de Geoestatística, o quais foramexplicados nos Capítulos 2 e 3.
Para o CRF utilizado o algoritmo de Loopy Belief Propagation(LBP) para realizara inferência estatística, dado a sua baixa taxa de erros e alta performance (WEISS, 2000).
6.3 TreinamentoAqui é descrito como foi realizado o treinamento das partes do sistema onde otreinamento é necessário.
6.3.1 Treinamento do ClassificadorO treinamento unário diz respeito ao treinamento da função de discriminação doclassificador.
856.3. TreinamentoTanto para o dataset Redsea quanto para o Marker foram feitas diversas amostra-gens dos mosaicos existentes para o treinamento do classificador de cada uma das classes.
A Figura 26, mostra exemplos de segmentos usados para o treinamento do classificadorpara os dois datasets utilizados. Foram feitas amostras de por volta de 200 segmentospara cada classe sendo cada uma tendo 64x64 pixeis. As amostras foram indicadas porespecialistas da universidade de Miami.
Figura 26 – Partes manualmente segmentadas utilizadas para treinamento do classifica-dor. A esquerda são mostrados exemplos de nove amostras usadas para treinar o datasetRedsea. A direita são apresentadas nove amostras do dataset Marker.
6.3.2 Treinamento UnárioPara gerar a curva de confiança, usada para gerar os distribuição de probabilida-des unária tanto para o CRF, quanto para o modelo de Geoestátistica, foram tambémutilizadas amostras do mosaico de treinamento da Figura 26.
As Figuras 27 e 28 mostram as curvas de confiança obtidas para cada um dosdois datasets em cada uma das classes. O processo de geração das curvas é descrito noCapítulo 3 Seção 3.2.
Pelos gráficos das Figuras 27 e 28 percebe-se que determinadas classes se adaptammelhor que outras a uma curva de confiança, como a classe Sea Gorgon ( Fig. 28c) dodataset Marker. Para esta classe é possível saber quais distâncias do classificador queexiste uma grande probabilidade de se acertar a classe, enquanto para outras o modelonão se adaptou tão adequadamente (Fig. 29b).
Entretanto, o principal erro em adaptação da curva se da na classe Backgroundpara os dois casos (Fig. 27a e Fig. 29a). Isso se da devido a alta variabilidade intra-classeinerente a classe Background, a qual contém todos os tipos de objetos que não são deinteresse para classificação.
86Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática(a) Classe Background(b) Classe Urchin(c) Classe Branching Coral(d) Classe Brain Coral(e) Classe Faviid CoralFigura 27 – Curvas de confiança geradas no treinamento unário de cada classe para odataset Redsea. A curva de confiança 𝐶𝑙𝑖 treinada para cada uma das classes é mostrada,se bem como o grau de confiança obtido.
6.3.3 Treinamento Potenciais LocaisPara treinamento dos potenciais locais foi utilizado cada dataset na sua totalidade.
Para o caso do CRF foi utilizado o algoritmo de treinamento descrito no Capítulo2, Seção 2.2.2.2 .
As Tabelas 2 e 3 mostram a matriz de covariância obtida para cada um dos doisdatasets. Tal matriz está relacionada a uma indicação de determinada classe estar próximaa outra.
Background Urchin Branching Coral Brain Coral Faviid CoralClassesBackgroundUrchinBranching CoralBrain CoralFaviid CoralTabela 2 – Matriz de covariância que mostra as relações de proximidade entre as classes.
Tais medidas são fatores que indicam correlação e não distribuições de probabilidade. Esteresultado é normalizado ao final.
1.91150.78440.76580.87670.76120.85990.96790.98970.96050.94270.85590.94581.38700.94610.91110.90940.96701.02191.63840.93530.84001.04240.97450.89721.6972Os resultados do treinamento dos vetores de transição, necessários para a simulação876.3. Treinamento(a) Classe Background(b) Classe General Corals(c) Classe Sea Gorgon(d) Classe SandFigura 28 – Curvas de confiança geradas no treinamento unário de cada classe para o da-taset Marker. A curva de confiança 𝐶𝑙𝑖 treinada para cada uma das classes é apresentada,bem como o grau de confiança obtido.
Background General CoralSea Gorgon Sand0.90860.90280.89301.8773ClassesBackgroundGeneral CoralSea GorgonSand1.88310.90100.89050.89500.89670.95440.95160.89900.88990.95070.97380.8906Tabela 3 – Matriz de covariância que mostra as relações de proximidade entre as classes.
Tais medidas são fatores que indicam correlação e não distribuições de probabilidade. Esteresultado é normalizado ao final.
do método de Geoestatística, são mostrados na Figura 29 para ambos os datasets testados.
Para ambos os datasets analisados se observa a classe background como sendopredominante nas estatísticas medidas em ambos os treinamentos. No caso do treinamentodos vetores de transição (Geoestatística), também foi vista uma tendência de outras classesem transitar para o Background (Fig. 29). Algo que, para o treinamento dos potenciaislocais do CRF, indicou principalmente uma tendência do Background ter proximidadeconsigo próprio.
Para o dataset Redsea, nas relações locais treinadas pelo CRF se observa algumastendências:88Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática(a) Dataset Redsea(b) Dataset MarkerFigura 29 – Vetores de transição obtidos na etapa de treinamento para o método deGeoestatística do Capítulo 3. Os vetores indicam a probabilidade de uma classe transitarpara outra a uma determinada distância. O eixo x apresenta a distância em pixeis. O eixo𝑦 dos gráficos apresenta as probabilidades de transição. Pode-se observar, por exemplo,uma certa tendência na classe Urchin em transitar para categoria de background.
896.4.
Sistemas Testados∙ As classes Urchin tem uma grande possibilidade de estar próxima a classe FaviidCoral;∙ Cada classe tem uma forte tendência de estar próxima a si própria, o que enfatizaa pouca variabilidade de classes em espaços pequenos;∙ Existe algumas tendências assimétricas treinadas, como a grande tendência da classeFaviid Coral estar próxima da classe Urchin, mas não ao contrário.
As transições assimétricas, ou seja, uma dada classe A estar próxima a classe Bmas não B próxima da A, não são incentivadas pelos potenciais treinados pelo método deGeoestatística.
Considerando as relações treinadas pelo método de Geoestatística, existe umatendência forte principalmente de transição da classe Urchin para a classe Faviid Coral ea classe Background.
Para o dataset Marker, nenhuma outra tendência de proximidade foi obtida parao CRF, fora a tendência de background estar próximo de si mesmo. As mesmas tendênciassão observadas para o treinamento dos vetores de transição para o caso da Geoestatística.
6.4
Sistemas TestadosQuatro sistemas são testados quanto a sua taxa de acerto em relação a classificaçãode mosaicos de imagens. Isso foi feito principalmente de forma a avaliar a consideraçãode contexto, juntamente com a nova proposta apresentada no Capítulo 3Inicialmente foi avaliado o sistema Unário, proposto por Shihavuddin et al. (2013)onde somente as informações unárias são consideradas, ou seja, dada a definição de classifi-cação considerando uma segmentação em regiões (SHIHAVUDDIN et al., 2013). Somentea descrição da própria região foi usada para classificação, o sistema é detalhado no Cap.
4 .
Após foi testado e analisado o sistema Unário porém baseado em distribuição deprobabilidades. Em tal sistema foi feita a classificação apenas considerando a parcela uná-ria do sistema com base no modelo em Geoestatística proposto no Cap. 3. A classificaçãode um segmento foi escolhida como o rótulo com máxima a probabilidade.
Apresenta-se também o sistema, GS, baseado em Geoestatística proposto no Cap.
3. A classificação de cada segmento (Superpixel) é dada pela Eq. 3.1, do Cap. 3.
Por fim, apresenta-se os resultados do sistema CRF o qual é uma implementaçãodos Conditional Random Fields , tal qual explicada no Cap 2.
90Capítulo 6. Testes e Resultados 2: Contexto em Classificação SubaquáticaTodos os sistemas foram implementados em Matlab, para o CRF, foi utilizada abiblioteca UGM para inferência estatística (SCHMIDT et al., 2009).
6.5 Computação do Mapa TemáticoNo dataset Redsea, um mosaico de 3256x2939 pixeis foi utilizado para testes. Já
para dataset Marker,foi utilizado um mosaico de 2592x3963.
As Figuras 30 e 31 mostram os mapas temáticos completos computados para ambosos datasets.
Observa-se que num caso geral o CRF é o método que obtém os melhores resulta-dos. O método de Geoestatística é capaz de melhorar um pouco, porém depende muitode um bom treinamento da distribuição de probabilidades de cada segmento.
Para o caso do dataset Marker, a adição de contexto foi mais eficaz para ambos oscasos. Isso ocorre dado que muitas posições geraram resultados com distribuição unáriauniforme, ou seja sem uma classe com alta probabilidade. O que contribuiu para adiçãode contexto foi, que tais regiões, estavam cercadas por locais onde existia uma classepredominante.
Ao se observar a configuração do dataset Redsea se percebe uma tendência espacialem se ter "ilhas"de classes envolvidas pela classe background. Dado que a classe backgroundtem uma alta variabilidade intra-classe, é bastante complicado se ter uma tendência fortepara uma classe na distribuição unária. Isso dificulta a proliferação da informação decontexto na região.
De forma a analisar melhor as diferenças entre o CRF e o método de Geoestatística,é mostrado na Figura 32 duas áreas diferentes do mosaico do Redsea para mostrar algumasvantagens da abordagem com base em GS. É apresentada a área original da imagem coma classificação mostrada em cores. Na primeira linha, pode se perceber o grau de acertomaior para o CRF (Fig. 32c). O CRF tende a melhorar significativamente a suavizaçãolocal das estruturas classificadas. Ou seja, impõe que áreas pequenas devam ter menosvariações de classes. Por esta razão o CRF teve uma boa classificação especialmente parao caso da classe representada em azul (Faviid Corals).
Por outro lado, na segunda linha, GS (Fig. 32f) obteve um grau de acerto maior.
Dado que o CRF (Fig. 32g) impõe mais suavidade local, isso tende a eliminar classesmenores (Fig. 32g). Este caso é evitado pela GS pelo fato de que a abordagem baseadaem Geostatística usa estatísticas medidas em longas distâncias e assim o tamanho daclasse é considerado. Na terceira linha da Figura 32, são mostrados resultados similarespara o dataset Marker.
Também os algoritmos foram testados para múltiplos segmentos diferentes extraído916.6. ConclusõesTamanho do Segmento170011005002300 Média81.1% 78.0% 79% 80.2% 79.7%
81.2% 78.3% 79% 80.2% 79.8%
80.5% 78.9% 79.3% 79.7% 79.8%
78%78% 78.4% 80.2% 79.2%
UnitaryGSCRFVotingTabela 4 – Resultados para a taxa de acerto de diferentes segmentos para o dataset Redsea.
Foram testados diversos segmentos quadrados amostrados aleatoreamente nos mosaicos.
O tamanho do segmento é especificado pelo lado do quadradodos mosaicos. Foram recortadas amostras quadradas aleatórias de diferentes tamanhos.
Para cada tamanho recortado, a tabela 4 mostra a taxa de acerto média do métodoaplicado em 20 segmentos aleatórios. Também foi testado um método simples de votaçãoonde um superpixel é modificado caso a classe de todos os vizinhos seja differente.
No dataset Redsea, para todas as abordagens , não foi percebido mais do que ganhosmarginais quando comparados com a versão unitária. O método de votação tambémobteve resultados similares.
6.6 ConclusõesConclui-se que o uso de estatísticas mais ricas, inspiradas pelos conceitos de Geo-estatísticas, é benéfico e pode conduzir a melhores resultados que o CRF tradicional emalguns casos.
As melhorias obtidas, foram, no entanto, de pequena magnitude, o que esta ali-nhado com o que é discutido em (LUCCHI et al., 2011). Os resultados utilizando contextonormalmente não melhoram mais do que a suavidade local dos resultados, ou seja, nãomais do que evitam grande variação de classes em uma pequena área. Porém ainda épossível obter melhorias significativas, para alguns datasets como no caso do Marker.
92Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática(a) Unitário 76.83%
(b) Unitário com Curvas de Confiança 75.779%(c) Geoestatística 76.16%
(d) CRF 77.32%
(e) Ground TruthFigura 30 – Mapa temático dos Mosaicos para o dataset Redsea. As figuras mostram aporcentagem de acerto relativa ao GroundTruth. As classes são representadas pelas se-guintes cores: Verde Brain Coral; Amarelo Branchin Coral; Azul Faviid Coral; MagentaUrchin e sem cor é o background. Os seguintes resultados são mostrados.(30a) classifica-ção Unária. (30b) mostra a classificação Unária baseada nas curvas de confiança. (30c)classificação com adição de contexto baseada em Geoestatística. (30d) classificação comadição de contexto utilizando CRF.
936.6. Conclusões(a) Unitário 78.04%
(b) Unitário com Curvas de Confiança 78.02%
(c) Geoestatística 79.2%
(d) CRF 83.26%
(e) Ground TruthFigura 31 – Mapa temático dos Mosaicos para o dataset Marker. As figuras mostram aporcentagem de acerto relativa ao GroundTruth. As classes são representadas pelas se-guintes cores: Verde Sand; Amarelo Sea Gorgon; Azul Corals e sem cor é o background.
Os seguintes resultados são mostrados.(31a) classificação Unária. (31b) mostra a classifi-cação Unária baseada nas curvas de confiança. (31c) classificação com adição de contextobaseada em Geoestatística. (31d) classificação com adição de contexto utilizando CRF.
94Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática(a) 0.6985(b) 0.6988(c) 0.745
(d) Ground Truth(e) 0.859
(f) 0.8691(g) 0.858
(h) Ground Truth(i) 0.756
(j) 0.77
(k) 0.763
(l) Ground TruthFigura 32 – Resultados de classificação para os datasets Marker e os datasets Redsea. A
primeira coluna apresenta a classificação unitária. A segunda coluna apresenta os resulta-dos de Geoestatística. A terceira coluna apresenta os resultados para o CRF. Por fim, aultima coluna apresenta o GroundTruth. Foi utilizada como peso para o potencial local 𝑤𝑙como sendo 0.4 para ambas as abordagens. Na primeira coluna foi possível perceber umresultado melhor para o CRF devido a uma maior suavização local. Na segunda linha, ométodo de Geoestatística obteve melhores resultados devido a suas medidas estatísticasde longa distância. Na última linha é mostrado os resultados para o dataset Marker, ondeambas as abordagens tiveram melhores resultados para esse caso.
957 Conclusões FinaisConsiderando o problema de estender a utilização de métodos de visão computaci-onal para o cenário subaquático, esta dissertação apresentou o estudo e tratamento paraalguns dos principais problemas existentes no meio.
Foi feito um estudo sobre duas áreas distintas relevantes para o problema: A detec-ção de pontos de interesse e o uso da informação de contexto na classificação de imagens.
Nas seções que seguem serão apresentadas as contribuições sobre as duas áreasdistintas analisadas, como também as limitações das propostas.
7.1 Detectores de Pontos de Interesse em Imagens SubaquáticasTurvasNo contexto subaquático, foi feito um estudo sobre como se comportam os múlti-plos detectores de pontos de interesse sobre a presença da turbidez, fenômeno o qual sefaz presente no meio subaquático.
7.1.1 Contribuições ObtidasAs principais contribuições obtidas foram:∙ A proposta de um dataset novo contendo imagens reais do assoalho oceânico porémcom a turbidez controlada.
∙ Uma análise geral da repetibilidade dos detectores em meios túrbidos, dividindo aanálise em intervalos de turbidez distintos.
∙ Dentre os detectores estudados, foi apontado o DoG como o mais robusto detectorpara ambientes com presença de turbidez. Tal detector contém também invariânciaa escala.
∙ Foi concluída a possibilidade do uso de espaços não gaussianos para geração deespaço de escala em meios subaquáticos túrbidos.
7.1.2 Limitações e Trabalhos FuturosO estudo não foi capaz de propor um método para medir de fato a degradaçãocausada pela turbidez. A medida utilizada é capaz de verificar a degradação estrutural oque não necessariamente está associada a turbidez.
96Capítulo 7. Conclusões FinaisUm outro ponto a ser tratado diz respeito a uma análise mais criteriosa comrespeito a invariância a outras transformações como rotação ou escala, juntamente com arobustez à degradação causada pela turbidez.
7.2 Adição de Contexto Baseado em GeoestatísticaFoi proposto um novo método para adicionar informação espacial na classificaçãode imagens. O método se baseou nos estudos da área de Geoestatística. Tal método foiaplicado em imagens de mosaicos de recifes de corais. O mesmo foi comparado com asversões sem a utilização de contexto e com o modelo dos Conditional Random Fields(CRF).
Apresentou-se que a adição de contexto pode, em alguns casos, ser benéfica paraa classificação de imagens subaquáticas. Obtendo-se um ganho de até 5% a mais em taxade acerto.
7.2.1 Contribuições ObtidasO trabalho apresentou um novo método para adição de contexto em imagens su-baquáticas. O uso de medidas estatísticas mais ricas, como as baseadas em Geoestatística,mostrou-se útil em algumas situações para adição de informação de contexto.
Também essa dissertação serve como uma conexão entre duas áreas distintas: aGeoestatística e os Modelos Probabilístico Gráficos (MPGs). Acredita-se que através destaintersecção, as aplicações que fazem uso de Geoestatística podem também se beneficiardos MPGs.
7.2.2 Limitações e Trabalhos FuturosColoca-se que a abordagem apresentada foi aplicada para um cenário subaquáticoespecífico. Uma direção seria a aplicação em dataset com classes mais genéricas, os daPascal Visual Object Classes Challenge (VOC) (EVERINGHAM et al., 2010).
Os resultados para o método de Geoestatística foram satisfatórios porém ficaramabaixo em taxa de acerto quando comparados ao CRF. Apesar da tendência de se usar osmétodos de Geoestatística para casos onde há pouca quantidade de informações (CARLE;FOGG, 1996).
Existe ainda uma necessidade maior de alteração no modelo original de Geoesta-tística visando uma melhor adaptação para o caso de imagens subaquáticas.
97ReferênciasABFALG, J. et al. Multi-represented classification based on confidence estimation. In:Advances in Knowledge Discovery and Data Mining. [S.l.]: Springer, 2007. p. 23–34.
Citado 2 vezes nas páginas 51 e 52.
AGRAWAL, M.; KONOLIGE, K.; BLAS, M. R. Censure: Center surround extremasfor realtime feature detection and matching. In: Computer Vision–ECCV 2008. [S.l.]:
Springer, 2008. p. 102–115. Citado 4 vezes nas páginas 14, 35, 77 e 81.
AGTERBERG, F. Mathematical geologymathematical geology. In: General Geology.
Springer US, 1988, (Encyclopedia of Earth Science). p. 573–582. ISBN 978-0-442-22499-8.
Disponível em: <http://dx.doi.org/10.1007/0-387-30844-X 76>. Citado na página 55.
ALCANTARILLA, P. F.; BARTOLI, A.; DAVISON, A. J. Kaze features. In: ComputerVision–ECCV 2012. [S.l.]: Springer, 2012. p. 214–227. Citado 5 vezes nas páginas 35,36, 77, 80 e 82.
AULINAS, J. et al. Feature extraction for underwater visual slam. In: IEEE. OCEANS,2011 IEEE-Spain. [S.l.], 2011. p. 1–7. Citado na página 24.
BAR, M. Visual objects in context. Nature Reviews Neuroscience, Nature PublishingGroup, v. 5, n. 8, p. 617–629, 2004. Citado 2 vezes nas páginas 25 e 41.
BAY, H. et al. Speeded-up robust features (surf). Computer vision and imageunderstanding, Elsevier, v. 110, n. 3, p. 346–359, 2008. Citado 2 vezes nas páginas 33e 77.
BAZEILLE, S. et al. Automatic underwater image pre-processing. In: CMM’06. [S.l.:
s.n.], 2006. p. xx. Citado na página 66.
BEALL, C. et al. 3d reconstruction of underwater structures. In: IEEE/RSJ InternationalConference on Intelligent Robots and Systems (IROS). [S.l.: s.n.], 2010. p. 4418–4423.
Citado 2 vezes nas páginas 24 e 27.
BEATTIE, C.; MILLS, B.; MAYO, V. Development drilling of the tawila field, yemen,based on three-dimensional reservoir modeling and simulation. In: SPE annual technicalconference. [S.l.: s.n.], 1998. p. 715–725. Citado na página 49.
BEAUDET, P. R. Rotationally invariant image operators. In: Proceedings of the 4thInternational Joint Conference on Pattern Recognition. Kyoto, Japan: [s.n.], 1978. p.
579–583. Citado 4 vezes nas páginas 30, 71, 77 e 81.
BEIJBOM, O. et al. Automated annotation of coral reef survey images. In: IEEE.
Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. [S.l.],
2012. p. 1170–1177. Citado na página 67.
BIEDERMAN, I.; MEZZANOTTE, R. J.; RABINOWITZ, J. C. Scene perception:Detecting and judging objects undergoing relational violations. Cognitive psychology,Elsevier, v. 14, n. 2, p. 143–177, 1982. Citado na página 39.
98ReferênciasBOIX, X. et al. Harmony potentials. International journal of computer vision, Springer,v. 96, n. 1, p. 83–102, 2012. Citado 2 vezes nas páginas 46 e 47.
BOYKOV, Y. Y.; JOLLY, M.-P. Interactive graph cuts for optimal boundary & regionsegmentation of objects in nd images. In: IEEE. Computer Vision, 2001. ICCV 2001.
Proceedings. Eighth IEEE International Conference on. [S.l.], 2001. v. 1, p. 105–112.
Citado na página 45.
CARBONETTO, P.; FREITAS, N. de; BARNARD, K. A statistical model for generalcontextual object recognition. In: Computer Vision-ECCV 2004. [S.l.]: Springer, 2004. p.
350–362. Citado 2 vezes nas páginas 43 e 45.
CARLE, S. F.; FOGG, G. E. Transition probability-based indicator geostatistics.
Mathematical Geology, Springer, v. 28, n. 4, p. 453–476, 1996. Citado 4 vezes naspáginas 49, 56, 57 e 96.
CARLE, S. F. et al. Conditional simulation of hydrofacies architecture: a transitionprobability/markov approach. Hydrogeologic models of sedimentary aquifers, conceptsin hydrogeology and environmental geology, v. 1, p. 147–170, 1998. Citado 2 vezes naspáginas 53 e 55.
CORKE, P. et al. Experiments with underwater robot localization and tracking. In:Robotics and Automation, 2007 IEEE International Conference on. [S.l.: s.n.], 2007. p.
4556–4561. ISSN 1050-4729. Citado na página 27.
CRISTIANINI, N.; SHAWE-TAYLOR, J. An introduction to support vector machinesand other kernel-based learning methods. [S.l.]: Cambridge university press, 2000. Citadona página 51.
CRISTINACCE, D.; COOTES, T. F. Feature detection and tracking with constrainedlocal models. In: CITESEER. BMVC. [S.l.], 2006. v. 2, n. 5, p. 6. Citado na página 78.
DEMPSTER, A. P.; LAIRD, N. M.; RUBIN, D. B. Maximum likelihood fromincomplete data via the em algorithm. Journal of the royal statistical society. Series B(methodological), JSTOR, p. 1–38, 1977. Citado na página 45.
DERPANIS, K. G.; LEUNG, E. T.; SIZINTSEV, M. Fast scale-space featurerepresentations by generalized integral images. In: IEEE. Image Processing, 2007. ICIP2007. IEEE International Conference on. [S.l.], 2007. v. 4, p. IV–521. Citado na página33.
DUNTLEY, S. Q. Light in the sea. JOSA, Optical Society of America, v. 53, n. 2, p.
214–233, 1963. Citado 2 vezes nas páginas 65 e 73.
EMERY, X. Properties and limitations of sequential indicator simulation. StochasticEnvironmental Research and Risk Assessment, Springer, v. 18, n. 6, p. 414–424, 2004.
Citado na página 54.
EVERINGHAM, M. et al. The pascal visual object classes (voc) challenge. Internationaljournal of computer vision, Springer, v. 88, n. 2, p. 303–338, 2010. Citado na página 96.
FINK, M.; PERONA, P. Mutual boosting for contextual inference. In: Advances inneural information processing systems. [S.l.: s.n.], 2003. p. None. Citado na página 42.
99ReferênciasFISCHLER, M. A.; ELSCHLAGER, R. A. The representation and matching of pictorialstructures. IEEE Transactions on Computers, Citeseer, v. 22, n. 1, p. 67–92, 1973.
Citado na página 40.
FULKERSON, B.; VEDALDI, A.; SOATTO, S. Class segmentation and objectlocalization with superpixel neighborhoods. In: IEEE. Computer Vision, 2009 IEEE 12thInternational Conference on. [S.l.], 2009. p. 670–677. Citado 4 vezes nas páginas 41, 44,45 e 68.
GALLEGUILLOS, C.; BELONGIE, S. Context based object categorization: A criticalsurvey. Computer Vision and Image Understanding, Elsevier, v. 114, n. 6, p. 712–722,2010. Citado 3 vezes nas páginas 39, 40 e 41.
GARCIA, R.; GRACIAS, N. Detection of interest points in turbid underwater images.
In: IEEE. OCEANS, 2011 IEEE-Spain. [S.l.], 2011. p. 1–9. Citado 6 vezes nas páginas24, 71, 74, 76, 77 e 78.
GIL, A. et al. A comparative evaluation of interest point detectors and local descriptorsfor visual slam. Machine Vision and Applications, Springer, v. 21, n. 6, p. 905–920, 2010.
Citado 2 vezes nas páginas 27 e 78.
GONZALEZ, R. C.; WOODS, R. E. Digital Image Processing (3rd Edition). UpperSaddle River, NJ, USA: Prentice-Hall, Inc., 2006. ISBN 013168728X. Citado na página67.
GUO, Z.; ZHANG, D. A completed modeling of local binary pattern operator for textureclassification. Image Processing, IEEE Transactions on, IEEE, v. 19, n. 6, p. 1657–1663,2010. Citado na página 69.
HANSON, A. R.; RISEMAN, E. M. VISIONS: A computer system for interpretingscenes. In: HANSON, A. R.; RISEMAN, E. M. (Ed.). Computer Vision Systems. NewYork: Academic Press, 1978. Citado na página 40.
HARALICK, R. M.; SHANMUGAM, K.; DINSTEIN, I. H. Textural features for imageclassification. Systems, Man and Cybernetics, IEEE Transactions on, IEEE, n. 6, p.
610–621, 1973. Citado na página 69.
HARRIS, C.; STEPHENS, M. A combined corner and edge detector. In: MANCHESTER,UK. Alvey vision conference. [S.l.], 1988. v. 15, p. 50. Citado 5 vezes nas páginas 29, 30,71, 77 e 81.
JOHNSON-ROBERSON, M.; KUMAR, S.; WILLAMS, S. Segmentation andclassification of coral for oceanographic surveys: a semi-supervised machine learningapproach. In: IEEE. OCEANS 2006-Asia Pacific. [S.l.], 2007. p. 1–6. Citado na página66.
KOLTUN; VLADLEN. Efficient inference in fully connected crfs with gaussian edgepotentials. In: . [S.l.: s.n.], 2011. Citado 2 vezes nas páginas 46 e 60.
KOSCHMIEDER, H. Theorie der horizontalen Sichtweite. [S.l.]: Keim Nemnich, 1924.
Citado na página 64.
KRUPPA, H.; SCHIELE, B. Using Local Context to Improve Face Detection. 2003.
Citado na página 42.
100ReferênciasKUMAR, S.; HEBERT, M. A hierarchical field framework for unified context-basedclassification. In: IEEE. Computer Vision, 2005. ICCV 2005. Tenth IEEE InternationalConference on. [S.l.], 2005. v. 2, p. 1284–1291. Citado na página 40.
LEVINSHTEIN, A. et al. Turbopixels: Fast superpixels using geometric flows. PatternAnalysis and Machine Intelligence, IEEE Transactions on, IEEE, v. 31, n. 12, p.
2290–2297, 2009. Citado 3 vezes nas páginas 49, 69 e 84.
LINDEBERG, T. Scale-space theory: A basic tool for analyzing structures at differentscales. Journal of applied statistics, Taylor & Francis, v. 21, p. 225–270, 1994. Citado 2vezes nas páginas 31 e 32.
LINDEBERG, T. On the axiomatic foundations of linear scale-space. [S.l.]: Springer,1997. Citado na página 32.
LINDEBERG, T. Feature detection with automatic scale selection. International journalof computer vision, Springer, v. 30, n. 2, p. 79–116, 1998. Citado na página 32.
LINDEBERG, T.; EKLUNDH, J.-O. On the computation of a scale-space primal sketch.
Journal of Visual Communication and Image Representation, v. 2, n. 1, p. 55 – 78, 1991.
ISSN 1047-3203. Citado na página 29.
LOWE, D. G. Distinctive image features from scale-invariant keypoints. Internationaljournal of computer vision, Springer, v. 60, n. 2, p. 91–110, 2004. Citado 8 vezes naspáginas 11, 33, 34, 45, 72, 77, 80 e 82.
LUCCHI, A. et al. Are spatial and global constraints really necessary for segmentation?
In: IEEE. Computer Vision (ICCV), 2011 IEEE International Conference on. [S.l.],
2011. p. 9–16. Citado 3 vezes nas páginas 47, 49 e 91.
MARCOS, M. S. A.; SORIANO, M.; SALOMA, C. Classification of coral reef imagesfrom underwater video using neural networks. Optics express, Optical Society of America,v. 13, n. 22, p. 8766–8771, 2005. Citado na página 67.
MARQUARDT, D. W. An algorithm for least-squares estimation of nonlinearparameters. Journal of the Society for Industrial & Applied Mathematics, SIAM, v. 11,n. 2, p. 431–441, 1963. Citado na página 52.
MIKOLAJCZYK, K.; SCHMID, C. Scale & affine invariant interest point detectors.
International journal of computer vision, Springer, v. 60, n. 1, p. 63–86, 2004. Citado 2vezes nas páginas 32 e 71.
NARASIMHAN, S. G. et al. Acquiring scattering properties of participating media bydilution. ACM Transactions on Graphics (TOG), ACM, v. 25, n. 3, p. 1003–1012, 2006.
Citado na página 73.
NEMETH, R. S. et al. Characterization of deep water reef communities within themarine conservation district, st. thomas, us virgin islands. 2008. Citado na página 23.
NICOSEVICI, T. et al. Efficient three-dimensional scene modeling and mosaicing.
Journal of Field Robotics, v. 26, 2009. Citado 2 vezes nas páginas 24 e 27.
101ReferênciasOMAR, A. F. B.; MATJAFRI, M. Z. B. Turbidimeter design and analysis: a review onoptical fiber sensors for the measurement of water turbidity. Sensors, Molecular DiversityPreservation International, v. 9, n. 10, p. 8311–8335, 2009. Citado na página 65.
PADMAVATHI, G.; MUTHUKUMAR, M.; THAKUR, S. K. Kernel principal componentanalysis feature detection and classification for underwater images. In: IEEE. Imageand Signal Processing (CISP), 2010 3rd International Congress on. [S.l.], 2010. v. 2, p.
983–988. Citado 2 vezes nas páginas 24 e 27.
PERONA, P.; MALIK, J. Scale-space and edge detection using anisotropic diffusion.
Pattern Analysis and Machine Intelligence, IEEE Transactions on, IEEE, v. 12, n. 7, p.
629–639, 1990. Citado na página 36.
PETROU, M.; GARCÍA-SEVILLA, P. Image processing - dealing with texture. [S.l.]:
Wiley, 2006. ISBN 978-0-470-02628-1. Citado na página 69.
PIZARRO, O.; EUSTICE, R.; SINGH, H. Large area 3d reconstructions from underwatersurveys. In: OCEANS ’04. MTTS/IEEE TECHNO-OCEAN ’04. [S.l.: s.n.], 2004. v. 2,
p. 678–687 Vol.2. Citado 2 vezes nas páginas 66 e 67.
PIZARRO, O. et al. Towards image-based marine habitat classification. In: IEEE.
OCEANS 2008. [S.l.], 2008. p. 1–7. Citado na página 66.
PLATT, J. C. Probabilistic outputs for support vector machines and comparisons toregularized likelihood methods. In: CITESEER. Advances in large margin classifiers.
[S.l.], 1999. Citado na página 52.
PORTER, R.; CANAGARAJAH, N. Robust rotation-invariant texture classification:wavelet, gabor filter and gmrf based schemes. In: IET. Vision, Image and SignalProcessing, IEE Proceedings-. [S.l.], 1997. v. 144, n. 3, p. 180–188. Citado na página 69.
PURKIS, S.; VLASWINKEL, B.; GRACIAS, N. Vertical-to-lateral transitions amongcretaceous carbonate facies: A means to 3-d framework construction via markov analysis.
Journal of Sedimentary Research, SEPM, v. 82, n. 4, p. 232–243, 2012. Citado napágina 49.
RABINOVICH, A. et al. Objects in context. In: Proceedings of the InternationalConference on Computer Vision (ICCV). [S.l.: s.n.], 2007. Citado na página 40.
SCHETTINI, R.; CORCHS, S. Underwater image processing: state of the art ofrestoration and image enhancement methods. EURASIP Journal on Advances in SignalProcessing, Hindawi Publishing Corp., v. 2010, p. 14, 2010. Citado na página 67.
SCHMID, C.; MOHR, R.; BAUCKHAGE, C. Evaluation of interest point detectors.
International Journal of computer vision, Springer, v. 37, 2000. Citado 2 vezes naspáginas 30 e 77.
SCHMIDT, M. W. et al. Optimizing costly functions with simple constraints: Alimited-memory projected quasi-newton algorithm. In: International Conference onArtificial Intelligence and Statistics. [S.l.: s.n.], 2009. p. None. Citado na página 90.
102ReferênciasSHIHAVUDDIN, A. et al. Image-based coral reef classification and thematic mapping.
Remote Sensing, v. 5, n. 4, p. 1809–1841, 2013. ISSN 2072-4292. Disponível em:<http://www.mdpi.com/2072-4292/5/4/1809>. Citado 7 vezes nas páginas 25, 66, 67,68, 69, 70 e 89.
SHOTTON, J. et al. Textonboost for image understanding: Multi-class object recognitionand segmentation by jointly modeling texture, layout, and context. International Journalof Computer Vision, Springer, v. 81, n. 1, p. 2–23, 2009. Citado 2 vezes nas páginas 44e 45.
SIVIC, J.; ZISSERMAN, A. Video google: Efficient visual search of videos. In: TowardCategory-Level Object Recognition. [S.l.]: Springer, 2006. p. 127–144. Citado na página45.
SOJKA, E. A new approach to detecting the corners in digital images. In: IEEE. ImageProcessing, 2003. ICIP 2003. Proceedings. 2003 International Conference on. [S.l.], 2003.
v. 3, p. III–445. Citado 2 vezes nas páginas 11 e 31.
STOKES, M. D.; DEANE, G. B. Automated processing of coral reef benthic images.
Limnol. Oceanogr.: Methods, v. 7, n. 157, p. 157–168, 2009. Citado 2 vezes nas páginas67 e 70.
SUTTON, C.; MCCALLUM, A. An introduction to conditional random fields forrelational learning. Introduction to statistical relational learning, MIT press, p. 93–128,2006. Citado 2 vezes nas páginas 42 e 43.
TORRALBA, A. Contextual priming for object detection. International journal ofcomputer vision, Springer, v. 53, n. 2, p. 169–191, 2003. Citado na página 40.
TORRALBA, A.; MURPHY, K. P.; FREEMAN, W. T. Contextual models for objectdetection using boosted random fields. In: Advances in neural information processingsystems. [S.l.: s.n.], 2004. p. 1401–1408. Citado 2 vezes nas páginas 40 e 41.
TREIBITZ, T.; SCHECHNER, Y. Y. Instant 3descatter. In: Proceedings of the 2006IEEE Computer Society Conference on Computer Vision and Pattern Recognition -Volume 2. [S.l.: s.n.], 2006. (CVPR ’06), p. 1861–1868. Citado 2 vezes nas páginas 64e 73.
TUYTELAARS, T.; MIKOLAJCZYK, K. Local invariant feature detectors: a survey.
Foundations and Trends R○ in Computer Graphics and Vision, Now Publishers Inc., v. 3,
n. 3, p. 177–280, 2008. Citado 4 vezes nas páginas 27, 28, 30 e 77.
WANG, Z. et al. Image quality assessment: From error visibility to structural similarity.
Image Processing, IEEE Transactions on, IEEE, v. 13, n. 4, p. 600–612, 2004. Citado 2vezes nas páginas 76 e 78.
WEICKERT, J.; ROMENY, B. T. H.; VIERGEVER, M. A. Efficient and reliableschemes for nonlinear diffusion filtering. Image Processing, IEEE Transactions on, IEEE,v. 7, n. 3, p. 398–410, 1998. Citado na página 36.
WEIJER, J. V. D.; SCHMID, C. Coloring local feature extraction. In: ComputerVision–ECCV 2006. [S.l.]: Springer, 2006. p. 334–348. Citado na página 69.
Felipe Codevilla MoraesVisão computacional em meio subaquático:Um estudo sobre detecção de pontos de interessee classificação utilizando contexto.
Universidade Federal de Rio GrandePrograma de Pós graduação em ComputaçãoMestrado em Engenharia de ComputaçãoOrientador: Nelson Duarte Lopez FilhoCoorientador: Silvia Silva da Costa BotelhoBrasil5 de março, 2015Um estudo sobre detecção de pontos de interessee classificação utilizando contexto./ Felipe Codevilla Moraes. – Brasil, 5 de março,2015-Orientador: Nelson Duarte Lopez FilhoFelipe Codevilla MoraesVisão computacional em meio subaquático:Dissertação de Mestrado – Universidade Federal de Rio GrandePrograma de Pós graduação em ComputaçãoMestrado em Engenharia de Computação, 5 de março, 2015.
1. Visão Computacional; 2. Visão Subaquática.
CDU 02:141:005.7
Felipe Codevilla MoraesVisão computacional em meio subaquático:Um estudo sobre detecção de pontos de interessee classificação utilizando contexto.
Nelson Duarte Lopez FilhoOrientadorSilvia Silva da Costa BotelhoCo-orientadoraNuno Estrela GraciasConvidadoGlauber Acunha GonçalvezConvidadoRafael GarciaConvidadoBrasil5 de março, 2015AgradecimentosEntre tantas dúvidas , resolvi apostar permanecer onde estava e, ao contrário doque se espera, não poderia ter acertado mais.
Primeiramente gostaria de agradecer a minha orientadora Silvia Botelho por todasas brilhantes ideias e oportunidades oferecidas, obviamente nada disso seria possível semela.
Agradeço a todos os colegas e amigos onde destaco Luan Silveira, Joel Gaya, FelipeGuth e, em especial, a ajuda fornecida pelo Pedro Ballester na última hora.
Agradeço a banca por comparecer e avaliar este trabalho.
I want to thank all the people from the ViCOROB Lab in Girona for receiving meso well during the 10 months I spent in Catalonia. Without this experience, the majorityof this thesis would not be possible.
I also want to thank all my classmates and friends from Vibot (and Patryk) for allthe fun and professional adventures we had toguether.
Agradeço o apoio financeiro da Agência Nacional do Petróleo, Gás Natural e Bio-combustíveis – ANP – , da Financiadora de Estudos e Projetos – FINEP – e do Ministérioda Ciência e Tecnologia – MCT por meio do Programa de Recursos Humanos da ANP parao Setor Petróleo e Gás – PRH-ANP/MCT. Um agradecimento especial aos professoresresponsáveis pelo PRH - 27, Maria Isabel e Gilberto Griep.
Por fim, agradeço a minha família pelo apoio e carinho que sempre me deram, emespecial ao meu pai, por sempre servir como um formidável exemplo ético em minha vida.
ResumoA exploração e o monitoramento do bentos no ambiente marinho possuemimportância econômica e ambiental crescente na sociedade atual. A qualidade datecnologia de obtenção de imagens óticas subaquáticas tem melhorado consideravel-mente devido ao advento dos Remotely Operated Vehicles (ROV) e dos AutonomousUnderwater Vehicles (AUVs), o que tem possibilitado a coleta de milhares de dadosvisuais do fundo do oceano.
Técnicas de visão computacional, atualmente em franca utilização em am-bientes terrestres, podem auxiliar a interpretação automática destas imagens, sejapara minimizar o trabalho de identificação e monitoramento de feições e espécies,seja para fornecer subsídios a realização autônoma de missões.
Porém devido a presença do meio líquido, a propagação da luz no meio su-baquático apresenta efeitos fotométricos que causam degradação na imagem, emer-gindo diversas questões a serem tratadas na classificação de imagens subaquáticas,as quais não estão presentes em outros ambientes.
Assim, o objetivo geral deste trabalho é estudar técnicas de visão computa-cional, e sua sensibilidade a presença do meio líquido. De forma mais precisa, duastécnicas de visão computacional são principalmente tratadas: a detecção de pontosde interesse e a adição das informações de contexto para classificação de objetos emambientes subsea.
São aplicados e analisados diferentes algoritmos de detecção de pontos deinteresse frente a imagens com diferentes níveis de turbidez. Um novo dataset foiproposto capaz de fornecer cenários com diferentes níveis de turbidez e objetos emcena, permitindo o testes múltiplos dos detectores mais usados na literatura e seucomportamento frente os fenômenos de degradação causados na imagem no meiosubaquático. Foi encontrado que o algoritmo DoG se mostrou como uma melhoralternativa para resolver tal problema de forma invariante a escala.
Também foi estudada a questão da adição de contexto como forma de me-lhorar a taxa de acerto da classificação de imagens subaquáticas. Foi proposto umnovo método para incluir contexto na classificação baseado em Geoestatística ecomparou-se com outras formas tradicionais de adição de contexto como os Condi-tional Random Fields (CRF).
Palavras-chaves: Visão Computacional, Geostatística, Visão Subaquática.
AbstractThe exploration and monitoring of the benthic sea zone has an importanteconomic and environmental role in the nowadays society. The quality of the opticalimage acquiring technologies has become considerably better. This happened mainlydue to the advent of the Remotely Operated Vehicles (ROV) and the AutonomousUnderwater Vehicles (AUVs) and has opened the possibility to collect thousands ofvisual data from the seabed environment.
Computer vision techniques are today being largely used in over-land envi-ronments and can help the autonomous interpretation of images. These techniquescan help to minimize the work of identifying and monitoring species and objects.
Either having vision as a data acquiring source or to assist the automation of theoperations.
However, due to the presence of the liquid media, the light propagationin underwater environments has photometric effects that cause degradation of theimage. This degradation develops a lot of issues to be treated on underwater imagesthat do not exist in other environments.
Thus, the objective of this work is to study computer vision tecniques consid-ering their sensibility to phenomenas of the underwater environments media. Moreprecisely, mainly two computer vision techniques are considered: feature point detec-tion and the adition context information for image classification, both on underwaterimages.
Different algorithms for feature point detection are applied for feature pointdetection under different turbidity levels. We provide a new dataset capable ofproviding different scenarios with different levels of turbidity. This dataset allowedthe test of multiple feature detectors regarding their behavior with respect to thedegradation effects of water turbidity. We found that, in this scenario, the DoGalgorithm is the best alternative to solve scale invariant feature detection problems.
Finally, we studied the issue concerning the addition of context as a way toimprove the accuracy of underwater image classification. We proposed a new methodto include the context information on classification that is based on Geostatistics.
This method was compared with an other traditional form of context addition thatis the Conditional Random Fields (CRF).
Key-words: Computer Vision, Geostatistics, Underwater Vision.
Lista de ilustraçõesFigura 1 – Comportamento da aplicação dos kernels Hessian e Harris para umaimagem teste (1a). (1b) mostra a saída da medida de Harris (Eq. 1.4).
(1c) mostra a saída do determinante da matriz Hessian ( Eq. 1.5 )
para a imagem teste. Tanto o Hessian como o Harris tem como saídaas regiões de alta curvatura ( Figura por Sojka (2003)). . . . . . . . . . 31
Figura 2 – O processo para geração do espaço de escala pelo DoG. Ao invés decomputar o Laplacian para cada escala, o mesmo é estimado pela dife-rença entre escalas consecutivas. Figura adaptada de (LOWE, 2004).
. 34
Figura 3 – Exemplo de um filtro caixa de tamanho 9x9 aplicado para geração deum espaço de escala equivalente a 𝜎 = 1.2. Outros espaços podem sergerados usando caixas maiores.
. . . . . . . . . . . . . . . . . . . . . . 34
Figura 4 – Alguns tipos de filtros utilizados para geração do espaço de escala peloCenSurE. O filtro estrela, o filtro hexagonal e o filtro por diferença decaixas. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
Figura 5 – Espaços de escala gerados. Primeira coluna mostra o espaço Gaussiano.
Segunda coluna mostra o filtro média de caixas usado pelo FastHes-sian. Terceira coluna mostra um filtro poligonal estrelar de seis lados.
A quarta Coluna mostra o espaço de escala anisotrópico usado peloKAZE.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
Figura 6 – Janela considerada para a classificação usando contexto. No caso daintegração de contexto diretamente nos classificadores (Fig. 6a), nãosão considerada as relações entre a vizinhança com si própria (Fig. 6b).
Ou seja, se existem propriedades correlacionadas na vizinhança.
. . . . 42
Figura 7 – A representação gráfica de um modelo CRF. Os quadrados em verme-lho (𝜙𝑢𝑖 (𝑥𝑖, 𝜃𝑢)) são os fatores unitários calculados com o resultado dadopelo classificador. Os quadrados em azul são os fatores locais computa-dos em cada aresta e utilizados para introduzir informação contextual.
Os circulos verdes representam os superpixeis sendo classificados.
. . . 44
Figura 8 – Tendências que existem para as classes estarem próximas umas dasoutras, quanto mais claro, maior é a tendência existente. Por exemplo,é possível perceber que a classe B é provável de aparecer perto de umaclasse C mas não próxima de uma classe E.
. . . . . . . . . . . . . . . 46
Figura 9 – Divisão especificada em dois níveis de classificação. O nível unário𝑃𝑢(𝐿|𝜃𝑢) onde somente a informação do superpixel segmentado é uti-lizada, apresentado em verde. E o nível local 𝑃𝑙(𝐿|𝑊), onde um de-terminado contexto local é incluído na classificação, representado pelocirculo azul. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
Figura 10 –Figura do separador linear obtido pelo treinamento do SVM. Dado osconjuntos de dados já rotulados ( Azuis e Vermelhos), o SVM determinao separador de máxima margem. A saído numérica do SVM já é própriapara se ter um certo grau de confiança do classificador.
. . . . . . . . 51
Figura 11 –Gráfico mostrando a probabilidade de acerto em função da máximaconfiança retornada pelo classificador para um conjunto de dados. Em
vermelho tem-se a função 𝐶𝑙𝑖 treinada a partir do conjunto de dadosem azul. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
Figura 12 –Histograma mostrando a distribuição de probabilidades de saída deum classificador. Para o caso, a segunda classe, é a que obteve maiorprobabilidade, porém existe uma certa incerteza com relação a primeiraclasse.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
Figura 13 –Diagrama geral da adição de contexto local utilizando Geoestatística.
Primeiramente é medida a variabilidade entre as classes no contextoespacial. Tanto diretamente através das frequências de transição naimagem (taxa de transição medida), quanto através da inferência depropriedades estatísticas vindas da imagem (taxa de transição mode-lada). Em seguida são calculados os vetores de transição. Na segundaparte os vetores são utilizados para gerar pesos para imagem. Com isso,utilizando os pesos, o sistema SIS computa a adição de contexto localpara cada superpixel.
. . . . . . . . . . . . . . . . . . . . . . . . . . . 54
Figura 14 –Medida feita do número de transições que uma classe faz para cadaoutra para múltiplas distâncias. Foi utilizada um kernel móvel e foramcontadas as transições desde o centro (ponto vermelho) para todas asdireções (representado pelos quadrados). . . . . . . . . . . . . . . . . 56
Figura 15 –A transição de probabilidade modelada para um determinado dataset.
O eixo y apresenta a distância em pixeis. As linhas verdes mostramas proporções para cada classe. Pode-se observar uma certa tendênciana classe Urchin em transitar para categoria de background. Ainda,percebe-se que a classe de background tem um grande comprimentomédio, dado que sua taxa de decaimento é bastante alta.
. . . . . . . . 58
Figura 16 –Exemplo de uma vizinhança sendo considerada para um superpixel (apontado em vermelho). Um raio 𝑟 é considerado e 𝑁 pontos são amos-trados nessa vizinhança ( em azul). Cada um dos pontos amostradosirá influenciar no potencial do superpixel apontado em vermelho. . . . . 60
Figura 17 –Representação gráfica do modelo de Geoestatística (GS). Os fatoreslocais são representados em azul e usam a estatística de probabilidadede transição computada pela Eq. 3.3. Diferentemente do que no modeloda Fig. 7, vizinhos de diferentes distâncias também contribuem paracalcular a distribuição de cada posição.
. . . . . . . . . . . . . . . . . 61
Figura 18 –Três trajetórias da luz até o plano da imagem. O componente direto,contendo a informação direta da cena. O forward-scattering, contendoinformação da cena espalhada. Por fim, o backscattering contendo in-formações de fora da cena. . . . . . . . . . . . . . . . . . . . . . . . . . 64
Figura 19 –Imagem de exemplo para as degradações do ambiente subaquático. É
possível ver que existe uma variação conforme a distância e uma perdasignificativa da informação de cor. . . . . . . . . . . . . . . . . . . . . . 65
Figura 20 –A sequência utilizada para classificação de imagens em meio subaquático. 66
Figura 21 –A cena criada para avaliar os algoritmos de avaliação de features. Ela écomposta por lampadas fluorescentes e uma camera fotografando fotosimpressas do assoalho do oceano.
. . . . . . . . . . . . . . . . . . . . . 72
Figura 22 –As imagens utilizadas no teste. As três imagens foram capturadas nasBahamas em condições de turbidez próximas do ideal em uma resoluçãode 4928x3264 pixeis. . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
Figura 23 –As imagens capturadas sob diferentes níveis de degradação devido aturbidez, controlado pela adição de leite. Foram fotografadas três fotosimpressas diferentes, 𝑃1 (primeira coluna), 𝑃2 (segunda coluna) e 𝑃3(terceira coluna). Na primeira linha foi mostrada a imagem limpa (semleite) para cada foto capturada. A segunda linha apresenta o intervalode Baixa Turbidez com por volta de 15ml de leite (𝑇4). O intervalo deMédia Turbidez é mostrado na segunda linha e contém por volta de 50ml de leite (𝑇10). Finalmente, na ultima (quarta) linha é mostrado ointervalo com Alta turbidez tendo por volta de 100 ml de leite (𝑇16).
Quantidade de leite setada para uma caixa com 1000 litros de água. . . 76
Figura 24 –Repetibilidade ( Taxa de Acerto) contra o indice de degradação estru-tural normalizado (NSDI). As linhas em laranja indicam os intervalosde degradação. Baixa Turbidez 0 até 0.25; Média Turbidez, 0.25 até0.75, e Alta Turbidez de 0.75 até 1.
. . . . . . . . . . . . . . . . . . . . 79
Figura 25 –Comparação entre a geração de um nível do kernel do espaço de escalausado por quatro detectores diferentes. O kernel foi aplicado em níveisde turbidez diferentes para a imagem 𝑃1. Sendo que a primeira linha éa imagem limpa (𝑇0), a segunda linha é uma imagem com baixo nívelde degradação (𝑇4), a terceira linha apresenta uma imagem com médionível de degradação (𝑇10), a quarta linha apresenta imagens do nível dedegradação alto (𝑇16). Para cada caso é mostrado o resultado de filtroequivalente a a aproximadamente um kernel gaussiano de 𝜎 = 59.0.
Primeira Coluna: Gaussiano puro. Segunda Coluna: Borramento apro-ximado em caixas . Terceira Coluna: Difusão utilizando um polígono es-trelar de seis pontas. Quarta Coluna: kernel anisotrópico g2 do KAZE.
É possível ver de certa forma estruturas mais definidas para o esquemade difusão usado pelo CenSurE (AGRAWAL; KONOLIGE; BLAS, 2008). 81
Figura 26 –Partes manualmente segmentadas utilizadas para treinamento do clas-sificador. A esquerda são mostrados exemplos de nove amostras usadaspara treinar o dataset Redsea. A direita são apresentadas nove amostrasdo dataset Marker.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
Figura 27 –Curvas de confiança geradas no treinamento unário de cada classe parao dataset Redsea. A curva de confiança 𝐶𝑙𝑖 treinada para cada uma dasclasses é mostrada, se bem como o grau de confiança obtido.
. . . . . . 86
Figura 28 –Curvas de confiança geradas no treinamento unário de cada classe parao dataset Marker. A curva de confiança 𝐶𝑙𝑖 treinada para cada uma dasclasses é apresentada, bem como o grau de confiança obtido.
. . . . . . 87
Figura 29 –Vetores de transição obtidos na etapa de treinamento para o métodode Geoestatística do Capítulo 3. Os vetores indicam a probabilidade deuma classe transitar para outra a uma determinada distância. O eixox apresenta a distância em pixeis. O eixo 𝑦 dos gráficos apresenta asprobabilidades de transição. Pode-se observar, por exemplo, uma certatendência na classe Urchin em transitar para categoria de background.
88Figura 30 –Mapa temático dos Mosaicos para o dataset Redsea. As figuras mostrama porcentagem de acerto relativa ao GroundTruth. As classes são repre-sentadas pelas seguintes cores: Verde Brain Coral; Amarelo BranchinCoral; Azul Faviid Coral; Magenta Urchin e sem cor é o background.
Os seguintes resultados são mostrados.(30a) classificação Unária. (30b)mostra a classificação Unária baseada nas curvas de confiança. (30c)classificação com adição de contexto baseada em Geoestatística. (30d)classificação com adição de contexto utilizando CRF.
. . . . . . . . . . 92
Figura 31 –Mapa temático dos Mosaicos para o dataset Marker. As figuras mos-tram a porcentagem de acerto relativa ao GroundTruth. As classes sãorepresentadas pelas seguintes cores: Verde Sand; Amarelo Sea Gorgon;Azul Corals e sem cor é o background. Os seguintes resultados sãomostrados.(31a) classificação Unária. (31b) mostra a classificação Uná-ria baseada nas curvas de confiança. (31c) classificação com adição decontexto baseada em Geoestatística. (31d) classificação com adição decontexto utilizando CRF.
. . . . . . . . . . . . . . . . . . . . . . . . . 93
Figura 32 –Resultados de classificação para os datasets Marker e os datasets Red-sea. A primeira coluna apresenta a classificação unitária. A segundacoluna apresenta os resultados de Geoestatística. A terceira colunaapresenta os resultados para o CRF. Por fim, a ultima coluna apre-senta o GroundTruth. Foi utilizada como peso para o potencial local𝑤𝑙 como sendo 0.4 para ambas as abordagens. Na primeira coluna foipossível perceber um resultado melhor para o CRF devido a uma maiorsuavização local. Na segunda linha, o método de Geoestatística obtevemelhores resultados devido a suas medidas estatísticas de longa distân-cia. Na última linha é mostrado os resultados para o dataset Marker,onde ambas as abordagens tiveram melhores resultados para esse caso.
94Lista de tabelasTabela 1 – A quantidade de leite adicionada para cada nível de turbidez simulado. 75
Tabela 2 – Matriz de covariância que mostra as relações de proximidade entre asclasses. Tais medidas são fatores que indicam correlação e não distri-buições de probabilidade. Este resultado é normalizado ao final.
. . . . 86
Tabela 3 – Matriz de covariância que mostra as relações de proximidade entre asclasses. Tais medidas são fatores que indicam correlação e não distri-buições de probabilidade. Este resultado é normalizado ao final.
. . . . 87
Tabela 4 – Resultados para a taxa de acerto de diferentes segmentos para o data-set Redsea. Foram testados diversos segmentos quadrados amostradosaleatoreamente nos mosaicos. O tamanho do segmento é especificadopelo lado do quadrado . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
SumárioIntrodução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
0.1 Motivação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
0.2 Detectores de Pontos de Interesse . . . . . . . . . . . . . . . . . . . . . . . 24
0.3 Classificação de Imagens do Assoalho Oceânico . . . . . . . . . . . . . . . . 24
0.4 Sumário desta Dissertação . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
1Fundamentação Teórica 1: Detectores de Pontos de Interesse . . . . . . . 27
1.1 Detectores de Única Escala . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.1.1 Harris . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.1.2 Hessian e Laplacian . . . . . . . . . . . . . . . . . . . . . . . . . . 30
1.1.3 Comparação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
1.2 Detectores Invariantes a Escala . . . . . . . . . . . . . . . . . . . . . . . . 31
. . . . . . . . . . . . . . . . . . 32
1.2.1 Hessian-Laplace e Hessian-Laplace1.2.2 Diference-of-Gaussians(DoG). . . . . . . . . . . . . . . . . . . . . 33
1.2.3 Fast Hessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
1.2.4 Center Surround Extrema Filters(CenSurE) . . . . . . . . . . . . . 35
1.2.5 KAZE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
1.2.6 Comparação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2 Fundamentação Teórica 2: Classificação de Imagens Utilizando Contexto . 39
2.1 Utilização do Contexto em Visão Computacional . . . . . . . . . . . . . . . 39
2.1.1 Níveis de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
2.1.2
Interações de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . 40
Integração de Contexto Na Classificação . . . . . . . . . . . . . . . . . . . 41
Integrando contexto com base em Classificadores . . . . . . . . . . 42
2.2.1
Integrando contexto com base em Modelos Probabilísticos Gráficos2.2.2
422.2.2.1 O Problema da Inferência Estatística . . . . . . . . . . . . 44
2.2.2.2 Aprendizado de parâmetros . . . . . . . . . . . . . . . . . 45
2.3 Trabalhos utilizando Modelos Probabilísticos Gráficos. . . . . . . . . . . 45
2.4 Sumário . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
2.2
3 Classificação Baseada em Contexto utilizando Geoestatística. . . . . . . 49
3.1 Visão Geral da Proposta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.2 Nível Unário 𝑃𝑢(𝐿|𝜃𝑢). . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
Classificador. . . . . . . . . . . . . . . . . . . 51
Treinando Curvas de Confiança3.2.1
3.2.2
3.3 Distribuição de Probabilidades . . . . . . . . . . . . . . . . . . . . . . . . . 53
3.4 Nível Local 𝑃𝑙(𝐿|𝑊). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
. . . . . . . . . . . . . . . . 54
Taxa de Transição Medida 𝑅𝑚𝑒𝑠. . . . . . . . . . . . . . 55
3.4.1.1
3.4.1.2
Calculo da Matriz 𝑅𝑚𝑜𝑑 . . . . . . . . . . . . . . . . . . . 57
Sequential Indicator Simulation . . . . . . . . . . . . . . . . . . . . 58
. . . . . . . . . . . . . . . . . 59
3.5 Geoestatística e CRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.6 Sumário . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
3.4.1 Medindo Transições de Probabilidades3.4.2
3.4.3 Computando o Potencial Final 𝑃(𝐿)4 Classificação de Imagens do Assoalho Oceânico. . . . . . . . . . . . . . . 63
4.1 Propriedades de Imagens Subaquáticas . . . . . . . . . . . . . . . . . . . . 63
4.2 Classificação Autônoma de Imagens do fundo Oceânico . . . . . . . . . . . 66
4.2.1 Pré-Processamento . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
4.2.1.1 Contraste . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
4.2.1.2 Correção de Cor. . . . . . . . . . . . . . . . . . . . . . . 68
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
Segmentação4.2.2
4.2.3 Descritores. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
4.2.4 Treinamento e Classificação . . . . . . . . . . . . . . . . . . . . . . 70
4.3 Conclusões . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
5 Testes e Resultados 1: Detecção de Pontos de Interesse em AmbienteSubaquático . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
5.1 Descrição do experimento . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
5.1.1 Cena Montada5.1.2 Procedimento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
5.2 Avaliando a degradação causada pela turbidez . . . . . . . . . . . . . . . . 75
5.3 Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
5.3.1 Procedimento de Avaliação . . . . . . . . . . . . . . . . . . . . . . . 77
5.3.2 Comparação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
5.4 Conclusões finais6 Testes e Resultados 2: Contexto em Classificação Subaquática . . . . . . . 83
6.1 Datasets Utilizados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
6.2 Descrição do Geral do Sistema . . . . . . . . . . . . . . . . . . . . . . . . 83
6.2.1 Pré-Processamento . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.2.2
. . . . . . . . . . . . . . . . . . . . . . . 84
6.2.3 Classificação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.2.4 Adição de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.3 Treinamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
Segmentação e Descrição. . . . . . . . . . . . . . . . . . . . . 84
6.3.1 Treinamento do Classificador6.3.2 Treinamento Unário. . . . . . . . . . . . . . . . . . . . . . . . . . 85
6.3.3 Treinamento Potenciais Locais . . . . . . . . . . . . . . . . . . . . . 86
6.4
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Sistemas Testados6.5 Computação do Mapa Temático . . . . . . . . . . . . . . . . . . . . . . . . 90
6.6 Conclusões . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
7 Conclusões Finais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
7.1 Detectores de Pontos de Interesse em Imagens Subaquáticas Turvas . . . . 95
7.1.1 Contribuições Obtidas. . . . . . . . . . . . . . . . . . . . . . . . . 95
7.1.2 Limitações e Trabalhos Futuros . . . . . . . . . . . . . . . . . . . . 95
7.2 Adição de Contexto Baseado em Geoestatística . . . . . . . . . . . . . . . 96
7.2.1 Contribuições Obtidas. . . . . . . . . . . . . . . . . . . . . . . . . 96
7.2.2 Limitações e Trabalhos Futuros . . . . . . . . . . . . . . . . . . . . 96
Referências . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
23IntroduçãoEste trabalho apresenta um estudo sobre técnicas de visão computacional consi-derando os aspectos fotométricos do meio subaquático. Dois pontos chaves no processosão analisados: A extração autônoma de pontos de interesse; e a utilização do contextoespacial para a classificação.
0.1 MotivaçãoVisão computacional é a ciência que visa possibilitar às máquinas a capacidade deinterpretação e representação de informações visuais.
Com tal capacidade, diversas aplicações podem ser então desenvolvidas, como: ainspeção industrial autônoma , a reconstrução de cenas em três dimensões, a localizaçãode robôs, a rotulação ou classificação de objetos em imagens, entre outras. Tais aplicaçõespodem ser implementadas nos mais diversos ambientes, desde o domínio industrial oudoméstico, em ambientes fechados ou abertos, em localidades sobre a terra ou no fundodo mar, etc.
Neste trabalho se dá atenção especial ao ambiente marinho, o qual, cobrindo emtorno de 70% da terra, e contendo cerca de 90% de sua biodiversidade, é de evidenteimportância. O advento dos Remotely Operated Vehicles(ROV ) e dos Autonomous Un-derwater Vehicles (AUVs), tem possibilitado a coleta de milhares de imagens para moni-toramento do oceano, ampliando as possibilidades de aplicações em visão computacionalem ambientes subseaDiversas das aplicações para visão computacional em terra podem ser facilmenteextrapoladas para utilização no meio subaquático. Como exemplo, tem-se o caso da clas-sificação autônoma de imagens do assoalho oceânico. Para tal aplicação, tem-se o caso dosrecifes de corais, os quais desde 1980 sofrem de massivas perdas devido a poluição, pescaexcessiva e espécies invasivas (NEMETH et al., 2008). Uma classificação autônoma é fun-damental, dada a grande área monitorada e a necessidade de reduzir o tempo necessáriode especialistas para se classificar as espécies.
O monitoramento é também uma realidade que gera demanda para sistemas robó-ticos autônomos. Isso gera margem para utilização de sistemas visuais nas mais diversasaplicações como: a localização de robôs subaquáticos, a inspeção e rastreio de risers eflows na indústria de óleo e gás, entre outras.
Devido a dificuldade de desenvolvimento e instrumentação subsea, o uso de ROVse AUVs é recente, implicando em uma limitada quantidade de estudos relacionados ao24Introduçãodomínio da visão computacional para o ambiente subaquático. Nesse ambiente existemdesafios específicos que não necessitam ser tratados em outros ambientes. A propagação daluz em meio subaquático apresenta efeitos fotométricos associados o que causa degradaçãona formação da imagem. Efeitos como borramento, espalhamento da informação luminosae atenuação de cor na imagem, são alguns exemplos que precisam ser considerados emaplicações subaquáticasAlém disso, quando se trata das cenas capturadas em tais ambientes, a monotoni-cidade do ambiente, dada pela falta de diversificação dos objetos e a falta de estruturasgeométricas bem definidas, muito causada pela erosão, dificulta a interpretação visual, oque por sua vez, acarreta no aumento da complexidade das aplicações em visão compu-tacional.
Neste contexto, o objetivo deste trabalho é analisar duas aplicações fundamentaispara visão computacional em meio subaquático: a detecção de pontos de interesse e aconsideração de contexto para classificação de grande extensões de mosaicos de imagensdo assoalho oceânico.
0.2 Detectores de Pontos de InteresseA detecção de pontos de interesse é de fundamental importância para diversasáreas fundamentais de uso no meio subaquático, como a classificação de imagens (PAD-MAVATHI; MUTHUKUMAR; THAKUR, 2010), reconstrução 3D (BEALL et al., 2010)(NICOSEVICI et al., 2009), localização de robôs (AULINAS et al., 2011) , etc.
Este trabalho propõe um novo dataset de imagens subaquáticas, o qual é usadopara apontar os detectores de pontos de interesse mais adaptados ao meio subaquático. Taldataset deve ser capaz de isolar a degradação causada pelo comportamento da propagaçãoda luz em meio subaquáticos como a principal fonte de degradação.
Serão testados detectores, considerando diversos paradigmas para detecção, comrespeito a sua robustez a degradação das imagens subaquáticas. Um especial tratamentoserá dado aos detectores invariantes a escala por sua comprovada baixa performance nestemeio (GARCIA; GRACIAS, 2011).
0.3 Classificação de Imagens do Assoalho OceânicoA outra aplicação analisada diz respeito ao uso do contexto espacial, muito poucoutilizado para classificação de imagens subaquáticas e, de fundamental importância, amedida que grandes extensões passam a ser monitoradas.
Na classificação de grandes extensões de recifes de corais, por exemplo, é natural250.4. Sumário desta Dissertaçãoque as diferentes espécies possam estar inseridas dentro de um contexto. A utilização dainformação de contexto pode auxiliar a interpretação da cena (BAR, 2004). Assim, analisa-se diversos algoritmos para a utilização de contexto em situações e cenários genéricos.
Com isso, este trabalho tem como objetivo também propor um novo algoritmopara adição de contexto inspirado em Geoestatística, área que modela a variabilidade degrandezas no espaço geométrico, de tal forma o método proposto seja capaz de mitigar afalta de informação anotada no meio subaquático.
0.4 Sumário desta DissertaçãoO Capítulo 1 apresenta a fundamentação teórica sobre a detecção de pontos deinteresse. Primeiramente, uma definição formal de pontos de interesse é realizada e suasprincipais características desejadas são apontadas. São apresentadas as definições dosdetectores Harris e Hessian, Harris-Laplace, Hessian-Laplace, Difference of Gaussians(DoG), FastHessian, CenSurE e KAZE.
O Capítulo 2 apresenta o problema de classificação de imagens usando o contexto.
Uma definição de como representar as relações de contexto em uma imagem é apresentado.
Em seguida é feita uma revisão dos métodos de visão computacional os quais incorporamesses conceitos. Um destaque é dado aos métodos que utilizam os Conditional RandomField (CRF) para incorporar o contexto.
No Capítulo 3 é apresentado um sistema de classificação de imagens baseado emGeoestatística, a qual é uma área da estatística que busca modelar a variabilidade espacialde uma determinada grandeza. Nesse capítulo é proposta uma extensão deste conceitopara adição de informação de contexto na classificação de imagens.
O Capítulo 4 apresenta os problemas existentes na classificação de imagens su-baquáticas e também, os aspectos especiais que existem para aplicações em visão su-baquática. Também se apresenta uma breve revisão dos resultados já obtidos na classifi-cação de mosaicos do bentos sem utilização do contexto e, também, uma visão geral dosistema proposto por Shihavuddin et al. (2013) o qual foi usado como base para os testese resultados.
O Capítulo 5 apresenta um estudo sobre o comportamento dos detectores apresen-tados no Capítulo 1 quanto a sua robustez à degradação causada em imagens subaquáticas.
É especificado um experimento realizado para geração de diferentes níveis de degradaçãonas imagens. Por fim, são apresentados os detectores mais adaptados ao meio.
O Capítulo 6 apresenta um estudo de caso da aplicação de contexto para classifi-cação no meio subaquático. Os resultados gerados para o novo método proposto baseadoem Geoestatística são mostrados, e também a sua comparação com os demais métodos26Introduçãodo estado da arte em adição de contexto.
Por fim, no Capítulo 7 as conclusões deste trabalho são apresentadas.
271 Fundamentação Teórica 1: Detectores dePontos de InteresseEste capítulo apresenta a fundamentação teórica sobre detectores de pontos deinteresse. Formalmente pontos de interesse são definidos como um padrão de uma ima-gem que difere de sua vizinhança imediata (TUYTELAARS; MIKOLAJCZYK, 2008).
Normalmente são pontos com particularidades de uma imagem as quais possuem algumacaracterística visual relevante. Vale notar que, apesar do termo utilizado ser "pontos deinteresse", não é utilizada a definição matemática de um ponto infinitesimal sendo de-finidos como pequenas regiões. Pontos de interesse servem como âncoras de regiões daimagem, determinando quais posições podem ser descritas para se ter uma representaçãoconfiável da mesma. Distintas aplicações fazem uso dos pontos de interesse como: a clas-sificação de imagens (PADMAVATHI; MUTHUKUMAR; THAKUR, 2010), reconstrução3D (BEALL et al., 2010) (NICOSEVICI et al., 2009), mapeamento e localização (GIL etal., 2010) , rastreio (CORKE et al., 2007), etc.
Um exemplo de pontos de interesse seriam as quinas, as quais são responsáveispor boa parte do processo de interpretação visual de um objeto (TUYTELAARS; MIKO-LAJCZYK, 2008). Muitas vezes, os pontos de interesse apresentam uma relação semânticamais estreita com a aplicação. Por exemplo, ao classificar faces, as regiões do olho ou daboca são de grande interesse para a classificação.
A utilização de pontos de interesse locais traz as seguintes vantagens, em contrastecom o uso do contexto geral da imagem:∙ Redução significativa do custo computacional;∙ Descarte de parte do ruído presente na imagem pois somente os pontos relevantessão utilizados;∙ Obtenção e uso de apenas características mais distintas da imagem;∙ Possibilidade de reconhecimento de cenas sem a necessidade de segmentação.
Porém, para um ponto de interesse ser eficaz, a presença de algumas propriedadessão de fundamental importância (TUYTELAARS; MIKOLAJCZYK, 2008). Entre as maisimportantes tem-se:∙ Repetibilidade: Um ponto de interesse deve representar características que possamser encontradas em determinados objetos, independente da configuração em que tal28Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de Interesseobjecto foi fotografado. Dado duas imagens de um mesmo objeto ou cena, o que foivisto em ambas as cenas deve ser detectado como ponto de interesse em ambas ascenas.
∙ Distintividade: Um ponto de interesse deve representar características que sejamdistintas, com destaque sobre as demais características e que sejam especificas deum determinado objeto. Só assim este objeto pode ser descriminado com relaçãoaos demais.
A repetibilidade, de fato a propriedade mais importante (TUYTELAARS; MI-KOLAJCZYK, 2008), pode ser atingida tendo os pontos de interesse sendo invariantes adeterminadas transformações que uma imagem pode sofrer, tais como:∙ Rotação: Um ponto que pertence a uma cena, deve ser encontrado independente daorientação que a cena foi capturada.
∙ Translação: Se o ponto representa o mesma objeto, o mesmo deve ser encontradoindependente da posição na imagem onde ele foi capturado.
∙ Escala: Independente da distância em que a cena foi capturada, o mesmo pontodeverá ser encontrado.
Para outras transformações que a imagem possa sofrer, muitas vezes é interessanteque um ponto seja somente robusto. Ou seja, capaz de ser encontrado somente até umdeterminado nível da transformação. Alguns efeitos, ou transformações, a se ter robustezsão: efeitos de discretização, artefatos causados por compressão, borramento devido amovimento, ruído branco, distorção de perspectiva, etc.
Diversos algoritmos são desenvolvidos para encontrar pontos os quais apresentamas propriedades acima descritas. São eles chamados os Detectores de Pontos de Interesse.
Os Detectores são desenvolvidos de forma a terem um valor de retorno alto em relação acertas estruturas presentes na imagens. Define-se estrutura como um determinado padrãocom respeito a variação de intensidade luminosa em uma região da imagem.
Divide-se os Detectores de Pontos de Interesse com respeito as determinadas pro-priedades as quais os mesmos possuem invariância.
Neste trabalho, selecionou-se nove detectores principais encontrados na bibliografiaa serem fundamentados. Primeiramente, na seção 1.1, são expostos os detectores capazesde responder a estruturas possuindo invariância a rotação e translação. Tais detectoressão chamados também de detectores de única escala pois, não possuindo invariância aescala, somente analisam a imagem em uma única escala.
291.1. Detectores de Única EscalaPor fim, na seção 1.2, são apresentados detectores que convivem também com ainvariância a escala. Estes simulam múltiplas escalas de forma a encontrar pontos invari-antes a escala. Tais detectores são chamados de detectores de múltipla escala.
1.1 Detectores de Única EscalaOs detectores apresentados nessa seção possuem invariância a translação ou rota-ção, podendo possuir em algum nível, também invariância a escala. Os detectores apre-sentados podem também ter robustez a diversos tipos de ruído.
Normalmente um detector é implementado como uma função, ou kernel, o qual éconvoluida com a imagem e produz uma imagem de saída a qual apresenta o resultadoda aplicação deste kernel.
Como já explicado, existem diversas características em uma imagem a serem bus-cadas como pontos de interesse. Neste trabalho, tanto para o caso de única, como demúltipla escala, seleciona-se características baseadas na alta curvatura de uma região,calculada através do gradiente da imagem. Duas estruturas são escolhidas, quinas e blobs.
Ambas são bastante utilizadas como pontos de interesse pelos detectores mais populares.
As quinas, são estruturas que não necessariamente representam uma quina defato. São estruturas as quais possuem gradientes de alta intensidade em pelo menos duasdireções distintas.
Blobs são definidos como regiões que são diferentes em intensidade da região ao re-dor. Normalmente são associados com algum ponto de extremo na intensidade da imagem(LINDEBERG; EKLUNDH, 1991).
1.1.1 HarrisO detector Harris (HARRIS; STEPHENS, 1988) é um dos mais populares detec-tores de quinas encontrados na literatura. Uma quina é detectada quando existir variaçãoem duas direções principais de uma função analítica de auto-correlação na imagem. Talfunção indica a variação de intensidade em todas as direções para uma imagem 𝐼(𝑥, 𝑦) epode ser definida pela equação 1.1.
⎡⎣⎤⎦𝑥(𝑥, 𝑦, 𝜎𝐷)𝐼2𝐼𝑥(𝑥, 𝜎𝐷)𝐼𝑦(𝑥, 𝑦, 𝜎𝐷)𝐷𝑔(𝜎𝐼) *𝑀 = 𝜎2(1.1)
𝐼𝑥(𝑥, 𝑦, 𝜎𝐷)𝐼𝑦(𝑥, 𝑦, 𝜎𝐷)𝑦(𝑥, 𝑦, 𝜎𝐷)𝐼2onde:𝑔(𝜎𝐷) * 𝐼(𝑥, 𝑦)𝐼𝑥(𝑥, 𝑦, 𝜎𝐷) = 𝜕𝜕𝑥(1.2)
30Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de Interessee 𝑔 é uma função gaussiana definida por:𝑔(𝜎) = 1− 𝑥2+𝑦22𝜎2(1.3)
2𝜋𝜎2 𝑒A quina pode ser computada por uma análise dos autovalores da matriz 𝑀 .
Quando os dois autovalores tiverem valores altos, isso indica a existência de uma quina.
Uma maneira de medir a intensidade dos autovalores sem a necessidade de computar osautovalores de 𝑀 diretamente, é através da medida de Harris dada por:𝑐𝑖𝑛 = 𝑑𝑒𝑡(𝑀) − 𝑘 𝑡𝑟𝑎𝑐𝑜(𝑀),(1.4)
onde 𝑘 é uma constante normalmente setada entre 0.04 e 0.06. Quando a medida 𝑐𝑖𝑛 daEq. 1.4 for alta, a presença de quinas também o será (HARRIS; STEPHENS, 1988). Um
ponto da imagem é considerado uma quina, se a saída da aplicação da Eq. 1.4 for maiorque um limiar 𝑡.
Harris já foi avaliado como sendo o detector com melhor repetibilidade quandocomparado com outros detectores de única escala (SCHMID; MOHR; BAUCKHAGE,2000).
1.1.2 Hessian e LaplacianO detector Hessian, proposto inicialmente por (BEAUDET, 1978), é um métodobastante usado para detecção de blobs em imagens. Para uma imagem 𝐼(𝑥, 𝑦), os blobspodem ser calculado pelo determinante da matriz Hessiana:⎡⎣𝐼𝑥𝑥(𝑥, 𝑦, 𝜎𝐷) 𝐼𝑥𝑦(𝑥, 𝑦, 𝜎𝐷)⎤⎦𝐻 =(1.5)
𝐼𝑥𝑦(𝑥, 𝑦, 𝜎𝐷) 𝐼𝑦𝑦(𝑥, 𝑦, 𝜎𝐷)O determinante responde aos gradientes em múltiplas direções da imagem e tendea revelar blobs de alta curvatura, o que representa uma região distinta. O detector, deter-minante de Hessian, ou simplesmente detector Hessian é dado selecionando os pontos osquais tem uma saída com respeito a matriz H maior que um valor de limiar 𝑡.
Uma variação do Hessian é a aplicação de um kernel Laplacian o qual é computadopelo traço da matriz 𝐻 ( 𝐼𝑥𝑥+𝐼𝑦𝑦). Porém o Laplacian tende também a responder a bordas(TUYTELAARS; MIKOLAJCZYK, 2008). Bordas não são bons pontos de interesse pois,não possuem uma aceitável invariância a rotação (TUYTELAARS; MIKOLAJCZYK,2008).
311.2. Detectores Invariantes a Escala1.1.3 ComparaçãoA Figura 1 mostra um exemplo de aplicação do Hessian e Harris em uma imagem.
As blobs podem ser vistos como a área mais elevada em morros de intensidade. As quinaspodem ser juntas "T"ou "L", também podendo ter formato mais arredondado.
(a) Original(b) Harris(c) HessianFigura 1 – Comportamento da aplicação dos kernels Hessian e Harris para uma imagemteste (1a). (1b) mostra a saída da medida de Harris (Eq. 1.4). (1c) mostra a saída dodeterminante da matriz Hessian ( Eq. 1.5 ) para a imagem teste. Tanto o Hessian comoo Harris tem como saída as regiões de alta curvatura ( Figura por Sojka (2003)).
Percebe-se que há semelhança entre ambos, dado que ambos são associados aregiões de alto gradiente.
1.2 Detectores Invariantes a EscalaA noção de escala é crucial na interpretação de uma imagem (LINDEBERG, 1994).
Alguns objetos só são entidades visuais significativas em uma determinada escala. Sendoassim, uma modelagem explicita de cada nível de escala se torna necessário para o pro-32Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de Interessecessamento (LINDEBERG, 1998). Ou seja, uma imagem não mais pode ser representadacomo uma matriz 𝐼(𝑥, 𝑦) e passa a ter um terceiro componente de escala 𝑠, sendo assimdeterminada como a função 𝐿(𝑥, 𝑦, 𝑠).
Para gerar o conjunto espaços de escala 𝐿(𝑥, 𝑦, 𝑠), pode-se utilizar o princípio dadifusão (LINDEBERG, 1994). O qual determina que uma família de escalas 𝐿 pode serdeterminada através da equação da difusão:2 ▽2 𝐿 = 1𝜕𝜎𝐿 = 12(𝜕𝑥𝑥 + 𝜕𝑦𝑦)𝐿(1.6)
O que representa o fato de que, à medida que a escala se torna menos detalhada,a informação visual tende a se dispersar.
Portanto, para a geração do espaço de escala de uma imagem 𝐿(𝑥, 𝑦, 𝑠) deve serproposta uma equação que atenda a Equação 1.6. Inicialmente, foi adotado que a funçãogaussiana seria a única a ser uma solução da equação 1.6. Posteriormente, outras funçõesforam colocadas como possíveis para geração do espaço de escala (LINDEBERG, 1997).
Considerando determinada uma escala 𝑠, definida igual a um parâmetro de difusão 𝜎, ageração de um espaço de escala 𝜎 é dada por:𝐿(𝑥, 𝑦, 𝜎) = 𝑔(𝑥, 𝑦, 𝜎) * 𝐼(𝑥, 𝑦)(1.7)
sendo a função gaussiana 𝑔(𝑥, 𝑦, 𝜎) calculada como na Eq.1.3.
De forma a atingir a invariância a escala, os detectores passam a considerar essafunção 𝐿(𝑥, 𝑦, 𝜎) para se detectar os pontos de interesse. Porém, (LINDEBERG, 1994) de-terminou que é possível realizar a escolha de uma escala, e tal escala será sempre escolhidaindependente do ambiente e sem a necessidade de escolha de parâmetros. Caracterizandouma escala onde existe invariância.
Foi sugerido que os pontos de extremo de funções gradientes das estruturas en-tre as escalas tem propriedades invariantes. Isso representa a escala com o máximo desensibilidade a função. Tal escala é chamada de escala característica.
Nesta seção apresentam-se alguns detectores invariantes a escala. A ideia de má-ximo de uma determinada função gradiente entre escalas é usada por todos os métodosapresentados.
1.2.1 Hessian-Laplace e Hessian-LaplaceUmas primeiras extensões para detectores de múltipla escala foram feitas para asas funções Harris e Hessian (MIKOLAJCZYK; SCHMID, 2004) Nestes métodos, o espaço331.2. Detectores Invariantes a Escalade escala é gerado por uma equação gaussiana tal como na Eq. 1.7. Os pontos de extremoentre um conjunto de escalas 𝜎𝑛 são computados conforme a Eq. 1.8.
|𝐿𝑜𝐺(𝑥, 𝑦, 𝜎𝑛)| = 𝜎2|𝐿𝑥𝑥(𝑥, 𝑦, 𝜎𝑛) + 𝐿𝑦𝑦(𝑥, 𝑦, 𝜎𝑛)|(1.8)
sendo a Eq. 1.8 uma representação da função Laplacian em múltiplas escalas. Desta forma, são selecionados os pontos extremos que tem alta reposta a função Harris, para o casodo Harris-Laplace ou da função Hessian para o caso do Hessian-Laplace.
1.2.2 Diference-of-Gaussians(DoG)O detector DoG é uma otimização a aplicação do Hessian-Laplace. É o detectorproposto pelo método SIFT (LOWE, 2004).
Ao invés de computar o Laplacian para cada escala, neste aplica-se o Laplacianpela diferença, 𝐷(𝑥, 𝑦, 𝜎), entre múltiplos níveis do espaço gaussiano 𝐿(𝑥, 𝑦, 𝜎). Sendoassim:𝐷(𝑥, 𝑦, 𝜎) = 𝐿(𝑥, 𝑦, 𝑘𝜎) − 𝐿(𝑥, 𝑦, 𝜎)(1.9)
Diversos níveis de escala são gerados. A cada determinado número de imagens,chamado oitava, é feito um redimensionamento na imagem. Dentro de uma oitava, asimagens diferentes são criadas pela aplicação do filtro gaussiano. A função 𝐷 é gerada apartir da diferença entre níveis vizinhos. O processo utilizado pelo algoritmo é mostradona Figura 2.
Para se encontrar a escala característica, basta encontrar o máximo na função𝐷(𝑥, 𝑦, 𝜎) variando 𝜎. Ao final, os extremos do espaço, os quais tem baixa resposta àfunção Hessian são eliminados.
1.2.3 Fast HessianTrata-se de um método que busca fazer uma otimização ainda maior em relação aoDoG para geração do espaço de escala (BAY et al., 2008). Trata-se de um filtro que não usao filtro gaussiano para geração do espaço de escala . Os filtros gaussianos são aproximadospor filtros caixas. Um filtro caixa basicamente computa a média de uma imagem dadouma janela de convolução, podendo ser computado rapidamente pela utilização de ImagensIntegrais (DERPANIS; LEUNG; SIZINTSEV, 2007).
É possível neste caso fazer a abordagem de diferença de caixas, o que permitejuntar a aplicação do filtro Hessian com a geração do espaço de escala. Uma aproximaçãodo Hessian já é computada diretamente ao se aplicar as diferenças de caixas.
34Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de InteresseFigura 2 – O processo para geração do espaço de escala pelo DoG. Ao invés de computar oLaplacian para cada escala, o mesmo é estimado pela diferença entre escalas consecutivas.
Figura adaptada de (LOWE, 2004).
Para um determinado tamanho de caixa de aresta 𝑁, a resposta do Hessian é dadapor:𝑑𝑒𝑡(𝐻𝑎𝑝𝑝𝑟𝑜𝑥) = 𝐷𝑥𝑥𝐷𝑦𝑦 − (0.9𝐷𝑥𝑦)2(1.10)
A Figura 22 mostra um exemplo de filtros 𝐷𝑥𝑥 e 𝐷𝑥𝑦 que são aplicados. Enquantoaplicar a diferença entre caixas, produz o Hessian, a computação em blocos aplica adifusão na imagem.
(a) 𝐷𝑥𝑥(b) 𝐷𝑥𝑦Figura 3 – Exemplo de um filtro caixa de tamanho 9x9 aplicado para geração de umespaço de escala equivalente a 𝜎 = 1.2. Outros espaços podem ser gerados usando caixasmaiores.
Para relacionar com o espaço gaussiano, basta saber que uma imagem de filtrogaussiano 𝜎 = 1.2 é equivalente a utilização de um filtro caixa 9x9. Então, para geração351.2. Detectores Invariantes a Escalado espaço de escala basta gerar a resposta de vários tamanhos de caixa 𝑁 = 9, 11, 13..
etc.
Para encontrar os pontos característicos basta encontrar o máximo para todos osníveis de escala.
1.2.4 Center Surround Extrema Filters(CenSurE)O Filtro de centro e arredores (AGRAWAL; KONOLIGE; BLAS, 2008) tem umaabordagem similar a utilizada pelo detector Fast Hessian, porém realizando a diferençaentre múltiplos níveis como no caso do DoG. Este processo visa também uma aproximaçãodo Laplacian. Os espaços de escala são criados pela geração de polígonos de múltiplostamanhos. Tal como o filtro caixa, um filtro poligonal representa a media através de umajanela de convolução.
De maneira similar ao FastHessian, um filtro de polígono lado 𝑁 = 2 é equivalentea um espaço gaussiano de 𝜎 = 1.88 A Figura 4 mostra alguns tipos de polígonos usadospara gerar o espaço de escala. Os polígonos podem ter estruturas estreladas, poligonais,entre outras.
(a) Estrela(b) Hexágono(c) QuadradoFigura 4 – Alguns tipos de filtros utilizados para geração do espaço de escala pelo Cen-SurE. O filtro estrela, o filtro hexagonal e o filtro por diferença de caixas.
Para gerar o Laplacian uma imagem a qual teve aplicada um filtro maior é sub-traída de uma imagem com um polígono menor aplicado.
O máximo deste espaço gerado é encontrado como pontos de interesse.
Por fim uma função Harris é aplicada, eliminando os pontos que obtiveram baixaresposta. Isso segue, pelo fato do Harris ter sido determinado como uma função commelhor repetibilidade.
1.2.5 KAZEA ideia do KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) é gerar umespaço de escala suavizando de maneira diferente em locais com alta intensidade de bordas.
Tal abordagem trata-se de uma difusão não linear.
36Capítulo 1. Fundamentação Teórica 1: Detectores de Pontos de InteresseA geração do espaço de escala é dada pela solução para equação da difusão nãolinear:= 𝑑𝑖𝑣(𝑐(𝑥, 𝑦, 𝑡) ▽ 𝐿),𝜕𝐿𝜕𝑡(1.11)
Abordagens que aplicam uma difusão não linear podem obter resultados melhorespara o caso da segmentação de imagens e remoção de ruído (WEICKERT; ROMENY;VIERGEVER, 1998).
A ideia principal é que, durante a formação da escala, as bordas das estruturasdevem se manter mais do que de fato acontece com o filtro gaussiano. Desta forma,primeiramente uma função ▽𝐼 que responde as bordas é aplicada. Sendo ▽𝐼 basicamenteum gradiente da imagem. Com base nessa saída, uma definição alternativa da funçãogaussiana é aplicada para geração do espaço de escala . Perona e Malik (1990), descreveramalgumas possíveis formulações de funções:𝑐1 = 𝑒𝑥𝑝(| ▽ 𝐼𝜎|2𝑘21), 𝑐2 = 𝑒𝑥𝑝((1.12)
)1 + |▽𝐼𝜎|2𝑘2sendo k um parâmetro que controla o nível de difusão. Alcantarilla, Bartoli e Davison(2012) propôs uma terceira formulação de kernel:⎧⎨⎩,| ▽ 𝐼𝜎|2 = 0,| ▽ 𝐼𝜎|2 > 011 − 𝑒𝑥𝑝((|▽𝐼𝜎|/𝑘)8 )𝑐3 =(1.13)
3.315
Levando em conta os kernels definidos, cada nível do espaço de escala 𝐿𝑘(𝑥, 𝑦, 𝑡)é gerado pela aplicação da seguinte função recursiva:𝐿𝑘(𝑥, 𝑦, 𝑡 + 1) = (𝐼 − (𝑡𝑖 + 1 − 𝑡𝑖).𝑐(𝑥, 𝑦, 𝑡) * 𝐿𝑘(𝑥, 𝑦, 𝑡))−1𝐿𝑘(𝑥, 𝑦, 𝑡)(1.14)
onde 𝑡 é um parâmetro de escala temporal facilmente relacionado a 𝜎. Ao final, tambémsão desconsideradas as regiões que tem baixa resposta a aplicação de uma matriz Hessian.
1.2.6 ComparaçãoA Figura 5 apresenta exemplos de geração do espaço de escala baseado em 4funções diferentes. O gaussiano, utilizado pelo DoG, Harris-Laplace e Hessian-Laplace, afunção de caixas utilizada pelo FastHessian, uma função poligonal estrelar de seis lados,utilizadas pelo CenSurE e a função de difusão anisotrópica utilizado pelo KAZE.
Pode-se perceber que determinadas estruturas se mantem mais que outras paraespaços diferentes. Claramente algumas aplicações se beneficiariam do uso de um espaçode escala diferente. No Capítulo 5 se estudam os melhores detectores para o campo deestudo de imagens subaquáticas com presença de turbidez.
371.2. Detectores Invariantes a Escala𝜎 = 3.6
𝜎 = 3.6
𝜎 = 3.6
𝜎 = 3.6
𝜎 = 11.6
𝜎 = 11.6
𝜎 = 11.6
𝜎 = 11.6
𝜎 = 27.6
𝜎 = 27.6
𝜎 = 27.6
𝜎 = 28.7
𝜎 = 59.6
𝜎 = 59.6
𝜎 = 59.6
𝜎 = 57.6
Figura 5 – Espaços de escala gerados. Primeira coluna mostra o espaço Gaussiano. Se-gunda coluna mostra o filtro média de caixas usado pelo FastHessian. Terceira colunamostra um filtro poligonal estrelar de seis lados. A quarta Coluna mostra o espaço deescala anisotrópico usado pelo KAZE.
392 Fundamentação Teórica 2: Classificação deImagens Utilizando ContextoEste capítulo apresenta a fundamentação teórica utilizada neste trabalho associadaa utilização de contexto para a classificação de imagens. Inicialmente são postuladas asdefinições de como representar as relações de contexto em uma imagem. Também é feitaa definição de classificação de imagens incorporando o conceito de contexto, bem comouma revisão dos métodos de visão computacional que os tratam são apresentados. Um
destaque é dado aos métodos que utilizam os Conditional Random Field (CRF).
2.1 Utilização do Contexto em Visão ComputacionalExistem diversos descritores capazes de discriminar os objetos com base em suascaracterísticas visuais, como textura, cor e forma. Tais características buscam capturar avariabilidade dos objetos para sua classificação (GALLEGUILLOS; BELONGIE, 2010).
Porém, estudos envolvendo o sistema perceptivo visual humano trazem novas perspectivasno que tange a como as típicas configurações dos objetos em uma cena podem contribuirpara a percepção, de tal forma que o reconhecimento de objetos no sistema visual humanoconsidera não somente os aspectos locais referentes a interpretação da cena, mas tambéma situação geral onde um objeto foi encontrado.
Biederman (BIEDERMAN; MEZZANOTTE; RABINOWITZ, 1982) estabelece al-guns tipos de relações contextuais importantes que são fundamentais para o reconheci-mento de objetos no sistema visual humano. Estas relações estabelecem níveis semânticostais como: i suporte (onde os objetos tendem a sustentar ou ser sustentados por outros),interposição (relativo a relações de oclusão), ii probabilidade (objetos tendem a aparecerna mesma situação), iii posição (objetos tendem a ficar em determinada posição relativacom outros) e iv tamanho (objetos tendem a ter certo tamanho se comparado com outrosem uma dada escala).
Vários modelos computacionais já fizeram uso destas relações semânticas as quaispodem ser usadas para classificar objetos. Essas relações normalmente são resumidas emtrês tipos de contexto principais: semântico, posição e escala.
O contexto semântico, tende a incluir as relações de ocorrência entre objetos. Ao
encontrar um determinado objeto em uma cena, o qual se possui certeza de sua pre-sença, considera-se uma maior probabilidade de presença de outros objetos. Por exemplo,a existência de um bule de chá implica em uma maior probabilidade de existência de40Capítulo 2. Fundamentação Teórica 2: Classificação de Imagens Utilizando Contextooutros utensílios de cozinha como talheres ou um fogão (FISCHLER; ELSCHLAGER,1973) (HANSON; RISEMAN, 1978). Como exemplo, Rabinovich et al. (2007), incorpo-rou a informação anotada pelos Google Sets indicando objetos que tendem a aparecer emsituações semelhantes de forma a melhorar a classificação.
O contexto de posição indica que os objetos tendem a ter uma relação espacialna imagem. Como por exemplo, o céu em uma imagem tende a estar acima do chão.
Já o contexto de escala esta associado as relações de tamanho entre objetos na cena(TORRALBA, 2003) (KUMAR; HEBERT, 2005) (TORRALBA; MURPHY; FREEMAN,2004). Pois, existe já, uma relação de tamanho típica que os objetos possuem entre eles(GALLEGUILLOS; BELONGIE, 2010).
Para incluir tais tipos de contexto na classificação de imagens, alguns aspectosfundamentais devem ser considerados. Primeiramente, qual nível de contexto será clas-sificado. Se as relações a serem consideradas serão apenas entre objetos próximos, ouno domínio geral de uma imagem. Ou ainda, por meio de que tipo de estrutura visualencontrada na imagem, a interação de contexto ocorre.
2.1.1 Níveis de ContextoOs sistemas que adicionam contexto na classificação normalmente dividem o con-texto em dois níveis (GALLEGUILLOS; BELONGIE, 2010): local e global.
O contexto local é onde somente as interações de vizinhança são utilizadas paraadicionar o contexto a um determinado objeto. O contexto local está relacionado aosobjetos que cercam outros objetos. Vale notar que a aplicação de contexto é recursiva, ouseja, a própria vizinhança possuí também suas próprias relações de contexto. Isso faz quenão somente as relações estritamente próximas façam parte do contexto local.
O contexto global está relacionado as interações de contexto presentes ao longode toda a imagem utilizada. O contexto global normalmente está associado ao ambienteonde os objetos estão posicionados. Por exemplo, se as relações contextuais indicam que osobjetos estão em uma cozinha, isso implica em uma alta probabilidade de um dos objetosser uma panela.
2.1.2 Interações de ContextoNão necessariamente cada componente da imagem deve ser um objeto com umconceito semântico relacionado. Na literatura se estabelecem três níveis básicos de inte-ração nos quais o contexto pode ser integrado (GALLEGUILLOS; BELONGIE, 2010).
Além de objetos, as interações também se dão entre pixeis ou regiões.
A interação em nível de pixel estabelece que pixeis vizinhos tendem a ter a mesmaclasse. Tais interações ajudam a inferir as bordas existentes na imagem. Vale notar a412.2.
Integração de Contexto Na Classificaçãoutilização de tais interações são mais computacionalmente intensas, dado que existemdiversas combinações entre pixeis da imagem. Ressalta-se que o uso de níveis mais baixosde contexto não necessariamente implica na perda da informação semântica. Ou seja,encontrar que pixeis de determinado objeto são próximos, é também identificar a altaprobabilidade de proximidade de tais objetos.
O conceito de pixel pode ser estendido para o nível de representação de regiões. Ao
utilizar regiões, tende-se a reduzir a complexidade levantada pelo grande número de pixeisexistentes na imagem. Uma estrutura de região bastante utilizada é a consideração de pe-quenas regiões adaptadas a estrutura local da imagem. Tais regiões chamadas, superpixeis,capturam a redundância dos dados, facilitando a utilização do contexto (FULKERSON;VEDALDI; SOATTO, 2009).
Já a interação em nível de objetos é a representação mais natural para reconhe-cimento de contexto humano (BAR, 2004). Sabendo-se já a classe do objeto é possíveltreinar as relações de contexto. No trabalho de (TORRALBA; MURPHY; FREEMAN,2004), os objetos mais fáceis de classificar ajudam, através do contexto, a obter a classe deobjetos mais difíceis. Se por um lado usar objetos tende a capturar melhor as interaçõesexistentes na cena, o uso do contexto em nível de objetos implica já o conhecimento pré-vio ( classificação) dos objetos existentes na imagem. A interação entre regiões, por outrolado, ajuda a reduzir a quantidade de combinações existentes na interação de pixeis, sem anecessidade de um conhecimento maior sobre a imagem (GALLEGUILLOS; BELONGIE,2010).
2.2 Integração de Contexto Na ClassificaçãoNesta seção são apresentadas algumas abordagens para integração do contexto naclassificação de imagens. São escolhidos métodos com integração baseada em superpixeis,com foco para integração local de contexto. Quanto aos tipos de contexto, por consideraro nível de interação como superpixeis, os principais tipos integrados são os de posição eescala.
Dado a representação da imagem como uma matriz 𝑆𝑃(𝑥, 𝑦) onde cada elemento𝑠𝑝 é um superpixel, a definição de classificação é dada pela determinação de um rótulo𝑙𝑖 dentre um conjunto possível de rótulos 𝐿 = 𝑙1, 𝑙2, ...𝑙𝑛 para cada 𝑠𝑝. Para classificaçõessem contexto, apenas o superpixel 𝑠𝑝 é considerado, já para o caso apresentado nestaseção, a vizinhança de 𝑠𝑝 é também importante para determinar um rótulo 𝑙𝑖.
Nesta seção são especificadas duas formas de incorporar o contexto. Utilizandoa vizinhança de um superpixel 𝑠𝑝 diretamente no classificador ou através de modelosprobabilísticos gráficos (MPGs).
42Capítulo 2. Fundamentação Teórica 2: Classificação de Imagens Utilizando Contexto2.2.1
Integrando contexto com base em ClassificadoresAs informações locais advindas de uma análise de contexto podem ser incorporadasdiretamente aos sistemas de classificação, considerando uma janela de contexto em tornoda região a ser classificada (Figura 6)Fink e Perona (2003) incorporou o contexto local usando a janela da região paratreinamento de classificador fracos em um esquema de boosting.
Kruppa e Schiele (2003), visando melhorar a classificação de rostos, incorporou adescrição dos descritores da vizinhança local da face em um sistema Naive BayesO principal problema é que tais aplicações não levam em conta as possíveis corre-lações entre os vizinhos. Este problema é demonstrado na Figura 6, a vizinhança só afetao que foi considerado no centro da imagem, sem afetar a si própria. Tais problemas sãoparcialmente resolvidos criando-se interações mais conectadas, como no caso dos modelosprobabilísticos gráficos a serem explicados na próxima seção.
(a)(b)Figura 6 – Janela considerada para a classificação usando contexto. No caso da integraçãode contexto diretamente nos classificadores (Fig. 6a), não são considerada as relações entrea vizinhança com si própria (Fig. 6b). Ou seja, se existem propriedades correlacionadasna vizinhança.
2.2.2
Integrando contexto com base em Modelos Probabilísticos GráficosNesta seção, serão apresentados os principais conceitos associados aos ModelosProbabilísticos Gráficos (MPGs) e seu uso na integração contextual em classificação deimagens.
Uma forma natural de representar a dependência entre variáveis é utilizando osModelos Probabilisticos Gráficos (MPGs)(SUTTON; MCCALLUM, 2006). Estes mode-los representam algumas fatorizações de uma função de probabilidades como o MarkovRandom Fields MRF ou Conditional Random Fields CRF.
432.2.
Integração de Contexto Na ClassificaçãoUm MPG é usado para capturar a correlações existentes dentro de um conjunto dedados. Baseado neste modelo, é possível calcular uma função potencial. Esta abordagem,quando baseada em modelos probabilísticos não direcionadas, é usada no MRF e no CRF(SUTTON; MCCALLUM, 2006).
O MRF modela a função de probabilidade 𝑝(𝑦, 𝑥) de um dado conjunto de rótulos𝑦 e os conjunto de descritores de entrada 𝑥. Esse modelo necessita um alto custo compu-tacional para classificação de imagens (CARBONETTO; FREITAS; BARNARD, 2004).
Ainda, dado que deve seguir a premissa de Markov, nenhuma característica global deveser adicionada. Paro caso de Markov, a computação de 𝑝(𝑦, 𝑥) necessita a computaçãode 𝑝(𝑦) e também 𝑝(𝑥), o qual não se tem conhecimento sobre, pois está relacionado aprobabilidade das descrições de entrada aparecerem.
Uma abordagem mais comumente utilizada para classificação de imagens é o mo-delo CRF. Neste modelo, somente a distribuição condicional, 𝑝(𝑦|𝑥) , é computada. Nor-malmente o CRF tem uma melhor associação aos dados, dado que não é necessário com-putar a probabilidade a priori para os dados de entrada (𝑝(𝑥)) (SUTTON; MCCALLUM,2006).
Considerando um dado modelo, é definida a probabilidade para um conjunto derótulos serem atribuídos . Esta probabilidade é estabelecida como uma função de um fatorunitário e um fator local. Deste modo, define-se a probabilidade de uma imagem possuirum certo conjunto de rótulos 𝐿 = 𝑙1, 𝑙2, ...𝑙𝑛 dado um grafo de um modelo 𝐺 e um conjuntode parâmetros 𝜃𝑢 e 𝜃𝑙 como a Eq. 2.1.
𝑢∑︁𝜖∑︁𝑙𝑜𝑔𝑃(𝐿|𝐺, 𝜃) = 𝑤𝑢𝑖 (𝑥𝑖, 𝜃𝑢) + 𝑤𝑙𝜙𝑢𝑖𝑗(𝑥𝑖, 𝑥𝑗, 𝜃𝑙)𝜙𝐿(2.1)
(𝑥𝑖,𝑥𝑗)𝜖𝜀𝑥𝑖𝜖𝑋onde 𝑋 é um conjunto de vértices no modelo probabilístico gráfico, cada um relacionadoa um superpixel da imagem e 𝜀 é o conjunto de arestas no grafo de adjacência 𝐺(𝑋, 𝜀).
𝑖 (𝑥𝑖, 𝜃𝑢) é a distribuição de probabilidades a priori de um rótulo, para este caso, o con-𝜙𝑢junto de parâmetros 𝜃𝑢 esta associado com o treinamento da geração da distribuição apriori . 𝜙𝐿
𝑖 (𝑥𝑖, 𝜃𝑙) é o fator local associado com a probabilidade de duas classes seremvizinhas uma da outra. Neste caso, o parâmetro 𝜃𝑙 está associado as matrizes de covari-ância, treinadas para indicar a probabilidades proximidade entre os rótulos do conjuntos𝐿 = 𝑙1, 𝑙2, ...𝑙𝑛 considerando sua conexão 𝐺.
Os pesos 𝑤𝑢 e 𝑤𝑙 facilitam a calibração empírica do modelo, determinando a im-portância de cada termo na Eq. 2.1. A Figura 7, mostra uma representação visual departe da modelagem usando CRF para a aplicação de interesse que é a classificação esegmentação de imagens.
No modelo CRF também é possível incluir diferentes aspectos baseado em proprie-44Capítulo 2. Fundamentação Teórica 2: Classificação de Imagens Utilizando ContextoFigura 7 – A representação gráfica de um modelo CRF. Os quadrados em vermelho(𝜙𝑢𝑖 (𝑥𝑖, 𝜃𝑢)) são os fatores unitários calculados com o resultado dado pelo classificador.
Os quadrados em azul são os fatores locais computados em cada aresta e utilizados paraintroduzir informação contextual. Os circulos verdes representam os superpixeis sendoclassificados.
dades da imagem. A função de bordas de Potts (SHOTTON et al., 2009) (FULKERSON;VEDALDI; SOATTO, 2009) reforça nodos que não são separados por bordas a perten-cerem a mesma classe. Isto é implementado incluindo o atributo 𝑔𝑖𝑗 em 𝜙𝐿𝑖 . Onde 𝑔𝑖𝑗 édefinido pela Eq. 2.2.
⎡⎣𝑒𝑥𝑝(−𝛽||𝑥𝑖 − 𝑥𝑗||2)⎤⎦𝑔𝑖𝑗 =(2.2)
1Onde 𝛽 é uma função de contraste dependente da imagem que pode ser facilmente esti-mada como explicado em (SHOTTON et al., 2009).
2.2.2.1 O Problema da Inferência EstatísticaDado um modelo probabilístico gráfico e uma função de probabilidades, uma dasprincipais dificuldades é encontrar um conjunto de rótulos 𝐿′ que maximize uma funçãode probabilidades como a função da Eq. 2.1. Em outras palavras, seria encontrar a con-figuração de classificação na imagem mais provável, dado um modelo probabilístico. Esteproblema é considerado NP-Hard, dado que existe uma combinação de rótulos exponen-cialmente grande. O problema de inferência é especialmente difícil quando se utiliza aabordagem MRF, dado que existem muito mais casos para computar a distribuição deprobabilidades conjunta.
Algumas aproximações são introduzidas de forma reduzir o custo computacional.
452.3. Trabalhos utilizando Modelos Probabilísticos GráficosPor exemplo, a abordagem loopy belief propagation (LBP) propaga as informações de dis-tribuição de probabilidades dos vértices ao longo do grafo através de mensagens e obtemboa performance (WEISS, 2000), entretanto, a convergência não pode ser garantida. Ou-tra estratégia é o corte de grafos baseado no alpha-cut (BOYKOV; JOLLY, 2001). Estealgoritmo produz melhores resultados apesar de possuir maior complexidade.
2.2.2.2 Aprendizado de parâmetrosÉ necessário estimar os parâmetros 𝜃𝑢 and 𝜃𝑙. Estes parâmetros são a matriz decovariância que representa as tendências das classes serem vizinhas (𝜃𝑙), a matriz 𝜃𝑙 estaassociada às relações espaciais entre as classes.
Os parâmetros podem ser estimados utilizando a técnica de máximo a-posteriori(MAP). Esta técnica seleciona os parâmetros que maximizam os resultados para a Eq.
2.1. Isto é custoso, dado que existe a necessidade de computar a inferência diversas vezes.
Porém, é possível realizar a estimativa, parte a parte, dividindo os parâmetros os quaismaximizar (SHOTTON et al., 2009), então reduzindo o custo computacional.
A Figura 10 mostra um exemplo de uma matriz de covariância estimada, sendoquanto mais claro for o quadrado mais relacionadas espacialmente as classes estão. É
possível perceber que a classe B tem uma probabilidade muito maior de ficar próxima aoC mas não necessariamente a classe E.
2.3 Trabalhos utilizando Modelos Probabilísticos GráficosDiversos trabalhos já utilizaram os modelos probablístico gráficos (MPGs) paraadição de contexto. Apresenta-se aqui alguns relevantes para elaboração deste trabalho.
Carbonetto, Freitas e Barnard (2004) foi um dos primeiros trabalhos a usar MPGspara classificação de imagens . O autor utilizou uma versão usando um modelo MRF como contexto local e propôs uma forma de reduzir o tempo de inferência usando uma técnicade expectation maximization (EM) (DEMPSTER; LAIRD; RUBIN, 1977).
Shotton et al. (2009) utilizou uma combinação de descritores diretamente dosdescritores de textura, cor e localização como fatores unários e adicionou a informaçãode contexto local usando a medida de potts. O nível de interação foi baseado em regiõesutilizando um novo esquema de representação de imagens através "canais de textura". A
inferência foi feita utilizando o algoritmo de alpha-cut (BOYKOV; JOLLY, 2001).
Fulkerson, Vedaldi e Soatto (2009), utiliza uma representação usando SIFT (LOWE,2004) para bag-of-words (SIVIC; ZISSERMAN, 2006) para o fator unário. Como nível deinteração, foram utilizadas regiões baseadas em superpixeis. Em seguida, aplica-se umsistema CRF similar ao proposto por (SHOTTON et al., 2009).
46Capítulo 2. Fundamentação Teórica 2: Classificação de Imagens Utilizando ContextoFigura 8 – Tendências que existem para as classes estarem próximas umas das outras,quanto mais claro, maior é a tendência existente. Por exemplo, é possível perceber que aclasse B é provável de aparecer perto de uma classe C mas não próxima de uma classe E.
Koltun e Vladlen (2011), utiliza um CRF com uma maior conectividade entre osvértices e utiliza um nível de interação por pixel. Neste caso, dado o conjunto de pixeis,cada par possível de pixeis é conectado. O aumento da complexidade de inferência éresolvido com um sistema aproximado baseado em médias.
Boix et al. (2012) propõem adicionar o contexto global ao CRF. Para isso, aEquação 2.1 pode ser extendida para a Eq. 2.3.
𝜖∑︁𝑢∑︁𝜖∑︁𝑙𝑜𝑔𝑃(𝐿|𝐺, 𝜃) = 𝑤𝑢𝑖𝑔(𝑥𝑖, 𝑥𝑔, 𝜃𝑔)𝜙𝐺𝑖𝑗(𝑥𝑖, 𝑥𝑗, 𝜃𝑙) + 𝑤𝑔𝜙𝐿𝑖 (𝑥𝑖, 𝜃𝑢) + 𝑤𝑙𝜙𝑢(𝑥𝑖,𝑥𝑔) 𝜀𝑔(𝑥𝑖,𝑥𝑗)𝜖𝜀𝑥𝑖𝜖𝑋(2.3)
𝑖𝑔(𝑥𝑖, 𝑥𝑔, 𝜃𝑔) representa as conexões com um nodo global que, tendo esti-onde a porção 𝜙𝐺472.4. Sumáriomado seu conjunto de parâmetros 𝜃𝑔, indica as configurações mais prováveis entre todasas porções da imagem. Com tal modelo, as relações de contexto global, como o conjuntotípico de objetos possíveis em cena, podem ser incorporadas.
Por fim, Lucchi et al. (2011) critica o funcionamento do CRF, comparando autilização do CRF com pontos de interesse globais (BOIX et al., 2012), concluindo quenão há ganho significativo. Além disso, o contexto local adicionado pelo CRF a tendeapenas melhorar a suavização da classificação local. Ou seja, dado uma pequena regiãoda imagem, as variabilidade de classes é reduzida.
2.4 SumárioEste capítulo apresentou os conceitos de utilização de contexto para visão compu-tacional. Apresentou-se em quais níveis o contexto pode ser utilizado, sendo eles globaisou locais. Também foi apresentado quais níveis de interação o contexto podem se dar,sendo eles no nível de pixeis, regiões ou objetos.
Nesse âmbito, formalizou-se a classificação utilizando contexto, considerando onível de interação baseado em regiões, no caso, superpixeis. Em seguida, foram apresen-tadas formas de utilizar o contexto. Primeiramente foram apresentadas formas de aplicaro contexto diretamente no classificador. Em seguida, foi apresentado o uso de modelosprobabilísticos gráficos para a aplicação de contexto.
Por fim, alguns dos principais trabalhos em modelos probabilísticos gráficos foramapresentados.
493 Classificação Baseada em Contexto utili-zando GeoestatísticaTendo em vista as limitações existentes no CRF (LUCCHI et al., 2011) e o conhe-cimento obtido através de estudos em Geoestatística, neste capítulo, busca-se propor umnovo método para adição de contexto baseado em Geoestatística.
Tal abordagem agrega duas áreas com aplicações distintas mas conceitos seme-lhantes. No campo da modelagem geológica, uma abordagem baseada em geostatísticaprimeiramente busca modelar a variabilidade espacial de uma determinada medida como objetivo de interpolar este comportamento para áreas desconhecidas (CARLE; FOGG,1996). Esta estratégia é bastante utilizada para aplicações como modelagem de reservató-rios em campos de de extração óleo (BEATTIE; MILLS; MAYO, 1998) ou mapeamentogeológico (PURKIS; VLASWINKEL; GRACIAS, 2012).
Porém, neste trabalho busca-se também mostrar que este conceito se aplica parao caso de adição de contexto classificação de imagens. A abordagem apresentada é capazde assegurar a suavização de estruturas espaciais de maneira similar que o CRF, porém,o método proposto, também considera correlações em longa distância entre rótulos.
3.1
Visão Geral da PropostaA Equação 3.1 apresenta a adição do contexto espacial utilizando Geoestatística:𝑃(𝐿) = 𝑤𝑢𝑃𝑢(𝐿|𝜃𝑢) + 𝑤𝑙𝑃𝑙(𝐿|𝑊),(3.1)
sabe-se que a probabilidade, 𝑃 de um dado conjunto de rótulos 𝐿, é dada pela somaponderada, pelos pesos 𝑤𝑢 e 𝑤𝑙, das probabilidades unária 𝑃𝑢(𝐿|𝜃𝑢), da parte segmentada,e a probabilidade do contexto local 𝑃𝑙(𝐿|𝑊). A matriz W está associada ao peso atribuídoaos superpixeis da vizinhança. 𝜃𝑢 está associado aos parâmetros de usados para obtençãoda distribuição unária.
Como nível de interação, parte-se de uma segmentação baseada em superpixeisem um grid retangular e uniforme onde cada superpixel tem aproximadamente o mesmotamanho. O sistema de classificação proposto neste capítulo, é mostrado na Figura 10.
Nesta proposta, o nível de interação, em uma imagem segmentada ocorre através deTurbopixels (LEVINSHTEIN et al., 2009).
No nível unário 𝑃𝑢(𝐿|𝜃𝑢), somente as informações visuais descritas de um único50Capítulo 3. Classificação Baseada em Contexto utilizando GeoestatísticaFigura 9 – Divisão especificada em dois níveis de classificação. O nível unário 𝑃𝑢(𝐿|𝜃𝑢)onde somente a informação do superpixel segmentado é utilizada, apresentado em verde.
E o nível local 𝑃𝑙(𝐿|𝑊), onde um determinado contexto local é incluído na classificação,representado pelo circulo azul.
superpixel são relevantes para a classificação do mesmo. Na seção 3.2, mostra-se a compu-tação do nível unário e a necessidade do mesmo de produzir uma distribuição confiável.
No nível local 𝑃𝑙(𝐿|𝑊), se considera as conexões de uma determinada área ondemedidas estatísticas são utilizadas (Circulo Azul Fig. 10). O nível 𝑃𝑙(𝐿|𝑊) é apresentadona seção 3.4.
3.2 Nível Unário 𝑃𝑢(𝐿|𝜃𝑢)Para o sistema proposto, o foco da classificação unária é obter uma distribuiçãode probabilidades previa para cada superpixel. Essa probabilidade a priori vai ser usadapara inferir a vizinhança.
Em um dado superpixel o qual pode ser classificado como um dentre um conjuntoonde ∑︀ 𝑃𝑢(𝐿|𝜃𝑢) = 1. Onde 𝜃𝑢 é conjunto de parâmetros usados para se ter essa saída.
de rótulos 𝐿 = 𝑙1, 𝑙2..𝑙𝑛 busca-se obter uma saída 𝑃𝑢(𝐿|𝜃𝑢) = 𝑃𝑢(𝑙1|𝜃𝑢), 𝑃𝑢(𝑙2|𝜃𝑢)...𝑃𝑢(𝑙𝑛|𝜃𝑢)Para se chegar em tal resultado, a geração do nível unário é dividida em duasetapas. A primeira corresponde ao treinamento da função de discriminação 𝑓(𝑥), do clas-sificador. No caso, é feito o treinamento de um kernel linear para uma Support VectorMachine (SVM). A segunda etapa é a determinação das curvas de confiança, que corres-ponde ao grau de certeza da classificação. Ou seja, o grau de certeza 𝐶𝑙𝑖 é dado como uma3.2. Nível Unário 𝑃𝑢(𝐿|𝜃𝑢)51função treinada, e é usado para gerar 𝑃𝑢(𝐿|𝜃𝑢) (ABFALG et al., 2007).
3.2.1
ClassificadorComo classificador, foi utilizado uma Support Vector Machine(SVM) com um ker-nel linear. A ideia do algoritmo é encontrar uma função de hiperplano 𝑓𝑙𝑖(𝑥), para cadaclasse 𝑙𝑖 que separa linearmente um conjunto de dados previamente rotulados, porémmaximizando uma determinada margem. Trata-se de uma abordagem de classificaçãosupervisionada.
Para dada aplicação é necessário que o classificador produza uma distância de umobjeto à borda de classe mais próxima a borda entre classes (ABFALG et al., 2007). Talresultado é obtido diretamente pelo SVM dado que sua função de hiperplano já maximizaa margem entre classes. A saído numérica do SVM já é própria para se ter um certo graude confiança do classificador.
Figura 10 – Figura do separador linear obtido pelo treinamento do SVM. Dado os conjun-tos de dados já rotulados ( Azuis e Vermelhos), o SVM determina o separador de máximamargem. A saído numérica do SVM já é própria para se ter um certo grau de confiançado classificador.
3.2.2 Treinando Curvas de ConfiançaSomente as distâncias de saída do SVM (CRISTIANINI; SHAWE-TAYLOR, 2000),não estabelecem diretamente o grau de confiança de uma classificação (ABFALG et al.,
2007) . Ou seja, uma distância de valor número 5 para o SVM pode ser para alguns casosuma saída confiável, para outros não. É necessário treinar para quais distâncias existe uma52Capítulo 3. Classificação Baseada em Contexto utilizando Geoestatísticagrande probabilidade da predição ser correta. Isso depende do dataset que foi utilizado,da classe (rótulo) e também do classificador.
O estudo apresentado por Platt (PLATT, 1999) demonstra que comportamentosigmoidal pode modelar a distribuição de probabilidade do SVM.
Sendo assim, para cada classe 𝑙𝑖 é feito um ajuste de uma função sigmoidal 𝐶𝑙𝑖. Estafunção 𝐶𝑙𝑖 não mais retorna uma distância e sim uma probabilidade de uma determinadaentrada na função 𝑓𝑙𝑖(𝑥) ser correta.
A Figura 11 apresenta a saída esperada para a curva de confiança treinada 𝐶𝑙𝑖,para um dado rótulo 𝑙𝑖. Dado um conjunto de validação em que já se possui os retornos𝑓𝑙𝑖(𝑥), o treinamento é feito da seguinte forma: Obtém-se os pontos em azul os quaisindicam a porcentagem de acertos que se tem utilizando apenas as parcelas de dadosas quais seu retorno vindo do classificador (𝑓𝑙𝑖(𝑥)) é de no máximo o que é mostradono eixo 𝑥. Por exemplo, na Figura 11, para um conjunto de dados com uma distânciado classificador(𝑓𝑙𝑖(𝑥)) de até dois, tem-se uma porcentagem de acerto de 70%. Dadoesse conjunto de pontos, o algoritmo de Levenberg-Marquardt (MARQUARDT, 1963) deotimização é utilizado para encontrar os coeficientes, 𝛼𝑘 e 𝛽𝑘 da função sigmoidal:0.5
1 + 𝑒𝑥𝑝(𝛼𝑙𝑖 * 𝑓𝑙𝑖(𝑥) + 𝛽𝑙𝑖) + 0.5
(3.2)
𝐶𝑙𝑖 = 𝑁𝑙𝑖onde 𝑁𝑙𝑖 é uma constante de normalização para a classe 𝑙𝑖. A função inicia de 0.5 pois éa probabilidade inicial de uma classe ser acertada aleatoriamente. A abordagem propostacontrasta com a proposta apresentada por ABfalg et al. (2007) por propor uma curva deconfiança para cada classe. Isso também leva em conta as diferenças existentes em cadaclasse. 𝜃𝑢 está relacionado aos parâmetros 𝛼𝑘 e 𝛽𝑘 de 𝑃𝑢(𝐿|𝜃𝑢).
Figura 11 – Gráfico mostrando a probabilidade de acerto em função da máxima confiançaretornada pelo classificador para um conjunto de dados. Em vermelho tem-se a função𝐶𝑙𝑖 treinada a partir do conjunto de dados em azul.
533.3. Distribuição de Probabilidades3.3 Distribuição de ProbabilidadesNormalizando o grau de confiança para a distância com relação a todas as classes,se obtém a distribuição de probabilidades para um determinado objeto. Sendo assim, umclassificador não mais produz somente uma saída, mas também uma chance de cada itemde um conjunto de dados a pertencer a cada uma das classes. A Figura 12 mostra a saídada classificação de um exemplo calculado. Sendo que cada barra representa a chance doobjeto pertencer a tal classe.
Figura 12 – Histograma mostrando a distribuição de probabilidades de saída de um clas-sificador. Para o caso, a segunda classe, é a que obteve maior probabilidade, porém existeuma certa incerteza com relação a primeira classe.
Observa-se na Figura 12 que a saída do classificador mostra a classe mais provávelmas existe uma incerteza significativa para uma segunda classe ser a correta.
3.4 Nível Local 𝑃𝑙(𝐿|𝑊)A Figura 13 mostra o conjunto de passos para calcular os parcelas locais utilizandoo contexto baseado em Geoestatística.
A primeira parte do método (lado direito da Figura 13) é estimar e modelar aincerteza existente nos conjunto de dados os quais se quer adicionar o contexto. Essa mo-delagem se da através da estimativa da matriz de probabilidade de transição (𝑇) entre ospossíveis rótulos presentes no conjunto de dados. Isso é feito em uma etapa de treinamentooffline do método A estimativa é feita em duas partes que são combinadas: analisandoas frequências de transições entre as classes de um conjunto de imagens (CARLE et al.,
1998) e medindo propriedades estatísticas nos dados como proporções e espessuras.
54Capítulo 3. Classificação Baseada em Contexto utilizando GeoestatísticaFigura 13 – Diagrama geral da adição de contexto local utilizando Geoestatística. Primei-ramente é medida a variabilidade entre as classes no contexto espacial. Tanto diretamenteatravés das frequências de transição na imagem (taxa de transição medida), quanto atravésda inferência de propriedades estatísticas vindas da imagem (taxa de transição modelada).
Em seguida são calculados os vetores de transição. Na segunda parte os vetores são utiliza-dos para gerar pesos para imagem. Com isso, utilizando os pesos, o sistema SIS computaa adição de contexto local para cada superpixel.
A segunda parte do método é a geração do contexto local 𝑃𝑙(𝐿|𝑊). Deste modo,para cada superpixel que se deseja computar, a matriz de probabilidades de transiçãoé usada para computar os pesos 𝑊, para servir como entrada em um sistema de SIS,Sequential Indicator Simulation (Indicador de simulação sequencial) (EMERY, 2004) oqual computa 𝑃𝑙(𝐿|𝑊). Cada um dos processos apontados na Figura 13 são detalhadosno restante desta seção.
3.4.1 Medindo Transições de ProbabilidadesPrimeiramente, um sistema de transição de probabilidades baseado em cadeias deMarkov é medido. Este modelo representa a variabilidade espacial existente juntamentecom os dados da imagem.
A estrategia proposta é calcular uma matriz 𝑇, onde cada componente é a função𝑡𝑖𝑗(ℎ𝜑) a qual modela a probabilidade de uma classe 𝑖 de transitar para a classe 𝑗 emuma distância ℎ considerando a direção 𝜑. É necessário obter tal medida para cada parde classes 𝑖 e 𝑗 presente no conjunto de dados.
Neste método, assume-se que os dados são isomórficos. Portanto, para uma dadatransição, todas as direções são consideradas como idênticas. Não obstante, a abordagempode ser utilizada em casos não isomórficos, considerando duas ou mais direções, cadauma com sua própria matriz de probabilidade de transições.
Foi assumido que a transição de probabilidades tem um comportamento exponen-3.4. Nível Local 𝑃𝑙(𝐿|𝑊)55cial, como proposto por (CARLE et al., 1998). As equação 3.3 mostra como calcular atransição de probabilidades entre classes diferentes e também para a mesma classe ( autotransição).
⎧⎪⎨⎪⎩𝑡𝑖𝑗 = 𝑒𝑟𝑖𝑗 ℎ𝜑 + 𝑝𝑖 [𝑖 = 𝑗]⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣se [𝑖 = 𝑗]se [𝑖 ̸= 𝑗]𝑡𝑖𝑗 =(3.3)
𝑡𝑖𝑗 = 𝑝𝑗 − 𝑒−𝑟𝑖𝑗 ℎ𝜑 [𝑖 ̸= 𝑗]A função de transição na Equação 3.3 também depende da distância ℎ e da probabilidadea priori da classe 𝑝𝑗. Cada fator 𝑟𝑖𝑗 é um componente da matriz 𝑅 Essa matriz é a taxade transição entre as classes, para 𝑘 classes, 𝑅 pode ser calculada como:⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦... 𝑟1𝑖.
.
.
𝑟𝑗𝑖.
.
... 𝑟𝑘𝑖𝑟11.
𝑟𝑗1.
𝑟𝑘1... 𝑟1𝑘.
.
.
𝑟𝑗𝑘.
.
... 𝑟𝑘𝑘(3.4)
𝑅 =Cada elemento da matriz representa a taxa na qual ocorre a transição, sendo assim:𝑟𝑖𝑗 = 𝜕𝑡𝑖𝑖(0))(3.5)
𝜕ℎA matriz 𝑇 não pode ser diretamente calculada a partir dos dados (AGTERBERG,1988). Para tal, primeiramente, é necessario estimar a matriz 𝑅. Carle et al. (1998),propõem obter o calculo de 𝑅 através da multiplicação elemento a elemento das medidasda correlação entre as configurações espaciais diretas (𝑅𝑚𝑒𝑠) e da medida de conceitosestatísticos (𝑅𝑚𝑜𝑑) extraídos das imagens:𝑅 = 𝑅𝑚𝑒𝑠 * 𝑅𝑚𝑜𝑑.
(3.6)
Esta foi a técnica adotada neste trabalho para calcular 𝑅, porém com algumasmodificações. Na seção a seguir, mostra-se o processo para calcular as matrizes 𝑅𝑚𝑒𝑠 e𝑅𝑚𝑜𝑑.
3.4.1.1 Taxa de Transição Medida 𝑅𝑚𝑒𝑠𝑅𝑚𝑒𝑠 é calculado medindo a frequência de transição cumulativa da matriz 𝐹. Paracomputar 𝐹, foi somado o número de vezes que cada classe transita para cada outra classe.
Foi considerado um conjunto de direções e um conjunto de distâncias ℎ. Tal treinamento éfeito em um conjunto de imagens já previamente classificadas. Este processo é apresentadona Figura 14. Foi utilizado um kernel de janela deslizante que iterativamente se deslocaao longo de toda a imagem.
56Capítulo 3. Classificação Baseada em Contexto utilizando GeoestatísticaPara cada posição do kernel, foram contadas todas as transições que o rótulo doponto central do kernel faz. Isto é feito para diversas distâncias, o qual é representadopelos quadrados coloridos da Fig. 14. Ao final, cada linha de 𝐹 é normalizada.
Figura 14 – Medida feita do número de transições que uma classe faz para cada outrapara múltiplas distâncias. Foi utilizada um kernel móvel e foram contadas as transiçõesdesde o centro (ponto vermelho) para todas as direções (representado pelos quadrados)A equação 3.7 mostra um exemplo da matriz 𝐹 feitas para um "dataset” exemplo.
⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦0.762 0.007 0.037 0.060 0.132
0.639 0.066 0.048 0.061 0.184
0.607 0.010 0.214 0.052 0.115
0.594 0.006 0.032 0.261 0.104
0.642 0.010 0.036 0.054 0.255
𝐹 =(3.7)
A matriz estimada 𝐹 é afetada pelas incertezas nas premissas de probabilidadeassumidas. Por exemplo, a premissa do isomorfismo assumida não é perfeitamente verda-deira. Para reduzir o efeito das incertezas e encontrar um padrão na representação, umaanálise de autovetores e autovalores é aplicada na Eq. 3.7 (CARLE; FOGG, 1996).
A partir disso, é possível computar 𝑅𝑚𝑒𝑠 aplicando a equação 3.8.
𝐿∑︁𝑅𝑚𝑒𝑠 =(3.8)
𝜃𝑘𝑍𝑘𝑘=1onde o termo 𝜃𝑘 de 𝑘 = 1, ..., 𝐿 denota os autovalores de F e 𝑍𝑘 denota os componentesespectrais das matrizes desde a analise de auto-vetores. Foi calculado 𝑍𝑘 como mostradona Eq. 3.9.
∏︀∏︀𝑚̸=𝑘(𝜃𝑘𝐼 − 𝐹)𝑚̸=𝑘(𝜃𝑚 − 𝜃𝑘) 𝑘 = 1, ..., 𝐿
(3.9)
𝑍𝑘 =Esta computação consiste em uma medida inicial que congrega as tendências deverossimilhança espacial entre as classes. Contudo, esta medida ainda contém muita im-3.4. Nível Local 𝑃𝑙(𝐿|𝑊)57precisão para ser usada como entrada para a simulação. A medida pode ser ainda maisestabilizada adicionando a computação de 𝑅𝑚𝑜𝑑 assim como mostrado na Eq. 3.6.
3.4.1.2
Calculo da Matriz 𝑅𝑚𝑜𝑑Computa-se 𝑅𝑚𝑜𝑑 utilizando estatísticas extraída dos dados, como: proporções dasclasses, comprimentos médios das classes e as tendências de justaposição.
A proporção de uma classe 𝑙𝑖 é a probabilidade a priori desta classe aparecer. Em
outras palavras, a proporção é a chance de selecionar uma parcela da classe 𝑙𝑖 aleatoria-mente da imagem classificada (CARLE; FOGG, 1996).
O comprimento médio é calculado pela quantidade média de pixeis contínuos deuma certa classe ao longo de uma determinada direção. Como assume-se isomorfismo nosdados, esta direção é arbitraria. Considerando em termos de transição de probabilidades,o comprimento médio 𝐿ℎ𝜑 é a taxa de decaimento da curva de transição da função 𝑡𝑖𝑖(ℎ𝜑)na direção 𝜑 . O comprimento médio é mostrado na equação 3.10.
= 1𝐿ℎ,𝜑−𝜕𝑡𝑖𝑖(0))(3.10)
𝜕ℎIsso é análogo a taxa de uma classe transitar para si mesma, como mostrado naEq. 3.11 (CARLE; FOGG, 1996).
˜𝑟𝑖𝑖 = − 1𝐿ℎ,𝜑(3.11)
O conceito de tendência de justaposição modela as probabilidades de uma classetransitar fora de si mesmo e depois em outra dado uma distância. Considerando 𝑟𝑖𝑖 comoa taxa que a uma certa classe transita para si mesma, 𝑟𝑖𝑗 depende das proporções de 𝑗como mostrado na Eq. 3.12.
𝑝𝑘˜𝑟𝑗,𝑘(ℎ𝜑) =(3.12)
𝐿𝑗𝜑(1 − 𝑝𝑗)Para o caso de um dataset de cinco classes, a matrix 𝑅𝑚𝑜𝑑 tem a seguinte estrutura:⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦˜𝑟111𝐿22˜𝑟32˜𝑟42˜𝑟52˜𝑟13˜𝑟231𝐿33˜𝑟43˜𝑟53˜𝑟14˜𝑟24˜𝑟341𝐿44˜𝑟54˜𝑟15˜𝑟25˜𝑟35˜𝑟451𝐿551𝐿11˜𝑟21˜𝑟31˜𝑟41˜𝑟51𝑅𝑚𝑜𝑑 =(3.13)
Finalmente, usando 𝑅𝑚𝑒𝑠 e 𝑅𝑚𝑜𝑑 é possível computar a Eq 3.6. Na Figura 15são mostradas as transições de probabilidades calculadas para um dataset. Os gráficos58Capítulo 3. Classificação Baseada em Contexto utilizando Geoestatísticada Figura 15 foram computados aplicando a Eq. 3.3 variando a distância ℎ. Como umexemplo, pode-se perceber que o comprimento médio da classe background é bem alto.
Isso acontece por que o seu decaimento exponencial é muito baixo.
Figura 15 – A transição de probabilidade modelada para um determinado dataset. O
eixo y apresenta a distância em pixeis. As linhas verdes mostram as proporções para cadaclasse. Pode-se observar uma certa tendência na classe Urchin em transitar para categoriade background. Ainda, percebe-se que a classe de background tem um grande comprimentomédio, dado que sua taxa de decaimento é bastante alta.
3.4.2 Sequential Indicator SimulationDado que a matriz de transição 𝑇 já foi calculada para um dataset, o algoritmoSequential Indicator Simulation (SIS) tenta simular o 𝑃𝑙(𝐿|𝑊) de um superpixel com baseem sua vizinhança espacial. Para simular os fatores locais de um certo superpixel 𝑥0, umcerto número 𝑁 de posições aleatórias amostradas 𝑥𝛼 são computados em torno da regiãoem um raio 𝑟. Cada uma das posições amostradas vai contribuir para o computar o fatorlocal, sendo que a contribuição é feita de forma a minimizar a variança desta vizinhançacom respeito ao modelo.
Com isso, a probabilidade relacionada com o contexto espacial para cada classe 𝑘3.4. Nível Local 𝑃𝑙(𝐿|𝑊)59em uma certa parcela 𝑥0 é computada como:𝑁∑︁𝐾∑︁𝑃𝑙(𝑥0 = 𝑘|𝑃𝑢(𝑋𝛼)) = 𝑃𝑢(𝑥0 = 𝑘)𝑃𝑢(𝑋𝛼 = 𝑗)𝑤𝑗𝑘,𝛼(3.14)
𝛼=1𝑗=1onde 𝑃𝑢 é a probabilidade a priori (unário) de uma região, sendo 𝑃𝑢(𝑋0 = 𝑘) o superpixelem questão e 𝑃𝑢(𝑋𝛼 = 𝑗), os amostrados. 𝑤𝑗𝑘,𝛼 é o peso da posição 𝛼 para a classe 𝑗transitar para a classe 𝑘. Ou seja a probabilidade local de um superpixel é função dadistribuição do mesmo (𝑃𝑢(𝑋0 = 𝑘)) e o quanto cada posição amostrada contribui para∑︀𝐿𝑗=1 𝑃𝑢(𝑋𝛼 = 𝑗)). O fator é controlado pelo peso 𝑤𝑗𝑘,𝛼.
este superpixel (∑︀𝑁𝛼=1Os pesos para cada posição amostrada formam o conjunto de matrizes 𝑊𝑁 e sãocalculados resolvendo o sistema linear da Eq. 3.15 :⎡⎢⎢⎢⎣ 𝑇(𝑥1 − 𝑥1)⎤⎥⎥⎥⎦⎡⎢⎢⎢⎣ 𝑊1⎤⎥⎥⎥⎦⎡⎢⎢⎢⎣𝑤11,𝛼⎡⎢⎢⎢⎣ 𝑇(𝑥0 − 𝑋1)⎤⎥⎥⎥⎦ (3.15)
... 𝑇(𝑥𝑁 − 𝑥1).
... 𝑇(𝑥𝑁 − 𝑥𝑁)=.
.
.
.
𝑇(𝑥1 − 𝑥𝑁)𝑇(𝑥0 − 𝑋𝑁)𝑊𝑁⎤⎥⎥⎥⎦onde:... 𝑤1𝐿,𝛼.
𝑊𝑖 =(3.16)
.
.
𝑤𝐿1,𝛼 ... 𝑤𝐿𝐿,𝛼A Figura 16 mostra o exemplo de um superpixel arbitrário e sua respectiva regiãoamostrada, para a computação do potencial local. Para tal região a Eq. 3.15 será aplicadade forma a encontrar o peso para cada uma das posições. O peso encontrado é o quetornaria a região o mais homogênea possível.
3.4.3 Computando o Potencial Final 𝑃(𝐿)Depois de obter uma saída da curva de confiança para cada superpixel, primeira-mente se busca os superpixeis com uma saída bem alta de confiança. Foi decido computaro potencial local apenas para superpixeis onde a confiança está abaixo de um limiar 𝑡. O
limiar é selecionado como a confiança máxima, dado pelo conjunto de validação.
O processo do SIS é repetido para cada superpixel presente na imagem em ordemaleatória e os pesos já são atualizados. Isso garante que a correlação entre a própriavizinhança seja considerada.
Os pesos são obtidos diretamente pela Eq. 3.15. Dois parâmetros devem ser escolhi-dos para este método, o número de amostras 𝑁 e o raio 𝑟 onde vai ser feita a amostragem.
Experimentos preliminares mostraram que não existe vantagem pratica em usar mais de60Capítulo 3. Classificação Baseada em Contexto utilizando GeoestatísticaFigura 16 – Exemplo de uma vizinhança sendo considerada para um superpixel ( apontadoem vermelho). Um raio 𝑟 é considerado e 𝑁 pontos são amostrados nessa vizinhança ( emazul). Cada um dos pontos amostrados irá influenciar no potencial do superpixel apontadoem vermelho.
25 amostras. Também, o raio 𝑟 passa e se tornar irrelevante a partir de uma certa dis-tância, dado que às transições de probabilidade tendem a ser iguais as proporções nolimite.
3.5 Geoestatística e CRFTanto as abordagem de CRF, quanto de Geoestatística (GS) tentam minimizaruma função que tenta impor uma certa homogeneidade espacial. Ou seja, superpixeispróximos tendem a ser da mesma classe. A diferença é que o modelo de Geoestatística ébaseado em uma amostragem o que torna o problema da inferência mais simples. O modelode GS é também análogo a um CRF densamente conectado (KOLTUN; VLADLEN, 2011),mas com amostragens mais esparsas.
A abordagem de GS pode ser vista como uma representação mais esparsa do CRFporém, com medidas estatísticas mais ricas. Não obstante, a computação da matriz depesos 𝑊 para a Eq. 3.14 pode ser considerado como a minimização de uma função deenergia, usando uma soma ponderada.
Como uma forma de comparar ambos os métodos, a Figura 17 mostra o modeloGS como um modelo gráfico probabilístico. O vértice central, em verde claro, é o casoatual sendo calculado. Os vértices em verde escuro são aqueles amostrados. Cada verticeem verde escuro contribui para a distribuição do vertice central dependendo das proba-bilidades de transição estimadas da Fig. 15. Em vermelho são representados os fatores613.6. Sumáriounários de cada quadrado em azul é a contribuição desses mesmos ( fatores locais).
Figura 17 – Representação gráfica do modelo de Geoestatística (GS). Os fatores locaissão representados em azul e usam a estatística de probabilidade de transição computadapela Eq. 3.3. Diferentemente do que no modelo da Fig. 7, vizinhos de diferentes distânciastambém contribuem para calcular a distribuição de cada posição.
3.6 SumárioNeste Capítulo apresentou-se um novo método para adição de contexto na classifi-cação. O método foi inspirado nas técnicas de modelagem da variabilidade espacial usadaem Geoestatística.
Foi feita, por fim, uma comparação do método proposto com o CRF. Acredita-se que o método apresentado neste capítulo tende a se comportar melhor que o CRFquando existem menos dados de treinamento, e os mesmos dados não possuem padrõesbem definidos, como no caso do ambiente subaquático. Isso pode ser atingido visto queo método proposto estima padrões de forma para as classes. Sendo assim as relações decorrelação espacial, são também estimadas com base em um modelo para as classes. O
método proposto será testado e avaliado no Capítulo 6.
634 Classificação de Imagens do AssoalhoOceânicoNeste Capítulo é apresentado o domínio de aplicação no qual será aplicado ométodo de adição de contexto proposto no Capítulo 3.
Como apresentado na introdução, o conhecimento sobre as espécies presentes nofundo do mar, especialmente os recifes de corais, é de fundamental importância para osespecialistas na área.
Ao se fazer monitoramento do assoalho oceânico, assim como para o caso do sen-soriamento remoto, é interessante ser capaz de rotular automáticamente cada pixel dasimagens e assim ser capaz de medir propriedades relevantes. O objetivo desta classifica-ção é fazer os chamados mapas temáticos. Tais mapas são a representação final de ummapa classificado de uma imagem, feito de forma visualmente interpretável. Mapas temá-ticos agregam grandes conjuntos de imagens em mosaicos representando áreas de grandeextensão.
Considerando o ambiente subaquático, suas propriedades fotométricas demandamum tratamento especial para contornar a degradação da imagem. Esses desafios própriosdo meio não são comumente endereçados na literatura. Tais propriedades causam proble-mas como bordas confusas entre objetos, variação na qualidade da imagem, etc.
Neste capítulo primeiramente é formalizada as propriedades do meio subaquático,o que sera útil também para capítulos posteriores. Depois, é apresentada uma visão geraldos principais sistemas utilizados para classificação de mosaicos do assoalho oceânico.
Entre os sistemas apresentados, um em especial será detalhado, o qual será utilizadocomo um estudo de caso para adição de contexto.
4.1
Propriedades de Imagens SubaquáticasDe forma a obter imagens capturadas em ambiente subaquático com uma melhorqualidade visual, é fundamental o entendimento de sua formação, levando em conta osaspectos específicos que ocorrem no meio subaquático.
Um modelo de formação de imagens busca descrever os caminhos pelos quais a luzpassa, desde a fonte até a sua captura, onde é formada a imagem. A Figura 18 ilustraeste processo de propagação. Em meios participativos, a irradiação, ou seja, a quantidadede energia luminosa em um pixel, pode ser obtida pelo somatório de três componentes asquais chegam por caminhos distintos. A componente direta, a qual contém a luz sem es-64Capítulo 4. Classificação de Imagens do Assoalho Oceânicopalhamento que veio diretamente do objeto. Muitas vezes, informações que vinham de umúnico ponto são espalhadas entre seus pontos vizinhos causando um efeito de borramentona imagem. Este fenômeno é chamado espalhamento dianteiro (forward scattering),representado pela componente forward scattering. O forward-scattering faz com que asinformações visuais da cena fiquem espalhadas, causando um efeito de borramento.
Figura 18 – Três trajetórias da luz até o plano da imagem. O componente direto, con-tendo a informação direta da cena. O forward-scattering, contendo informação da cenaespalhada. Por fim, o backscattering contendo informações de fora da cena.
Por último, tem-se a componente de backscattering, a qual luz chega no plano daimagem a partir de um ponto que não faz parte da cena observada. Isso acontece devidoà alguma partícula flutuante que desvia a trajetória da luz para o plano da imagem. O
backscattering se comporta tal como um ruído aditivo.
Para calcular cada uma das componentes, algumas simplificações devem ser con-sideradas. Tais simplificações visam tornar o modelo mais simples e tratável computacio-nalmente, ressaltando somente alguns aspectos principais na formação da imagem.
Primeiramente, se assume o objeto como tendo sua reflectividade uniforme. Assume-se uma iluminação completa e uniforme da cena. Por fim, pode-se descartar os parâmetrosda câmera e considerar a captura da luz como sendo também uniforme.
Normalmente o efeito causado pelo forward-scattering tende ser desprezado, porcontribuir com uma participação menor que o backscattering na formação da imagem(TREIBITZ; SCHECHNER, 2006).
A descrição final do modelo é dada pela equação de Koschmieder (KOSCHMI-EDER, 1924), bastante utilizada para a propagação da luz na névoa. Sendo assim, a654.1. Propriedades de Imagens Subaquáticasformação de um ponto (𝑥, 𝑦) na imagem é dado por:𝐼(𝑥, 𝑦) = 𝐽(𝑥, 𝑦) 𝑒−𝑐𝑧(𝑥,𝑦) + 𝐵∞(1 − 𝑒−𝑐𝑧(𝑥,𝑦)),(4.1)
Sendo 𝐽(𝑥, 𝑦) a imagem sem degradação e 𝑧(𝑥, 𝑦) uma função da distância paracada ponto na imagem. Essa equação pode ser interpretada da seguinte forma: quantomais distante estiver o objeto maior será o componente backscattering, menos da cena realirá existir na imagem.
Sabe-se que, devido as propriedades do meio subaquático, existe uma diferença sig-nificativa entre a absorção e espalhamento dos comprimentos de onda (DUNTLEY, 1963)Desta forma, o modelo pode ser estendido de forma incorporar diferentes comprimentosde onda. A equação 4.1 modela a quantidade de luminosidade capturada relativa a umdeterminado pixel. Porém é possível adequá-la para diferentes comprimentos de onda, ouno caso do padrão RGB de representação, dividi-la em três canais conforme a equação4.2,
𝐼 𝜆(𝑥, 𝑦) = 𝐽 𝜆(𝑥, 𝑦) 𝑒−𝑐𝜆𝑧(𝑥,𝑦) + 𝐵𝜆∞(1 − 𝑒−𝑐𝜆𝑧(𝑥,𝑦)), 𝜆 𝜖 {𝑅, 𝐺, 𝐵}(4.2)
A Figura 19 apresenta uma típica imagem com alto nível de turbidez. Turbidez éuma propriedade comum no meio aquático que esta relacionada com a quantidade de luzque é absorvida ou espalhada ao invés de ser transmitida em uma linha reta (OMAR;MATJAFRI, 2009).
Figura 19 – Imagem de exemplo para as degradações do ambiente subaquático. É possívelver que existe uma variação conforme a distância e uma perda significativa da informaçãode cor.
66Capítulo 4. Classificação de Imagens do Assoalho OceânicoÉ interessante observar que a degradação não afeta uniformemente a imagem.
Existem níveis de degradação mais altos de acordo com a distância. Além disso, o com-primento de onda vermelho tende a se perder rapidamente, tendo a cor verde nesse casocomo predominante.
Por fim, vale notar que, fenômenos adicionais também acontecem. Um exemplo éo efeito da "neve submarina", a qual causa aparecimento de pequenos pontos brancos naimagem. Por estes e outros fatos é relevante constatar que o meio subaquático já tem umaalta presença de ruído (BAZEILLE et al., 2006).
4.2 Classificação Autônoma de Imagens do fundo OceânicoA Figura 20 mostra uma adaptação do que é usado pela maioria dos frameworksem visão computacional para criação de mapas temáticos de mosaicos em ambientessubaquáticos (SHIHAVUDDIN et al., 2013).
Figura 20 – A sequência utilizada para classificação de imagens em meio subaquático.
Para classificar os objetos de uma imagem é necessário passar por diversas etapas.
A seguir são listadas as etapas apresentando algumas das técnicas usadas na literatura:∙ Pré-processamento: etapa fundamental em ambientes subaquáticos. Normalmente éonde correções de cor (PIZARRO et al., 2008) e contraste (JOHNSON-ROBERSON;KUMAR; WILLAMS, 2007) são aplicadas para atenuar a degradação e ressaltaraspectos importantes das imagens subaquáticas.
∙ Segmentação: Nesta etapa a imagem é super-segmentada em regiões com proprie-dades similares. Tal etapa pode ser evitada, para o caso onde ocorre uma seleçãomanual do que ser classificado.
∙ Extração de Descritores: é onde as características relevantes para cada segmentosão extraídas e representadas. Diversas abordagens são utilizadas, um exemplo seriao uso de descritores locais e bag-of-words por Pizarro, Eustice e Singh (2004). Os
674.2. Classificação Autônoma de Imagens do fundo Oceânicodescritores de textura e cor são bastante utilizados no meio subaquático (BEIJBOMet al., 2012) (STOKES; DEANE, 2009), (MARCOS; SORIANO; SALOMA, 2005).
∙ Classificação: é onde se realiza o treinamento do classificador e classificação para ostestes. Diversos classificadores são utilizados como o SVM (PIZARRO; EUSTICE;SINGH, 2004) ou o LDA (MARCOS; SORIANO; SALOMA, 2005).
∙ Pós-processamento: é onde informações adicionais são utilizadas para refinar o resul-tado da classificação. Em (SHIHAVUDDIN et al., 2013) é feito um simples sistemade votação para verificar a consistência da vizinhança No caso, até onde se sabe, nãoocorreram outras aplicações de técnicas mais elaboradas para adição de contexto.
Nesta seção é especificado em detalhe cada etapa apresentada elucidando o quefoi utilizado por Shihavuddin et al. (2013) para geração de mapas temáticos. Tal métodofoi escolhido como base para aplicação de técnicas para adição de contexto. O mesmo foiescolhido devido a alta taxa de acerto na classificação quando comparados com diversosmétodos do estado da arte (SHIHAVUDDIN et al., 2013). Os algoritmos usados em cadauma das etapas da Figura 20 são elucidados a seguir.
4.2.1 Pré-ProcessamentoO processo de pré-processamento almeja deixar a imagem o mais próxima possívelda cena em qual a mesma foi capturada. Isso é feito tanto no escopo radiométrico quantogeométrico. Ou seja, o objectivo é tornar, as estruturas geométricas , seu brilho e cor omais próximos possível da cena (GONZALEZ; WOODS, 2006).
Para lidar com o processamento embaixo d’água, primeiramente, precisa-se consi-derar todos os princípios básicos de propagação da luz nesse meio os quais foram colocadosna Seção 4.1. (SCHETTINI; CORCHS, 2010)Seguindo a ideia de que a qualidade visual subjetiva é importante, pode-se melhor aqualidade de imagens subaquáticas utilizando técnicas que abordam diretamente os efeitosdegradantes apontados. Esta seção apresenta as alternativas existentes para corrigir cadaum dos tipos de degradação.
4.2.1.1 ContrasteObserva-se pela Equação 4.1 que o processo de degradação da imagem em ambientesubaquático não é uniforme ao longo da imagem. O mesmo depende da distância de cadaponto a câmera.
Nesse contexto, o Shihavuddin et al. (2013) faz o uso do CLAHE (Contrast LimitedAdaptative Histogram Equalization) (ZUIDERVELD, 1994) para correção de contraste.
68Capítulo 4. Classificação de Imagens do Assoalho OceânicoTal método faz uma construção de histograma diferente para cada segmento da imageme aplica uma equalização de histograma somente nesse segmento. Além disso, o métodocoloca um limite de intensidade maxima, redistribuindo todos as intensidades que ficamacima deste limite.
4.2.1.2 Correção de CorComo mostrado na seção 4.1, existe uma não uniformidade na absorção de cadacomprimento de onda no ambiente subaquático. Isso causa que boa parte da informaçãocromática da cena seja perdida.
De forma a obter cores mais próximas de realidade existe a necessidade de estimartais diferenças de absorção. Uma das formas de resolver isso é considerar que é possí-vel obter as diferenças de absorção considerando essas diferenças como uma questão deestimativa da fonte de luz. Colocado de tal forma, o problema, se torna basicamente aaplicação de algoritmos de balanceamento de branco, os quais podem ser uma simplesnormalização.
O método de (SHIHAVUDDIN et al., 2013) aplicou a premissa de que que oponto de maior intensidade da imagem foi causado por reflexão perfeita. Desta forma ailuminação pode ser estimada achando o ponto de maior intensidade da imagem. Sendoassim, para tornar a cor da imagem balanceada, o ganho para cada pixel pode ser dadocomo:𝑅𝑔𝑎𝑛ℎ𝑜 = 1/𝑅𝑚𝑎𝑥𝐺𝑔𝑎𝑛ℎ𝑜 = 1/𝐺𝑚𝑎𝑥𝐵𝑔𝑎𝑛ℎ𝑜 = 1/𝐵𝑚𝑎𝑥(4.3)
4.2.2 SegmentaçãoDiversos desafios em classificação de imagens colocam o desafio atual como classi-ficar os objetos pixel a pixel (FULKERSON; VEDALDI; SOATTO, 2009).
O caso da aplicação em sensoriamento remoto, claramente se beneficia deste fato,onde cada pixel da imagem é relevante. A questão é que, devido ao custo computacional,e ao fato que somente um pixel não possuir grande significado semântico para efetuara classificação e extrair os descritores, muitas vezes a abordagem de usar segmentos daimagem, ajuda a melhorar a consistência.
Existe e a tendência de muitos autores fazer uma pré-segmentação, a qual aparen-temente não esta relacionada com a classificação final. Porém, tal segmentação ajuda aa garantir que cada parte da imagem sendo classificada tenha uma homogeneidade local.
Tal segmentação é chamada de segmentação em superpixeis.
694.2. Classificação Autônoma de Imagens do fundo OceânicoPara o caso da abordagem de Shihavuddin et al. (2013), os superpixeis são utiliza-dos como estrutura de interação. A imagem é definida como um conjunto de superpixeisa serem classificados.
Diversos algoritmos existem para a criação de superpixeis. Porém, Shihavuddin etal. (2013) selecionou aquele que tende a manter uma estrutura o mais regular possível.
No caso foi utilizado os Turbopixels (LEVINSHTEIN et al., 2009) .
4.2.3 DescritoresPara descrever a imagem foi utilizado majoritariamente descritores de textura.
Textura pode ser definida como a variação dos dados visuais em escalas menores que aescala observada (PETROU; GARCÍA-SEVILLA, 2006).
O assoalho submarino é tipicamente texturizado. Observou-se diversos bancos dedados de corais, e outras estruturas encontradas no meio, e percebe-se que existem sem-pre oscilações na estrutura dos objetos em diferentes escalas. Tal fenômeno caracteriza aexistência da textura. Além da tendência existente na literatura em usar textura (SHIHA-VUDDIN et al., 2013).
Com isso em vista, (SHIHAVUDDIN et al., 2013) utiliza três descritores como des-critores de texturas: Gabor Filter, Grey Level Co-occurence Matrix (GLCM) e CompletedLocal Binary Pattern (CLBP).
Os Gabor Filters são um grupo de Wavelets 2D que tomam forma de uma gaussiana2D modulada no espaço 2D (PORTER; CANAGARAJAH, 1997). Basicamente são umarepresentação da variação de frequência em um segmento da imagem.
O GLCM (HARALICK; SHANMUGAM; DINSTEIN, 1973), utiliza a represen-tação de padrões de variações espaciais dos segmentos da imagem em uma matriz, querepresenta a variação de intensidade dos pixeis em diferentes ângulos e distâncias. Diver-sos indicadores são computados a partir dessas matrizes como a média de variações ou aentropia.
O CLBP (GUO; ZHANG, 2010), é um descritor de textura invariante a rotação oqual retrata, principalmente, a variação de sinais de um pixel central para com pixeis aoredor em uma determinada posição.
A utilização de cor é complexa dado a perda de cor não uniforme entre os compri-mentos de onda como mostrado na Seção 4.1. Porém ainda é possível utilizar um descritorde cor que possui propriedades importantes como robustez a variações fotométricas causa-das por sombras, sombreamento e também mudanças geométricas como escala e alteraçãode ponto de vista. (SHIHAVUDDIN et al., 2013) utiliza o trabalho de (WEIJER; SCH-MID, 2006) que aproximou tais propriedades.
70Capítulo 4. Classificação de Imagens do Assoalho OceânicoAo final, ao utilizar múltiplos descritores, se tem uma representação da imagemcom uma grande quantidade de dimensões e muitas vezes com um padrão pouco evidente.
Para resolver isso é aplicado normalizações e modificações nos descritores. Por exemplo,os descritores podem ser manipulados de forma que os mesmos sejam o mais próximos ase tornaram linearmente separáveis. Essa modificação é fundamental para se melhorar aqualidade da classificação. Por fim, os descritores são normalizados de forma a que todosos descritores estejam numa escala compatível.
4.2.4 Treinamento e ClassificaçãoO treinamento foi feito utilizando três classificadores distintos de forma mutu-almente exclusiva. Foram utilizados o Support Vector Machine (SVM), o K-nearest-neighbors e o PDWMD proposto por (STOKES; DEANE, 2009). Cada um destes classi-ficadores foi utilizado dependendo das características dos dados.
Dado que o aprendizado foi feito, novos dados podem ser classificados. É feitoum mapa temático baseado na segmentação em superpixeis. Sendo que cada superpixel éclassificado individualmente.
4.3 ConclusõesNeste capítulo apresentou-se o cenário onde vai ser feito o estudo desta dissertação.
Também se apresentou alguns métodos os quais já fizeram classificação de imagens dobentos.
No capítulo 6 serão apresentados os resultados de aplicação do método de (SHIHA-VUDDIN et al., 2013) e será feito o estudo sobre a incorporação de contexto para essemétodo.
715 Testes e Resultados 1: Detecção de Pontosde Interesse em Ambiente SubaquáticoUma das principais contribuições desta dissertação foi a criação de um experi-mento para analizar e compreender o comportamento dos detectores de pontos de interessequando utilizados em ambiente subaquático.
Como apresentado no Capítulo 1, diversos detectores foram desenvolvidos paraserem invariantes a uma serie de fenômenos. A ideia é que o mesmo ponto de interessepossa ser encontrado independentemente de diversas circunstâncias da cena.
Porém, existem fenômenos adicionais que atuam sobre a cena no ambiente su-baquatico os quais devem ser considerados. Quando a luz se propaga neste meio, ela éabsorvida e espalhada pelos diferentes coeficientes de refração encontrados nas particulaspresentes no meio. Isso espalha a informação capturada e cria o efeito de "enevoado"naimagem. Tais fenômenos foram descritos mais detalhadamente no Capítulo 4, Seção 4.1.
Um estudo feito por Garcia e Gracias (GARCIA; GRACIAS, 2011), comparouos detectores de pontos de interesse mais populares na literatura. Eles encontraram queestruturas do tipo blob, obtidos por métodos baseados em Hessian (BEAUDET, 1978),por exemplo, são melhores detectadas tanto para o caso de métodos invariantes a escalacomo os de única escala. A justificativa é que a turbidez da água tende a suavizar quinas eborrar regiões definidas, fazendo com que métodos como Harris (HARRIS; STEPHENS,1988) ou Harris-Laplace (MIKOLAJCZYK; SCHMID, 2004) sejam menos propícios parao ambiente. Entretanto, eles avaliaram somente algumas estruturas em uma única cena.
É do interesse desta dissertação melhorar este estudo. Neste contexto, alguns principaisobjetivos são buscados.
Foi proposto um novo dataset no qual é possível utilizar diferentes estruturassubmarinas obtidas através da impressão de fotos subaquáticas. Estas estruturas foramrefotografadas dentro de um tanque de água onde imagens com a degradação controladaforam produzidas. Isso é uma melhoria a tentativas anteriores em termos de diversidadede elementos visuais. Considerando que a degradação causada por imagens com baixa ealta turbidez não é linear, uma contribuição é dividir a análise em diferentes intervalosde turbidez.
Foram testados detectores de pontos de interesse, considerando diferentes aborda-gens, com respeito a sua robustez a degradação causada pela turbidez. Foi focado inves-tigar o problema de que detectores invariantes a escala tendem a ter baixa performance(GARCIA; GRACIAS, 2011). Isto é feito através da análise de diferentes espaços de es-72Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente Subaquáticocala. Finalmente, foi indicado o melhor detector invariante para imagens subaquáticascomo sendo o DoG (LOWE, 2004).
Este Capítulo está organizado da seguinte maneira. A seção 5.1 apresenta a des-crição completa do experimento a ser realizado. Tal seção mostra todos os detalhes daexperimentação necessários para que o mesmo seja bem sucedido. Também explica to-das as considerações feitas para se ter dados aceitaveis. Por fim, a Seção 5.3 mostra osresultados obtidos para tal experimento, e apresenta uma discussão sobre os resultadosencontrados.
5.1 Descrição do experimentoNa literatura, poucos são os trabalhos que analisam o comportamento dos detec-tores de pontos de interesse em ambiente subaquático. Nesta seção, descreve-se todo oprocesso de realização do experimento para que ele seja completamente reproduzível.
Neste experimento foram capturadas diversas imagens em uma cena onde a únicamodificação entra as cenas é a degradação causada pela turbidez. O objetivo fundamentaldo experimento é tentar obter o máximo de isolamento desta degradação possível. Paratal, a câmera utilizada deve estar estática e a iluminação deve ser controlada.
5.1.1 Cena MontadaConstruí-se uma cena onde as imagens foram colocadas. A Figura 21 mostra aespecificação da cena.
Figura 21 – A cena criada para avaliar os algoritmos de avaliação de features. Ela é com-posta por lampadas fluorescentes e uma camera fotografando fotos impressas do assoalhodo oceano.
Na cena montada existe uma fotografia a ser capturada por uma câmera posicio-nada a uma distância perpendicular de 0.58𝑐𝑚 . A fotografia esta posicionada em uma735.1. Descrição do experimentocaixa de água de mil litros. Duas luminárias usando lâmpadas fluorescentes brancas foramposicionadas perto do tanque.
Três fotografias diferentes foram utilizadas, representando o fundo do mar captu-rado nas Bahamas em condições próximas ao ideal de turbidez (ZVULONI et al., 2009). As
diferentes cenas contém os mais variados tipos de textura que podem ser encontradas noambiente subaquático e também objetos feitos pelo homem. As fotografias foram impres-sas usando um "ploter"a laser usando uma mídia de vinil adesivo fosco e a prova d’água.
Cada fotografia foi impressa num tamanho de 91cm X 60 cm e possuem 4928x3264 pixeisde resolução. O diferencial desta deste dataset é que ele contém verdadeiras estruturasdo assoalho oceano, e ainda algumas estruturas feitas pelo homem, sendo o seu princi-pal problema, a perda de resolução devido a impressão e a refotografia. Isso cria umaperda de resolução de 20 𝑝𝑖𝑥𝑒𝑙𝑠/𝑚𝑚2 para 4 𝑝𝑖𝑥𝑒𝑙𝑠/𝑚𝑚2 e adição de algumas pequenasimperfeições devido a erros de impressão.
A Figura mostra as imagens que foram impressas, nomea-se cada uma das imagenscomo 𝑃1, 𝑃2 e 𝑃3.
A câmera utilizada para a captura foi uma Gopro Hero 3 Black edition. Cadaimagem foi capturada em uma resolução de 12 mega pixels(3000x4000).
5.1.2 ProcedimentoFoi decidido simular principalmente o efeito do fenômeno de backscattering. Sabe-se que os motivos que levam a degradação de uma imagem capturada em meio subaquáticosão complexos (DUNTLEY, 1963). Porém, neste experimento tentou-se isolar o princi-pal fenômeno que causa a degradação na imagem. Um estudo feito por Narasimhan etal. (2006) mostra que uma solução de água e leite integral apresenta um alto grau debackscattering, apontado por alguns como a principal fonte de degradação da imagem(TREIBITZ; SCHECHNER, 2006). Isso é causado pelo maior tamanho das partículas doleite integral que fazem que o ângulo de refração seja maior, aumentando o backscattering.
Foi decidido dividir o experimento em 3 ensaios, cada um contendo uma imagemdiferente.
Cada ensaio foi capturado com 19 níveis de turbidez diferentes, cada um contendouma determinada quantidade de leite. Chamou-se cada nível de turbidez de 𝑇1...𝑇19.
Considera-se 𝑇0 como o nível de turbidez com a imagem limpa. A Tabela 1 mostra os níveisde turbidez e suas respectivas quantidades de leite (Em uma caixa com aproximadamente1000 litros de água).
Para capturar as imagens, a câmera foi setada para capturar uma foto a cada10 segundos. Para cada nível de turbidez foi escolhido um grupo de fotos com o menornível de perturbação. Como explicado no Capítulo 4, Seção 4.1, o meio subaquático é74Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente Subaquático(a) 𝑃1(b) 𝑃2(c) 𝑃3Figura 22 – As imagens utilizadas no teste. As três imagens foram capturadas nas Bahamasem condições de turbidez próximas do ideal em uma resolução de 4928x3264 pixeiscomposto por uma certa quantidade de ruído. Em um ambiente controlado, como o quefoi feito é possível, tendo uma seleção de fotos em um mesmo nível de turbidez 𝑇𝑖, reduziro ruído extraindo mediana entre as imagens iguais (GARCIA; GRACIAS, 2011). Destaforma busca-se reduzir a degradação na imagem por ruídos que podem ter diversas causas755.2. Avaliando a degradação causada pela turbidezImagem (𝑇𝑖) Quantidade de Leite Integral Leite AdicionadoT1T2T3T4T5T6T7T8T9T10T11T12T13T14T15T16T17T18T195 ml10 ml15 ml20 ml25 ml30 ml36 ml42 ml50 ml58 ml66 ml74 ml82 ml90 ml100 ml110 ml120 ml130 ml190 ml5 ml5 ml5 ml5 ml5 ml5 ml6 ml6 ml8 ml8 ml8 ml8 ml8 ml8 ml10 ml10 ml10 ml10 ml60 mlTabela 1 – A quantidade de leite adicionada para cada nível de turbidez simulado.
como erro no sensor da câmera, partículas bloqueando totalmente a passagem da luz, etc.
Tenta-se de certa forma isolar significativamente a degradação por turbidez (IDT), comoo principal fenômeno da cena.
A Figura 23 apresenta as imagens geradas pelo experimento. Neste caso fez-sea distinção entre diversos intervalos de turbidez. Na Figura 23 é mostrado um nível deturbidez por intervalo, para cada imagem.
5.2 Avaliando a degradação causada pela turbidezMedir a quantidade de degradação é fundamental neste experimento de forma acomparar os detectores somente relativo a este fenômeno. A degradação causada pela tur-bidez é dependende da quantidade de particulas em suspenção na água, e também os tiposde particulas em suspenção. Além disso, a quantidade de iluminação e a maneira como acena é iluminada é também fundamental para determinação da degradação causada pelaturbidez.
Este conceito difere do conceito de turbidez que esta relacionado somente com aquantidade de sedimentos flutuantes (SSC) na água os quais espalham a luz. A degradaçãocausada pela turbidez difere pois ela não esta relacionado somente as partículas presentesna água e sim a degradação que o SSC causa na cena, levando em conta os parâmetros76Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente SubaquáticoFigura 23 – As imagens capturadas sob diferentes níveis de degradação devido a turbi-dez, controlado pela adição de leite. Foram fotografadas três fotos impressas diferentes,𝑃1 (primeira coluna), 𝑃2 (segunda coluna) e 𝑃3 (terceira coluna). Na primeira linha foimostrada a imagem limpa (sem leite) para cada foto capturada. A segunda linha apre-senta o intervalo de Baixa Turbidez com por volta de 15ml de leite (𝑇4). O intervalo deMédia Turbidez é mostrado na segunda linha e contém por volta de 50 ml de leite (𝑇10).
Finalmente, na ultima (quarta) linha é mostrado o intervalo com Alta turbidez tendo porvolta de 100 ml de leite (𝑇16). Quantidade de leite setada para uma caixa com 1000 litrosde água.
da câmera e o volume de água iluminado.
Uma forma de medir a turbidez é usando um turbidímetro nefelômetro, o qualmede a turbidez pela quantidade de luz espalhada ao emitir um feixe de laser numaporção da água.
Esta alternativas não é capaz de estimar a degradação causada pela turbidez,que é também dependente da cena. Com essas considerações, Garcia e Gracias (2011)propuseram a utilização de uma variação Structural Similarity Index (WANG et al., 2004),para avaliar a degradação, chamado Structural Degradation Index (SDI). Essa abordagemavalia a degradação pela perda de informação estrutural, o que de fato esta relacionado775.3. Resultadoscom a turbidez. Porém, a mesma não tenta isolar a medição do fenômeno de absorção eespalhamento como principais causadores da degradação.
Neste trabalho utiliza-se a métrica proposta por (GARCIA; GRACIAS, 2011),porém normalizada em função da imagem completamente turva pelo leite. Tal métricaé capaz de medir a porcentagem de degradação em função da imagem onde teve suainformação visual inicial completamente eliminada. O método é explicado na secção 5.3.1
5.3 ResultadosNesta seção são mostradas a comparações entre os detectores. Foram comparadosos seguintes detectores, previamente definidos no Capítulo 1. Para única escala, Harris(HARRIS; STEPHENS, 1988), Hessian (BEAUDET, 1978) e Laplacian (TUYTELAARS;MIKOLAJCZYK, 2008). Com múltiplas escalas avaliou-se Fast Hessian do SURF (BAYet al., 2008) e Difference of Gaussians do SIFT (LOWE, 2004). Foram avaliados tambémoutros detectores com propriedades relevantes. Os três kernels baseados em difusão aniso-trópica do detector KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) e o geradopelo centro e arredores usando estruturas poligonais CenSurE (AGRAWAL; KONOLIGE;BLAS, 2008) usando tanto um polígono convexo de seis lados e um polígono estrelado detambém seis lados.
5.3.1 Procedimento de AvaliaçãoOs resultados são avaliados quanto ao critério de repetibilidade descrito em (SCH-MID; MOHR; BAUCKHAGE, 2000). Tal critério indica a porcentagem dos pontos deinteresse que se repetiram, ou seja, ainda foram encontrados após a aplicação da trans-formação.
Primeiramente computa-se 𝑁 = 1000 pontos de interesse para cada detector naimagem com a turbidez 𝑇0 e para todos os níveis 𝑇1...𝑇19. Os 𝑁 pontos de interesseselecionados são os N melhores pontos de interesse segundo o critério do detector, no casoHessian ou Harris. Na imagem com turbidez 𝑇0 é selecionada cada ponto-chave e é testadose esse ponto é resistente na presença de turbidez. Para esse ponto-chave ser resistente énecessário que o mesmo seja encontrado nas imagens turvas sem sofrer um deslocamentomaior que um fator de 𝑒 = 5 pixeis. Esse valor é determinado de forma a escolher somenteos melhores pontos de interesse. Subsequentemente, para determinar a repetibilidade deum certo detector, o número de pontos chaves encontrados em cada imagem túrbida sãocontados. Considerando essa questão, a repetibilidade quanto ao degradação por turbidez78Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente Subaquático(𝑅) é calculada como:𝑅 = 𝑁𝑖𝑁0(5.1)
Onde 𝑁0 é o número de pontos de interesse na imagem limpa (capturada em 𝑇0) e 𝑁𝑖 éa imagem com a degradação estimada.
Para medir a degradação causada pela turbidez, foi usado uma versão diferente doSDI (WANG et al., 2004) (GARCIA; GRACIAS, 2011). O índice SDI não responde comos mesmos valores para as mesmas quantidades de turbidez. Por esta razão, foi utilizadouma versão normalizada do SDI. Considerando a imagem 𝑇19 como sendo totalmentedegradada, pode-se medir o SDI como uma percentagem da degradação máxima, o quefacilita a comparação:𝑁 𝑆𝐷𝐼𝑖 = 𝑆𝐷𝐼𝑖/𝑆𝐷𝐼𝑁(5.2)
Onde 𝑆𝐷𝐼𝑁 é o índice de degradação da imagem 𝑇19.
5.3.2 ComparaçãoA Figura 24, mostra os gráficos com os valores de repetibilidade para as três fotosimpressas (𝑃1,𝑃2,𝑃3) testando multiplos detectores. No eixo 𝑥 é mostrado o indice 𝑁 𝑆𝐷𝐼e a quantidade de leite adicionada.
Da Figura 24, são mostrados as analises para três intervalos diferentes de degra-dação causada por turbidez baseado no NSDI . Desde 0 a 0.25 de 𝑁 𝑆𝐷𝐼 foi consideradocomo um ambiente de Baixa Turbidez(Fig. 23 segunda linha). Nestes casos a maioria dainformação estrutural é mantida e o backscattering é mínimo. No intervalo de 0.25 até0.75 foi considerado como imagens de parte de um intervalo de Média Turbidez( Fig. 23
terceira linha). Nestes níveis, a informação estrutural é parcialmente mantidas, mas asbordas passam a ser mal definidas. Ao final, desde 0.75 até 1, em Alta Turbidez(Fig. 23
quarta linha), quase nenhuma informação estrutural é mantida. Nestes níveis, os detec-tores podem somente fazer uso de algumas poucas pistas visuais que ainda resistiram aturbidez.
Para todos os intervalos de turbidez, é possível separar claramente os detectoresanalisados em quatro grupos.
Os detectores baseados em única escala (Azul Fig. 24) obtiveram os melhoresresultados em todos os intervalos de turbidez. Comparado com outras comparações dedetectores de pontos de interesse (GIL et al., 2010) (CRISTINACCE; COOTES, 2006),a superioridade dos detectores não invariantes a escala em comparação a aqueles que são795.3. ResultadosFigura 24 – Repetibilidade ( Taxa de Acerto) contra o indice de degradação estruturalnormalizado (NSDI). As linhas em laranja indicam os intervalos de degradação. BaixaTurbidez 0 até 0.25; Média Turbidez, 0.25 até 0.75, e Alta Turbidez de 0.75 até 1.
80Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente Subaquáticoinvariantes a escala, em situações onde a escala não varia, é mais expressiva. O detectorHarris foi melhor para o caso de 𝑃1 (Fig. 24a) até um nível médio de turbidez. Após issoo mesmo teve um decaimento maior, quando as estruturas começaram a se perder.
O detector baseado em espaços de escala com difusão anisotrópica, obteve os pioresresultados (Vermelho Fig. 24). Isso é o oposto do que é mostrado em cenas fora d’água(ALCANTARILLA; BARTOLI; DAVISON, 2012). O algoritmo KAZE necessita calcularas respostas das bordas antes de obter o espaço de escala. Isso é mais dificil em ambientessubaquáticos devido a suas propriedades naturais. Porém, no intervalo de Baixa Turbidez,KAZE foi capaz de obter uma repetibilidade maior que o FastHessian e o DoG, dado queas bordas ainda estão bem definidas. Para o caso de Média Turbidez, a taxa de acerto cairapidamente, chegando a zero em Alta Turbidez.
Os melhores resultados para níveis de media e alta turbidez, foram, de fato, obtidospelo detector DoG (LOWE, 2004). O detector Fast Hessian, possui uma aproximação maisbrusca do espaço de escala a qual tende a produzir artefatos. Por isso, tratou-se do piorresultado dentre os analisados.
CenSurPoly e o CenSurStar apresentaram resultados similares ao Kaze tendo pi-ores resultados para níveis mais altos de turbidez.
A Figura 25 mostra a comparação de um determinado nível de espaço de escalagerado por um kernel gaussiano , um kernel baseado em caixas (FastHessian), um kernelbaseado em polígonos estrelados (CenSurE) e um gerado pelo filtro anisotrópico (KAZE)𝑔2 da Eq. 1.12 . Tais kernels são aplicados em múltiplos níveis de turbidez, sendo quecada linha da figura apresenta um nível de turbidez diferente.
É possível perceber que a informação estrutural se mantém mais para o polígonoestrelado. O que justifica o seu estudo, principalmente para o caso de maior turbidez. Já
o KAZE também possui um comportamento interessante, porém muito da informaçãotende a se perder com a turbidez para um mesmo nível de escala.
Como mostrado no Capítulo 4, Seção 4.1 , existe um comportamento de borra-mento regido por um certo fenômeno. É possível que funções, como as utilizadas peloCenSurE e o KAZE, as quais tendem a não seguir o comportamento do borramento cau-sado pelas propriedades do meio subaquático, tendam a manter as estruturas geométricas, e , ao encontrar pontos que possuem máximo sobre escala, encontrem regiões em queainda existe informação visual provida pela imagem.
5.4 Conclusões finaisEste capítulo apresentou a avaliação a invariância a degradação em ambientessubaquáticos para detectores de pontos de interesse mais utilizados na literatura. Foi815.4. Conclusões finaisFigura 25 – Comparação entre a geração de um nível do kernel do espaço de escala usadopor quatro detectores diferentes. O kernel foi aplicado em níveis de turbidez diferentespara a imagem 𝑃1. Sendo que a primeira linha é a imagem limpa (𝑇0), a segunda linhaé uma imagem com baixo nível de degradação (𝑇4), a terceira linha apresenta uma ima-gem com médio nível de degradação (𝑇10), a quarta linha apresenta imagens do nível dedegradação alto (𝑇16). Para cada caso é mostrado o resultado de filtro equivalente a aaproximadamente um kernel gaussiano de 𝜎 = 59.0. Primeira Coluna: Gaussiano puro.
Segunda Coluna: Borramento aproximado em caixas . Terceira Coluna: Difusão utilizandoum polígono estrelar de seis pontas. Quarta Coluna: kernel anisotrópico g2 do KAZE. É
possível ver de certa forma estruturas mais definidas para o esquema de difusão usadopelo CenSurE (AGRAWAL; KONOLIGE; BLAS, 2008).
proposto um novo dataset, completamente aberto, usando fotos impressas reais as quaistinham uma quantidade controlada de turbidez.
Foi concluído que para, imagens subaquáticas, métodos de única escala tem umarepetibilidade consideravelmente melhor que abordagens de multipla escala. Entre Harris(HARRIS; STEPHENS, 1988) e Hessian (BEAUDET, 1978), Hessian obteve resultadosmelhores principalmente para níveis mais altos de turbidez e em imagens onde há poucainformação estrutural.
82Capítulo 5. Testes e Resultados 1: Detecção de Pontos de Interesse em Ambiente SubaquáticoConsiderando múltipla escala, foram avaliados novos detectores os quais não usamos espaços de escala Gaussianos. Foi proposto que nestes espaços diferentes, como os centersurround ou os baseados em difusão anisotrópica, a difusão não acontece com a mesmaestrutura que o fenômeno de degradação da turbidez, assim então produzindo melhoresresultados, em alguns níveis de turbidez.
Os melhores resultados para múltipla escala foram obtidos pelo DoG (LOWE,2004) Também mostrou-se que o KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012)apresenta resultados relevantes mas tende a perder precisão em níveis mais altos de tur-bidez.
Finalmente, a avaliação proposta mostra que um espaço de escala não Gaussianopode também produzir melhores resultados. Como trabalho futuro, buscar-se-á explorarque espaços de escala que consideram a degradação causada pela turbidez de forma aobter melhores resultados de repetibilidade.
836 Testes e Resultados 2: Contexto em Clas-sificação SubaquáticaAqui são apresentados os resultados de aplicação do método proposto baseado emGeoestatística (no Cap. 3), comparado com outros métodos, com e sem a incorporaçãodo contexto.
O método será aplicado em mosaicos de imagens do assoalho oceânico, para obten-ção de mapas temáticos. As imagens resultantes são a representação final de um mosaico,feito de forma visualmente interpretável, contendo a classificação realizada de forma pixel-a-pixel.
O capítulo apresenta os datasets, compostos por mosaicos, utilizados como caso deteste para a classificação e também as configurações utilizadas para os testes e, por fim,os resultados da classificação dos mosaicos são mostrados.
6.1 Datasets UtilizadosPara avaliação dos resultados obtidos foi proposto utilizar dois datasets distintosde mosaicos de recifes de corais. Cada dataset é composto por um mosaico obtido pelajunção de centenas de imagens coletadas por especialistas da Universidade de Miami.
O dataset Redsea contém imagens do Mar Vermelho, capturadas em águas bastanterasas perto da cidade de Eilat, como parte de uma pesquisa por ecologistas de recifesde corais (ZVULONI et al., 2009). Para a classificação, foram considerado cinco classes:Urchin, Branching Coral, Brain Coral, Favid Coral e o Background. Os mosaicos utilizadosforam capturados a uma resolução de 1.1 𝑝𝑖𝑥𝑒𝑖𝑠/𝑚𝑚2.
O segundo dataset chamado Marker, foi capturado nas Bahamas. Foi feita a divisãoem quatro classes para classificação. General Corals, Sea Gorgons, Sand e Background.
Os mosaicos utilizados foram capturado em uma resolução de 2.2 𝑝𝑖𝑥𝑒𝑖𝑠/𝑚𝑚2.
6.2 Descrição do Geral do SistemaNesta seção é descrito uma versão geral do sistema, tanto para a classificação emnível unário, quanto os tipos de classificação integrando contexto.
84Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática6.2.1 Pré-ProcessamentoTanto para os dados do dataset Redsea quanto para o caso do dataset Marker , aqualidade visual da imagem é bastante satisfatória, contendo baixa presença de degrada-ção devido a turbidez. O principal tipo de degradação encontrado é a variação de cor aolongo do datasets existentes durante a captura. Para resolver esta questão foi utilizadoCLAHE (ZUIDERVELD, 1994) e uma normalização de cor em ambos os datasets.
6.2.2 Segmentação e DescriçãoOs datasets foram segmentados como superpixeis baseados em TurboPixels (LE-VINSHTEIN et al., 2009). O tamanho do pixel foi escolhido como que para caber em umajanela de tamanho de aproximadamente 32x32 pixeis.
Para cada superpixel, a combinação entre três descritores de textura foi utilizada.
Filtros de Gabor, CLBP e GLCM. Um kernel mapping é feito depois para tornar osdescritores mais linearmente separáveis. O resultado é também por fim, normalizado.
6.2.3 ClassificaçãoNo caso, para todos os testes, foi utilizado um SVM configurado com um kernellinear.
6.2.4
Adição de ContextoA adição de contexto é apresentada feita de duas formas distintas: utilizando osConditional Random Fields (CRF) e utilizando o modelo de Geoestatística, o quais foramexplicados nos Capítulos 2 e 3.
Para o CRF utilizado o algoritmo de Loopy Belief Propagation(LBP) para realizara inferência estatística, dado a sua baixa taxa de erros e alta performance (WEISS, 2000).
6.3 TreinamentoAqui é descrito como foi realizado o treinamento das partes do sistema onde otreinamento é necessário.
6.3.1 Treinamento do ClassificadorO treinamento unário diz respeito ao treinamento da função de discriminação doclassificador.
856.3. TreinamentoTanto para o dataset Redsea quanto para o Marker foram feitas diversas amostra-gens dos mosaicos existentes para o treinamento do classificador de cada uma das classes.
A Figura 26, mostra exemplos de segmentos usados para o treinamento do classificadorpara os dois datasets utilizados. Foram feitas amostras de por volta de 200 segmentospara cada classe sendo cada uma tendo 64x64 pixeis. As amostras foram indicadas porespecialistas da universidade de Miami.
Figura 26 – Partes manualmente segmentadas utilizadas para treinamento do classifica-dor. A esquerda são mostrados exemplos de nove amostras usadas para treinar o datasetRedsea. A direita são apresentadas nove amostras do dataset Marker.
6.3.2 Treinamento UnárioPara gerar a curva de confiança, usada para gerar os distribuição de probabilida-des unária tanto para o CRF, quanto para o modelo de Geoestátistica, foram tambémutilizadas amostras do mosaico de treinamento da Figura 26.
As Figuras 27 e 28 mostram as curvas de confiança obtidas para cada um dosdois datasets em cada uma das classes. O processo de geração das curvas é descrito noCapítulo 3 Seção 3.2.
Pelos gráficos das Figuras 27 e 28 percebe-se que determinadas classes se adaptammelhor que outras a uma curva de confiança, como a classe Sea Gorgon ( Fig. 28c) dodataset Marker. Para esta classe é possível saber quais distâncias do classificador queexiste uma grande probabilidade de se acertar a classe, enquanto para outras o modelonão se adaptou tão adequadamente (Fig. 29b).
Entretanto, o principal erro em adaptação da curva se da na classe Backgroundpara os dois casos (Fig. 27a e Fig. 29a). Isso se da devido a alta variabilidade intra-classeinerente a classe Background, a qual contém todos os tipos de objetos que não são deinteresse para classificação.
86Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática(a) Classe Background(b) Classe Urchin(c) Classe Branching Coral(d) Classe Brain Coral(e) Classe Faviid CoralFigura 27 – Curvas de confiança geradas no treinamento unário de cada classe para odataset Redsea. A curva de confiança 𝐶𝑙𝑖 treinada para cada uma das classes é mostrada,se bem como o grau de confiança obtido.
6.3.3 Treinamento Potenciais LocaisPara treinamento dos potenciais locais foi utilizado cada dataset na sua totalidade.
Para o caso do CRF foi utilizado o algoritmo de treinamento descrito no Capítulo2, Seção 2.2.2.2 .
As Tabelas 2 e 3 mostram a matriz de covariância obtida para cada um dos doisdatasets. Tal matriz está relacionada a uma indicação de determinada classe estar próximaa outra.
Background Urchin Branching Coral Brain Coral Faviid CoralClassesBackgroundUrchinBranching CoralBrain CoralFaviid CoralTabela 2 – Matriz de covariância que mostra as relações de proximidade entre as classes.
Tais medidas são fatores que indicam correlação e não distribuições de probabilidade. Esteresultado é normalizado ao final.
1.91150.78440.76580.87670.76120.85990.96790.98970.96050.94270.85590.94581.38700.94610.91110.90940.96701.02191.63840.93530.84001.04240.97450.89721.6972Os resultados do treinamento dos vetores de transição, necessários para a simulação876.3. Treinamento(a) Classe Background(b) Classe General Corals(c) Classe Sea Gorgon(d) Classe SandFigura 28 – Curvas de confiança geradas no treinamento unário de cada classe para o da-taset Marker. A curva de confiança 𝐶𝑙𝑖 treinada para cada uma das classes é apresentada,bem como o grau de confiança obtido.
Background General CoralSea Gorgon Sand0.90860.90280.89301.8773ClassesBackgroundGeneral CoralSea GorgonSand1.88310.90100.89050.89500.89670.95440.95160.89900.88990.95070.97380.8906Tabela 3 – Matriz de covariância que mostra as relações de proximidade entre as classes.
Tais medidas são fatores que indicam correlação e não distribuições de probabilidade. Esteresultado é normalizado ao final.
do método de Geoestatística, são mostrados na Figura 29 para ambos os datasets testados.
Para ambos os datasets analisados se observa a classe background como sendopredominante nas estatísticas medidas em ambos os treinamentos. No caso do treinamentodos vetores de transição (Geoestatística), também foi vista uma tendência de outras classesem transitar para o Background (Fig. 29). Algo que, para o treinamento dos potenciaislocais do CRF, indicou principalmente uma tendência do Background ter proximidadeconsigo próprio.
Para o dataset Redsea, nas relações locais treinadas pelo CRF se observa algumastendências:88Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática(a) Dataset Redsea(b) Dataset MarkerFigura 29 – Vetores de transição obtidos na etapa de treinamento para o método deGeoestatística do Capítulo 3. Os vetores indicam a probabilidade de uma classe transitarpara outra a uma determinada distância. O eixo x apresenta a distância em pixeis. O eixo𝑦 dos gráficos apresenta as probabilidades de transição. Pode-se observar, por exemplo,uma certa tendência na classe Urchin em transitar para categoria de background.
896.4.
Sistemas Testados∙ As classes Urchin tem uma grande possibilidade de estar próxima a classe FaviidCoral;∙ Cada classe tem uma forte tendência de estar próxima a si própria, o que enfatizaa pouca variabilidade de classes em espaços pequenos;∙ Existe algumas tendências assimétricas treinadas, como a grande tendência da classeFaviid Coral estar próxima da classe Urchin, mas não ao contrário.
As transições assimétricas, ou seja, uma dada classe A estar próxima a classe Bmas não B próxima da A, não são incentivadas pelos potenciais treinados pelo método deGeoestatística.
Considerando as relações treinadas pelo método de Geoestatística, existe umatendência forte principalmente de transição da classe Urchin para a classe Faviid Coral ea classe Background.
Para o dataset Marker, nenhuma outra tendência de proximidade foi obtida parao CRF, fora a tendência de background estar próximo de si mesmo. As mesmas tendênciassão observadas para o treinamento dos vetores de transição para o caso da Geoestatística.
6.4
Sistemas TestadosQuatro sistemas são testados quanto a sua taxa de acerto em relação a classificaçãode mosaicos de imagens. Isso foi feito principalmente de forma a avaliar a consideraçãode contexto, juntamente com a nova proposta apresentada no Capítulo 3Inicialmente foi avaliado o sistema Unário, proposto por Shihavuddin et al. (2013)onde somente as informações unárias são consideradas, ou seja, dada a definição de classifi-cação considerando uma segmentação em regiões (SHIHAVUDDIN et al., 2013). Somentea descrição da própria região foi usada para classificação, o sistema é detalhado no Cap.
4 .
Após foi testado e analisado o sistema Unário porém baseado em distribuição deprobabilidades. Em tal sistema foi feita a classificação apenas considerando a parcela uná-ria do sistema com base no modelo em Geoestatística proposto no Cap. 3. A classificaçãode um segmento foi escolhida como o rótulo com máxima a probabilidade.
Apresenta-se também o sistema, GS, baseado em Geoestatística proposto no Cap.
3. A classificação de cada segmento (Superpixel) é dada pela Eq. 3.1, do Cap. 3.
Por fim, apresenta-se os resultados do sistema CRF o qual é uma implementaçãodos Conditional Random Fields , tal qual explicada no Cap 2.
90Capítulo 6. Testes e Resultados 2: Contexto em Classificação SubaquáticaTodos os sistemas foram implementados em Matlab, para o CRF, foi utilizada abiblioteca UGM para inferência estatística (SCHMIDT et al., 2009).
6.5 Computação do Mapa TemáticoNo dataset Redsea, um mosaico de 3256x2939 pixeis foi utilizado para testes. Já
para dataset Marker,foi utilizado um mosaico de 2592x3963.
As Figuras 30 e 31 mostram os mapas temáticos completos computados para ambosos datasets.
Observa-se que num caso geral o CRF é o método que obtém os melhores resulta-dos. O método de Geoestatística é capaz de melhorar um pouco, porém depende muitode um bom treinamento da distribuição de probabilidades de cada segmento.
Para o caso do dataset Marker, a adição de contexto foi mais eficaz para ambos oscasos. Isso ocorre dado que muitas posições geraram resultados com distribuição unáriauniforme, ou seja sem uma classe com alta probabilidade. O que contribuiu para adiçãode contexto foi, que tais regiões, estavam cercadas por locais onde existia uma classepredominante.
Ao se observar a configuração do dataset Redsea se percebe uma tendência espacialem se ter "ilhas"de classes envolvidas pela classe background. Dado que a classe backgroundtem uma alta variabilidade intra-classe, é bastante complicado se ter uma tendência fortepara uma classe na distribuição unária. Isso dificulta a proliferação da informação decontexto na região.
De forma a analisar melhor as diferenças entre o CRF e o método de Geoestatística,é mostrado na Figura 32 duas áreas diferentes do mosaico do Redsea para mostrar algumasvantagens da abordagem com base em GS. É apresentada a área original da imagem coma classificação mostrada em cores. Na primeira linha, pode se perceber o grau de acertomaior para o CRF (Fig. 32c). O CRF tende a melhorar significativamente a suavizaçãolocal das estruturas classificadas. Ou seja, impõe que áreas pequenas devam ter menosvariações de classes. Por esta razão o CRF teve uma boa classificação especialmente parao caso da classe representada em azul (Faviid Corals).
Por outro lado, na segunda linha, GS (Fig. 32f) obteve um grau de acerto maior.
Dado que o CRF (Fig. 32g) impõe mais suavidade local, isso tende a eliminar classesmenores (Fig. 32g). Este caso é evitado pela GS pelo fato de que a abordagem baseadaem Geostatística usa estatísticas medidas em longas distâncias e assim o tamanho daclasse é considerado. Na terceira linha da Figura 32, são mostrados resultados similarespara o dataset Marker.
Também os algoritmos foram testados para múltiplos segmentos diferentes extraído916.6. ConclusõesTamanho do Segmento170011005002300 Média81.1% 78.0% 79% 80.2% 79.7%
81.2% 78.3% 79% 80.2% 79.8%
80.5% 78.9% 79.3% 79.7% 79.8%
78%78% 78.4% 80.2% 79.2%
UnitaryGSCRFVotingTabela 4 – Resultados para a taxa de acerto de diferentes segmentos para o dataset Redsea.
Foram testados diversos segmentos quadrados amostrados aleatoreamente nos mosaicos.
O tamanho do segmento é especificado pelo lado do quadradodos mosaicos. Foram recortadas amostras quadradas aleatórias de diferentes tamanhos.
Para cada tamanho recortado, a tabela 4 mostra a taxa de acerto média do métodoaplicado em 20 segmentos aleatórios. Também foi testado um método simples de votaçãoonde um superpixel é modificado caso a classe de todos os vizinhos seja differente.
No dataset Redsea, para todas as abordagens , não foi percebido mais do que ganhosmarginais quando comparados com a versão unitária. O método de votação tambémobteve resultados similares.
6.6 ConclusõesConclui-se que o uso de estatísticas mais ricas, inspiradas pelos conceitos de Geo-estatísticas, é benéfico e pode conduzir a melhores resultados que o CRF tradicional emalguns casos.
As melhorias obtidas, foram, no entanto, de pequena magnitude, o que esta ali-nhado com o que é discutido em (LUCCHI et al., 2011). Os resultados utilizando contextonormalmente não melhoram mais do que a suavidade local dos resultados, ou seja, nãomais do que evitam grande variação de classes em uma pequena área. Porém ainda épossível obter melhorias significativas, para alguns datasets como no caso do Marker.
92Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática(a) Unitário 76.83%
(b) Unitário com Curvas de Confiança 75.779%(c) Geoestatística 76.16%
(d) CRF 77.32%
(e) Ground TruthFigura 30 – Mapa temático dos Mosaicos para o dataset Redsea. As figuras mostram aporcentagem de acerto relativa ao GroundTruth. As classes são representadas pelas se-guintes cores: Verde Brain Coral; Amarelo Branchin Coral; Azul Faviid Coral; MagentaUrchin e sem cor é o background. Os seguintes resultados são mostrados.(30a) classifica-ção Unária. (30b) mostra a classificação Unária baseada nas curvas de confiança. (30c)classificação com adição de contexto baseada em Geoestatística. (30d) classificação comadição de contexto utilizando CRF.
936.6. Conclusões(a) Unitário 78.04%
(b) Unitário com Curvas de Confiança 78.02%
(c) Geoestatística 79.2%
(d) CRF 83.26%
(e) Ground TruthFigura 31 – Mapa temático dos Mosaicos para o dataset Marker. As figuras mostram aporcentagem de acerto relativa ao GroundTruth. As classes são representadas pelas se-guintes cores: Verde Sand; Amarelo Sea Gorgon; Azul Corals e sem cor é o background.
Os seguintes resultados são mostrados.(31a) classificação Unária. (31b) mostra a classifi-cação Unária baseada nas curvas de confiança. (31c) classificação com adição de contextobaseada em Geoestatística. (31d) classificação com adição de contexto utilizando CRF.
94Capítulo 6. Testes e Resultados 2: Contexto em Classificação Subaquática(a) 0.6985(b) 0.6988(c) 0.745
(d) Ground Truth(e) 0.859
(f) 0.8691(g) 0.858
(h) Ground Truth(i) 0.756
(j) 0.77
(k) 0.763
(l) Ground TruthFigura 32 – Resultados de classificação para os datasets Marker e os datasets Redsea. A
primeira coluna apresenta a classificação unitária. A segunda coluna apresenta os resulta-dos de Geoestatística. A terceira coluna apresenta os resultados para o CRF. Por fim, aultima coluna apresenta o GroundTruth. Foi utilizada como peso para o potencial local 𝑤𝑙como sendo 0.4 para ambas as abordagens. Na primeira coluna foi possível perceber umresultado melhor para o CRF devido a uma maior suavização local. Na segunda linha, ométodo de Geoestatística obteve melhores resultados devido a suas medidas estatísticasde longa distância. Na última linha é mostrado os resultados para o dataset Marker, ondeambas as abordagens tiveram melhores resultados para esse caso.
957 Conclusões FinaisConsiderando o problema de estender a utilização de métodos de visão computaci-onal para o cenário subaquático, esta dissertação apresentou o estudo e tratamento paraalguns dos principais problemas existentes no meio.
Foi feito um estudo sobre duas áreas distintas relevantes para o problema: A detec-ção de pontos de interesse e o uso da informação de contexto na classificação de imagens.
Nas seções que seguem serão apresentadas as contribuições sobre as duas áreasdistintas analisadas, como também as limitações das propostas.
7.1 Detectores de Pontos de Interesse em Imagens SubaquáticasTurvasNo contexto subaquático, foi feito um estudo sobre como se comportam os múlti-plos detectores de pontos de interesse sobre a presença da turbidez, fenômeno o qual sefaz presente no meio subaquático.
7.1.1 Contribuições ObtidasAs principais contribuições obtidas foram:∙ A proposta de um dataset novo contendo imagens reais do assoalho oceânico porémcom a turbidez controlada.
∙ Uma análise geral da repetibilidade dos detectores em meios túrbidos, dividindo aanálise em intervalos de turbidez distintos.
∙ Dentre os detectores estudados, foi apontado o DoG como o mais robusto detectorpara ambientes com presença de turbidez. Tal detector contém também invariânciaa escala.
∙ Foi concluída a possibilidade do uso de espaços não gaussianos para geração deespaço de escala em meios subaquáticos túrbidos.
7.1.2 Limitações e Trabalhos FuturosO estudo não foi capaz de propor um método para medir de fato a degradaçãocausada pela turbidez. A medida utilizada é capaz de verificar a degradação estrutural oque não necessariamente está associada a turbidez.
96Capítulo 7. Conclusões FinaisUm outro ponto a ser tratado diz respeito a uma análise mais criteriosa comrespeito a invariância a outras transformações como rotação ou escala, juntamente com arobustez à degradação causada pela turbidez.
7.2 Adição de Contexto Baseado em GeoestatísticaFoi proposto um novo método para adicionar informação espacial na classificaçãode imagens. O método se baseou nos estudos da área de Geoestatística. Tal método foiaplicado em imagens de mosaicos de recifes de corais. O mesmo foi comparado com asversões sem a utilização de contexto e com o modelo dos Conditional Random Fields(CRF).
Apresentou-se que a adição de contexto pode, em alguns casos, ser benéfica paraa classificação de imagens subaquáticas. Obtendo-se um ganho de até 5% a mais em taxade acerto.
7.2.1 Contribuições ObtidasO trabalho apresentou um novo método para adição de contexto em imagens su-baquáticas. O uso de medidas estatísticas mais ricas, como as baseadas em Geoestatística,mostrou-se útil em algumas situações para adição de informação de contexto.
Também essa dissertação serve como uma conexão entre duas áreas distintas: aGeoestatística e os Modelos Probabilístico Gráficos (MPGs). Acredita-se que através destaintersecção, as aplicações que fazem uso de Geoestatística podem também se beneficiardos MPGs.
7.2.2 Limitações e Trabalhos FuturosColoca-se que a abordagem apresentada foi aplicada para um cenário subaquáticoespecífico. Uma direção seria a aplicação em dataset com classes mais genéricas, os daPascal Visual Object Classes Challenge (VOC) (EVERINGHAM et al., 2010).
Os resultados para o método de Geoestatística foram satisfatórios porém ficaramabaixo em taxa de acerto quando comparados ao CRF. Apesar da tendência de se usar osmétodos de Geoestatística para casos onde há pouca quantidade de informações (CARLE;FOGG, 1996).
Existe ainda uma necessidade maior de alteração no modelo original de Geoesta-tística visando uma melhor adaptação para o caso de imagens subaquáticas.
97ReferênciasABFALG, J. et al. Multi-represented classification based on confidence estimation. In:Advances in Knowledge Discovery and Data Mining. [S.l.]: Springer, 2007. p. 23–34.
Citado 2 vezes nas páginas 51 e 52.
AGRAWAL, M.; KONOLIGE, K.; BLAS, M. R. Censure: Center surround extremasfor realtime feature detection and matching. In: Computer Vision–ECCV 2008. [S.l.]:
Springer, 2008. p. 102–115. Citado 4 vezes nas páginas 14, 35, 77 e 81.
AGTERBERG, F. Mathematical geologymathematical geology. In: General Geology.
Springer US, 1988, (Encyclopedia of Earth Science). p. 573–582. ISBN 978-0-442-22499-8.
Disponível em: <http://dx.doi.org/10.1007/0-387-30844-X 76>. Citado na página 55.
ALCANTARILLA, P. F.; BARTOLI, A.; DAVISON, A. J. Kaze features. In: ComputerVision–ECCV 2012. [S.l.]: Springer, 2012. p. 214–227. Citado 5 vezes nas páginas 35,36, 77, 80 e 82.
AULINAS, J. et al. Feature extraction for underwater visual slam. In: IEEE. OCEANS,2011 IEEE-Spain. [S.l.], 2011. p. 1–7. Citado na página 24.
BAR, M. Visual objects in context. Nature Reviews Neuroscience, Nature PublishingGroup, v. 5, n. 8, p. 617–629, 2004. Citado 2 vezes nas páginas 25 e 41.
BAY, H. et al. Speeded-up robust features (surf). Computer vision and imageunderstanding, Elsevier, v. 110, n. 3, p. 346–359, 2008. Citado 2 vezes nas páginas 33e 77.
BAZEILLE, S. et al. Automatic underwater image pre-processing. In: CMM’06. [S.l.:
s.n.], 2006. p. xx. Citado na página 66.
BEALL, C. et al. 3d reconstruction of underwater structures. In: IEEE/RSJ InternationalConference on Intelligent Robots and Systems (IROS). [S.l.: s.n.], 2010. p. 4418–4423.
Citado 2 vezes nas páginas 24 e 27.
BEATTIE, C.; MILLS, B.; MAYO, V. Development drilling of the tawila field, yemen,based on three-dimensional reservoir modeling and simulation. In: SPE annual technicalconference. [S.l.: s.n.], 1998. p. 715–725. Citado na página 49.
BEAUDET, P. R. Rotationally invariant image operators. In: Proceedings of the 4thInternational Joint Conference on Pattern Recognition. Kyoto, Japan: [s.n.], 1978. p.
579–583. Citado 4 vezes nas páginas 30, 71, 77 e 81.
BEIJBOM, O. et al. Automated annotation of coral reef survey images. In: IEEE.
Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. [S.l.],
2012. p. 1170–1177. Citado na página 67.
BIEDERMAN, I.; MEZZANOTTE, R. J.; RABINOWITZ, J. C. Scene perception:Detecting and judging objects undergoing relational violations. Cognitive psychology,Elsevier, v. 14, n. 2, p. 143–177, 1982. Citado na página 39.
98ReferênciasBOIX, X. et al. Harmony potentials. International journal of computer vision, Springer,v. 96, n. 1, p. 83–102, 2012. Citado 2 vezes nas páginas 46 e 47.
BOYKOV, Y. Y.; JOLLY, M.-P. Interactive graph cuts for optimal boundary & regionsegmentation of objects in nd images. In: IEEE. Computer Vision, 2001. ICCV 2001.
Proceedings. Eighth IEEE International Conference on. [S.l.], 2001. v. 1, p. 105–112.
Citado na página 45.
CARBONETTO, P.; FREITAS, N. de; BARNARD, K. A statistical model for generalcontextual object recognition. In: Computer Vision-ECCV 2004. [S.l.]: Springer, 2004. p.
350–362. Citado 2 vezes nas páginas 43 e 45.
CARLE, S. F.; FOGG, G. E. Transition probability-based indicator geostatistics.
Mathematical Geology, Springer, v. 28, n. 4, p. 453–476, 1996. Citado 4 vezes naspáginas 49, 56, 57 e 96.
CARLE, S. F. et al. Conditional simulation of hydrofacies architecture: a transitionprobability/markov approach. Hydrogeologic models of sedimentary aquifers, conceptsin hydrogeology and environmental geology, v. 1, p. 147–170, 1998. Citado 2 vezes naspáginas 53 e 55.
CORKE, P. et al. Experiments with underwater robot localization and tracking. In:Robotics and Automation, 2007 IEEE International Conference on. [S.l.: s.n.], 2007. p.
4556–4561. ISSN 1050-4729. Citado na página 27.
CRISTIANINI, N.; SHAWE-TAYLOR, J. An introduction to support vector machinesand other kernel-based learning methods. [S.l.]: Cambridge university press, 2000. Citadona página 51.
CRISTINACCE, D.; COOTES, T. F. Feature detection and tracking with constrainedlocal models. In: CITESEER. BMVC. [S.l.], 2006. v. 2, n. 5, p. 6. Citado na página 78.
DEMPSTER, A. P.; LAIRD, N. M.; RUBIN, D. B. Maximum likelihood fromincomplete data via the em algorithm. Journal of the royal statistical society. Series B(methodological), JSTOR, p. 1–38, 1977. Citado na página 45.
DERPANIS, K. G.; LEUNG, E. T.; SIZINTSEV, M. Fast scale-space featurerepresentations by generalized integral images. In: IEEE. Image Processing, 2007. ICIP2007. IEEE International Conference on. [S.l.], 2007. v. 4, p. IV–521. Citado na página33.
DUNTLEY, S. Q. Light in the sea. JOSA, Optical Society of America, v. 53, n. 2, p.
214–233, 1963. Citado 2 vezes nas páginas 65 e 73.
EMERY, X. Properties and limitations of sequential indicator simulation. StochasticEnvironmental Research and Risk Assessment, Springer, v. 18, n. 6, p. 414–424, 2004.
Citado na página 54.
EVERINGHAM, M. et al. The pascal visual object classes (voc) challenge. Internationaljournal of computer vision, Springer, v. 88, n. 2, p. 303–338, 2010. Citado na página 96.
FINK, M.; PERONA, P. Mutual boosting for contextual inference. In: Advances inneural information processing systems. [S.l.: s.n.], 2003. p. None. Citado na página 42.
99ReferênciasFISCHLER, M. A.; ELSCHLAGER, R. A. The representation and matching of pictorialstructures. IEEE Transactions on Computers, Citeseer, v. 22, n. 1, p. 67–92, 1973.
Citado na página 40.
FULKERSON, B.; VEDALDI, A.; SOATTO, S. Class segmentation and objectlocalization with superpixel neighborhoods. In: IEEE. Computer Vision, 2009 IEEE 12thInternational Conference on. [S.l.], 2009. p. 670–677. Citado 4 vezes nas páginas 41, 44,45 e 68.
GALLEGUILLOS, C.; BELONGIE, S. Context based object categorization: A criticalsurvey. Computer Vision and Image Understanding, Elsevier, v. 114, n. 6, p. 712–722,2010. Citado 3 vezes nas páginas 39, 40 e 41.
GARCIA, R.; GRACIAS, N. Detection of interest points in turbid underwater images.
In: IEEE. OCEANS, 2011 IEEE-Spain. [S.l.], 2011. p. 1–9. Citado 6 vezes nas páginas24, 71, 74, 76, 77 e 78.
GIL, A. et al. A comparative evaluation of interest point detectors and local descriptorsfor visual slam. Machine Vision and Applications, Springer, v. 21, n. 6, p. 905–920, 2010.
Citado 2 vezes nas páginas 27 e 78.
GONZALEZ, R. C.; WOODS, R. E. Digital Image Processing (3rd Edition). UpperSaddle River, NJ, USA: Prentice-Hall, Inc., 2006. ISBN 013168728X. Citado na página67.
GUO, Z.; ZHANG, D. A completed modeling of local binary pattern operator for textureclassification. Image Processing, IEEE Transactions on, IEEE, v. 19, n. 6, p. 1657–1663,2010. Citado na página 69.
HANSON, A. R.; RISEMAN, E. M. VISIONS: A computer system for interpretingscenes. In: HANSON, A. R.; RISEMAN, E. M. (Ed.). Computer Vision Systems. NewYork: Academic Press, 1978. Citado na página 40.
HARALICK, R. M.; SHANMUGAM, K.; DINSTEIN, I. H. Textural features for imageclassification. Systems, Man and Cybernetics, IEEE Transactions on, IEEE, n. 6, p.
610–621, 1973. Citado na página 69.
HARRIS, C.; STEPHENS, M. A combined corner and edge detector. In: MANCHESTER,UK. Alvey vision conference. [S.l.], 1988. v. 15, p. 50. Citado 5 vezes nas páginas 29, 30,71, 77 e 81.
JOHNSON-ROBERSON, M.; KUMAR, S.; WILLAMS, S. Segmentation andclassification of coral for oceanographic surveys: a semi-supervised machine learningapproach. In: IEEE. OCEANS 2006-Asia Pacific. [S.l.], 2007. p. 1–6. Citado na página66.
KOLTUN; VLADLEN. Efficient inference in fully connected crfs with gaussian edgepotentials. In: . [S.l.: s.n.], 2011. Citado 2 vezes nas páginas 46 e 60.
KOSCHMIEDER, H. Theorie der horizontalen Sichtweite. [S.l.]: Keim Nemnich, 1924.
Citado na página 64.
KRUPPA, H.; SCHIELE, B. Using Local Context to Improve Face Detection. 2003.
Citado na página 42.
100ReferênciasKUMAR, S.; HEBERT, M. A hierarchical field framework for unified context-basedclassification. In: IEEE. Computer Vision, 2005. ICCV 2005. Tenth IEEE InternationalConference on. [S.l.], 2005. v. 2, p. 1284–1291. Citado na página 40.
LEVINSHTEIN, A. et al. Turbopixels: Fast superpixels using geometric flows. PatternAnalysis and Machine Intelligence, IEEE Transactions on, IEEE, v. 31, n. 12, p.
2290–2297, 2009. Citado 3 vezes nas páginas 49, 69 e 84.
LINDEBERG, T. Scale-space theory: A basic tool for analyzing structures at differentscales. Journal of applied statistics, Taylor & Francis, v. 21, p. 225–270, 1994. Citado 2vezes nas páginas 31 e 32.
LINDEBERG, T. On the axiomatic foundations of linear scale-space. [S.l.]: Springer,1997. Citado na página 32.
LINDEBERG, T. Feature detection with automatic scale selection. International journalof computer vision, Springer, v. 30, n. 2, p. 79–116, 1998. Citado na página 32.
LINDEBERG, T.; EKLUNDH, J.-O. On the computation of a scale-space primal sketch.
Journal of Visual Communication and Image Representation, v. 2, n. 1, p. 55 – 78, 1991.
ISSN 1047-3203. Citado na página 29.
LOWE, D. G. Distinctive image features from scale-invariant keypoints. Internationaljournal of computer vision, Springer, v. 60, n. 2, p. 91–110, 2004. Citado 8 vezes naspáginas 11, 33, 34, 45, 72, 77, 80 e 82.
LUCCHI, A. et al. Are spatial and global constraints really necessary for segmentation?
In: IEEE. Computer Vision (ICCV), 2011 IEEE International Conference on. [S.l.],
2011. p. 9–16. Citado 3 vezes nas páginas 47, 49 e 91.
MARCOS, M. S. A.; SORIANO, M.; SALOMA, C. Classification of coral reef imagesfrom underwater video using neural networks. Optics express, Optical Society of America,v. 13, n. 22, p. 8766–8771, 2005. Citado na página 67.
MARQUARDT, D. W. An algorithm for least-squares estimation of nonlinearparameters. Journal of the Society for Industrial & Applied Mathematics, SIAM, v. 11,n. 2, p. 431–441, 1963. Citado na página 52.
MIKOLAJCZYK, K.; SCHMID, C. Scale & affine invariant interest point detectors.
International journal of computer vision, Springer, v. 60, n. 1, p. 63–86, 2004. Citado 2vezes nas páginas 32 e 71.
NARASIMHAN, S. G. et al. Acquiring scattering properties of participating media bydilution. ACM Transactions on Graphics (TOG), ACM, v. 25, n. 3, p. 1003–1012, 2006.
Citado na página 73.
NEMETH, R. S. et al. Characterization of deep water reef communities within themarine conservation district, st. thomas, us virgin islands. 2008. Citado na página 23.
NICOSEVICI, T. et al. Efficient three-dimensional scene modeling and mosaicing.
Journal of Field Robotics, v. 26, 2009. Citado 2 vezes nas páginas 24 e 27.
101ReferênciasOMAR, A. F. B.; MATJAFRI, M. Z. B. Turbidimeter design and analysis: a review onoptical fiber sensors for the measurement of water turbidity. Sensors, Molecular DiversityPreservation International, v. 9, n. 10, p. 8311–8335, 2009. Citado na página 65.
PADMAVATHI, G.; MUTHUKUMAR, M.; THAKUR, S. K. Kernel principal componentanalysis feature detection and classification for underwater images. In: IEEE. Imageand Signal Processing (CISP), 2010 3rd International Congress on. [S.l.], 2010. v. 2, p.
983–988. Citado 2 vezes nas páginas 24 e 27.
PERONA, P.; MALIK, J. Scale-space and edge detection using anisotropic diffusion.
Pattern Analysis and Machine Intelligence, IEEE Transactions on, IEEE, v. 12, n. 7, p.
629–639, 1990. Citado na página 36.
PETROU, M.; GARCÍA-SEVILLA, P. Image processing - dealing with texture. [S.l.]:
Wiley, 2006. ISBN 978-0-470-02628-1. Citado na página 69.
PIZARRO, O.; EUSTICE, R.; SINGH, H. Large area 3d reconstructions from underwatersurveys. In: OCEANS ’04. MTTS/IEEE TECHNO-OCEAN ’04. [S.l.: s.n.], 2004. v. 2,
p. 678–687 Vol.2. Citado 2 vezes nas páginas 66 e 67.
PIZARRO, O. et al. Towards image-based marine habitat classification. In: IEEE.
OCEANS 2008. [S.l.], 2008. p. 1–7. Citado na página 66.
PLATT, J. C. Probabilistic outputs for support vector machines and comparisons toregularized likelihood methods. In: CITESEER. Advances in large margin classifiers.
[S.l.], 1999. Citado na página 52.
PORTER, R.; CANAGARAJAH, N. Robust rotation-invariant texture classification:wavelet, gabor filter and gmrf based schemes. In: IET. Vision, Image and SignalProcessing, IEE Proceedings-. [S.l.], 1997. v. 144, n. 3, p. 180–188. Citado na página 69.
PURKIS, S.; VLASWINKEL, B.; GRACIAS, N. Vertical-to-lateral transitions amongcretaceous carbonate facies: A means to 3-d framework construction via markov analysis.
Journal of Sedimentary Research, SEPM, v. 82, n. 4, p. 232–243, 2012. Citado napágina 49.
RABINOVICH, A. et al. Objects in context. In: Proceedings of the InternationalConference on Computer Vision (ICCV). [S.l.: s.n.], 2007. Citado na página 40.
SCHETTINI, R.; CORCHS, S. Underwater image processing: state of the art ofrestoration and image enhancement methods. EURASIP Journal on Advances in SignalProcessing, Hindawi Publishing Corp., v. 2010, p. 14, 2010. Citado na página 67.
SCHMID, C.; MOHR, R.; BAUCKHAGE, C. Evaluation of interest point detectors.
International Journal of computer vision, Springer, v. 37, 2000. Citado 2 vezes naspáginas 30 e 77.
SCHMIDT, M. W. et al. Optimizing costly functions with simple constraints: Alimited-memory projected quasi-newton algorithm. In: International Conference onArtificial Intelligence and Statistics. [S.l.: s.n.], 2009. p. None. Citado na página 90.
102ReferênciasSHIHAVUDDIN, A. et al. Image-based coral reef classification and thematic mapping.
Remote Sensing, v. 5, n. 4, p. 1809–1841, 2013. ISSN 2072-4292. Disponível em:<http://www.mdpi.com/2072-4292/5/4/1809>. Citado 7 vezes nas páginas 25, 66, 67,68, 69, 70 e 89.
SHOTTON, J. et al. Textonboost for image understanding: Multi-class object recognitionand segmentation by jointly modeling texture, layout, and context. International Journalof Computer Vision, Springer, v. 81, n. 1, p. 2–23, 2009. Citado 2 vezes nas páginas 44e 45.
SIVIC, J.; ZISSERMAN, A. Video google: Efficient visual search of videos. In: TowardCategory-Level Object Recognition. [S.l.]: Springer, 2006. p. 127–144. Citado na página45.
SOJKA, E. A new approach to detecting the corners in digital images. In: IEEE. ImageProcessing, 2003. ICIP 2003. Proceedings. 2003 International Conference on. [S.l.], 2003.
v. 3, p. III–445. Citado 2 vezes nas páginas 11 e 31.
STOKES, M. D.; DEANE, G. B. Automated processing of coral reef benthic images.
Limnol. Oceanogr.: Methods, v. 7, n. 157, p. 157–168, 2009. Citado 2 vezes nas páginas67 e 70.
SUTTON, C.; MCCALLUM, A. An introduction to conditional random fields forrelational learning. Introduction to statistical relational learning, MIT press, p. 93–128,2006. Citado 2 vezes nas páginas 42 e 43.
TORRALBA, A. Contextual priming for object detection. International journal ofcomputer vision, Springer, v. 53, n. 2, p. 169–191, 2003. Citado na página 40.
TORRALBA, A.; MURPHY, K. P.; FREEMAN, W. T. Contextual models for objectdetection using boosted random fields. In: Advances in neural information processingsystems. [S.l.: s.n.], 2004. p. 1401–1408. Citado 2 vezes nas páginas 40 e 41.
TREIBITZ, T.; SCHECHNER, Y. Y. Instant 3descatter. In: Proceedings of the 2006IEEE Computer Society Conference on Computer Vision and Pattern Recognition -Volume 2. [S.l.: s.n.], 2006. (CVPR ’06), p. 1861–1868. Citado 2 vezes nas páginas 64e 73.
TUYTELAARS, T.; MIKOLAJCZYK, K. Local invariant feature detectors: a survey.
Foundations and Trends R○ in Computer Graphics and Vision, Now Publishers Inc., v. 3,
n. 3, p. 177–280, 2008. Citado 4 vezes nas páginas 27, 28, 30 e 77.
WANG, Z. et al. Image quality assessment: From error visibility to structural similarity.
Image Processing, IEEE Transactions on, IEEE, v. 13, n. 4, p. 600–612, 2004. Citado 2vezes nas páginas 76 e 78.
WEICKERT, J.; ROMENY, B. T. H.; VIERGEVER, M. A. Efficient and reliableschemes for nonlinear diffusion filtering. Image Processing, IEEE Transactions on, IEEE,v. 7, n. 3, p. 398–410, 1998. Citado na página 36.
WEIJER, J. V. D.; SCHMID, C. Coloring local feature extraction. In: ComputerVision–ECCV 2006. [S.l.]: Springer, 2006. p. 334–348. Citado na página 69.
