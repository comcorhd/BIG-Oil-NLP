{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ~/; git clone https://github.com/alvelvis/ACDC-UD; git clone https://github.com/comcorhd/BIG-Oil-NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/elvis/ACDC-UD')\n",
    "import estrutura_ud\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converter 400 TEM para utf-8\n",
    "Necessário ter a pasta do Petrolês em utf-16 (no repositório a conversão para utf-8 já foi realizada)\n",
    "\n",
    "Etapa necessária, caso contrário o UDPipe terá problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/Petrolês/processado-utf8\n",
    "! mkdir ~/Petrolês/gambiarra-utf8\n",
    "for file in os.listdir(\"/home/elvis/Petrolês/TXT_Teses e Monografias\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(f\"/home/elvis/Petrolês/TXT_Teses e Monografias/{file}\", encoding=\"utf-16\") as f:\n",
    "            with open(f\"/home/elvis/Petrolês/processado-utf8/{file}\", 'w', encoding=\"utf-8\") as r:\n",
    "                r.write(f.read())\n",
    "                \n",
    "for file in os.listdir(\"/home/elvis/Petrolês/Corpus Gambiarra\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(f\"/home/elvis/Petrolês/Corpus Gambiarra/{file}\", encoding=\"utf-16\") as f:\n",
    "            with open(f\"/home/elvis/Petrolês/gambiarra-utf8/{file}\", 'w', encoding=\"utf-8\") as r:\n",
    "                r.write(f.read())             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anotar 400TEM\n",
    "--> DEMORADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UDPipe model: done.\n"
     ]
    }
   ],
   "source": [
    "! ~/BIG-Oil-NLP/udpipe/udpipe-1.2.0 --tokenize --tag --parse ~/BIG-Oil-NLP/udpipe/bosqueud_2.5_workbench.udpipe ~/Petrolês/processado-utf8/*.txt > ~/Petrolês/bem_processado.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UDPipe model: done.\n"
     ]
    }
   ],
   "source": [
    "! ~/BIG-Oil-NLP/udpipe/udpipe-1.2.0 --tokenize --tag --parse ~/BIG-Oil-NLP/udpipe/bosqueud_2.5_workbench.udpipe ~/Petrolês/gambiarra-utf8/*.txt > ~/Petrolês/gambiarra.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionar sent_id às frases das 400TEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 ~/BIG-Oil-NLP/scripts/fix_sent_id.py ~/Petrolês/bem_processado.conllu > ~/Petrolês/bem_processado_sentid.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 ~/BIG-Oil-NLP/scripts/fix_sent_id.py ~/Petrolês/gambiarra.conllu > ~/Petrolês/gambiarra_sentid.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrigir fórmulas nas 400TEM\n",
    "(ou só gambiarra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019922\n",
      "1019916\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/elvis/Petrolês/gambiarra_sentid.conllu\") as f:\n",
    "    gambiarra = f.read()\n",
    "\n",
    "gambiarra_split = gambiarra.split(\"\\n\\n\")\n",
    "print(len(gambiarra_split))\n",
    "gambiarra = [x for x in gambiarra_split if not \"\\t\\n\" in x and not re.search(r'\\n[^\\d#]', x)]\n",
    "print(len(gambiarra))\n",
    "\n",
    "with open(\"/home/elvis/Petrolês/gambiarra_sentid_formula.conllu\", 'w') as f:\n",
    "    f.write(\"\\n\\n\".join(gambiarra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abrir 400TEM\n",
    "--> DEMORADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gambiarra = estrutura_ud.Corpus()\n",
    "gambiarra.load(\"/home/elvis/Petrolês/gambiarra_sentid_formula.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bemprocessado = estrutura_ud.Corpus()\n",
    "bemprocessado.load(\"/home/elvis/Petrolês/bem_processado_sentid.conllu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de documentos em bemprocessado e gambiarra \n",
    "(estranho -- número diferente. Anotar novamente.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos em bemprocessado (403) que faltam em gambiarra (415):\n",
      "['343-20150401-TESEMSC_0']\n",
      "\n",
      "Documentos em gambiarra que faltam em bemprocessado:\n",
      "['1-20140905-TESEDSC_0', '140-20141209-TESEMSC_0', '18-20140905-TESEDSC_0', '255-20150506-MONOGRAFIA_0', '273-20140930-MONOGRAFIA_0', '29-20150519-TESEDSC_0', '37-20150226-TESEDSC_0', '43-20150519-MONOGRAFIA_0', '5-20140905-TESEDSC_0', '78-20140905-TESEDSC_0', '79-20140905-TESEDSC_0', '89-20141112-TESEDSC_0', '9-20140905-TESEDSC_0']\n"
     ]
    }
   ],
   "source": [
    "lista_documentos_bemprocessado = []\n",
    "[lista_documentos_bemprocessado.append(x.rsplit(\"-\", 1)[0]) for x in bemprocessado.sentences if x.rsplit(\"-\", 1)[0] not in lista_documentos_bemprocessado]\n",
    "\n",
    "lista_documentos_gambiarra = []\n",
    "[lista_documentos_gambiarra.append(x.rsplit(\"-\", 1)[0]) for x in gambiarra.sentences if x.rsplit(\"-\", 1)[0] not in lista_documentos_gambiarra]\n",
    "\n",
    "fora_de_gambiarra = [x for x in lista_documentos_bemprocessado if x not in lista_documentos_gambiarra]\n",
    "fora_de_bemprocessado = [x for x in lista_documentos_gambiarra if x not in lista_documentos_bemprocessado]\n",
    "print(f\"Documentos em bemprocessado ({len(lista_documentos_bemprocessado)}) que faltam em gambiarra ({len(lista_documentos_gambiarra)}):\")\n",
    "print(fora_de_gambiarra)\n",
    "print(\"\\nDocumentos em gambiarra que faltam em bemprocessado:\")\n",
    "print(fora_de_bemprocessado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização dos documentos em ambos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos proibidos:\n",
      "[]\n",
      "Documentos em bemprocessado (402) que faltam em gambiarra (402):\n",
      "[]\n",
      "\n",
      "Documentos em gambiarra que faltam em bemprocessado:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "lista_documentos_proibidos = fora_de_gambiarra + fora_de_bemprocessado\n",
    "print(\"Documentos proibidos:\")\n",
    "print(lista_documentos_proibidos)\n",
    "gambiarra.sentences = {x: y for x, y in gambiarra.sentences.items() if x.rsplit(\"-\", 1)[0] not in lista_documentos_proibidos}\n",
    "bemprocessado.sentences = {x: y for x, y in bemprocessado.sentences.items() if x.rsplit(\"-\", 1)[0] not in lista_documentos_proibidos}\n",
    "\n",
    "lista_documentos_bemprocessado = []\n",
    "[lista_documentos_bemprocessado.append(x.rsplit(\"-\", 1)[0]) for x in bemprocessado.sentences if x.rsplit(\"-\", 1)[0] not in lista_documentos_bemprocessado]\n",
    "lista_documentos_gambiarra = []\n",
    "[lista_documentos_gambiarra.append(x.rsplit(\"-\", 1)[0]) for x in gambiarra.sentences if x.rsplit(\"-\", 1)[0] not in lista_documentos_gambiarra]\n",
    "fora_de_gambiarra = [x for x in lista_documentos_bemprocessado if x not in lista_documentos_gambiarra]\n",
    "fora_de_bemprocessado = [x for x in lista_documentos_gambiarra if x not in lista_documentos_bemprocessado]\n",
    "print(f\"\\nDocumentos em bemprocessado ({len(lista_documentos_bemprocessado)}) que faltam em gambiarra ({len(lista_documentos_gambiarra)}):\")\n",
    "print(fora_de_gambiarra)\n",
    "print(\"\\nDocumentos em gambiarra que faltam em bemprocessado:\")\n",
    "print(fora_de_bemprocessado)\n",
    "\n",
    "gambiarra.save('/home/elvis/Petrolês/gambiarra_sentid_formula_normalizado.conllu')\n",
    "bemprocessado.save('/home/elvis/Petrolês/bemprocessado_sentid_normalizado.conllu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anotar com jPTDP\n",
    "--> DEMORADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo -S apt install python-pip --yes < ~/sudopass\n",
    "! pip install cython numpy\n",
    "! pip install dynet==2.0.3\n",
    "! cd ~/BIG-Oil-NLP/jPTDP; wget https://www.dropbox.com/s/fn0r48xhn67inpt/outputs.tar.gz; tar -xvzf outputs.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/home/elvis/BIG-Oil-NLP/jPTDP/src/jPTDP.py\", line 3, in <module>\r\n",
      "    import pickle, utils, learner, os, os.path, time\r\n",
      "  File \"/mnt/c/Users/elvis/BIG-Oil-NLP/jPTDP/src/learner.py\", line 2, in <module>\r\n",
      "    from dynet import *\r\n",
      "  File \"/home/elvis/.local/lib/python2.7/site-packages/dynet.py\", line 31, in <module>\r\n",
      "    init()\r\n",
      "  File \"_dynet.pyx\", line 235, in _dynet.init\r\n",
      "  File \"_dynet.pyx\", line 127, in _dynet.DynetParams.from_args\r\n",
      "UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 18: ordinal not in range(128)\r\n"
     ]
    }
   ],
   "source": [
    "! python ~/BIG-Oil-NLP/jPTDP/src/jPTDP.py --predict --model ~/BIG-Oil-NLP/jPTDP/outputs/jPTDP_pt_ud.model --params ~/BIG-Oil-NLP/jPTDP/outputs/jPTDP_pt_ud.params --test ~/Petrolês/gambiarra_sentid_formula_normalizado.conllu --outdir ~/Petrolês/ --output ~/Petrolês/gambiarra_jptdp.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/elvis/BIG-Oil-NLP/jPTDP/src/jPTDP.py\", line 3, in <module>\n",
      "    import pickle, utils, learner, os, os.path, time\n",
      "  File \"/mnt/c/Users/elvis/BIG-Oil-NLP/jPTDP/src/learner.py\", line 2, in <module>\n",
      "    from dynet import *\n",
      "  File \"/home/elvis/.local/lib/python2.7/site-packages/dynet.py\", line 31, in <module>\n",
      "    init()\n",
      "  File \"_dynet.pyx\", line 235, in _dynet.init\n",
      "  File \"_dynet.pyx\", line 127, in _dynet.DynetParams.from_args\n",
      "UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 18: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "! python ~/BIG-Oil-NLP/jPTDP/src/jPTDP.py --predict --model ~/BIG-Oil-NLP/jPTDP/outputs/jPTDP_pt_ud.model --params ~/BIG-Oil-NLP/jPTDP/outputs/jPTDP_pt_ud.params --test ~/Petrolês/bemprocessado_sentid_normalizado.conllu --outdir ~/Petrolês/ --output ~/Petrolês/bemprocessado_jptdp.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abrir 400TEM\n",
    "--> DEMORADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gambiarra = estrutura_ud.Corpus()\n",
    "gambiarra.load(\"/home/elvis/Petrolês/gambiarra_jptdp.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bemprocessado = estrutura_ud.Corpus()\n",
    "bemprocessado.load(\"/home/elvis/Petrolês/bemprocessado_jptdp.conllu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volte três casas: teste e normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição de DP e POS (ajustar onde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_pos_dp_gambiarra = {}\n",
    "dic_pos_dp_bemprocessado = {}\n",
    "for sent, sentence in gambiarra.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if not '-' in token.id:\n",
    "            dic_pos_dp_gambiarra[token.upos] = 1 if not token.upos in dic_pos_dp_gambiarra else dic_pos_dp_gambiarra[token.upos] + 1\n",
    "            dic_pos_dp_gambiarra[token.deprel] = 1 if not token.deprel in dic_pos_dp_gambiarra else dic_pos_dp_gambiarra[token.deprel] + 1\n",
    "for sent, sentence in bemprocessado.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if not '-' in token.id:\n",
    "            dic_pos_dp_bemprocessado[token.upos] = 1 if not token.upos in dic_pos_dp_bemprocessado else dic_pos_dp_bemprocessado[token.upos] + 1\n",
    "            dic_pos_dp_bemprocessado[token.deprel] = 1 if not token.deprel in dic_pos_dp_bemprocessado else dic_pos_dp_bemprocessado[token.deprel] + 1\n",
    "\n",
    "print(f\"Classes em gambiarra ({len(dic_pos_dp_gambiarra)})\")\n",
    "print(sorted(dic_pos_dp_gambiarra))\n",
    "print(f\"\\nClasses em bemprocessado ({len(dic_pos_dp_bemprocessado)})\")\n",
    "print(sorted(dic_pos_dp_bemprocessado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Número de sentenças e tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = []\n",
    "[documentos.append(x.rsplit(\"-\", 1)[0]) for x in bemprocessado.sentences if x.rsplit(\"-\", 1)[0] not in documentos]\n",
    "print(f\"{len(documentos)} documentos foram encontrados em FINAL\")\n",
    "print(\"\\n\".join([\"* \" + x for x in documentos]))\n",
    "\n",
    "# a contagem de tokens não leva em consideração aqueles que têm \"-\" no seu id (indicação de contração (a contração em si conta, é claro))\n",
    "print(\"\\n|Versão|Sentenças|Tokens|\")\n",
    "print(\"|---|---|---|\")\n",
    "tokens_gambiarra = len([x for sentence in gambiarra.sentences.values() for x in sentence.tokens if not '-' in x.id])\n",
    "tokens_final = len([x for sentence in bemprocessado.sentences.values() for x in sentence.tokens if not '-' in x.id])\n",
    "print(\"|GAMBIARRA|{}|{}|\".format(len(gambiarra.sentences), tokens_gambiarra))\n",
    "print(\"|FINAL|{}|{}|\".format(len(bemprocessado.sentences), tokens_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição das categorias bruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDistribuição das categorias bruta\")\n",
    "print(\"| {:25} | {:25} | {:25} |\".format('Anotação', 'GAMBIARRA', 'FINAL'))\n",
    "print(\"| {:25} | {:25} | {:25} |\".format(\"---\", \"---\", \"---\"))\n",
    "lista_pos_dp = [x for x in dic_pos_dp_gambiarra]\n",
    "[lista_pos_dp.append(x) for x in dic_pos_dp_bemprocessado if not x in lista_pos_dp]\n",
    "for pos_dp in sorted(lista_pos_dp):\n",
    "    print(\"| {:25} | {:25} | {:25} |\".format(pos_dp, dic_pos_dp_gambiarra[pos_dp] if pos_dp in dic_pos_dp_gambiarra else 0, dic_pos_dp_bemprocessado[pos_dp] if pos_dp in dic_pos_dp_bemprocessado else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição das categorias relativa ao total de tokens da versão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDistribuição das categorias relativa ao total de tokens na versão\")\n",
    "print(\"| {:25} | {:25} | {:25} |\".format('Anotação', 'GAMBIARRA', 'FINAL'))\n",
    "print(\"| {:25} | {:25} | {:25} |\".format(\"---\", \"---\", \"---\"))\n",
    "lista_pos_dp = [x for x in dic_pos_dp_gambiarra]\n",
    "[lista_pos_dp.append(x) for x in dic_pos_dp_bemprocessado if not x in lista_pos_dp]\n",
    "for pos_dp in sorted(lista_pos_dp):\n",
    "    print(\"| {:25} | {:25} | {:25} |\".format(pos_dp, str((dic_pos_dp_gambiarra[pos_dp]/tokens_gambiarra)*100)+'%' if pos_dp in dic_pos_dp_gambiarra else 0, str((dic_pos_dp_bemprocessado[pos_dp]/tokens_final)*100)+'%' if pos_dp in dic_pos_dp_bemprocessado else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização dos lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_lemas_gambiarra = [lista_lemas_gambiarra.append(x.lemma) for y in gambiarra.sentences.values() for x in y.tokens if not '-' in x.id]\n",
    "lista_lemas_bemprocessado = [lista_lemas_bemprocessado.append(x.lemma) for y in bemprocessado.sentences.values() for x in y.tokens if not '-' in x.id]\n",
    "\n",
    "print(\"|{:25}|{:25}|{:25}|\".format('', 'GAMBIARRA', 'FINAL'))\n",
    "print(\"|{:25}|{:25}|{:25}|\".format(\"---\", \"---\", \"---\"))\n",
    "print(\"|{:25}|{:25}|{:25}|\".format('Lemas diferentes', len(list(dict.fromkeys(lista_lemas_gambiarra))), len(list(dict.fromkeys(lista_lemas_bemprocessado)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDistribuição dos lemas em GAMBIARRA\")\n",
    "print(\"|{:25}|{:25}|{:25}|\".format('LEMA', 'OCORRÊNCIA', 'REPRESENTATIVIDADE'))\n",
    "print(\"|{:25}|{:25}|{:25}|\".format('', 'GAMBIARRA', 'FINAL'))\n",
    "[\n",
    "    print(\"|{:25}|{:25}|{:25}|\".format(\n",
    "            x, \n",
    "            lista_lemas_gambiarra.count(x), \n",
    "            str((lista_lemas_gambiarra.count(x)/len(lista_lemas_gambiarra))*100)+'%',\n",
    "        ))\n",
    "        for x in sorted(lista_lemas_gambiarra, reverse=True, key=lambda y: lista_lemas_gabiarra.count(y))\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
